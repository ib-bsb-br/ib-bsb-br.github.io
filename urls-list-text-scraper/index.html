<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- Basic Metadata -->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Title with fallback for home or page title -->
    <title>
      
        URLs list text scraper - infoBAG
      
    </title>
    <meta name="title" content="URLs list text scraper - infoBAG" />
    
    <!-- Description with fallback and truncation -->
    <meta name="description" content="">
    
    <!-- Open Graph Tags -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://ib.bsb.br/urls-list-text-scraper/">
    <meta property="og:title" content="URLs list text scraper - infoBAG">
    <meta property="og:description" content="">
    <meta property="og:image" content="/favicon.ico">
    
    <!-- Twitter Cards -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:url" content="https://ib.bsb.br/urls-list-text-scraper/">
    <meta name="twitter:title" content="URLs list text scraper - infoBAG">
    <meta name="twitter:description" content="">
    <meta name="twitter:image" content="/favicon.ico">
    
    <!-- Canonical URL -->
    <link rel="canonical" href="https://ib.bsb.br/urls-list-text-scraper/">
    
    <!-- RSS Feed -->
    <link rel="alternate" type="application/rss+xml" title="infoBAG" href="https://ib.bsb.br/rss.xml">
    
    <!-- Keywords / Tags -->
    
      <meta name="keywords" content="scripts&gt;powershell,,software&gt;windows">
      
        <meta property="article:tag" content="scripts&gt;powershell,">
      
        <meta property="article:tag" content="software&gt;windows">
      
    
    
    <!-- Favicons -->
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    
    
    <!-- Main Stylesheet -->
    <link rel="stylesheet" href="/style.css">
    
    <!-- Additional CSS (compiled SCSS and inline styles) -->
    <style>
      /* SCSS compiled styles for post navigation */
      .post-navigation-combined {
        clear: both;
        width: 100%;
        display: flex;
        justify-content: space-between;
      }
      .nav-arrow {
        z-index: 1;
        position: fixed;
        font-size: 1.5rem;
      }
      .nav-arrow.chronological {
        top: 40vh;
      }
      .nav-arrow.tags {
        top: 60vh;
      }
      .nav-arrow.prev {
        left: 0;
      }
      .nav-arrow.next {
        right: 0;
      }
      .nav-arrow a {
        line-height: inherit;
        background-color: transparent;
        border-radius: 50%;
        padding: 0;
        transition: all 0.3s ease;
      }
      .nav-arrow a:hover {
        background-color: rgba(0, 0, 0, 0.1);
      }
      .nav-arrow a:before {
        content: ' ';
        position: absolute;
        top: 0;
        bottom: 0;
        left: 0;
        right: 0;
        cursor: pointer;
        background-color: transparent;
      }
      @media print {
        .post-navigation-combined .nav-arrow {
          display: none;
        }
        .cluster rect {
          fill: #ffffff;
          stroke: #000000;
        }
        .cluster text,
        .node text {
          fill: #000000;
        }
        .edgeLabel {
          background-color: #ffffff;
          border: 1px solid #000000;
          color: #000000;
        }
        .edgePath .path,
        .edgePath .arrowheadPath,
        .edgePath .arrow-tagsheadPath {
          stroke: #000000;
        }
        .node rect,
        .node circle,
        .node ellipse,
        .node polygon {
          fill: #ffffff;
          stroke: #000000;
          transition: fill 0.3s ease;
        }
        .node rect:hover,
        .node circle:hover,
        .node ellipse:hover,
        .node polygon:hover {
          fill: #cccccc;
        }
      }
      /* Footer inline styles */
      .back-to-top-link {
        display: inline-block;
        width: 32px;
        height: 32px;
        background: url("/assets/Rope_(Old).gif") center center no-repeat;
        background-size: contain;
        text-decoration: none;
        vertical-align: middle;
      }
      .sr-only {
        position: absolute;
        width: 1px;
        height: 1px;
        padding: 0;
        margin: -1px;
        overflow: hidden;
        clip: rect(0, 0, 0, 0);
        white-space: nowrap;
        border: 0;
      }
    </style>
  </head>
  <body class="post-content-body">
    <header class="header-container">
      <nav aria-label="Main navigation" class="header-content">
        <a href="/" aria-label="Home">
          <img src="/favicon.ico" alt="Home" class="favicon search-link" width="45" height="45" loading="lazy">
        </a>
        <a href="/tags" aria-label="Tags">
          <img src="/assets/Label.gif" alt="Tags" class="favicon search-link" width="45" height="45" loading="lazy">
        </a>
        <a href="/archive" aria-label="Archive">
          <img src="/assets/Loose_Stone_Pile.gif" alt="Archive" class="favicon search-link" width="45" height="45" loading="lazy">
        </a>
        <a href="/events" aria-label="Events">
          <img src="/assets/Paralyse_Rune.gif" alt="Events" class="favicon search-link" width="45" height="45" loading="lazy">
        </a>
        <a href="/archive-created" aria-label="Archive created">
          <img src="/assets/Hole_(Rock).gif" alt="Archive created" class="favicon search-link" width="32" height="32" loading="lazy">
        </a>
        <a href="/rot64" aria-label="rot">
          <img src="/assets/rot.gif" alt="rot" class="favicon search-link" width="32" height="32" loading="lazy">
        </a>
      </nav>
      <h5 class="post-title">
        <a href="#bottom-of-page" aria-label="Go to bottom">
          URLs list text scraper
        </a>
      </h5>
      <div class="post-meta">
        <time datetime="2024-09-12T00:00:00+00:00" class="post-date">
          12 Sep 2024
        </time>
        
          <span class="post-updated">
            ↣
            <time datetime="2024-12-29T18:40:23+00:00">
              29 Dec 2024
            </time>
          </span>
        
        
          <p class="post-slug">
            Slug: <a href="https://ib.bsb.br/urls-list-text-scraper" class="tag">urls-list-text-scraper</a>
          </p>
        
        
          <p class="post-tags">
            Tags:
            
              <a href="https://ib.bsb.br/tags/#scripts-powershell" class="tag">scripts>powershell,</a>
            
              <a href="https://ib.bsb.br/tags/#software-windows" class="tag">software>windows</a>
            
          </p>
        
      </div>
      <div class="post-actions">
        <div class="page-stats mt-3" role="status" aria-label="Page statistics">
          <span class="badge bg-primary">
            12631 characters
          </span>
          <span class="separator mx-2" aria-hidden="true">•</span>
          <span class="badge bg-primary">
            893 words
          </span>
        </div>
        <div class="action-buttons d-flex flex-wrap gap-2">
          
            
              <form action="https://github.com/ib-bsb-br/ib-bsb-br.github.io/edit/main/_posts/2024-09-12-urls-list-text-scraper.md"
                    method="GET"
                    target="_blank"
                    rel="noopener noreferrer"
                    class="d-inline-block">
                <button type="submit" class="btn btn-danger" aria-label="Edit page content">
                  <span class="button-text">Improve this page?</span>
                  <span class="info-text">aberto.</span>
                </button>
              </form>
            
            <form action="https://github.com/ib-bsb-br/ib-bsb-br.github.io/commits/main/_posts/2024-09-12-urls-list-text-scraper.md"
                  method="GET"
                  target="_blank"
                  rel="noopener noreferrer"
                  class="d-inline-block">
              <button type="submit" class="btn btn-danger" aria-label="View page revision history">
                View revision history
              </button>
            </form>
          
        </div>
      </div>
    </header>
    <main class="content">
      <article class="post-wrapper">
        <div class="post-content-body">
          

          <p>Reference: <code class="language-plaintext highlighter-rouge">https://github.com/kitsuyui/scraper</code></p>

<p>To download the text content of multiple URLs from a list on Windows 11, we’ll create a PowerShell script that’s more robust and flexible than the previously suggested batch file. This approach leverages PowerShell’s strengths and provides better error handling and output formatting.</p>

<ol>
  <li>First, ensure you have <code class="language-plaintext highlighter-rouge">scraper.exe</code> set up:
    <ul>
      <li>Download the latest Windows executable from https://github.com/kitsuyui/scraper/releases/latest</li>
      <li>Rename it to <code class="language-plaintext highlighter-rouge">scraper.exe</code> and place it in a directory that’s in your system PATH</li>
    </ul>
  </li>
  <li>Create a file named <code class="language-plaintext highlighter-rouge">scraper-config.json</code> with the following content:
    <div class="language-json highlighter-rouge"><div class="highlight"><section><code><span class="p">[</span><span class="w">
  </span><span class="p">{</span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"xpath"</span><span class="p">,</span><span class="w"> </span><span class="nl">"label"</span><span class="p">:</span><span class="w"> </span><span class="s2">"BodyText"</span><span class="p">,</span><span class="w"> </span><span class="nl">"query"</span><span class="p">:</span><span class="w"> </span><span class="s2">"//body//text()"</span><span class="p">}</span><span class="w">
</span><span class="p">]</span><span class="w">
</span></code></section></div>    </div>
  </li>
  <li>Create a text file named <code class="language-plaintext highlighter-rouge">urls.txt</code> with one URL per line:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><section><code>https://example.com
https://another-example.com
https://third-example.com
</code></section></div>    </div>
  </li>
  <li>
    <p>Create a new file named <code class="language-plaintext highlighter-rouge">Scrape-Urls.ps1</code> with the following PowerShell script:</p>

    <div class="language-powershell highlighter-rouge"><div class="highlight"><section><code><span class="c"># Scrape-Urls.ps1</span><span class="w">
</span><span class="kr">param</span><span class="p">(</span><span class="w">
    </span><span class="p">[</span><span class="n">string</span><span class="p">]</span><span class="nv">$UrlFile</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"urls.txt"</span><span class="p">,</span><span class="w">
    </span><span class="p">[</span><span class="n">string</span><span class="p">]</span><span class="nv">$ConfigFile</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"scraper-config.json"</span><span class="p">,</span><span class="w">
    </span><span class="p">[</span><span class="n">string</span><span class="p">]</span><span class="nv">$OutputDir</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"scraped_content"</span><span class="w">
</span><span class="p">)</span><span class="w">

</span><span class="c"># Ensure the output directory exists</span><span class="w">
</span><span class="n">New-Item</span><span class="w"> </span><span class="nt">-ItemType</span><span class="w"> </span><span class="nx">Directory</span><span class="w"> </span><span class="nt">-Force</span><span class="w"> </span><span class="nt">-Path</span><span class="w"> </span><span class="nv">$OutputDir</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">Out-Null</span><span class="w">

</span><span class="c"># Read URLs from file</span><span class="w">
</span><span class="nv">$urls</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Get-Content</span><span class="w"> </span><span class="nv">$UrlFile</span><span class="w">

</span><span class="kr">foreach</span><span class="w"> </span><span class="p">(</span><span class="nv">$url</span><span class="w"> </span><span class="kr">in</span><span class="w"> </span><span class="nv">$urls</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="kr">try</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="n">Write-Host</span><span class="w"> </span><span class="s2">"Processing: </span><span class="nv">$url</span><span class="s2">"</span><span class="w">
           
        </span><span class="c"># Generate a safe filename</span><span class="w">
        </span><span class="nv">$filename</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="nv">$url</span><span class="w"> </span><span class="o">-replace</span><span class="w"> </span><span class="s2">"https?://"</span><span class="p">,</span><span class="w"> </span><span class="s2">""</span><span class="w"> </span><span class="o">-replace</span><span class="w"> </span><span class="s2">"[^a-zA-Z0-9]+"</span><span class="p">,</span><span class="w"> </span><span class="s2">"_"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s2">".txt"</span><span class="w">
        </span><span class="nv">$outputPath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Join-Path</span><span class="w"> </span><span class="nv">$OutputDir</span><span class="w"> </span><span class="nv">$filename</span><span class="w">

        </span><span class="c"># Download and scrape content</span><span class="w">
        </span><span class="nv">$content</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Invoke-WebRequest</span><span class="w"> </span><span class="nt">-Uri</span><span class="w"> </span><span class="nv">$url</span><span class="w"> </span><span class="nt">-UseBasicParsing</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">Select-Object</span><span class="w"> </span><span class="nt">-ExpandProperty</span><span class="w"> </span><span class="nx">Content</span><span class="w">
        </span><span class="nv">$scrapedContent</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">$content</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">scraper</span><span class="w"> </span><span class="nt">-c</span><span class="w"> </span><span class="nv">$ConfigFile</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">ConvertFrom-Json</span><span class="w">

        </span><span class="c"># Extract text from JSON and save</span><span class="w">
        </span><span class="nv">$bodyText</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">$scrapedContent</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">Where-Object</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="bp">$_</span><span class="o">.</span><span class="nf">label</span><span class="w"> </span><span class="o">-eq</span><span class="w"> </span><span class="s2">"BodyText"</span><span class="w"> </span><span class="p">}</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">Select-Object</span><span class="w"> </span><span class="nt">-ExpandProperty</span><span class="w"> </span><span class="nx">results</span><span class="w">
        </span><span class="nv">$bodyText</span><span class="w"> </span><span class="o">-join</span><span class="w"> </span><span class="s2">" "</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">Out-File</span><span class="w"> </span><span class="nt">-FilePath</span><span class="w"> </span><span class="nv">$outputPath</span><span class="w">

        </span><span class="n">Write-Host</span><span class="w"> </span><span class="s2">"Saved to: </span><span class="nv">$outputPath</span><span class="s2">"</span><span class="w">
    </span><span class="p">}</span><span class="w">
    </span><span class="kr">catch</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="n">Write-Host</span><span class="w"> </span><span class="s2">"Error processing </span><span class="nv">$url</span><span class="s2"> : </span><span class="bp">$_</span><span class="s2">"</span><span class="w"> </span><span class="nt">-ForegroundColor</span><span class="w"> </span><span class="nx">Red</span><span class="w">
    </span><span class="p">}</span><span class="w">
    </span><span class="n">Write-Host</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="n">Write-Host</span><span class="w"> </span><span class="s2">"All URLs processed."</span><span class="w"> </span><span class="nt">-ForegroundColor</span><span class="w"> </span><span class="nx">Green</span><span class="w">
</span></code></section></div>    </div>
  </li>
  <li>
    <p>Open PowerShell and navigate to the directory containing your script and files.</p>
  </li>
  <li>Run the script:
    <div class="language-powershell highlighter-rouge"><div class="highlight"><section><code><span class="o">.</span><span class="n">\Scrape-Urls.ps1</span><span class="w">
</span></code></section></div>    </div>
  </li>
</ol>

<p>This improved solution offers several advantages:</p>

<ul>
  <li>It uses PowerShell, which is more powerful and flexible than batch scripts on Windows.</li>
  <li>It includes error handling to manage issues with individual URLs without stopping the entire process.</li>
  <li>It creates a separate output directory for scraped content, keeping things organized.</li>
  <li>It generates safe filenames based on the URLs, avoiding potential naming conflicts or invalid characters.</li>
  <li>It extracts the actual text content from the JSON output, providing clean text files.</li>
  <li>It’s more customizable, allowing you to specify different input files, config files, or output directories.</li>
</ul>

<p>Additional notes:</p>

<ol>
  <li>
    <p>This script respects rate limiting by processing URLs sequentially. For a large number of URLs, consider adding a delay between requests.</p>
  </li>
  <li>
    <p>Some websites may block or behave differently with automated requests. You might need to add user-agent headers or other modifications for certain sites:</p>

    <div class="language-powershell highlighter-rouge"><div class="highlight"><section><code><span class="nv">$headers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">@{</span><span class="w">
    </span><span class="s2">"User-Agent"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span><span class="nv">$content</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Invoke-WebRequest</span><span class="w"> </span><span class="nt">-Uri</span><span class="w"> </span><span class="nv">$url</span><span class="w"> </span><span class="nt">-UseBasicParsing</span><span class="w"> </span><span class="nt">-Headers</span><span class="w"> </span><span class="nv">$headers</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">Select-Object</span><span class="w"> </span><span class="nt">-ExpandProperty</span><span class="w"> </span><span class="nx">Content</span><span class="w">
</span></code></section></div>    </div>
  </li>
  <li>
    <p>Always ensure you have permission to scrape the websites you’re targeting and that you’re complying with their terms of service and robots.txt files.</p>
  </li>
  <li>
    <p>For very large lists of URLs, consider implementing parallel processing or breaking the list into smaller batches to improve efficiency.</p>
  </li>
  <li>
    <p>You may want to add more robust URL validation and error checking, depending on your specific needs and the reliability of your URL list.</p>
  </li>
</ol>

        </div>
        
          URL: https://ib.bsb.br/urls-list-text-scraper
        
      </article>
      <nav class="post-navigation-combined" aria-label="Post navigation">
          <div class="tag-selector">
            <p>Select a tag for navigation:</p>
            <ul>
              
                
                
                  <li>
                    <a href="#" class="tag-option" data-tag="scripts-powershell">
                      ["scripts>powershell
                    </a>
                  </li>
                
              
                
                
                  <li>
                    <a href="#" class="tag-option" data-tag="">
                      "
                    </a>
                  </li>
                
              
                
                
                  <li>
                    <a href="#" class="tag-option" data-tag="software-windows">
                      "software>windows"]
                    </a>
                  </li>
                
              
            </ul>
          </div>
        
        
          
          
        
          
          
        
          
          
        
        <script>
        document.addEventListener("DOMContentLoaded", function(){
          var tagLinks = document.querySelectorAll('.tag-option');
          tagLinks.forEach(function(link){
            link.addEventListener('click', function(event){
              event.preventDefault();
              // Hide all navigation blocks
              document.querySelectorAll('.nav-group.tags').forEach(function(block){
                block.style.display = 'none';
              });
              // Show the navigation block for the selected tag
              var tagSlug = this.getAttribute('data-tag');
              var target = document.getElementById('tag-nav-' + tagSlug);
              if(target) {
                target.style.display = 'block';
              }
            });
          });
        });
        </script>
      </nav>
    </main>
    <footer id="bottom-of-page" class="site-footer">
      <p>
        <a href="#" aria-label="Back to top" class="back-to-top-link">
          <span class="sr-only">Back to top</span>
        </a>
        
        
        
        <a href="https://ib.bsb.br/404" aria-label="404">
          2025-02-01 14:39:21
        </a>
        &hArr;
        <a href="https://github.com/ib-bsb-br/ib-bsb-br.github.io" aria-label="GitHub">&#8505;</a>
        <a href="/" aria-label="Homepage">
          infoBAG
        </a>
        <button id="copyAllButton" aria-label="Copy all code">
          &copy;
        </button>
      </p>
    </footer>
    <script type="application/ld+json">
      {
        "@context": "https://schema.org",
        "@type": "Article",
        "mainEntityOfPage": {
          "@type": "WebPage",
          "@id": "https://ib.bsb.br/urls-list-text-scraper/"
        },
        "headline": "URLs list text scraper",
        "description": "",
        "datePublished": "2024-09-12T00:00:00+00:00",
        "dateModified": "2024-12-29T18:40:23+00:00",
        "author": {
          "@type": "Person",
          "name": "Author"
        },
        "publisher": {
          "@type": "Organization",
          "name": "infoBAG"
          
        }
        
      }
    </script>
    <script src="/assets/js/prism.js" defer></script>
    <script src="/assets/js/copy-all-code.js"></script>
  </body>
</html>

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>
    
      URLs list text scraper — infoBAG
    
  </title>
  <meta name="title" content="URLs list text scraper - infoBAG" />
  <meta name="description" content="Reference: https://github.com/kitsuyui/scraper
" />
  <meta property="og:title" content="URLs list text scraper - infoBAG">
  <meta property="og:description" content="Reference: https://github.com/kitsuyui/scraper
">
  <meta property="og:url" content="https://ib.bsb.br/urls-list-text-scraper/">
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="infoBAG">
  <meta property="og:image" content="https://ib.bsb.br/assets/og-image.jpg">
  <link rel="canonical" href="https://ib.bsb.br/urls-list-text-scraper/">
  <link rel="alternate" type="application/rss+xml" title="infoBAG" href="https://ib.bsb.br/rss.xml">
  
    <meta itemprop="keywords" content="scripts>powershell, software>windows">
    
      <meta property="article:tag" content="scripts>powershell, software>windows">
    
  
  <link href="/style.css" rel="stylesheet">
  <link href="/pagefind/pagefind-ui.css" rel="stylesheet">
  <script src="/pagefind/pagefind-ui.js" defer></script>
  <script type="module">
    import PagefindHighlight from '/pagefind/pagefind-highlight.js';
    new PagefindHighlight({ highlightParam: "highlight" });
  </script>
  <script src="/assets/js/search.js" defer></script>
  <script src="/assets/js/prism.js" defer></script>
</head>
<body class="post-content-body">
  <header class="header-container">
    <div id="search" class="search-input-block"></div>
    <nav aria-label="Main navigation" class="header-content">
      <a href="/" aria-label="Home page link">
        <img src="/assets/Sudden_Death_Rune.gif" alt="Navigate to homepage" class="favicon search-link">
      </a>
      <a href="https://ib.bsb.br/archive" aria-label="Archive page link">
        <img src="/favicon.ico" alt="Navigate to archive page" class="favicon search-link">
      </a>
      <a href="https://ib.bsb.br/tags" aria-label="Tags page link">
        <img src="/assets/Label.gif" alt="Navigate to tags page" class="favicon search-link">
      </a>
      <a href="https://ib.bsb.br/events" aria-label="Events page link">
        <img src="/assets/Paralyse_Rune.gif" alt="Navigate to events page" class="favicon search-link">
      </a>
    </nav>
  </header>

  <main class="content">
    <article class="post-wrapper">
      <div class="post-heading">
        <h1 class="post-title">URLs list text scraper</h1>
        <div class="post-meta">
          <time datetime="2024-09-12T00:00:00+00:00" class="post-date">12 Sep 2024</time>
          
            <span class="post-updated"> &rightarrowtail; 
              <time datetime="2024-09-20T02:37:06+00:00">20 Sep 2024</time>
            </span>
          
          
          
          <div class="post-info">
            Edit: aberto.
          </div>
          
          
          
          <div class="post-tags">
            Tags:
            
            <a href="https://ib.bsb.br/tags/#scripts-powershell-software-windows" class="tag">
              scripts>powershell, software>windows
            </a>
            
          </div>
          
          
          <div class="post-actions">
            <a href="https://github.com/ib-bsb-br/ib-bsb-br.github.io/edit/main/_posts/2024-09-12-urls-list-text-scraper.md" target="_blank" rel="noopener noreferrer" class="btn-primary">Improve this page</a>&hArr;
            <a href="https://github.com/ib-bsb-br/ib-bsb-br.github.io/commits/main/_posts/2024-09-12-urls-list-text-scraper.md" target="_blank" rel="noopener noreferrer" class="btn-secondary">View revision history</a>
          </div>
        </div>
      </div>

      <!-- Main content and code block -->
      

      <p>Reference: <code class="language-plaintext highlighter-rouge">https://github.com/kitsuyui/scraper</code></p>

<p>To download the text content of multiple URLs from a list on Windows 11, we’ll create a PowerShell script that’s more robust and flexible than the previously suggested batch file. This approach leverages PowerShell’s strengths and provides better error handling and output formatting.</p>

<ol>
  <li>First, ensure you have <code class="language-plaintext highlighter-rouge">scraper.exe</code> set up:
    <ul>
      <li>Download the latest Windows executable from https://github.com/kitsuyui/scraper/releases/latest</li>
      <li>Rename it to <code class="language-plaintext highlighter-rouge">scraper.exe</code> and place it in a directory that’s in your system PATH</li>
    </ul>
  </li>
  <li>Create a file named <code class="language-plaintext highlighter-rouge">scraper-config.json</code> with the following content:
    <div class="language-json highlighter-rouge"><div class="highlight"><section><code><span class="p">[</span><span class="w">
  </span><span class="p">{</span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"xpath"</span><span class="p">,</span><span class="w"> </span><span class="nl">"label"</span><span class="p">:</span><span class="w"> </span><span class="s2">"BodyText"</span><span class="p">,</span><span class="w"> </span><span class="nl">"query"</span><span class="p">:</span><span class="w"> </span><span class="s2">"//body//text()"</span><span class="p">}</span><span class="w">
</span><span class="p">]</span><span class="w">
</span></code></section></div>    </div>
  </li>
  <li>Create a text file named <code class="language-plaintext highlighter-rouge">urls.txt</code> with one URL per line:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><section><code>https://example.com
https://another-example.com
https://third-example.com
</code></section></div>    </div>
  </li>
  <li>
    <p>Create a new file named <code class="language-plaintext highlighter-rouge">Scrape-Urls.ps1</code> with the following PowerShell script:</p>

    <div class="language-powershell highlighter-rouge"><div class="highlight"><section><code><span class="c"># Scrape-Urls.ps1</span><span class="w">
</span><span class="kr">param</span><span class="p">(</span><span class="w">
    </span><span class="p">[</span><span class="n">string</span><span class="p">]</span><span class="nv">$UrlFile</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"urls.txt"</span><span class="p">,</span><span class="w">
    </span><span class="p">[</span><span class="n">string</span><span class="p">]</span><span class="nv">$ConfigFile</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"scraper-config.json"</span><span class="p">,</span><span class="w">
    </span><span class="p">[</span><span class="n">string</span><span class="p">]</span><span class="nv">$OutputDir</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"scraped_content"</span><span class="w">
</span><span class="p">)</span><span class="w">

</span><span class="c"># Ensure the output directory exists</span><span class="w">
</span><span class="n">New-Item</span><span class="w"> </span><span class="nt">-ItemType</span><span class="w"> </span><span class="nx">Directory</span><span class="w"> </span><span class="nt">-Force</span><span class="w"> </span><span class="nt">-Path</span><span class="w"> </span><span class="nv">$OutputDir</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">Out-Null</span><span class="w">

</span><span class="c"># Read URLs from file</span><span class="w">
</span><span class="nv">$urls</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Get-Content</span><span class="w"> </span><span class="nv">$UrlFile</span><span class="w">

</span><span class="kr">foreach</span><span class="w"> </span><span class="p">(</span><span class="nv">$url</span><span class="w"> </span><span class="kr">in</span><span class="w"> </span><span class="nv">$urls</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="kr">try</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="n">Write-Host</span><span class="w"> </span><span class="s2">"Processing: </span><span class="nv">$url</span><span class="s2">"</span><span class="w">
           
        </span><span class="c"># Generate a safe filename</span><span class="w">
        </span><span class="nv">$filename</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="nv">$url</span><span class="w"> </span><span class="o">-replace</span><span class="w"> </span><span class="s2">"https?://"</span><span class="p">,</span><span class="w"> </span><span class="s2">""</span><span class="w"> </span><span class="o">-replace</span><span class="w"> </span><span class="s2">"[^a-zA-Z0-9]+"</span><span class="p">,</span><span class="w"> </span><span class="s2">"_"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s2">".txt"</span><span class="w">
        </span><span class="nv">$outputPath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Join-Path</span><span class="w"> </span><span class="nv">$OutputDir</span><span class="w"> </span><span class="nv">$filename</span><span class="w">

        </span><span class="c"># Download and scrape content</span><span class="w">
        </span><span class="nv">$content</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Invoke-WebRequest</span><span class="w"> </span><span class="nt">-Uri</span><span class="w"> </span><span class="nv">$url</span><span class="w"> </span><span class="nt">-UseBasicParsing</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">Select-Object</span><span class="w"> </span><span class="nt">-ExpandProperty</span><span class="w"> </span><span class="nx">Content</span><span class="w">
        </span><span class="nv">$scrapedContent</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">$content</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">scraper</span><span class="w"> </span><span class="nt">-c</span><span class="w"> </span><span class="nv">$ConfigFile</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">ConvertFrom-Json</span><span class="w">

        </span><span class="c"># Extract text from JSON and save</span><span class="w">
        </span><span class="nv">$bodyText</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">$scrapedContent</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">Where-Object</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="bp">$_</span><span class="o">.</span><span class="nf">label</span><span class="w"> </span><span class="o">-eq</span><span class="w"> </span><span class="s2">"BodyText"</span><span class="w"> </span><span class="p">}</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">Select-Object</span><span class="w"> </span><span class="nt">-ExpandProperty</span><span class="w"> </span><span class="nx">results</span><span class="w">
        </span><span class="nv">$bodyText</span><span class="w"> </span><span class="o">-join</span><span class="w"> </span><span class="s2">" "</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">Out-File</span><span class="w"> </span><span class="nt">-FilePath</span><span class="w"> </span><span class="nv">$outputPath</span><span class="w">

        </span><span class="n">Write-Host</span><span class="w"> </span><span class="s2">"Saved to: </span><span class="nv">$outputPath</span><span class="s2">"</span><span class="w">
    </span><span class="p">}</span><span class="w">
    </span><span class="kr">catch</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="n">Write-Host</span><span class="w"> </span><span class="s2">"Error processing </span><span class="nv">$url</span><span class="s2"> : </span><span class="bp">$_</span><span class="s2">"</span><span class="w"> </span><span class="nt">-ForegroundColor</span><span class="w"> </span><span class="nx">Red</span><span class="w">
    </span><span class="p">}</span><span class="w">
    </span><span class="n">Write-Host</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="n">Write-Host</span><span class="w"> </span><span class="s2">"All URLs processed."</span><span class="w"> </span><span class="nt">-ForegroundColor</span><span class="w"> </span><span class="nx">Green</span><span class="w">
</span></code></section></div>    </div>
  </li>
  <li>
    <p>Open PowerShell and navigate to the directory containing your script and files.</p>
  </li>
  <li>Run the script:
    <div class="language-powershell highlighter-rouge"><div class="highlight"><section><code><span class="o">.</span><span class="n">\Scrape-Urls.ps1</span><span class="w">
</span></code></section></div>    </div>
  </li>
</ol>

<p>This improved solution offers several advantages:</p>

<ul>
  <li>It uses PowerShell, which is more powerful and flexible than batch scripts on Windows.</li>
  <li>It includes error handling to manage issues with individual URLs without stopping the entire process.</li>
  <li>It creates a separate output directory for scraped content, keeping things organized.</li>
  <li>It generates safe filenames based on the URLs, avoiding potential naming conflicts or invalid characters.</li>
  <li>It extracts the actual text content from the JSON output, providing clean text files.</li>
  <li>It’s more customizable, allowing you to specify different input files, config files, or output directories.</li>
</ul>

<p>Additional notes:</p>

<ol>
  <li>
    <p>This script respects rate limiting by processing URLs sequentially. For a large number of URLs, consider adding a delay between requests.</p>
  </li>
  <li>
    <p>Some websites may block or behave differently with automated requests. You might need to add user-agent headers or other modifications for certain sites:</p>

    <div class="language-powershell highlighter-rouge"><div class="highlight"><section><code><span class="nv">$headers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">@{</span><span class="w">
    </span><span class="s2">"User-Agent"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span><span class="nv">$content</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Invoke-WebRequest</span><span class="w"> </span><span class="nt">-Uri</span><span class="w"> </span><span class="nv">$url</span><span class="w"> </span><span class="nt">-UseBasicParsing</span><span class="w"> </span><span class="nt">-Headers</span><span class="w"> </span><span class="nv">$headers</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">Select-Object</span><span class="w"> </span><span class="nt">-ExpandProperty</span><span class="w"> </span><span class="nx">Content</span><span class="w">
</span></code></section></div>    </div>
  </li>
  <li>
    <p>Always ensure you have permission to scrape the websites you’re targeting and that you’re complying with their terms of service and robots.txt files.</p>
  </li>
  <li>
    <p>For very large lists of URLs, consider implementing parallel processing or breaking the list into smaller batches to improve efficiency.</p>
  </li>
  <li>
    <p>You may want to add more robust URL validation and error checking, depending on your specific needs and the reliability of your URL list.</p>
  </li>
</ol>

      
      <!-- Code block inside main content -->
      
    </article>
  </main>

  <!-- Navigation in aside -->
  <aside class="aside">
    
    <div class="nav-arrow prev">
      <a href="/mlo-ratz/" title="MLO setup using Ratz Computed-Score Algorithm">
        <span aria-hidden="true"><img src="data:image/png;base64,..." alt="Go to previous post" style="max-width: 45px; height: auto;"></span>
      </a>
    </div>
    
    
    
    <div class="nav-arrow next">
      <a href="/daily-coffee-for-the-heart/" title="Daily coffee for the heart">
        <span aria-hidden="true"><img src="data:image/png;base64,..." alt="Go to next post" style="max-width: 45px; height: auto;"></span>
      </a>
    </div>
    
    
    
  </aside>
</body>
</html>

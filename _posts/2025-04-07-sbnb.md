---
tags:
  - linux>software>dotfile
info: aberto.
date: 2025-04-07
type: post
layout: post
published: true
slug: sbnb
title: Portable linux via Sbnb distro with persistence
comment: https://github.com/sbnb-io/sbnb
---

This guide presents a unified, comprehensive utility script to prepare SBNB (Secure Bare-Metal Node Bootstrap) Linux bootable drives. It combines robust partitioning, flexible image deployment, and advanced persistent storage configuration into a single, user-friendly Bash script. Whether you need a quick standard bootable drive or a complex setup with persistent Docker storage and automated system management, this utility adapts to your needs.

This approach synergizes two powerful methodologies:
1.  A straightforward script for creating standard bootable drives from a local `.raw` image.
2.  A sophisticated set of scripts for advanced USB preparation, including partitioning for persistent data and deploying a full suite of configuration files for Docker management, backups, and system health monitoring.

The unified script below encapsulates all necessary logic, providing a single entry point for various SBNB drive preparation tasks.

## Prerequisites

Before using the script, ensure you have the following on your Linux preparation system:
*   **Bash shell.**
*   **Core Linux utilities:** `lsblk`, `grep`, `sed`, `awk`, `mktemp`, `mount`, `umount`, `cp`, `tee`, `sync`, `dd`, `parted`, `mkfs.vfat`, `mkfs.ext4`, `wipefs`, `findmnt`, `blkid`, `fsck.vfat`, `e2fsck`, `id`, `read`, `sleep`, `xargs`, `partprobe`, `realpath`, `dirname`, `basename`, `cat`, `cmp`, `date`. (The script checks for most).
*   **`sudo` privileges:** The script must be run as root (e.g., `sudo ./scriptname.sh`).
*   **Python 3:** Required for the advanced configuration deployment mode.
*   **`sbnb.raw` file:** (For Simple Mode) A complete raw disk image of SBNB Linux.
*   **`sbnb.efi` file:** (For Advanced Mode) The SBNB EFI bootloader file (often `BOOTX64.EFI` from a standard SBNB installation or build).
*   **(Optional) `sbnb-tskey.txt`:** (For Simple Mode) A Tailscale authentication key file, to be placed in the same directory as this script.
*   **(Optional) Custom `sbnb-cmds.sh`:** (For Simple Mode) A user-provided script to run at boot.
*   **(Required for full functionality in Advanced Mode) Tailscale Authentication Key:** (For Advanced Mode) Your actual Tailscale auth key string will be prompted for.

**EXTREME CAUTION:** Disk operations performed by this script are destructive to the target device. ALL DATA on the selected device WILL BE PERMANENTLY LOST. Double-check your target device selection. Proceed at your own risk.

## The Unified SBNB Drive Preparation Utility Script

Save the following script as `unified_sbnb_prep.sh`, make it executable (`chmod +x unified_sbnb_prep.sh`), and run it with `sudo ./unified_sbnb_prep.sh`.

```bash
#!/bin/bash

# ==============================================================================
# Unified SBNB Drive Preparation Utility
# Version 1.1
# Last Updated: 2025-05-13
#
# Combines functionalities for simple SBNB raw image deployment and
# advanced SBNB drive preparation with persistent storage.
# ==============================================================================

# Exit immediately if a command exits with a non-zero status
# Treat unset variables as an error when substituting.
# Pipelines return the exit status of the last command to exit non-zero.
set -euo pipefail

# --- Color Codes ---
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# --- Global Variables ---
MAIN_TEMP_BASE_DIR="" # Will be created by mktemp

# --- Helper Functions ---
_log_msg() {
    local color_prefix="$1"
    local type_prefix="$2"
    local message="$3"
    echo -e "${color_prefix}[${type_prefix}]${NC} ${message}"
}
info() { _log_msg "${GREEN}" "INFO" "$1"; }
warn() { _log_msg "${YELLOW}" "WARN" "$1"; }
error() { _log_msg "${RED}" "ERROR" "$1"; exit 1; } # Exit on error
prompt() { read -p "$(echo -e "${BLUE}[PROMPT]${NC} $1")" "$2"; }

confirm_action() {
    local message="$1"
    local confirmation_var_name="$2"
    echo -e "\n${RED}====================== WARNING ======================${NC}"
    echo -e "${RED}${message}${NC}"
    echo -e "${RED}ALL DATA ON THE TARGET DEVICE WILL BE PERMANENTLY DESTROYED!${NC}"
    echo -e "${RED}This operation is IRREVERSIBLE.${NC}"
    echo -e "${RED}=====================================================${NC}"
    prompt "Are you absolutely sure you want to proceed? (Type 'yes' to confirm): " "$confirmation_var_name"
    # Default to NO if user just presses Enter
    eval "$confirmation_var_name=\${${confirmation_var_name}:-NO}"
}

check_command_exists() {
    if ! command -v "$1" &> /dev/null; then
        error "Required command '$1' not found. Please install it."
    fi
}

# Trap for global cleanup
global_cleanup_trap() {
    info "Initiating global cleanup..."
    if [ -n "$MAIN_TEMP_BASE_DIR" ] && [ -d "$MAIN_TEMP_BASE_DIR" ]; then
        info "Removing main temporary base directory ${MAIN_TEMP_BASE_DIR}..."
        # Ensure nothing is mounted underneath it before rm -rf
        # This is a safeguard; specific unmounts should happen in function-scoped traps
        find "$MAIN_TEMP_BASE_DIR" -mindepth 1 -type d -print0 | xargs -0 -I {} sh -c 'if mountpoint -q "{}"; then umount "{}"; fi' || true
        rm -rf "$MAIN_TEMP_BASE_DIR" || warn "Failed to remove main temporary base directory ${MAIN_TEMP_BASE_DIR} during cleanup."
    fi
    info "Global cleanup finished."
}
trap global_cleanup_trap EXIT HUP INT TERM


# --- Initial Checks ---
info "Starting Unified SBNB Drive Preparation Utility."

if [[ $EUID -ne 0 ]]; then
   error "This script must be run as root (e.g., using sudo)."
fi

REQUIRED_CMDS_ALL=(
    "lsblk" "grep" "sed" "awk" "mktemp" "mount" "umount" "cp" "tee" "sync" "dd"
    "parted" "mkfs.vfat" "mkfs.ext4" "wipefs" "findmnt" "blkid" "fsck.vfat"
    "e2fsck" "id" "read" "sleep" "xargs" "partprobe" "realpath" "dirname"
    "basename" "cat" "cmp" "date" "python3"
)
info "Checking for required commands..."
for cmd_check in "${REQUIRED_CMDS_ALL[@]}"; do
    check_command_exists "$cmd_check"
done
info "All common required commands found."

# Create main temporary directory
MAIN_TEMP_BASE_DIR=$(mktemp -d -t sbnb_unified_creator.XXXXXX)
info "Main temporary directory created at: ${MAIN_TEMP_BASE_DIR}"


# ==============================================================================
# SECTION 1: Simple SBNB Raw Image Deployment (Derived from script1)
# ==============================================================================
run_simple_mode() {
    info "Starting Simple SBNB Raw Image Deployment Mode."

    local SBNB_RAW_FILE_NAME="sbnb.raw"
    local SBNB_TSKEY_FILE_NAME="sbnb-tskey.txt" # Source name, expected in PWD
    local SBNB_CMDS_FILE_TARGET_NAME="sbnb-cmds.sh" # Target name on ESP

    local sbnb_raw_path
    prompt "Enter the full path to your '${SBNB_RAW_FILE_NAME}' disk image file: " sbnb_raw_path

    if [ ! -r "$sbnb_raw_path" ]; then
      error "'$sbnb_raw_path' not found or not readable."
    fi
    info "Using SBNB raw image: $sbnb_raw_path"

    local local_ts_key_path_simple="./${SBNB_TSKEY_FILE_NAME}" # Check in current dir
    local use_local_ts_key=false
    if [ -r "$local_ts_key_path_simple" ]; then
        info "Found optional Tailscale key file: $local_ts_key_path_simple"
        use_local_ts_key=true
    else
        info "Optional Tailscale key file ('$local_ts_key_path_simple' in current directory) not found. Skipping."
    fi

    # --- Disk Selection ---
    info "Enumerating available block devices..."
    mapfile -t devices < <(lsblk -dpno NAME,SIZE,MODEL,TYPE | grep -E 'disk|rom' | grep -v 'loop')

    if [ ${#devices[@]} -eq 0 ]; then error "No suitable disk devices found."; fi

    echo -e "\n${YELLOW}Available Devices:${NC}"
    echo "--------------------------------------------------"
    for i in "${!devices[@]}"; do printf "%3d) %s\n" $((i+1)) "${devices[$i]}"; done
    echo "--------------------------------------------------"

    local selected_disk_index
    local selected_drive
    while true; do
        prompt "Enter the index number of the target device: " selected_disk_index
        if [[ "$selected_disk_index" =~ ^[0-9]+$ ]] && [ "$selected_disk_index" -ge 1 ] && [ "$selected_disk_index" -le ${#devices[@]} ]; then
            selected_drive=$(echo "${devices[$((selected_disk_index-1))]}" | awk '{print $1}')
            info "You selected index $selected_disk_index: $selected_drive"
            break
        else
            warn "Invalid input. Please enter a number between 1 and ${#devices[@]}."
        fi
    done

    # --- Confirmation ---
    local confirmation_simple_mode
    confirm_action "You have selected device: $selected_drive for SBNB raw image deployment." "confirmation_simple_mode"
    if [[ "$confirmation_simple_mode" != "yes" ]]; then info "Operation cancelled by user."; return 0; fi

    # --- Unmount Partitions ---
    info "Checking for and unmounting partitions on $selected_drive..."
    # Use findmnt to get mount points and umount them safely
    findmnt -n -o TARGET --source "${selected_drive}*" | xargs --no-run-if-empty umount -v -l || info "No partitions were mounted or umount failed (might be okay)."
    umount "$selected_drive" &>/dev/null || true # Attempt to unmount base device, ignore errors
    sleep 1; info "Finished unmounting checks for $selected_drive."

    # --- Write Image ---
    info "Writing '$sbnb_raw_path' to $selected_drive..."
    warn "This may take a while. Please wait..."
    if ! dd if="$sbnb_raw_path" of="$selected_drive" bs=4M status=progress conv=fsync; then
        error "Failed to write image to $selected_drive using dd."
    fi
    info "Image write completed successfully."

    # --- Partition Recognition ---
    info "Ensuring partition table is recognized..."
    sync
    if command -v partprobe &> /dev/null; then
        info "Running 'partprobe $selected_drive' to update partition table..."
        partprobe "$selected_drive" || warn "'partprobe' failed, but continuing..."
    else
        warn "'partprobe' command not found. The system might take longer to recognize partitions."
    fi
    sleep 3

    # --- Mount ESP Partition ---
    info "Attempting to identify and mount the first partition (ESP)..."
    local first_partition=""
    # Check for pattern like /dev/sda1, /dev/hda1
    if [ -b "${selected_drive}1" ]; then first_partition="${selected_drive}1";
    # Check for pattern like /dev/nvme0n1p1, /dev/mmcblk0p1
    elif [ -b "${selected_drive}p1" ]; then first_partition="${selected_drive}p1";
    else # Poll briefly
        warn "First partition not immediately found, polling for 5 seconds..."
        local found_part_simple=false
        for _ in {1..5}; do
            sleep 1
            if [ -b "${selected_drive}1" ]; then first_partition="${selected_drive}1"; found_part_simple=true; break; fi
            if [ -b "${selected_drive}p1" ]; then first_partition="${selected_drive}p1"; found_part_simple=true; break; fi
        done
        if ! $found_part_simple; then error "Could not find the first partition device node on $selected_drive. Cannot copy optional files."; fi
    fi
    info "Identified first partition as: $first_partition"

    local temp_esp_mount_simple
    temp_esp_mount_simple="${MAIN_TEMP_BASE_DIR}/simple_esp_mnt"
    mkdir -p "$temp_esp_mount_simple"

    # Setup trap for ESP mount cleanup (specific to this function's scope)
    simple_mode_local_cleanup() {
        info "Simple mode: Cleaning up ESP mount..."
        if mountpoint -q "$temp_esp_mount_simple"; then
            umount "$temp_esp_mount_simple" 2>/dev/null || warn "Failed to unmount $temp_esp_mount_simple during simple_mode_local_cleanup."
        fi
        # The directory itself will be removed by global_cleanup_trap
    }
    trap 'simple_mode_local_cleanup' RETURN # RETURN ensures it runs when function exits normally or via 'return'

    info "Mounting $first_partition to $temp_esp_mount_simple..."
    if ! mount "$first_partition" "$temp_esp_mount_simple"; then
        error "Failed to mount ESP partition $first_partition at $temp_esp_mount_simple."
    fi
    info "ESP partition successfully mounted at $temp_esp_mount_simple"

    # --- Copy Files to ESP ---
    if [ "$use_local_ts_key" = true ]; then
      local target_ts_key_path_simple="$temp_esp_mount_simple/$SBNB_TSKEY_FILE_NAME" # Use source name as target name
      info "Copying local '$local_ts_key_path_simple' to $target_ts_key_path_simple..."
      if ! cp "$local_ts_key_path_simple" "$target_ts_key_path_simple"; then
          error "Failed to copy Tailscale key to ESP." # error will trigger trap
      fi
      info "Tailscale key copied successfully."
    fi

    local custom_script_path_source
    prompt "Enter path to custom script file (optional, saved as '$SBNB_CMDS_FILE_TARGET_NAME' on drive, runs at boot) [Press Enter to skip]: " custom_script_path_source
    if [ -n "$custom_script_path_source" ]; then
      if [ -f "$custom_script_path_source" ] && [ -r "$custom_script_path_source" ]; then
        local target_script_path_simple="$temp_esp_mount_simple/$SBNB_CMDS_FILE_TARGET_NAME"
        info "Copying custom script '$custom_script_path_source' to $target_script_path_simple..."
        if ! cp "$custom_script_path_source" "$target_script_path_simple"; then
            error "Failed to copy custom script to ESP." # error will trigger trap
        fi
        info "Custom script copied successfully."
      else
        warn "Custom script file '$custom_script_path_source' not found or not readable. Skipping."
      fi
    else
      info "No custom script path provided. Skipping."
    fi

    info "File copying complete."
    # Unmounting and cleanup is handled by the trap

    echo -e "\n${BLUE}=========================================${NC}"
    echo -e "${GREEN} Simple Mode Operation completed successfully! ${NC}"
    echo -e "${GREEN} Target device: $selected_drive ${NC}"
    echo -e "${BLUE}=========================================${NC}"

    trap - RETURN # Disable local trap
    simple_mode_local_cleanup # Perform cleanup explicitly
}


# ==============================================================================
# SECTION 2: Advanced SBNB Drive Preparation (Derived from script2 components)
# ==============================================================================
run_advanced_mode() {
    info "Starting Advanced SBNB Drive Preparation Mode."

    # --- Component 2a: prepare_usb.sh logic ---
    prepare_usb_advanced() {
        local TARGET_DEVICE_ADV="$1"
        info "--- USB Drive Partitioning and Formatting for Advanced Mode on ${TARGET_DEVICE_ADV} ---"
        
        local ESP_LABEL_ADV="sbnb" # Critical for SBNB boot
        local DATA_LABEL_ADV="SBNB_DATA"
        local ESP_SIZE_ADV="1025MiB"
        
        # --- Validate Device (already selected, but re-check type) ---
        if [ ! -b "$TARGET_DEVICE_ADV" ]; then error "'$TARGET_DEVICE_ADV' is not a valid block device."; fi

        # --- CRITICAL SAFETY CHECK: Prevent targeting the root filesystem device ---
        info "Performing safety checks for $TARGET_DEVICE_ADV..."
        local root_dev_path_adv; root_dev_path_adv=$(findmnt -n -o SOURCE /)
        local root_base_dev_name_adv; root_base_dev_name_adv=$(lsblk -no pkname "$(realpath "$root_dev_path_adv")") || error "Cannot find base device for root FS."
        local target_base_dev_name_adv; target_base_dev_name_adv=$(lsblk -no pkname "$(realpath "$TARGET_DEVICE_ADV")") || error "Cannot find base device for target $TARGET_DEVICE_ADV."
        local root_base_dev_adv="/dev/${root_base_dev_name_adv}"; local target_base_dev_adv="/dev/${target_base_dev_name_adv}"

        if [ "$target_base_dev_adv" == "$root_base_dev_adv" ]; then
          error "FATAL ERROR: Target device '$TARGET_DEVICE_ADV' appears to be the same device ('$root_base_dev_adv') as the running root filesystem ('$root_dev_path_adv'). Aborting."
        fi
        info "Safety check passed: Target device '$TARGET_DEVICE_ADV' is not the root filesystem device ('$root_base_dev_adv')."

        if [[ "$TARGET_DEVICE_ADV" == /dev/mmcblk* ]]; then warn "'$TARGET_DEVICE_ADV' looks like an SD card. Double-check this is not your primary OS drive!"; fi

        info "Target Device for partitioning: $TARGET_DEVICE_ADV"
        info "Partitions to be created: ESP (Label: '$ESP_LABEL_ADV', Size: $ESP_SIZE_ADV), Data (Label: '$DATA_LABEL_ADV', Remaining space)"
        
        info "Unmounting any existing partitions on ${TARGET_DEVICE_ADV}* ..."
        findmnt -n -o TARGET --source "${TARGET_DEVICE_ADV}*" | xargs --no-run-if-empty umount -v -l || info "No partitions were mounted or umount failed (might be okay)."
        umount "$TARGET_DEVICE_ADV" &>/dev/null || true; sleep 1

        info "Wiping filesystem/partition signatures from $TARGET_DEVICE_ADV..."; wipefs --all --force "$TARGET_DEVICE_ADV"; sync
        info "Creating new GPT partition table on $TARGET_DEVICE_ADV..."; parted "$TARGET_DEVICE_ADV" --script -- mklabel gpt; sync
        info "Creating ESP partition (1) on $TARGET_DEVICE_ADV..."; parted "$TARGET_DEVICE_ADV" --script -- mkpart "${ESP_LABEL_ADV}" fat32 1MiB "${ESP_SIZE_ADV}"; parted "$TARGET_DEVICE_ADV" --script -- set 1 boot on; parted "$TARGET_DEVICE_ADV" --script -- set 1 esp on; sync
        info "Creating Linux data partition (2) on $TARGET_DEVICE_ADV..."; parted "$TARGET_DEVICE_ADV" --script -- mkpart "${DATA_LABEL_ADV}" ext4 "${ESP_SIZE_ADV}" 100%; sync
        info "Waiting for kernel to recognize new partitions..."; sleep 2

        local part_prefix_adv=""; if [[ "$TARGET_DEVICE_ADV" == *nvme* ]] || [[ "$TARGET_DEVICE_ADV" == *mmcblk* ]]; then part_prefix_adv="p"; fi
        ESP_PARTITION_DEVICE="${TARGET_DEVICE_ADV}${part_prefix_adv}1" # Make global for this function scope
        DATA_PARTITION_DEVICE="${TARGET_DEVICE_ADV}${part_prefix_adv}2" # Make global for this function scope

        info "Checking for partition device nodes (${ESP_PARTITION_DEVICE}, ${DATA_PARTITION_DEVICE})..."
        local partitions_found_adv_check=false
        for i_adv_check in {1..5}; do
          if [ -b "$ESP_PARTITION_DEVICE" ] && [ -b "$DATA_PARTITION_DEVICE" ]; then info "Partition nodes found."; partitions_found_adv_check=true; break; fi
          info "Partition nodes not yet found. Retrying probe (Attempt $i_adv_check/5)..."; partprobe "$TARGET_DEVICE_ADV" || warn "partprobe failed, continuing check..."; sleep 1
        done
        if [ "$partitions_found_adv_check" = false ]; then lsblk "$TARGET_DEVICE_ADV"; error "Partition devices ($ESP_PARTITION_DEVICE, $DATA_PARTITION_DEVICE) not found."; fi

        info "Verifying partitions on $TARGET_DEVICE_ADV..."; parted "$TARGET_DEVICE_ADV" --script -- print; lsblk -o NAME,SIZE,TYPE,FSTYPE,PARTLABEL,MOUNTPOINT,PARTFLAGS "$TARGET_DEVICE_ADV"

        info "Formatting ESP partition (${ESP_PARTITION_DEVICE}) as FAT32 with label '${ESP_LABEL_ADV}'..."; mkfs.vfat -F 32 -n "${ESP_LABEL_ADV}" "${ESP_PARTITION_DEVICE}"; sync
        info "Checking ESP filesystem (fsck.vfat)..."; local fsck_vfat_ec=0; fsck.vfat -a "${ESP_PARTITION_DEVICE}" || fsck_vfat_ec=$?;
        if [ $fsck_vfat_ec -eq 0 ]; then info "ESP fsck passed."; elif [ $fsck_vfat_ec -eq 1 ]; then warn "fsck.vfat found/corrected errors on ESP."; else error "fsck.vfat uncorrectable errors (Code: $fsck_vfat_ec) on ESP."; fi
        if ! blkid -s LABEL -o value "${ESP_PARTITION_DEVICE}" | grep -q "^${ESP_LABEL_ADV}$"; then blkid "${ESP_PARTITION_DEVICE}"; error "Failed to verify ESP Label '${ESP_LABEL_ADV}'."; fi; info "ESP Label '${ESP_LABEL_ADV}' verified."

        info "Formatting Data partition (${DATA_PARTITION_DEVICE}) as ext4 with label '${DATA_LABEL_ADV}'..."; mkfs.ext4 -m 0 -L "${DATA_LABEL_ADV}" "${DATA_PARTITION_DEVICE}"; sync
        info "Checking Data partition filesystem (e2fsck)..."; local e2fsck_ec=0; e2fsck -f -y "${DATA_PARTITION_DEVICE}" || e2fsck_ec=$?;
        if [ $e2fsck_ec -eq 0 ]; then info "Data partition fsck passed."; elif [ $e2fsck_ec -eq 1 ]; then warn "e2fsck found/corrected errors on Data partition."; else error "e2fsck uncorrectable errors (Code: $e2fsck_ec) on Data partition."; fi
        if ! blkid -s LABEL -o value "${DATA_PARTITION_DEVICE}" | grep -q "^${DATA_LABEL_ADV}$"; then blkid "${DATA_PARTITION_DEVICE}"; error "Failed to verify Data Label '${DATA_LABEL_ADV}'."; fi; info "Data Label '${DATA_LABEL_ADV}' verified."
        info "USB drive partitioning and formatting complete for $TARGET_DEVICE_ADV."
    }

    # --- Component 2b: Python Configuration Deployment Script logic ---
    deploy_python_config_advanced() {
        local TARGET_DEVICE_PY="$1" # Base device, e.g. /dev/sdb (unused by Python, but for context)
        local ESP_MOUNT_POINT_PY="$2"
        local DATA_MOUNT_POINT_PY="$3"
        local TAILSCALE_AUTH_KEY_PY="$4"
        local SBNB_EFI_FILE_PATH_PY="$5" # Path to the sbnb.efi or BOOTX64.EFI file

        info "--- Deploying SBNB Configuration via Python Script ---"
        
        info "Copying SBNB EFI file '$SBNB_EFI_FILE_PATH_PY' to '${ESP_MOUNT_POINT_PY}/EFI/BOOT/BOOTX64.EFI'..."
        mkdir -p "${ESP_MOUNT_POINT_PY}/EFI/BOOT" # Ensure directory exists
        if ! cp "$SBNB_EFI_FILE_PATH_PY" "${ESP_MOUNT_POINT_PY}/EFI/BOOT/BOOTX64.EFI"; then
            error "Failed to copy SBNB EFI file to ESP."
        fi
        info "SBNB EFI file copied."

        local temp_python_script_adv; temp_python_script_adv=$(mktemp -p "${MAIN_TEMP_BASE_DIR}" sbnb_config_py.XXXXXX.py)
        
        # Python script content (heredoc)
        # All lines of the Python script must start at the beginning of the line in the heredoc.
        # Shell variables are expanded when the heredoc is defined because EOF_PYTHON_SCRIPT is not quoted.
        # This is intentional here to inject Bash variable values into the Python script string.
        # However, for the generated shell scripts *within* Python, f-strings are used, which is Python's mechanism.
        cat > "$temp_python_script_adv" <<EOF_PYTHON_SCRIPT
#!/usr/bin/env python3
# Unified SBNB Configuration Deployment Script (Python Part)
# Version 1.1
import os
import stat
import sys
import pathlib
import json
import shutil
from datetime import datetime

# --- Configuration: Read from Environment Variables set by Bash ---
ESP_MOUNT = os.environ.get("SBNB_ESP_MOUNT_PY")
DATA_MOUNT = os.environ.get("SBNB_DATA_MOUNT_PY")
TAILSCALE_AUTH_KEY_CONTENT = os.environ.get("SBNB_TS_KEY_PY", "tskey-auth-placeholder-python-fallback")

if not ESP_MOUNT or not DATA_MOUNT:
    print("PYTHON CRITICAL ERROR: ESP_MOUNT or DATA_MOUNT environment variables not set.", file=sys.stderr)
    sys.exit(1)

# --- Static Configurations (can be customized further if needed) ---
PERSISTENT_DOCKER_ROOT = f"{DATA_MOUNT}/docker-root"
DOCKER_CONFIG_DIR_TARGET = "/etc/docker" # This path is on the target SBNB system
DOCKER_CONFIG_FILE_TARGET = f"{DOCKER_CONFIG_DIR_TARGET}/daemon.json"
DOCKER_CONFIG_BACKUP_SUFFIX_TARGET = ".sbnb-orig-backup"
DOCKER_DATA_EPHEMERAL_TARGET = "/var/lib/docker"
DOCKER_ROOT_PERMISSIONS_OCTAL = 0o711
DOCKER_CONFIG_PERMISSIONS_OCTAL = 0o644

BACKUP_BASE_DIR_TARGET = f"{DATA_MOUNT}/backups/docker"
BACKUP_KEEP_COUNT_CONFIG = 3
STOP_DOCKER_FOR_BACKUP_CONFIG = 1 # 1 = Stop Docker during backup (safer), 0 = Attempt live backup
BACKUP_DIR_PERMISSIONS_OCTAL = 0o750

VOLUME_CHECK_THRESHOLD_PERCENT_CONFIG = 10
VOLUME_CHECK_PRUNE_LEVEL_CONFIG = 1 # 0=None, 1=Containers/Dangling Images, 2=All Unused Images+Containers

# --- Content Definitions ---
# Note: Using triple single quotes for multiline f-strings to avoid issues with double quotes inside shell scripts
SBNB_CMDS_SH_CONTENT = f'''#!/bin/sh
# Sbnb Custom Commands Script (Generated by Unified SBNB Drive Prep Utility)
# Configures persistent Docker root, data migration, systemd services.
set -e -o pipefail -u

log() {{ echo "[sbnb-cmds.sh] $1" > /dev/kmsg; }}
log "Starting SBNB custom boot commands (v1.1)..."

check_cmds() {{
    local missing_cmd_flag=0
    log "Checking required commands..."
    for cmd_item in "$@"; do
        if ! command -v "$cmd_item" >/dev/null 2>&1; then
            log "ERROR: Required command '$cmd_item' not found on target system."
            missing_cmd_flag=1
        fi
    done
    if [ $missing_cmd_flag -eq 1 ]; then
        log "ERROR: Missing one or more required commands. Cannot proceed with full configuration."
        exit 1 # Critical, full setup cannot proceed
    fi
    log "All required commands found."
    if ! command -v jq >/dev/null 2>&1; then
        log "WARNING: 'jq' command not found on target. JSON handling for daemon.json will be less robust."
    else
        log "OK: 'jq' command found (recommended for daemon.json)."
    fi
}}
# Define all commands potentially used in this script and its sub-functions
check_cmds mountpoint readlink mkdir mount echo sleep rm find ln systemctl mktemp cp mv chmod chown dirname basename jq grep cat cmp date sed ls df awk tar gzip nice

# --- Mount Persistent Data Partition ---
DATA_PARTITION_LABEL="SBNB_DATA" # Must match label set during partitioning
DATA_DEVICE_SYMLINK_PATH="/dev/disk/by-label/${{DATA_PARTITION_LABEL}}"
# DATA_MOUNT_POINT_TARGET is the DATA_MOUNT passed from Bash
DATA_MOUNT_POINT_TARGET="{DATA_MOUNT}"
MAX_WAIT_SECONDS_FOR_DEVICE=15
WAIT_INTERVAL_SECONDS=1
elapsed_time_counter=0

log "Waiting up to ${{MAX_WAIT_SECONDS_FOR_DEVICE}}s for data device (Label: ${{DATA_PARTITION_LABEL}} at ${{DATA_DEVICE_SYMLINK_PATH}})..."
while [ ! -L "${{DATA_DEVICE_SYMLINK_PATH}}" ]; do # Check for symlink specifically
    if [ ${{elapsed_time_counter}} -ge ${{MAX_WAIT_SECONDS_FOR_DEVICE}} ]; then
        log "ERROR: Timeout waiting for data device symlink ${{DATA_DEVICE_SYMLINK_PATH}}. Persistent data cannot be mounted."
        exit 1
    fi
    sleep ${{WAIT_INTERVAL_SECONDS}}
    elapsed_time_counter=$((elapsed_time_counter + WAIT_INTERVAL_SECONDS))
done
ACTUAL_DATA_DEVICE=$(readlink -f "${{DATA_DEVICE_SYMLINK_PATH}}")
log "Data partition device resolved to ${{ACTUAL_DATA_DEVICE}} via symlink after ${{elapsed_time_counter}}s."

mkdir -p "${{DATA_MOUNT_POINT_TARGET}}" # Ensure mount point directory exists

log "Attempting to mount ${{ACTUAL_DATA_DEVICE}} at ${{DATA_MOUNT_POINT_TARGET}} (type ext4, rw,noatime,nodiratime)..."
if ! mountpoint -q "${{DATA_MOUNT_POINT_TARGET}}"; then
    if mount -t ext4 -o rw,noatime,nodiratime "${{ACTUAL_DATA_DEVICE}}" "${{DATA_MOUNT_POINT_TARGET}}"; then
        log "Successfully mounted persistent data partition at ${{DATA_MOUNT_POINT_TARGET}}."
    else
        log "ERROR: Failed to mount ${{ACTUAL_DATA_DEVICE}} at ${{DATA_MOUNT_POINT_TARGET}}! Check filesystem and device."
        exit 1
    fi
else
    log "Persistent partition already mounted at ${{DATA_MOUNT_POINT_TARGET}}. Ensuring read-write..."
    if ! mount -o remount,rw "${{DATA_MOUNT_POINT_TARGET}}"; then
        log "ERROR: Failed to remount ${{DATA_MOUNT_POINT_TARGET}} as read-write! Docker requires write access."
        exit 1
    fi
fi

# --- Configure Docker to use Persistent Data Directory ---
log "Setting up Docker to use persistent data-root..."

PERSISTENT_DOCKER_ROOT_TARGET="{PERSISTENT_DOCKER_ROOT}" # Python var injected
DOCKER_DAEMON_CONFIG_DIR_TARGET="{DOCKER_CONFIG_DIR_TARGET}"
DOCKER_DAEMON_CONFIG_FILE_PATH_TARGET="{DOCKER_CONFIG_FILE_TARGET}"
DOCKER_DAEMON_CONFIG_BACKUP_PATH_TARGET="{DOCKER_CONFIG_FILE_TARGET}{DOCKER_CONFIG_BACKUP_SUFFIX_TARGET}"
DOCKER_EPHEMERAL_DATA_PATH_TARGET="{DOCKER_DATA_EPHEMERAL_TARGET}"
DOCKER_CONFIG_HAS_CHANGED=0 # Flag to track if we need to restart docker

log "Ensuring persistent Docker data directory exists: ${{PERSISTENT_DOCKER_ROOT_TARGET}}"
mkdir -p -m {DOCKER_ROOT_PERMISSIONS_OCTAL:o} "${{PERSISTENT_DOCKER_ROOT_TARGET}}"
if [ ! -d "${{PERSISTENT_DOCKER_ROOT_TARGET}}" ]; then log "ERROR: Failed to create persistent Docker data directory ${{PERSISTENT_DOCKER_ROOT_TARGET}}!"; exit 1; fi
log "Ensuring ownership of ${{PERSISTENT_DOCKER_ROOT_TARGET}} is root:root..."
chown root:root "${{PERSISTENT_DOCKER_ROOT_TARGET}}" || log "WARNING: Failed to set ownership on ${{PERSISTENT_DOCKER_ROOT_TARGET}}. Docker might have issues."
log "Ensuring permissions of ${{PERSISTENT_DOCKER_ROOT_TARGET}} are {DOCKER_ROOT_PERMISSIONS_OCTAL:o}..."
chmod {DOCKER_ROOT_PERMISSIONS_OCTAL:o} "${{PERSISTENT_DOCKER_ROOT_TARGET}}" || log "WARNING: Failed to set permissions on ${{PERSISTENT_DOCKER_ROOT_TARGET}}."
log "Persistent Docker data directory setup complete."

log "Configuring Docker daemon (${{DOCKER_DAEMON_CONFIG_FILE_PATH_TARGET}}) to use data-root: ${{PERSISTENT_DOCKER_ROOT_TARGET}}"
mkdir -p "${{DOCKER_DAEMON_CONFIG_DIR_TARGET}}"
if [ -f "${{DOCKER_DAEMON_CONFIG_FILE_PATH_TARGET}}" ] && [ ! -f "${{DOCKER_DAEMON_CONFIG_BACKUP_PATH_TARGET}}" ]; then
    log "Backing up original Docker config to ${{DOCKER_DAEMON_CONFIG_BACKUP_PATH_TARGET}}..."
    cp -a "${{DOCKER_DAEMON_CONFIG_FILE_PATH_TARGET}}" "${{DOCKER_DAEMON_CONFIG_BACKUP_PATH_TARGET}}" || log "WARNING: Failed to create backup of ${{DOCKER_DAEMON_CONFIG_FILE_PATH_TARGET}}."
fi

# Safely update daemon.json
NEEDS_DAEMON_JSON_UPDATE=0
if command -v jq >/dev/null 2>&1; then
    log "Using jq to manage daemon.json."
    [ -f "${{DOCKER_DAEMON_CONFIG_FILE_PATH_TARGET}}" ] || echo "{{}}" > "${{DOCKER_DAEMON_CONFIG_FILE_PATH_TARGET}}" # Ensure file exists for jq
    current_data_root_val=$(jq -r '.["data-root"] // ""' "${{DOCKER_DAEMON_CONFIG_FILE_PATH_TARGET}}")
    if [ "$current_data_root_val" != "${{PERSISTENT_DOCKER_ROOT_TARGET}}" ]; then
        log "Data-root needs update (jq check found '$current_data_root_val', expected '${{PERSISTENT_DOCKER_ROOT_TARGET}}'). Preparing changes..."
        NEEDS_DAEMON_JSON_UPDATE=1
    else
        log "Docker data-root already correctly set in daemon.json (jq check)."
    fi
    if [ $NEEDS_DAEMON_JSON_UPDATE -eq 1 ]; then
        TEMP_JSON_FILE=$(mktemp "${{DOCKER_DAEMON_CONFIG_DIR_TARGET}}/daemon.json.tmp.XXXXXX")
        log "Attempting to merge data-root setting using jq into ${{TEMP_JSON_FILE}}..."
        if jq --arg new_path "${{PERSISTENT_DOCKER_ROOT_TARGET}}" '. + {{"data-root": $new_path}}' "${{DOCKER_DAEMON_CONFIG_FILE_PATH_TARGET}}" > "${{TEMP_JSON_FILE}}"; then
            if jq -e . "${{TEMP_JSON_FILE}}" > /dev/null; then # Validate new JSON
                if ! cmp -s "${{TEMP_JSON_FILE}}" "${{DOCKER_DAEMON_CONFIG_FILE_PATH_TARGET}}"; then
                    mv "${{TEMP_JSON_FILE}}" "${{DOCKER_DAEMON_CONFIG_FILE_PATH_TARGET}}"
                    chmod {DOCKER_CONFIG_PERMISSIONS_OCTAL:o} "${{DOCKER_DAEMON_CONFIG_FILE_PATH_TARGET}}"
                    log "Successfully updated daemon.json using jq."
                    DOCKER_CONFIG_HAS_CHANGED=1
                else
                    log "daemon.json content unchanged after jq merge, removing temp file."
                    rm -f "${{TEMP_JSON_FILE}}"
                fi
            else log "ERROR: jq produced invalid JSON output. Config not updated."; rm -f "${{TEMP_JSON_FILE}}"; fi
        else jq_exit_code=$?; log "ERROR: jq command failed (exit code $jq_exit_code) while updating config. Config not updated."; rm -f "${{TEMP_JSON_FILE}}"; fi
    fi
else # Fallback logic if jq is NOT available
    log "WARNING: jq not found. Using less robust grep/sed fallback for daemon.json."
    # This simplified fallback assumes a very simple or non-existent daemon.json
    # It will create a new one if missing, or overwrite if it's empty or just {{}}.
    # It will NOT attempt to merge with complex existing configurations without jq.
    DESIRED_JSON_CONTENT=$(printf '{{\\n  "data-root": "%s"\\n}}\\n' "${{PERSISTENT_DOCKER_ROOT_TARGET}}") # Simple JSON
    CREATE_NEW_DAEMON_JSON=0
    if [ ! -f "${{DOCKER_DAEMON_CONFIG_FILE_PATH_TARGET}}" ]; then
        log "daemon.json does not exist. Will create new."
        CREATE_NEW_DAEMON_JSON=1
    else # File exists, check if it's empty or just {{}} or if data-root is already set
        if ! grep -q '"data-root":' "${{DOCKER_DAEMON_CONFIG_FILE_PATH_TARGET}}"; then # No data-root key
             if ! grep -q '[^[:space:]]' "${{DOCKER_DAEMON_CONFIG_FILE_PATH_TARGET}}" || grep -q '^\\s*{{\\s*}}\\s*$' "${{DOCKER_DAEMON_CONFIG_FILE_PATH_TARGET}}"; then
                log "Existing daemon.json is empty or just {{}}. Will overwrite."
                CREATE_NEW_DAEMON_JSON=1
             else
                log "ERROR: Existing daemon.json is non-empty, lacks 'data-root', and jq is not available. Cannot safely update. Manual intervention required."
             fi
        elif ! grep -q '"data-root"\\s*:\\s*"${{PERSISTENT_DOCKER_ROOT_TARGET}}"' "${{DOCKER_DAEMON_CONFIG_FILE_PATH_TARGET}}"; then
             log "ERROR: Existing daemon.json has 'data-root' but points elsewhere, and jq is not available. Cannot safely update. Manual intervention required."
        else
            log "daemon.json exists and data-root seems correct (grep check)."
        fi
    fi
    if [ $CREATE_NEW_DAEMON_JSON -eq 1 ]; then
        log "Writing new/simple daemon.json (fallback method)..."
        echo "${{DESIRED_JSON_CONTENT}}" > "${{DOCKER_DAEMON_CONFIG_FILE_PATH_TARGET}}"
        chmod {DOCKER_CONFIG_PERMISSIONS_OCTAL:o} "${{DOCKER_DAEMON_CONFIG_FILE_PATH_TARGET}}"
        log "Successfully wrote simple daemon.json."
        DOCKER_CONFIG_HAS_CHANGED=1
    fi
fi
log "Docker daemon configuration check finished."

# Data Migration
log "Checking for existing Docker data in ephemeral location (${{DOCKER_EPHEMERAL_DATA_PATH_TARGET}})..."
if [ -d "${{DOCKER_EPHEMERAL_DATA_PATH_TARGET}}" ] && [ -n "$(ls -A "${{DOCKER_EPHEMERAL_DATA_PATH_TARGET}}" | grep -v -e '^lost+found$' -e '^\\.sbnb_persistent_redirect$' -e '^README_DO_NOT_USE\\.txt$' 2>/dev/null)" ]; then
    log "Found potentially significant data in ${{DOCKER_EPHEMERAL_DATA_PATH_TARGET}}."
    persistent_dir_is_effectively_empty=0
    if [ ! "$(ls -A "${{PERSISTENT_DOCKER_ROOT_TARGET}}" | grep -v '^lost+found$' 2>/dev/null)" ]; then
        persistent_dir_is_effectively_empty=1
    fi
    if [ $persistent_dir_is_effectively_empty -eq 1 ]; then
        log "Persistent location ${{PERSISTENT_DOCKER_ROOT_TARGET}} is empty. Proceeding with data migration..."
        if systemctl is-active --quiet docker; then
            log "Stopping Docker service for migration..."; systemctl stop docker || log "WARNING: Failed to stop Docker. Migration proceeding with risk!"; sleep 3
        fi
        log "Starting migration using 'cp -a -u' from '${{DOCKER_EPHEMERAL_DATA_PATH_TARGET}}/' to '${{PERSISTENT_DOCKER_ROOT_TARGET}}/'..."; MIGRATION_SUCCEEDED=0
        if cp -a -u "${{DOCKER_EPHEMERAL_DATA_PATH_TARGET}}/." "${{PERSISTENT_DOCKER_ROOT_TARGET}}/"; then # Source ends with /. to copy contents
             MIGRATION_SUCCEEDED=1
        else log "ERROR: 'cp -a -u' migration failed with exit code $?! Data may be inconsistent."; fi
        if [ $MIGRATION_SUCCEEDED -eq 1 ]; then
            log "Migration completed successfully."
            OLD_EPHEMERAL_DATA_BACKUP_PATH="${{DOCKER_EPHEMERAL_DATA_PATH_TARGET}}.migrated.$(date +%Y%m%d_%H%M%S).bak"
            log "Attempting to rename old ephemeral data directory to ${{OLD_EPHEMERAL_DATA_BACKUP_PATH}}..."
            if mv -T "${{DOCKER_EPHEMERAL_DATA_PATH_TARGET}}" "${{OLD_EPHEMERAL_DATA_BACKUP_PATH}}"; then log "Successfully renamed old ephemeral data directory."; else log "WARNING: Could not rename old ephemeral data directory ${{DOCKER_EPHEMERAL_DATA_PATH_TARGET}}."; fi
            DOCKER_CONFIG_HAS_CHANGED=1 # Docker needs restart after migration
        else log "ERROR: Data migration failed! Docker data in ${{PERSISTENT_DOCKER_ROOT_TARGET}} may be incomplete or inconsistent. Manual intervention required."; exit 1; fi
    else
        log "Persistent location ${{PERSISTENT_DOCKER_ROOT_TARGET}} already contains data. Skipping migration from ephemeral storage."
        # Optionally, rename the ephemeral data if it's unwanted and migration was skipped
        if [ -d "${{DOCKER_EPHEMERAL_DATA_PATH_TARGET}}" ]; then # Check again if it exists
            OLD_EPHEMERAL_DATA_IGNORED_PATH="${{DOCKER_EPHEMERAL_DATA_PATH_TARGET}}.ignored.$(date +%Y%m%d_%H%M%S).bak"
            log "Attempting to rename unused ephemeral data directory to ${{OLD_EPHEMERAL_DATA_IGNORED_PATH}}..."
            mv -T "${{DOCKER_EPHEMERAL_DATA_PATH_TARGET}}" "${{OLD_EPHEMERAL_DATA_IGNORED_PATH}}" || log "WARNING: Could not rename ephemeral data directory ${{DOCKER_EPHEMERAL_DATA_PATH_TARGET}}."
        fi
    fi
else
    log "No significant data found in ephemeral location ${{DOCKER_EPHEMERAL_DATA_PATH_TARGET}}. No migration needed."
fi
# Ensure the original ephemeral directory path exists but is empty, with a marker
log "Ensuring ephemeral path ${{DOCKER_EPHEMERAL_DATA_PATH_TARGET}} exists and is marked as unused."
if [ -d "${{DOCKER_EPHEMERAL_DATA_PATH_TARGET}}" ]; then rm -rf "${{DOCKER_EPHEMERAL_DATA_PATH_TARGET}}" || log "WARNING: Failed to remove original ephemeral directory after processing."; fi
mkdir -p "${{DOCKER_EPHEMERAL_DATA_PATH_TARGET}}"
touch "${{DOCKER_EPHEMERAL_DATA_PATH_TARGET}}/.sbnb_persistent_redirect"
echo "SBNB: Docker data is managed at ${{PERSISTENT_DOCKER_ROOT_TARGET}}. This directory should remain empty." > "${{DOCKER_EPHEMERAL_DATA_PATH_TARGET}}/README_DO_NOT_USE.txt"
chmod 0644 "${{DOCKER_EPHEMERAL_DATA_PATH_TARGET}}/README_DO_NOT_USE.txt"
chmod 0600 "${{DOCKER_EPHEMERAL_DATA_PATH_TARGET}}/.sbnb_persistent_redirect"
log "Data migration and ephemeral directory handling finished."

# Restart Docker Service if configuration was changed OR migration occurred
if [ $DOCKER_CONFIG_HAS_CHANGED -eq 1 ]; then
    log "Configuration or data migration requires Docker restart. Reloading daemon and restarting service..."
    if ! systemctl daemon-reload; then log "ERROR: Failed to reload systemd daemon! Docker restart might fail or use old config."; exit 1; fi
    log "Attempting to restart docker.service..."
    if systemctl restart docker.service; then log "Docker service restarted successfully."; else log "ERROR: Failed to restart Docker service! Check 'journalctl -u docker.service'."; exit 1; fi
else
    log "No configuration changes or migration occurred. Docker restart not required by this script's actions."
    # Optional: ensure Docker is running if it wasn't touched
    # if ! systemctl is-active --quiet docker.service; then log "Docker service not active. Attempting to start..."; systemctl start docker.service || log "WARNING: Failed to start inactive Docker."; fi
fi
log "Docker setup finished."

# --- Update Optional Development Environment Script ---
# This script is assumed to be located at {DATA_MOUNT}/scripts/sbnb-dev-env.sh if used
TARGET_DEV_ENV_SCRIPT_PATH="/usr/sbin/sbnb-dev-env.sh" # Target location on SBNB system
SOURCE_DEV_ENV_SCRIPT_PATH="${{DATA_MOUNT_POINT_TARGET}}/scripts/sbnb-dev-env.sh"

log "Checking for optional development environment script update: ${{SOURCE_DEV_ENV_SCRIPT_PATH}}"
if [ -f "${{SOURCE_DEV_ENV_SCRIPT_PATH}}" ] && [ -r "${{SOURCE_DEV_ENV_SCRIPT_PATH}}" ]; then
    log "Source development script found. Attempting atomic update of ${{TARGET_DEV_ENV_SCRIPT_PATH}}..."
    TARGET_DEV_SCRIPT_DIR=$(dirname "${{TARGET_DEV_ENV_SCRIPT_PATH}}")
    TEMP_DEV_SCRIPT_FILE=""
    # Setup trap for dev script update cleanup
    trap 'cleanup_dev_script_temp_file' EXIT HUP INT QUIT TERM
    cleanup_dev_script_temp_file() {{
        if [ -n "${{TEMP_DEV_SCRIPT_FILE:-}}" ] && [ -f "${{TEMP_DEV_SCRIPT_FILE}}" ]; then
            rm -f "${{TEMP_DEV_SCRIPT_FILE}}"
            log "Cleaned up temporary dev script file ${{TEMP_DEV_SCRIPT_FILE}}"
        fi
        trap - EXIT HUP INT QUIT TERM # Reset this specific trap
    }}
    if [ ! -d "${{TARGET_DEV_SCRIPT_DIR}}" ] || [ ! -w "${{TARGET_DEV_SCRIPT_DIR}}" ]; then log "WARNING: Target directory ${{TARGET_DEV_SCRIPT_DIR}} for dev script does not exist or is not writable. Cannot update script.";
    else
        TEMP_DEV_SCRIPT_FILE=$(mktemp "${{TARGET_DEV_SCRIPT_DIR}}/sbnb-dev-env.sh.tmp.XXXXXX")
        if [ -z "${{TEMP_DEV_SCRIPT_FILE}}" ] || [ ! -f "${{TEMP_DEV_SCRIPT_FILE}}" ]; then log "WARNING: Failed to create temporary file in ${{TARGET_DEV_SCRIPT_DIR}} for dev script. Skipping update."; TEMP_DEV_SCRIPT_FILE=""; # Prevent trap issues
        else
            if cp "${{SOURCE_DEV_ENV_SCRIPT_PATH}}" "${{TEMP_DEV_SCRIPT_FILE}}"; then
                if chmod +x "${{TEMP_DEV_SCRIPT_FILE}}"; then
                    if mv -T "${{TEMP_DEV_SCRIPT_FILE}}" "${{TARGET_DEV_ENV_SCRIPT_PATH}}"; then log "Successfully updated ${{TARGET_DEV_ENV_SCRIPT_PATH}}."; TEMP_DEV_SCRIPT_FILE=""; # Clear var so trap doesn't remove final script
                    else log "WARNING: Failed to move temporary dev script file ${{TEMP_DEV_SCRIPT_FILE}} to ${{TARGET_DEV_ENV_SCRIPT_PATH}}. Update failed."; fi
                else log "WARNING: Failed to set execute permissions on temporary dev script file ${{TEMP_DEV_SCRIPT_FILE}}. Update failed."; fi
            else log "WARNING: Failed to copy content from ${{SOURCE_DEV_ENV_SCRIPT_PATH}} to temporary dev script file ${{TEMP_DEV_SCRIPT_FILE}}. Update failed."; fi
        fi
        # Clean up temp file if it still exists (e.g., on mv failure) and TEMP_DEV_SCRIPT_FILE is set
        if [ -n "${{TEMP_DEV_SCRIPT_FILE:-}}" ] && [ -f "${{TEMP_DEV_SCRIPT_FILE}}" ]; then rm -f "${{TEMP_DEV_SCRIPT_FILE}}"; fi; TEMP_DEV_SCRIPT_FILE="";
    fi
    trap - EXIT HUP INT QUIT TERM # Clear specific trap explicitly
else
    log "NOTE: Source development script ${{SOURCE_DEV_ENV_SCRIPT_PATH}} not found or not readable. Skipping update."
fi
log "Update of optional development environment script finished."

# --- Enable Systemd Units (Backup/Purge + Health/Volume Checks) ---
SYSTEMD_UNITS_SOURCE_DIR="${{DATA_MOUNT_POINT_TARGET}}/systemd"
SYSTEMD_UNITS_TARGET_DIR="/etc/systemd/system" # Standard systemd unit location
SYSTEMD_TIMERS_WANTS_DIR="${{SYSTEMD_UNITS_TARGET_DIR}}/timers.target.wants" # For enabling timers

log "Enabling custom systemd units (Source: ${{SYSTEMD_UNITS_SOURCE_DIR}})..."
if [ -d "${{SYSTEMD_UNITS_SOURCE_DIR}}" ] && [ -r "${{SYSTEMD_UNITS_SOURCE_DIR}}" ]; then
    mkdir -p "${{SYSTEMD_UNITS_TARGET_DIR}}" # Ensure target systemd directory exists
    mkdir -p "${{SYSTEMD_TIMERS_WANTS_DIR}}" # Ensure timers.target.wants directory exists
    
    any_units_linked=0
    log "Linking systemd unit files from ${{SYSTEMD_UNITS_SOURCE_DIR}} to ${{SYSTEMD_UNITS_TARGET_DIR}}..."
    # Use find with -print0 and read -d '' for safe filename handling, even with spaces/special chars
    find "${{SYSTEMD_UNITS_SOURCE_DIR}}" -maxdepth 1 -type f \\( -name '*.service' -o -name '*.timer' \\) -print0 | while IFS= read -r -d '' source_unit_file_path; do
        unit_filename=$(basename "${{source_unit_file_path}}")
        target_symlink_path="${{SYSTEMD_UNITS_TARGET_DIR}}/${{unit_filename}}"
        log "  Linking ${{unit_filename}} to ${{target_symlink_path}}..."
        # Use ln -sf: symbolic, force overwrite if link exists
        if ln -sf "${{source_unit_file_path}}" "${{target_symlink_path}}"; then
            any_units_linked=1
        else
            log "  WARNING: Failed to link systemd unit ${{unit_filename}}."
        fi
    done

    if [ $any_units_linked -eq 0 ]; then
        log "No systemd unit files found in ${{SYSTEMD_UNITS_SOURCE_DIR}} to link."
    else
        log "Reloading systemd daemon after linking unit files..."
        # Reload daemon again (might be redundant if Docker restart already did it, but safe practice)
        systemctl daemon-reload || log "WARNING: 'systemctl daemon-reload' failed after linking units. Units may not be recognized."

        log "Enabling relevant systemd timers and services..."
        any_units_enabled=0
        # Define ALL units expected to be enabled by this script for clarity
        UNITS_TO_BE_ENABLED="docker-backup.timer docker-purge.timer docker-shutdown-backup.service docker-health-check.timer docker-volume-check.timer"
        final_list_of_enabled_units=""
        # Use 'for unit_to_enable_name in $UNITS_TO_BE_ENABLED' which relies on word splitting (safe here as names are simple)
        # shellcheck disable=SC2086
        for unit_to_enable_name in $UNITS_TO_BE_ENABLED; do
            # Check if the link exists and points to an actual file before enabling
            if [ -L "${{SYSTEMD_UNITS_TARGET_DIR}}/${{unit_to_enable_name}}" ] && [ -f "${{SYSTEMD_UNITS_TARGET_DIR}}/${{unit_to_enable_name}}" ]; then
                log "  Enabling systemd unit: ${{unit_to_enable_name}}..."
                # Use --now to also start timers immediately if desired, otherwise just enable for next boot/trigger
                if systemctl enable "${{unit_to_enable_name}}"; then # Add --now here if timers should start immediately
                    any_units_enabled=1
                    final_list_of_enabled_units="${{final_list_of_enabled_units}} ${{unit_to_enable_name}}"
                else
                    log "  WARNING: Failed to enable systemd unit ${{unit_to_enable_name}}."
                fi
            else
                log "  Skipping enable for systemd unit ${{unit_to_enable_name}} (symlink missing or broken in ${{SYSTEMD_UNITS_TARGET_DIR}})."
            fi
        done

        if [ $any_units_enabled -eq 1 ]; then
            final_list_of_enabled_units=$(echo "${{final_list_of_enabled_units}}" | sed 's/^ *//') # Remove leading space
            log "Systemd units enabled successfully: ${{final_list_of_enabled_units}}"
        else
            log "No relevant systemd units were successfully enabled from the list."
        fi
    fi # end if any_units_linked
else
    log "WARNING: Systemd source directory ${{SYSTEMD_UNITS_SOURCE_DIR}} not found or not readable. Cannot enable custom systemd units."
fi
log "Systemd unit setup finished."

# --- Script Finish Logging ---
log "SBNB custom boot commands completed successfully."

# Clear main script trap if any was set by mistake from within this generated script (should not happen)
trap - EXIT HUP INT QUIT TERM
exit 0
'''

# --- Tailscale Key File Content ---
# TAILSCALE_AUTH_KEY_CONTENT is already defined from environment variable

# --- Backup Script Content ---
BACKUP_DOCKER_SH_CONTENT = f'''#!/bin/sh
# SBNB Docker Backup Script
# File: {DATA_MOUNT}/scripts/backup-docker.sh
set -e -u

DOCKER_DATA_DIR_TO_BACKUP="{PERSISTENT_DOCKER_ROOT}" # Source is PERSISTENT root
BACKUP_DESTINATION_DIR="{BACKUP_BASE_DIR_TARGET}"
CURRENT_TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_ARCHIVE_FILE="${{BACKUP_DESTINATION_DIR}}/docker_backup_${{CURRENT_TIMESTAMP}}.tar.gz"
LATEST_BACKUP_SYMLINK="${{BACKUP_DESTINATION_DIR}}/docker_latest.tar.gz"
SHOULD_STOP_DOCKER={STOP_DOCKER_FOR_BACKUP_CONFIG} # 1=Stop Docker (safer), 0=Live backup

log_backup() {{ echo "[backup-docker.sh] $1" > /dev/kmsg; }}

check_backup_cmds() {{
    local missing_cmd_flag_backup=0
    for cmd_item_backup in "$@"; do
        if ! command -v "$cmd_item_backup" >/dev/null 2>&1; then log_backup "ERROR: Command '$cmd_item_backup' not found."; missing_cmd_flag_backup=1; fi
    done
    [ $missing_cmd_flag_backup -eq 1 ] && exit 1 # Exit if any command is missing
}}
# Core commands needed for backup
check_backup_cmds date mkdir tar gzip ln mv sleep dirname basename
# Check systemctl only if stopping docker is enabled
[ $SHOULD_STOP_DOCKER -eq 1 ] && check_backup_cmds systemctl

NICE_COMMAND_PREFIX=""
if command -v nice >/dev/null 2>&1; then NICE_COMMAND_PREFIX="nice -n 19"; log_backup "Using 'nice' for lower tar priority."; fi

log_backup "Starting Docker backup process..."
log_backup "Source:         ${{DOCKER_DATA_DIR_TO_BACKUP}}"
log_backup "Destination:    ${{BACKUP_ARCHIVE_FILE}}"

log_backup "Ensuring backup destination directory exists: ${{BACKUP_DESTINATION_DIR}}"
mkdir -p "${{BACKUP_DESTINATION_DIR}}"
if [ ! -w "${{BACKUP_DESTINATION_DIR}}" ]; then log_backup "ERROR: Backup directory not writable: ${{BACKUP_DESTINATION_DIR}}"; exit 1; fi

DOCKER_SERVICE_WAS_RUNNING=0
if [ $SHOULD_STOP_DOCKER -eq 1 ]; then
    log_backup "Attempting to stop Docker service for safer backup..."
    if systemctl is-active --quiet docker.service; then
        DOCKER_SERVICE_WAS_RUNNING=1
        log_backup "Docker service is active, stopping..."
        if systemctl stop docker.service; then
            log_backup "Docker service stopped. Waiting 5 seconds for files to release..."; sleep 5
        else
            log_backup "ERROR: Failed to stop Docker service gracefully! Backup might be inconsistent or fail. Aborting."
            exit 1 # Exit if stop fails, as backup consistency is compromised
        fi
    else
        log_backup "Docker service was already stopped."
    fi
fi

log_backup "Creating backup archive..."
if [ -d "${{DOCKER_DATA_DIR_TO_BACKUP}}" ] && [ -r "${{DOCKER_DATA_DIR_TO_BACKUP}}" ]; then
    PARENT_DIR_OF_SOURCE=$(dirname "${{DOCKER_DATA_DIR_TO_BACKUP}}")
    SOURCE_DIR_BASENAME=$(basename "${{DOCKER_DATA_DIR_TO_BACKUP}}")
    log_backup "Archiving '${{SOURCE_DIR_BASENAME}}' from parent directory '${{PARENT_DIR_OF_SOURCE}}'..."
    # Use -C to change directory, archive relative path 'docker-root/...'
    # Add --warning=no-file-changed to suppress warnings about files changing during read
    # shellcheck disable=SC2086 # Allow word splitting for $NICE_COMMAND_PREFIX
    if ${{NICE_COMMAND_PREFIX}} tar --warning=no-file-changed -czf "${{BACKUP_ARCHIVE_FILE}}" -C "${{PARENT_DIR_OF_SOURCE}}" "${{SOURCE_DIR_BASENAME}}"; then
        log_backup "Backup archive created successfully: ${{BACKUP_ARCHIVE_FILE}}"
        if [ -s "${{BACKUP_ARCHIVE_FILE}}" ]; then # Check if file exists and is not empty
            log_backup "Updating latest backup symlink: ${{LATEST_BACKUP_SYMLINK}}"
            # Atomic symlink update: create temp link, then rename over old one
            ln -sfT "${{BACKUP_ARCHIVE_FILE}}" "${{LATEST_BACKUP_SYMLINK}}.tmp" && mv -Tf "${{LATEST_BACKUP_SYMLINK}}.tmp" "${{LATEST_BACKUP_SYMLINK}}"
            if [ $? -eq 0 ]; then log_backup "Updated latest symlink to point to ${{BACKUP_ARCHIVE_FILE}}."; else log_backup "WARNING: Failed to update latest backup symlink."; rm -f "${{LATEST_BACKUP_SYMLINK}}.tmp"; fi
        else log_backup "WARNING: Backup file seems invalid (empty or missing): ${{BACKUP_ARCHIVE_FILE}}. Removing."; rm -f "${{BACKUP_ARCHIVE_FILE}}"; fi
    else
        tar_exit_code_backup=$?
        log_backup "ERROR: tar command failed with exit code ${{tar_exit_code_backup}}! Backup failed."
        rm -f "${{BACKUP_ARCHIVE_FILE}}" # Clean up partial archive if tar failed
    fi
else
    log_backup "WARNING: Docker data directory not found or not readable: ${{DOCKER_DATA_DIR_TO_BACKUP}}. Skipping backup."
fi

if [ $DOCKER_SERVICE_WAS_RUNNING -eq 1 ]; then
    log_backup "Restarting Docker service..."
    if ! systemctl start docker.service; then log_backup "WARNING: Failed to restart Docker service after backup."; else log_backup "Docker service restarted."; fi
fi
log_backup "Docker backup process finished."; exit 0
'''

# --- Purge Script Content ---
PURGE_DOCKER_BACKUPS_SH_CONTENT = f'''#!/bin/sh
# SBNB Docker Backups Purge Script
# File: {DATA_MOUNT}/scripts/purge-docker-backups.sh
set -e -u

BACKUPS_DIRECTORY_TO_PURGE="{BACKUP_BASE_DIR_TARGET}"
NUMBER_OF_BACKUPS_TO_KEEP={BACKUP_KEEP_COUNT_CONFIG}

log_purge() {{ echo "[purge-docker-backups.sh] $1" > /dev/kmsg; }}

check_purge_cmds() {{
    local missing_cmd_flag_purge=0
    for cmd_item_purge in "$@"; do if ! command -v "$cmd_item_purge" >/dev/null 2>&1; then log_purge "ERROR: Command '$cmd_item_purge' not found."; missing_cmd_flag_purge=1; fi; done
    [ $missing_cmd_flag_purge -eq 1 ] && exit 1
}}
check_purge_cmds find wc sort head cut xargs rm mkdir date

log_purge "Purging old Docker backups in ${{BACKUPS_DIRECTORY_TO_PURGE}}, keeping last ${{NUMBER_OF_BACKUPS_TO_KEEP}}..."

if ! [ "$NUMBER_OF_BACKUPS_TO_KEEP" -ge 0 ] 2>/dev/null; then log_purge "ERROR: NUMBER_OF_BACKUPS_TO_KEEP (${{NUMBER_OF_BACKUPS_TO_KEEP}}) is invalid."; exit 1; fi
if ! mkdir -p "${{BACKUPS_DIRECTORY_TO_PURGE}}"; then log_purge "ERROR: Failed to create backup directory ${{BACKUPS_DIRECTORY_TO_PURGE}}!"; exit 1; fi
if [ ! -d "${{BACKUPS_DIRECTORY_TO_PURGE}}" ] || [ ! -r "${{BACKUPS_DIRECTORY_TO_PURGE}}" ] || [ ! -w "${{BACKUPS_DIRECTORY_TO_PURGE}}" ]; then log_purge "ERROR: Cannot access backup directory ${{BACKUPS_DIRECTORY_TO_PURGE}}!"; exit 1; fi

log_purge "Counting existing backup files matching 'docker_backup_*.tar.gz'..."
# Use find -print to count, handle potential errors from find itself
current_backup_files_count=$(find "${{BACKUPS_DIRECTORY_TO_PURGE}}" -maxdepth 1 -name 'docker_backup_*.tar.gz' -type f -print 2>/dev/null | wc -l)
find_command_exit_code=$?

if [ $find_command_exit_code -ne 0 ]; then log_purge "WARNING: 'find' command failed (exit code ${{find_command_exit_code}}) while counting backups. Skipping purge."; exit 0; fi
log_purge "Found ${{current_backup_files_count}} backup files."

if [ "$current_backup_files_count" -gt "$NUMBER_OF_BACKUPS_TO_KEEP" ]; then
    number_of_backups_to_delete=$(( current_backup_files_count - NUMBER_OF_BACKUPS_TO_KEEP ))
    log_purge "Need to delete ${{number_of_backups_to_delete}} oldest backup(s)."

    log_purge "Identifying oldest backups to delete using find, sort, head, cut, xargs..."
    # Use find -printf with null terminators for safe filename handling with xargs -0
    # Sort by modification time (%T@), take the oldest ones, extract filename, then delete.
    # Capture rm output (stdout+stderr) for logging
    delete_operation_output=$(find "${{BACKUPS_DIRECTORY_TO_PURGE}}" -maxdepth 1 -name 'docker_backup_*.tar.gz' -type f -printf '%T@ %p\\0' 2>/dev/null | \\
        sort -zn | \\
        head -zn "${{number_of_backups_to_delete}}" | \\
        cut -z -d' ' -f2- | \\
        xargs -0 -r rm -v -- 2>&1) # xargs -0 -r: null delimited, run if not empty; rm -v: verbose
    remove_command_exit_code=$?

    if [ $remove_command_exit_code -eq 0 ]; then
        log_purge "Purge command completed successfully."
        if [ -n "$delete_operation_output" ]; then # Log deleted files if any output from rm -v
            log_purge "Deleted files:"
            echo "$delete_operation_output" | while IFS= read -r log_line || [ -n "$log_line" ]; do log_purge "  $log_line"; done
        fi
    else
        log_purge "WARNING: Purge command (rm) failed with exit code ${{remove_command_exit_code}}. Check output below."
        log_purge "rm command output:"
        echo "$delete_operation_output" | while IFS= read -r log_line || [ -n "$log_line" ]; do log_purge "  $log_line"; done
    fi
else
    log_purge "${{current_backup_files_count}} backups found, which is less than or equal to ${{NUMBER_OF_BACKUPS_TO_KEEP}}. No backups purged."
fi
log_purge "Docker backup purge process finished."; exit 0
'''

# --- Health Check Script Content ---
DOCKER_HEALTH_CHECK_SH_CONTENT = f'''#!/bin/sh
# SBNB Docker Health Check Script
# File: {DATA_MOUNT}/scripts/docker-health-check.sh
set -e -u

PERSISTENT_DOCKER_ROOT_FOR_HEALTH_CHECK="{PERSISTENT_DOCKER_ROOT}"
DOCKER_DAEMON_CONFIG_FILE_FOR_HEALTH_CHECK="{DOCKER_CONFIG_FILE_TARGET}" # For reference in logs

log_health() {{ echo "[docker-health-check] $1" | tee /dev/kmsg; }} # Log to kmsg and stdout/stderr for immediate visibility

log_health "Starting Docker health check..."

check_health_cmds() {{ for c_health in "$@"; do if ! command -v "$c_health" >/dev/null 2>&1; then log_health "ERROR: Command '$c_health' not found."; exit 1; fi; done }}
check_health_cmds systemctl docker # Essential for this script

log_health "Checking if docker.service is active..."
if ! systemctl is-active --quiet docker.service; then
    log_health "WARNING: Docker service is not running. Attempting to restart..."
    if systemctl restart docker.service; then log_health "Docker service restarted successfully."; sleep 5; # Give time to start
    else log_health "ERROR: Failed to restart inactive Docker service! Requires manual investigation."; exit 1; fi
fi

log_health "Checking Docker daemon responsiveness via 'docker info'..."
if ! docker info > /dev/null 2>&1; then
    log_health "WARNING: Docker service is running but 'docker info' command failed. Attempting restart..."
    if systemctl restart docker.service; then log_health "Docker service restarted successfully after 'info' failure."; sleep 5; # Give time
        if ! docker info > /dev/null 2>&1; then log_health "ERROR: Docker daemon still not responding after restart! Requires manual investigation."; exit 1;
        else log_health "Docker daemon is now responsive after restart."; fi
    else log_health "ERROR: Failed to restart unresponsive Docker service! Requires manual investigation."; exit 1; fi
else log_health "Docker daemon is responsive."; fi

log_health "Checking configured Docker data-root directory..."
# Use docker info with Go template for precise extraction; handle potential error if Docker is broken
CURRENT_DOCKER_ROOT_DIR=$(docker info --format '{{{{.DockerRootDir}}}}' 2>/dev/null || echo "ERROR_GETTING_DOCKER_INFO")

if [ "$CURRENT_DOCKER_ROOT_DIR" = "ERROR_GETTING_DOCKER_INFO" ]; then
    log_health "ERROR: Could not determine Docker's current data-root using 'docker info'. Health check incomplete. Docker might be broken."
    exit 1 # Exit as this is a significant issue
elif [ "$CURRENT_DOCKER_ROOT_DIR" != "$PERSISTENT_DOCKER_ROOT_FOR_HEALTH_CHECK" ]; then
    log_health "CRITICAL ERROR: Docker is using an INCORRECT data-root directory!"
    log_health "  Expected: $PERSISTENT_DOCKER_ROOT_FOR_HEALTH_CHECK"
    log_health "  Actual:   $CURRENT_DOCKER_ROOT_DIR"
    log_health "This indicates a serious configuration problem in $DOCKER_DAEMON_CONFIG_FILE_FOR_HEALTH_CHECK or Docker failed to apply it. Manual intervention required."
    exit 1 # Critical configuration error
else
    log_health "Docker is correctly using the persistent data-root: $PERSISTENT_DOCKER_ROOT_FOR_HEALTH_CHECK"
fi
log_health "Docker health check completed successfully."; exit 0
'''

# --- Volume Check Script Content ---
# Define prune command based on configuration
if VOLUME_CHECK_PRUNE_LEVEL_CONFIG == 0: PRUNE_COMMAND_CONFIG = "echo 'Automatic Docker pruning is disabled (Level 0).'" # No-op
elif VOLUME_CHECK_PRUNE_LEVEL_CONFIG == 1: PRUNE_COMMAND_CONFIG = "docker container prune -f && docker image prune -f" # Prune stopped containers and dangling images only
elif VOLUME_CHECK_PRUNE_LEVEL_CONFIG >= 2: PRUNE_COMMAND_CONFIG = "docker container prune -f && docker image prune -a -f" # Prune stopped containers and *all* unused images
else: PRUNE_COMMAND_CONFIG = "docker container prune -f && docker image prune -f" # Default to level 1 if invalid config

DOCKER_VOLUME_CHECK_SH_CONTENT = f'''#!/bin/sh
# SBNB Docker Volume Space Check Script
# File: {DATA_MOUNT}/scripts/docker-volume-check.sh
set -e -u

DOCKER_PERSISTENT_ROOT_FOR_VOLUME_CHECK="{PERSISTENT_DOCKER_ROOT}"
MINIMUM_FREE_SPACE_PERCENTAGE={VOLUME_CHECK_THRESHOLD_PERCENT_CONFIG}
# Prune command determined by Python script configuration (Level: {VOLUME_CHECK_PRUNE_LEVEL_CONFIG})
DOCKER_PRUNE_COMMAND_TO_RUN="{PRUNE_COMMAND_CONFIG}"

log_volume() {{ echo "[docker-volume-check] $1" | tee /dev/kmsg; }}

log_volume "Checking Docker volume free space for: ${{DOCKER_PERSISTENT_ROOT_FOR_VOLUME_CHECK}}"

check_volume_cmds() {{ for c_vol in "$@"; do if ! command -v "$c_vol" >/dev/null 2>&1; then log_volume "ERROR: Command '$c_vol' not found."; exit 1; fi; done }}
check_volume_cmds df awk sed docker # Need docker if pruning is enabled

if [ ! -d "$DOCKER_PERSISTENT_ROOT_FOR_VOLUME_CHECK" ]; then log_volume "ERROR: Docker root directory not found: $DOCKER_PERSISTENT_ROOT_FOR_VOLUME_CHECK"; exit 1; fi

log_volume "Calculating free space using 'df -P'..."
# Get Available and Total blocks (in 1K blocks usually for POSIX df -P)
df_output_volume=$(df -P "$DOCKER_PERSISTENT_ROOT_FOR_VOLUME_CHECK" | awk 'NR==2 {{print $4, $2}}' 2>/dev/null)
if [ -z "$df_output_volume" ]; then log_volume "ERROR: Failed to get disk usage using 'df -P' for $DOCKER_PERSISTENT_ROOT_FOR_VOLUME_CHECK. Check path and df command."; exit 1; fi

available_kb_volume=$(echo "$df_output_volume" | awk '{{print $1}}')
total_kb_volume=$(echo "$df_output_volume" | awk '{{print $2}}')

if ! [[ "$available_kb_volume" =~ ^[0-9]+$ ]] || ! [[ "$total_kb_volume" =~ ^[0-9]+$ ]]; then log_volume "ERROR: Invalid (non-numeric) disk space values from df: Avail='$available_kb_volume', Total='$total_kb_volume'"; exit 1; fi
if [ "$total_kb_volume" -le 0 ]; then log_volume "WARNING: Total disk size reported as zero or invalid for $DOCKER_PERSISTENT_ROOT_FOR_VOLUME_CHECK. Cannot calculate percentage accurately."; exit 0; fi # Exit gracefully, can't do much

current_free_percentage=$(( (available_kb_volume * 100) / total_kb_volume ))
total_size_human_readable=$(df -h "$DOCKER_PERSISTENT_ROOT_FOR_VOLUME_CHECK" | awk 'NR==2 {{print $2}}') # For logging
available_size_human_readable=$(df -h "$DOCKER_PERSISTENT_ROOT_FOR_VOLUME_CHECK" | awk 'NR==2 {{print $4}}') # For logging

log_volume "Volume Stats: Total=${{total_size_human_readable}}, Available=${{available_size_human_readable}}, Free=${{current_free_percentage}}%"

if [ "$current_free_percentage" -lt "$MINIMUM_FREE_SPACE_PERCENTAGE" ]; then
    log_volume "WARNING: Low disk space detected! Free: ${{current_free_percentage}}% (Threshold is ${{MINIMUM_FREE_SPACE_PERCENTAGE}}%)"
    if [ {VOLUME_CHECK_PRUNE_LEVEL_CONFIG} -gt 0 ]; then
        log_volume "Attempting automatic Docker prune (Level: {VOLUME_CHECK_PRUNE_LEVEL_CONFIG}) due to low space..."
        prune_operation_full_output=$({DOCKER_PRUNE_COMMAND_TO_RUN} 2>&1) || prune_command_exit_code=$? # Capture output and exit code
        if [ "${{prune_command_exit_code:-0}}" -eq 0 ]; then log_volume "Docker prune command executed successfully."; else log_volume "WARNING: Docker prune command finished with exit code ${{prune_command_exit_code}}. Check output."; fi
        log_volume "Prune command output:"
        echo "$prune_operation_full_output" | while IFS= read -r log_line_prune || [ -n "$log_line_prune" ]; do log_volume "  $log_line_prune"; done

        log_volume "Recalculating free space after cleanup attempt..."
        df_output_after_prune=$(df -P "$DOCKER_PERSISTENT_ROOT_FOR_VOLUME_CHECK" | awk 'NR==2 {{print $4, $2}}' 2>/dev/null)
        available_kb_after_prune=$(echo "$df_output_after_prune" | awk '{{print $1}}'); total_kb_after_prune=$(echo "$df_output_after_prune" | awk '{{print $2}}')
        if ! [[ "$available_kb_after_prune" =~ ^[0-9]+$ ]] || ! [[ "$total_kb_after_prune" =~ ^[0-9]+$ ]]; then log_volume "ERROR: Invalid disk space values after prune."; current_free_percentage_after_prune="N/A"; else
        if [ "$total_kb_after_prune" -gt 0 ]; then current_free_percentage_after_prune=$(( (available_kb_after_prune * 100) / total_kb_after_prune )); else current_free_percentage_after_prune=0; fi; fi
        available_size_hr_after_prune=$(df -h "$DOCKER_PERSISTENT_ROOT_FOR_VOLUME_CHECK" | awk 'NR==2 {{print $4}}')
        log_volume "Space after cleanup: Available=${{available_size_hr_after_prune}}, Free=${{current_free_percentage_after_prune}}%"
        if [ "$current_free_percentage_after_prune" != "N/A" ] && [ "$current_free_percentage_after_prune" -lt "$MINIMUM_FREE_SPACE_PERCENTAGE" ]; then log_volume "ERROR: Disk space is still critically low after cleanup attempt! Manual intervention likely required.";
        else log_volume "Disk space is now above threshold after cleanup, or was not critically low."; fi
    else log_volume "Automatic Docker pruning is disabled (Level 0). Manual cleanup is needed for low space condition."; fi
else log_volume "Sufficient free space available (${{current_free_percentage}}%). No cleanup action needed by this script."; fi
log_volume "Docker volume space check completed."; exit 0
'''

# --- Systemd Unit File Contents (Concise for brevity in Python script) ---
DOCKER_BACKUP_SERVICE_CONTENT = f"""[Unit]
Description=SBNB - Backup Docker Data ({PERSISTENT_DOCKER_ROOT})
Documentation=file://{DATA_MOUNT}/scripts/backup-docker.sh
Requires=mnt-sbnb-data.mount
After=mnt-sbnb-data.mount docker.service

[Service]
Type=oneshot
ExecStart=/bin/sh {DATA_MOUNT}/scripts/backup-docker.sh
"""
DOCKER_BACKUP_TIMER_CONTENT = f"""[Unit]
Description=SBNB - Daily Docker Backup Timer
Requires=docker-backup.service

[Timer]
OnCalendar=daily
AccuracySec=1h
Persistent=true
RandomizedDelaySec=600

[Install]
WantedBy=timers.target
""" # OnCalendar=daily is equivalent to *-*-* 00:00:00, often preferred for readability
DOCKER_PURGE_SERVICE_CONTENT = f"""[Unit]
Description=SBNB - Purge Old Docker Backups ({BACKUP_BASE_DIR_TARGET})
Documentation=file://{DATA_MOUNT}/scripts/purge-docker-backups.sh
Requires=mnt-sbnb-data.mount
After=mnt-sbnb-data.mount

[Service]
Type=oneshot
ExecStart=/bin/sh {DATA_MOUNT}/scripts/purge-docker-backups.sh
"""
DOCKER_PURGE_TIMER_CONTENT = f"""[Unit]
Description=SBNB - Daily Docker Backup Purge Timer
Requires=docker-purge.service

[Timer]
OnCalendar=daily # Runs shortly after backup timer due to typical execution order or can be offset
AccuracySec=1h
Persistent=true
RandomizedDelaySec=900 # Slightly different delay

[Install]
WantedBy=timers.target
"""
DOCKER_SHUTDOWN_BACKUP_SERVICE_CONTENT = f"""[Unit]
Description=SBNB - Backup Docker Data on Shutdown (Best Effort)
Documentation=file://{DATA_MOUNT}/scripts/backup-docker.sh
DefaultDependencies=no
Requires=mnt-sbnb-data.mount docker.service
After=mnt-sbnb-data.mount docker.service network.target
Before=shutdown.target reboot.target halt.target kexec.target umount.target final.target

[Service]
Type=oneshot
RemainAfterExit=true
TimeoutStopSec=180
ExecStop=/bin/sh {DATA_MOUNT}/scripts/backup-docker.sh

[Install]
WantedBy=shutdown.target reboot.target halt.target kexec.target
"""
DOCKER_HEALTH_SERVICE_CONTENT = f"""[Unit]
Description=SBNB - Docker Health Check Service
Documentation=file://{DATA_MOUNT}/scripts/docker-health-check.sh
Requires=mnt-sbnb-data.mount docker.service
After=mnt-sbnb-data.mount docker.service

[Service]
Type=oneshot
ExecStart=/bin/sh {DATA_MOUNT}/scripts/docker-health-check.sh
"""
DOCKER_HEALTH_TIMER_CONTENT = f"""[Unit]
Description=SBNB - Regular Docker Health Check Timer
Requires=docker-health-check.service

[Timer]
OnBootSec=5min
OnUnitActiveSec=15min # Runs 15 minutes after the last time it was activated
AccuracySec=1min

[Install]
WantedBy=timers.target
"""
DOCKER_VOLUME_SERVICE_CONTENT = f"""[Unit]
Description=SBNB - Docker Volume Space Check Service ({PERSISTENT_DOCKER_ROOT})
Documentation=file://{DATA_MOUNT}/scripts/docker-volume-check.sh
Requires=mnt-sbnb-data.mount docker.service
After=mnt-sbnb-data.mount docker.service

[Service]
Type=oneshot
ExecStart=/bin/sh {DATA_MOUNT}/scripts/docker-volume-check.sh
"""
DOCKER_VOLUME_TIMER_CONTENT = f"""[Unit]
Description=SBNB - Regular Docker Volume Check Timer
Requires=docker-volume-check.service

[Timer]
OnBootSec=10min
OnUnitActiveSec=1h # Runs 1 hour after the last time it was activated
AccuracySec=5min

[Install]
WantedBy=timers.target
"""

# --- Dictionary of All Files to Create ---
FILES_TO_CREATE_PY = {
    # --- ESP Files ---
    f"{ESP_MOUNT}/sbnb-cmds.sh": {"content": SBNB_CMDS_SH_CONTENT, "permissions": 0o755}, # rwxr-xr-x
    f"{ESP_MOUNT}/sbnb-tskey.txt": {"content": TAILSCALE_AUTH_KEY_CONTENT, "permissions": 0o600}, # rw-------
    # --- Data Partition Files ---
    # Helper Scripts in {DATA_MOUNT}/scripts/
    f"{DATA_MOUNT}/scripts/backup-docker.sh": {"content": BACKUP_DOCKER_SH_CONTENT, "permissions": 0o750}, # rwxr-x---
    f"{DATA_MOUNT}/scripts/purge-docker-backups.sh": {"content": PURGE_DOCKER_BACKUPS_SH_CONTENT, "permissions": 0o750},
    f"{DATA_MOUNT}/scripts/docker-health-check.sh": {"content": DOCKER_HEALTH_CHECK_SH_CONTENT, "permissions": 0o750},
    f"{DATA_MOUNT}/scripts/docker-volume-check.sh": {"content": DOCKER_VOLUME_CHECK_SH_CONTENT, "permissions": 0o750},
    # Systemd Units in {DATA_MOUNT}/systemd/
    f"{DATA_MOUNT}/systemd/docker-backup.service": {"content": DOCKER_BACKUP_SERVICE_CONTENT, "permissions": 0o644}, # rw-r--r--
    f"{DATA_MOUNT}/systemd/docker-backup.timer": {"content": DOCKER_BACKUP_TIMER_CONTENT, "permissions": 0o644},
    f"{DATA_MOUNT}/systemd/docker-purge.service": {"content": DOCKER_PURGE_SERVICE_CONTENT, "permissions": 0o644},
    f"{DATA_MOUNT}/systemd/docker-purge.timer": {"content": DOCKER_PURGE_TIMER_CONTENT, "permissions": 0o644},
    f"{DATA_MOUNT}/systemd/docker-shutdown-backup.service": {"content": DOCKER_SHUTDOWN_BACKUP_SERVICE_CONTENT, "permissions": 0o644},
    f"{DATA_MOUNT}/systemd/docker-health-check.service": {"content": DOCKER_HEALTH_SERVICE_CONTENT, "permissions": 0o644},
    f"{DATA_MOUNT}/systemd/docker-health-check.timer": {"content": DOCKER_HEALTH_TIMER_CONTENT, "permissions": 0o644},
    f"{DATA_MOUNT}/systemd/docker-volume-check.service": {"content": DOCKER_VOLUME_SERVICE_CONTENT, "permissions": 0o644},
    f"{DATA_MOUNT}/systemd/docker-volume-check.timer": {"content": DOCKER_VOLUME_TIMER_CONTENT, "permissions": 0o644},
}

# --- Global counters for create_files_py status ---
py_warning_count = 0
py_fail_count = 0

# --- Main Python Script Logic ---
def check_python_script_prerequisites():
    """Verify script prerequisites before attempting file creation."""
    print("--- PYTHON: Checking Prerequisites ---")
    prerequisites_passed = True
    # UID check is implicitly handled by parent Bash script ensuring root
    print(f"PYTHON: Running as UID {os.geteuid()}. Expecting 0 (root).")

    mount_points_to_check = {ESP_MOUNT: "ESP", DATA_MOUNT: "Data"}
    for mount_path_str, name_str in mount_points_to_check.items():
        mount_path_obj = pathlib.Path(mount_path_str)
        print(f"PYTHON: Checking {name_str} mount point: {mount_path_str}...")
        if not mount_path_obj.is_dir():
            print(f"PYTHON ERROR: Base {name_str} directory '{mount_path_str}' does not exist or is not a directory.", file=sys.stderr)
            prerequisites_passed = False
        elif not os.access(mount_path_obj, os.W_OK): # Check writability by current user (root)
            print(f"PYTHON ERROR: Base {name_str} directory '{mount_path_str}' is not writable by current user (UID {os.geteuid()}). Check mount options or permissions.", file=sys.stderr)
            prerequisites_passed = False
        else:
            print(f"PYTHON: OK: Base {name_str} directory '{mount_path_str}' exists and is writable.")
    
    # Check for optional but recommended commands needed by generated scripts (on target system)
    # This Python script only informs; sbnb-cmds.sh does the runtime check on target.
    print("PYTHON: Checking for optional command (jq) availability on this preparation host (for info only)...")
    if shutil.which("jq"): print("PYTHON: OK: 'jq' command found on this host (recommended for robust daemon.json handling by generated script).")
    else: print("PYTHON: WARNING: 'jq' command not found on this host. Generated sbnb-cmds.sh will use less robust methods for daemon.json if jq is also missing on target.")

    if not prerequisites_passed:
        print("PYTHON ERROR: Prerequisites not met. Aborting Python script.", file=sys.stderr)
        sys.exit(1) # Exit Python script with error
    print("--- PYTHON: Prerequisites OK ---")
    return True

def create_all_files_py():
    """Creates directories and files as defined in FILES_TO_CREATE_PY."""
    global py_warning_count, py_fail_count # Declare intent to modify globals
    print("\n--- PYTHON: Starting File Creation Process ---")
    files_successfully_processed = 0
    py_warning_count = 0 # Reset global counter
    py_fail_count = 0    # Reset global counter

    # Ensure the base backup directory exists first with correct permissions
    try:
        print(f"\nPYTHON: Ensuring base backup directory exists: {BACKUP_BASE_DIR_TARGET}")
        os.makedirs(BACKUP_BASE_DIR_TARGET, mode=BACKUP_DIR_PERMISSIONS_OCTAL, exist_ok=True)
        current_backup_dir_perm = stat.S_IMODE(os.stat(BACKUP_BASE_DIR_TARGET).st_mode)
        if current_backup_dir_perm != BACKUP_DIR_PERMISSIONS_OCTAL:
            print(f"  PYTHON: Adjusting permissions on {BACKUP_BASE_DIR_TARGET} from {current_backup_dir_perm:o} to {BACKUP_DIR_PERMISSIONS_OCTAL:o}...")
            os.chmod(BACKUP_BASE_DIR_TARGET, BACKUP_DIR_PERMISSIONS_OCTAL)
        print(f"PYTHON: OK: Backup directory ensured: {BACKUP_BASE_DIR_TARGET} with permissions {BACKUP_DIR_PERMISSIONS_OCTAL:o}")
    except OSError as e_backup_dir:
        print(f"PYTHON ERROR: Failed to create or set permissions on base backup directory {BACKUP_BASE_DIR_TARGET}: {e_backup_dir}", file=sys.stderr)
        sys.exit(f"PYTHON ERROR: Could not ensure backup directory '{BACKUP_BASE_DIR_TARGET}'. Exiting Python script.") # Critical
    except Exception as e_backup_dir_unexpected:
        print(f"PYTHON ERROR: An unexpected error occurred ensuring backup directory {BACKUP_BASE_DIR_TARGET}: {e_backup_dir_unexpected}", file=sys.stderr)
        sys.exit(f"PYTHON ERROR: Could not ensure backup directory '{BACKUP_BASE_DIR_TARGET}'. Exiting Python script.")

    # Process the files dictionary
    for file_to_create_path_str, file_details_dict in FILES_TO_CREATE_PY.items():
        current_file_path_obj = pathlib.Path(file_to_create_path_str)
        file_write_or_dir_create_succeeded = False

        try:
            file_content_str = file_details_dict["content"]
            file_permissions_octal = file_details_dict["permissions"]
        except KeyError as e_key_error:
            print(f"\nPYTHON ERROR: Configuration error in FILES_TO_CREATE_PY - Missing '{e_key_error}' key for entry {file_to_create_path_str}. Skipping this item.", file=sys.stderr)
            py_fail_count += 1
            continue # Skip to the next file
        except Exception as e_config_error: # Catch any other unexpected errors in details
            print(f"\nPYTHON ERROR: Unexpected configuration error for {file_to_create_path_str}: {e_config_error}. Skipping this item.", file=sys.stderr)
            py_fail_count += 1
            continue

        print(f"\nPYTHON: Processing: {current_file_path_obj}")

        # 1. Create parent directories robustly
        try:
            parent_directory_path = current_file_path_obj.parent
            if not parent_directory_path.is_dir(): # Check if parent needs creation
                print(f"  PYTHON: Creating parent directory: {parent_directory_path}")
                os.makedirs(parent_directory_path, mode=0o755, exist_ok=True) # Default rwxr-xr-x for new parent dirs
                print(f"  PYTHON: Ensuring parent directory permissions are 0755 for {parent_directory_path}...")
                os.chmod(parent_directory_path, 0o755) # Explicitly set permissions
            else: # Parent exists, ensure it's writable and has correct permissions
                print(f"  PYTHON: Parent directory exists: {parent_directory_path}")
                if not os.access(parent_directory_path, os.W_OK):
                    print(f"  PYTHON WARNING: Parent directory {parent_directory_path} is not writable by current user (UID {os.geteuid()})! File write may fail.", file=sys.stderr)
                    py_warning_count += 1
                # Ensure existing parent has standard 0755 permissions
                try:
                    current_parent_perm_octal = stat.S_IMODE(os.stat(parent_directory_path).st_mode)
                    if current_parent_perm_octal != 0o755:
                        print(f"  PYTHON: Ensuring parent directory {parent_directory_path} permissions are 0755 (currently {current_parent_perm_octal:o})...")
                        os.chmod(parent_directory_path, 0o755)
                except OSError as e_parent_perm:
                    print(f"  PYTHON WARNING: Could not check/set permissions on existing parent directory {parent_directory_path}: {e_parent_perm}", file=sys.stderr)
                    py_warning_count += 1
        except OSError as e_parent_create:
            print(f"  PYTHON ERROR: Failed to create or set permissions on parent directory {parent_directory_path}: {e_parent_create}", file=sys.stderr)
            print(f"  PYTHON: Skipping item: {current_file_path_obj}")
            py_fail_count += 1
            continue
        except Exception as e_parent_unexpected: # Catch any other unexpected errors
            print(f"  PYTHON ERROR: An unexpected error occurred creating parent directory for {current_file_path_obj}: {e_parent_unexpected}", file=sys.stderr)
            print(f"  PYTHON: Skipping item: {current_file_path_obj}")
            py_fail_count += 1
            continue

        # 2. Write the file content
        if file_content_str is not None: # It's a file
            try:
                print(f"  PYTHON: Writing content to {current_file_path_obj}...")
                current_file_path_obj.write_text(file_content_str, encoding='utf-8')
                print(f"  PYTHON: Successfully wrote: {current_file_path_obj}")
                file_write_or_dir_create_succeeded = True
            except IOError as e_io_error:
                print(f"  PYTHON ERROR: Failed to write file {current_file_path_obj}: {e_io_error}", file=sys.stderr)
                py_fail_count += 1
                continue # Skip permissions if write failed
            except Exception as e_write_unexpected: # Catch any other unexpected errors
                print(f"  PYTHON ERROR: An unexpected error occurred writing {current_file_path_obj}: {e_write_unexpected}", file=sys.stderr)
                py_fail_count += 1
                continue
        # This script does not currently define directories to be created via FILES_TO_CREATE_PY where content is None
        # else: # It's a directory (content is None) - Placeholder for future if needed

        # 3. Set permissions (only if write/dir creation succeeded)
        if file_write_or_dir_create_succeeded:
            try:
                current_file_perm_octal = stat.S_IMODE(os.stat(current_file_path_obj).st_mode)
                if current_file_perm_octal != file_permissions_octal:
                    print(f"  PYTHON: Setting permissions for {current_file_path_obj} to {file_permissions_octal:o} (currently {current_file_perm_octal:o})...")
                    os.chmod(current_file_path_obj, file_permissions_octal)
                    print(f"  PYTHON: Successfully set permissions for: {current_file_path_obj}")
                else:
                    print(f"  PYTHON: Permissions already set correctly ({file_permissions_octal:o}) for: {current_file_path_obj}")
                files_successfully_processed += 1 # Count full success (write/dir + chmod)
            except OSError as e_chmod_error:
                print(f"  PYTHON WARNING: Failed to set permissions on {current_file_path_obj} after writing: {e_chmod_error}", file=sys.stderr)
                py_warning_count += 1 # Item created/written, but permissions failed/check failed
            except Exception as e_chmod_unexpected: # Catch any other unexpected errors
                print(f"  PYTHON WARNING: An unexpected error occurred setting permissions for {current_file_path_obj}: {e_chmod_unexpected}", file=sys.stderr)
                py_warning_count += 1

    # --- Summary ---
    print("\n--- PYTHON: File Creation Summary ---")
    print(f"PYTHON: Successfully processed (created/permissioned): {files_successfully_processed} items")
    print(f"PYTHON: Items processed but with warnings:             {py_warning_count}")
    print(f"PYTHON: Failed operations (write/dir/parent):          {py_fail_count}")
    print("-------------------------------------------\n")

    if py_fail_count > 0:
        print("PYTHON ERROR: Fatal errors occurred during file creation by Python script. Deployment incomplete.", file=sys.stderr)
        return False # Fatal errors occurred
    elif py_warning_count > 0:
        print("PYTHON NOTE: Deployment completed by Python script, but with warnings. Please review the output above.")
        return True # Only non-fatal warnings
    else:
        print("PYTHON: SBNB configuration file deployment completed successfully by Python script.")
        return True

# --- Python Script Execution Entry Point ---
if __name__ == "__main__":
    print("=====================================================================")
    print(" SBNB Unified Configuration Deployment Script (Python Part v1.1) ")
    print(f"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"Configuring for ESP Mount: {ESP_MOUNT}, Data Mount: {DATA_MOUNT}")
    print(f"Using Tailscale Key: {'Provided (see content below)' if TAILSCALE_AUTH_KEY_CONTENT and 'placeholder' not in TAILSCALE_AUTH_KEY_CONTENT else 'Placeholder/Not Provided (MANUAL ACTION REQUIRED)'}")
    if TAILSCALE_AUTH_KEY_CONTENT and 'placeholder' not in TAILSCALE_AUTH_KEY_CONTENT :
        print(f"Tailscale Key Content (first 15 chars): {TAILSCALE_AUTH_KEY_CONTENT[:15]}...") # Avoid logging full key
    print("=====================================================================\n")

    if check_python_script_prerequisites():
        if create_all_files_py():
            print("\nPYTHON: --- Next Steps & Reminders ---")
            if 'placeholder' in TAILSCALE_AUTH_KEY_CONTENT or not TAILSCALE_AUTH_KEY_CONTENT:
                print("PYTHON CRITICAL REMINDER: The Tailscale authentication key ('sbnb-tskey.txt' on ESP) was set to a placeholder or may be missing.")
                print(f"                     YOU MUST MANUALLY EDIT '{ESP_MOUNT}/sbnb-tskey.txt' with your actual Tailscale auth key for Tailscale to function!")
            print("PYTHON: 1. Review any WARNINGS in the Python script output above.")
            print("PYTHON: 2. After the main Bash script finishes and unmounts, safely eject the USB drive.")
            print("PYTHON: 3. Configure server BIOS/UEFI to boot from the USB in UEFI mode (Secure Boot OFF).")
            print("PYTHON: 4. After booting SBNB, verify Docker configuration and systemd timers/services.")
            print("PYTHON:    - Check data root: `docker info | grep 'Docker Root Dir'` (should show persistent path)")
            print("PYTHON:    - Check Docker status: `systemctl status docker.service`")
            print("PYTHON:    - Check SBNB boot script logs: `journalctl -t sbnb-cmds.sh --no-pager` or `/dev/kmsg` during boot")
            print("PYTHON:    - Check custom timers: `systemctl list-timers --all | grep docker`")
            print("PYTHON:    - Check helper script logs: `journalctl -t backup-docker.sh -t purge-docker-backups.sh -t docker-health-check -t docker-volume-check --no-pager`")

            if py_warning_count > 0:
                print("\nPYTHON: Deployment by Python script finished with WARNINGS.")
                sys.exit(2) # Specific exit code for success with warnings
            else:
                print("\nPYTHON: Deployment by Python script finished successfully.")
                sys.exit(0) # Exit successfully
        else: # create_all_files_py returned False due to fatal errors
            print("\nPYTHON ERROR: --- Python Deployment Failed ---", file=sys.stderr)
            print("PYTHON ERROR: Fatal errors occurred during file creation by Python script. System configuration may be incomplete or inconsistent.", file=sys.stderr)
            sys.exit(1) # Exit with error code for fatal errors
    else: # check_python_script_prerequisites returned False
        sys.exit(1) # Exit with error code for prerequisite failure
EOF_PYTHON_SCRIPT
        chmod +x "$temp_python_script_adv"

        info "Executing Python configuration deployment script..."
        export SBNB_ESP_MOUNT_PY="$ESP_MOUNT_POINT_PY"
        export SBNB_DATA_MOUNT_PY="$DATA_MOUNT_POINT_PY"
        export SBNB_TS_KEY_PY="$TAILSCALE_AUTH_KEY_PY"

        if python3 "$temp_python_script_adv"; then
            info "Python configuration script executed successfully."
        else
            python_exit_code=$?
            if [ $python_exit_code -eq 2 ]; then # Success with warnings from Python script
                warn "Python configuration script completed with warnings. Please review Python script output."
            else # Actual error from Python script
                error "Python configuration script failed with exit code ${python_exit_code}. Check Python script output above."
            fi
        fi
        # rm -f "$temp_python_script_adv" # Cleaned by global trap if under MAIN_TEMP_BASE_DIR
        unset SBNB_ESP_MOUNT_PY SBNB_DATA_MOUNT_PY SBNB_TS_KEY_PY
    }


    # --- Advanced Mode Execution Flow ---
    local target_disk_for_advanced_setup
    info "Advanced mode requires preparing a disk with an ESP and a Data partition."
    info "Listing available block devices..."
    mapfile -t devices_for_advanced < <(lsblk -dpno NAME,SIZE,MODEL,TYPE | grep -E 'disk|rom' | grep -v 'loop')
    if [ ${#devices_for_advanced[@]} -eq 0 ]; then error "No suitable disk devices found."; fi

    echo -e "\n${YELLOW}Available Devices:${NC}"
    echo "--------------------------------------------------"
    for i_adv_select in "${!devices_for_advanced[@]}"; do printf "%3d) %s\n" $((i_adv_select+1)) "${devices_for_advanced[$i_adv_select]}"; done
    echo "--------------------------------------------------"
    local selected_disk_index_for_advanced
    while true; do
        prompt "Enter the index number of the TARGET DEVICE for partitioning: " selected_disk_index_for_advanced
        if [[ "$selected_disk_index_for_advanced" =~ ^[0-9]+$ ]] && [ "$selected_disk_index_for_advanced" -ge 1 ] && [ "$selected_disk_index_for_advanced" -le ${#devices_for_advanced[@]} ]; then
            target_disk_for_advanced_setup=$(echo "${devices_for_advanced[$((selected_disk_index_for_advanced-1))]}" | awk '{print $1}')
            info "You selected index $selected_disk_index_for_advanced: $target_disk_for_advanced_setup for advanced setup."
            break
        else
            warn "Invalid input. Please enter a number between 1 and ${#devices_for_advanced[@]}."
        fi
    done
    
    local confirmation_advanced_mode_main
    confirm_action "You selected $target_disk_for_advanced_setup for ADVANCED partitioning and setup." "confirmation_advanced_mode_main"
    if [[ "$confirmation_advanced_mode_main" != "yes" ]]; then info "Operation cancelled by user."; return 0; fi

    # Step 1: Partition and Format the Drive. This function defines ESP_PARTITION_DEVICE and DATA_PARTITION_DEVICE
    prepare_usb_advanced "$target_disk_for_advanced_setup"
    info "USB drive prepared. ESP: ${ESP_PARTITION_DEVICE}, Data: ${DATA_PARTITION_DEVICE}"

    # Step 2: Get SBNB EFI File Path from user
    local sbnb_efi_file_path_adv
    prompt "Enter the full path to your SBNB EFI boot file (e.g., BOOTX64.EFI or sbnb.efi): " sbnb_efi_file_path_adv
    if [ ! -r "$sbnb_efi_file_path_adv" ]; then error "SBNB EFI boot file '$sbnb_efi_file_path_adv' not found or not readable."; fi

    # Define mount points within the main temporary directory
    local esp_mount_point_adv="${MAIN_TEMP_BASE_DIR}/adv_esp_mnt"
    local data_mount_point_adv="${MAIN_TEMP_BASE_DIR}/adv_data_mnt"
    mkdir -p "$esp_mount_point_adv" "$data_mount_point_adv"
    
    # Local trap for advanced mode mounts
    advanced_mode_local_cleanup() {
        info "Advanced mode: Cleaning up temporary mounts..."
        if mountpoint -q "$esp_mount_point_adv"; then umount "$esp_mount_point_adv" 2>/dev/null || warn "Failed to umount $esp_mount_point_adv"; fi
        if mountpoint -q "$data_mount_point_adv"; then umount "$data_mount_point_adv" 2>/dev/null || warn "Failed to umount $data_mount_point_adv"; fi
        # Directories themselves will be removed by global_cleanup_trap
    }
    trap 'advanced_mode_local_cleanup' RETURN # Clean up when function returns

    info "Mounting ESP partition ${ESP_PARTITION_DEVICE} to ${esp_mount_point_adv}..."
    mount "${ESP_PARTITION_DEVICE}" "${esp_mount_point_adv}"
    info "Mounting Data partition ${DATA_PARTITION_DEVICE} to ${data_mount_point_adv}..."
    mount "${DATA_PARTITION_DEVICE}" "${data_mount_point_adv}"

    # Step 3: Get Tailscale Key from user
    local tailscale_auth_key_for_python
    echo -e "\n${YELLOW}The SBNB system can be configured with a Tailscale authentication key.${NC}"
    echo -e "If you provide a key now, it will be embedded into '${esp_mount_point_adv}/sbnb-tskey.txt'."
    echo -e "If you press Enter without providing a key, a NON-FUNCTIONAL PLACEHOLDER will be written."
    echo -e "${RED}In that case, YOU MUST MANUALLY EDIT the 'sbnb-tskey.txt' file on the ESP later with your actual key for Tailscale to work.${NC}"
    prompt "Enter your Tailscale authentication key (e.g., tskey-auth-...) [Press Enter for placeholder]: " tailscale_auth_key_for_python
    if [ -z "$tailscale_auth_key_for_python" ]; then
        tailscale_auth_key_for_python="tskey-auth-PLACEHOLDER-EDIT-THIS-FILE-MANUALLY" # Explicit placeholder
        warn "NO TAILSCALE KEY PROVIDED. A non-functional placeholder will be used."
        warn "You MUST edit '${esp_mount_point_adv}/sbnb-tskey.txt' MANUALLY with a real key."
    fi

    # Step 4: Deploy Python Configuration (which also copies EFI file now)
    deploy_python_config_advanced "$target_disk_for_advanced_setup" "$esp_mount_point_adv" "$data_mount_point_adv" "$tailscale_auth_key_for_python" "$sbnb_efi_file_path_adv"

    info "Syncing data to disk before unmounting..."
    sync

    echo -e "\n${BLUE}====================================================${NC}"
    echo -e "${GREEN} Advanced Mode SBNB Drive Preparation Complete! ${NC}"
    echo -e "${GREEN} Target device: $target_disk_for_advanced_setup ${NC}"
    echo -e "${GREEN} ESP partition: ${ESP_PARTITION_DEVICE} (mounted at $esp_mount_point_adv during script)"
    echo -e "${GREEN} Data partition: ${DATA_PARTITION_DEVICE} (mounted at $data_mount_point_adv during script)"
    if [[ "$tailscale_auth_key_for_python" == "tskey-auth-PLACEHOLDER-EDIT-THIS-FILE-MANUALLY" ]]; then
        echo -e "${RED} CRITICAL REMINDER: You used a placeholder Tailscale key. Edit '${esp_mount_point_adv}/sbnb-tskey.txt' with your actual key! ${NC}"
    fi
    echo -e "${BLUE}====================================================${NC}"
    
    trap - RETURN # Disable local trap
    advanced_mode_local_cleanup # Perform cleanup explicitly
}


# --- Main Menu ---
info "Welcome to the Unified SBNB Drive Preparation Utility (Version 1.1)."
echo "Please choose an operation mode:"
echo "  1) Simple Mode: Create a standard SBNB bootable drive from a local 'sbnb.raw' image."
echo "  2) Advanced Mode: Set up an SBNB drive with ESP, persistent Data partition, and deploy advanced configurations (Docker persistence, backups, etc.)."
main_user_choice=""
prompt "Enter your choice (1 or 2): " main_user_choice

case "$main_user_choice" in
    1)
        run_simple_mode
        ;;
    2)
        run_advanced_mode
        ;;
    *)
        error "Invalid choice '$main_user_choice'. Exiting."
        ;;
esac

info "Unified SBNB Drive Preparation Utility finished its selected mode."
# Global cleanup trap will handle MAIN_TEMP_BASE_DIR removal on exit.
exit 0
```

## How to Use the Unified Utility

1.  **Save the Script:** Copy the entire script above and save it to a file named `unified_sbnb_prep.sh` on your Linux preparation system.
2.  **Make it Executable:** Open a terminal and run `chmod +x unified_sbnb_prep.sh`.
3.  **Run the Script:** Execute the script with root privileges: `sudo ./unified_sbnb_prep.sh`.
4.  **Follow Prompts:** The script will guide you through selecting a mode and providing necessary information.

### Simple Mode Instructions:

This mode is for creating a standard SBNB bootable drive by writing a complete `sbnb.raw` disk image to a target USB/disk.
1.  When prompted, choose option `1` for Simple Mode.
2.  Enter the full path to your `sbnb.raw` disk image file.
3.  The script will check for `sbnb-tskey.txt` in the current directory to optionally include a Tailscale key.
4.  Select the target USB/disk device from the listed available devices. **Be extremely careful with this selection.**
5.  Confirm the destructive operation by typing `yes`.
6.  (Optional) Enter the path to a local custom script (e.g., `my-custom-boot.sh`) if you want it copied to the ESP as `sbnb-cmds.sh` to run at boot.
7.  The script will then write the image and copy optional files.

### Advanced Mode Instructions:

This mode is for preparing a USB/disk with a dedicated EFI System Partition (ESP) and a separate data partition for persistent storage. It then deploys a comprehensive SBNB configuration for Docker persistence, backups, and monitoring.

1.  When prompted, choose option `2` for Advanced Mode.
2.  Select the target USB/disk device for partitioning and setup. **Be extremely careful.**
3.  Confirm the destructive partitioning operation by typing `yes`. The script will then partition and format the drive. The script will output the ESP and Data partition device names (e.g., `/dev/sdb1`, `/dev/sdb2`).
4.  Enter the full path to your `sbnb.efi` file (this is the SBNB bootloader, often named `BOOTX64.EFI` in a standard SBNB setup).
5.  You will be prompted to enter your Tailscale authentication key. If you skip this or provide an empty string, a **non-functional placeholder key** will be written to `sbnb-tskey.txt` on the ESP. **You MUST manually edit this file with your actual key if you use the placeholder for Tailscale to work.**
6.  The script will then mount the partitions and deploy all necessary configuration files, including `sbnb-cmds.sh` on the ESP, the SBNB EFI file, and helper scripts/systemd units on the data partition.
7.  Once complete, the script will unmount the partitions.

## Key Features of Components

This unified utility leverages the strengths of several well-designed components:

*   **Simple Bootable Drive Creation:**
    *   User-friendly prompts and clear warnings.
    *   Directly writes a `.raw` image using `dd` with progress.
    *   Handles optional Tailscale key and basic custom script deployment to the ESP.
    *   Robust cleanup of temporary mounts.

*   **Advanced USB Preparation (`prepare_usb_advanced` function):**
    *   Extremely robust partitioning and formatting.
    *   **Critical safety check** to prevent accidental wiping of the host operating system drive.
    *   Uses `wipefs` for a clean slate before partitioning.
    *   Creates GPT, FAT32 ESP (labeled `sbnb`), and ext4 Data partition (labeled `SBNB_DATA`).
    *   Performs filesystem integrity checks (`fsck.vfat`, `e2fsck`) after formatting.
    *   Verifies partition labels.
    *   Handles common partition naming schemes (SATA, NVMe, MMC).

*   **Comprehensive Configuration Deployment (Python script logic via `deploy_python_config_advanced` function):**
    *   Copies the SBNB EFI boot file to the ESP.
    *   Generates a sophisticated `sbnb-cmds.sh` for the ESP, which runs at boot to:
        *   Mount the persistent data partition by label.
        *   Configure Docker to use a persistent `data-root` on the data partition.
        *   Optionally migrate existing Docker data from ephemeral storage using `cp -a -u`.
        *   Atomically update an optional development environment script (if provided on the data partition).
        *   Link and enable systemd units.
    *   Deploys `sbnb-tskey.txt` (with user-provided or placeholder key) to the ESP.
    *   Deploys helper shell scripts to the data partition for:
        *   Docker data backup (with `tar`, optional Docker stop, latest link).
        *   Purging old Docker backups (configurable retention).
        *   Docker health checks (daemon status, responsiveness, correct data-root).
        *   Docker volume space checks (with configurable threshold and pruning levels).
    *   Deploys corresponding systemd `.service` and `.timer` units to automate these helper scripts.

## Post-Setup Steps

1.  **Safely Eject:** Once the script completes and the cleanup process finishes, your USB drive should be ready.
2.  **BIOS/UEFI Configuration:**
    *   Insert the USB drive into your target server.
    *   Enter the server's BIOS/UEFI setup utility (commonly by pressing DEL, F2, F10, F12, or ESC during startup).
    *   Ensure **UEFI Mode** is enabled.
    *   Disable **CSM (Compatibility Support Module)** or **Legacy Boot Mode**.
    *   Disable **Secure Boot** (SBNB EFI files are typically not signed for Secure Boot by default).
    *   Set the USB drive (e.g., "UEFI: USB Device Name") as the **primary boot device**.
    *   Save changes and exit the BIOS/UEFI setup.
3.  **Boot and Verify:**
    *   The server should now boot from the SBNB USB drive.
    *   **For Advanced Mode:**
        *   Monitor the boot process (if a console is attached) for messages from `sbnb-cmds.sh` (logged to `kmsg`).
        *   After booting, SSH into the SBNB system.
        *   Verify that the data partition is mounted at `/mnt/sbnb-data` (or the path configured if you modify the Python script section).
            ```bash
            lsblk -o NAME,SIZE,TYPE,FSTYPE,LABEL,MOUNTPOINT
            df -hT | grep -E 'Filesystem|/mnt/sbnb-data'
            ```
        *   Verify Docker is configured to use the persistent data root:
            ```bash
            docker info | grep "Docker Root Dir"
            # Should show something like /mnt/sbnb-data/docker-root
            ```
        *   Check the status of systemd timers:
            ```bash
            systemctl list-timers --all | grep docker
            ```
        *   Check logs for `sbnb-cmds.sh` and helper scripts:
            ```bash
            journalctl -t sbnb-cmds.sh --no-pager
            journalctl -t backup-docker.sh -t purge-docker-backups.sh -t docker-health-check -t docker-volume-check --no-pager
            ```
        *   If you used a placeholder Tailscale key, **ensure you have manually updated `/boot/efi/sbnb-tskey.txt` (or its equivalent mount point if accessed from within SBNB) with your real key.**

## Disclaimer

**EXTREME CAUTION: DATA DESTRUCTION RISK**

This script performs low-level disk operations (partitioning, formatting, direct image writing) that will **COMPLETELY AND PERMANENTLY ERASE ALL DATA** on the selected target disk. There is **NO UNDO** function.

*   **Triple-check the target disk selection.** Mistakenly choosing your computer's internal hard drive or another important storage device will result in catastrophic data loss.
*   The responsibility for correct disk selection and understanding the consequences rests solely with the user.
*   Use this script at your own risk. Always back up important data before running tools that modify disk structures.

<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://ib.bsb.br/feed.xml" rel="self" type="application/atom+xml" /><link href="https://ib.bsb.br/" rel="alternate" type="text/html" /><updated>2024-10-22T18:50:13+00:00</updated><id>https://ib.bsb.br/feed.xml</id><title type="html">infoBAG</title><entry><title type="html">Google Docs ABNT</title><link href="https://ib.bsb.br/google-docs-abnt/" rel="alternate" type="text/html" title="Google Docs ABNT" /><published>2024-10-22T00:00:00+00:00</published><updated>2024-10-22T18:49:25+00:00</updated><id>https://ib.bsb.br/google-docs-abnt</id><content type="html" xml:base="https://ib.bsb.br/google-docs-abnt/"><![CDATA[<h1 id="guia-completo-de-formatação-abnt-para-artigos-acadêmicos-no-google-docs">Guia Completo de Formatação ABNT para Artigos Acadêmicos no Google Docs</h1>

<h2 id="parte-i-estrutura-do-documento">PARTE I: ESTRUTURA DO DOCUMENTO</h2>

<h3 id="1-elementos-pré-textuais-em-ordem">1. Elementos Pré-textuais (em ordem)</h3>
<ol>
  <li>Capa</li>
  <li>Folha de rosto</li>
  <li>Errata (se necessário)</li>
  <li>Folha de aprovação (quando aplicável)</li>
  <li>Dedicatória (opcional)</li>
  <li>Agradecimentos (opcional)</li>
  <li>Epígrafe (opcional)</li>
  <li>Resumo em português (obrigatório)</li>
  <li>Resumo em língua estrangeira (obrigatório)</li>
  <li>Lista de ilustrações (se necessário)</li>
  <li>Lista de tabelas (se necessário)</li>
  <li>Lista de abreviaturas e siglas (se necessário)</li>
  <li>Lista de símbolos (se necessário)</li>
  <li>Sumário (obrigatório)</li>
</ol>

<h3 id="2-elementos-textuais">2. Elementos Textuais</h3>
<ol>
  <li>Introdução</li>
  <li>Desenvolvimento</li>
  <li>Conclusão</li>
</ol>

<h3 id="3-elementos-pós-textuais">3. Elementos Pós-textuais</h3>
<ol>
  <li>Referências</li>
  <li>Glossário</li>
  <li>Apêndice</li>
  <li>Anexo</li>
  <li>Índice</li>
</ol>

<h2 id="parte-ii-configurações-básicas">PARTE II: CONFIGURAÇÕES BÁSICAS</h2>

<h3 id="1-configuração-da-página">1. Configuração da Página</h3>
<ul>
  <li>Formato: A4 (21 cm × 29,7 cm)</li>
  <li>Margens:
    <ul>
      <li>Superior: 3 cm</li>
      <li>Inferior: 2 cm</li>
      <li>Esquerda: 3 cm</li>
      <li>Direita: 2 cm</li>
    </ul>
  </li>
</ul>

<p>Para configurar:</p>
<ol>
  <li>Menu “Arquivo” &gt; “Configurar página”</li>
  <li>Selecionar “A4”</li>
  <li>Definir margens</li>
  <li>Aplicar orientação “Retrato”</li>
</ol>

<h3 id="2-formatação-geral">2. Formatação Geral</h3>
<ul>
  <li>Fonte: Times New Roman ou Arial</li>
  <li>Tamanho: 12 pts (padrão)</li>
  <li>Cor: Preta</li>
  <li>Espaçamento entre linhas: 1,5</li>
  <li>Parágrafo: Recuo de 1,25 cm na primeira linha</li>
  <li>Alinhamento: Justificado</li>
</ul>

<p>Para aplicar:</p>
<ol>
  <li>Selecionar todo o texto (Ctrl + A)</li>
  <li>Menu “Formatar” &gt; “Texto”</li>
  <li>Configurar fonte e tamanho</li>
  <li>Menu “Formatar” &gt; “Espaçamento entre linhas” &gt; 1,5</li>
  <li>Menu “Formatar” &gt; “Alinhar e recuar” &gt; “Recuo especial” &gt; “Primeira linha: 1,25 cm”</li>
</ol>

<h2 id="parte-iii-elementos-específicos">PARTE III: ELEMENTOS ESPECÍFICOS</h2>

<h3 id="1-capa-primeira-página">1. Capa (primeira página)</h3>
<p>Elementos em ordem (todos centralizados):</p>
<ol>
  <li>Nome da instituição (maiúsculas)</li>
  <li>Nome dos autores</li>
  <li>Título do trabalho (maiúsculas, negrito)</li>
  <li>Subtítulo (se houver)</li>
  <li>Local</li>
  <li>Ano</li>
</ol>

<h3 id="2-folha-de-rosto">2. Folha de Rosto</h3>
<p>Similar à capa, acrescentando:</p>
<ul>
  <li>Natureza do trabalho (recuo de 8 cm da margem esquerda)</li>
  <li>Nome do orientador</li>
  <li>Espaçamento simples nesta seção</li>
</ul>

<h3 id="3-resumo">3. Resumo</h3>
<ul>
  <li>Palavra “RESUMO” centralizada</li>
  <li>Texto em parágrafo único</li>
  <li>150 a 500 palavras</li>
  <li>Espaçamento simples</li>
  <li>Palavras-chave após o texto, precedidas de “Palavras-chave:”</li>
</ul>

<h3 id="4-sumário">4. Sumário</h3>
<ol>
  <li>Menu “Inserir” &gt; “Sumário”</li>
  <li>Título “SUMÁRIO” centralizado</li>
  <li>Usar estilos de título para gerar automaticamente</li>
</ol>

<h2 id="parte-iv-elementos-textuais-específicos">PARTE IV: ELEMENTOS TEXTUAIS ESPECÍFICOS</h2>

<h3 id="1-títulos">1. Títulos</h3>
<ul>
  <li>Título 1: MAIÚSCULAS, negrito, numeração arábica</li>
  <li>Título 2: Primeira letra maiúscula, negrito</li>
  <li>Título 3: Primeira letra maiúscula, sem negrito</li>
  <li>Alinhamento: Esquerda</li>
  <li>Sem ponto final</li>
</ul>

<h3 id="2-citações">2. Citações</h3>
<p><strong>Diretas curtas (até 3 linhas):</strong></p>
<ul>
  <li>Entre aspas duplas</li>
  <li>No corpo do texto</li>
  <li>Fonte normal</li>
  <li>Indicar (AUTOR, ANO, p. XX)</li>
</ul>

<p><strong>Diretas longas (mais de 3 linhas):</strong></p>
<ul>
  <li>Recuo de 4 cm da margem esquerda</li>
  <li>Fonte tamanho 10</li>
  <li>Espaçamento simples</li>
  <li>Sem aspas</li>
  <li>Uma linha em branco antes e depois</li>
</ul>

<p><strong>Indiretas:</strong></p>
<ul>
  <li>Sem aspas</li>
  <li>No corpo do texto</li>
  <li>Indicar (AUTOR, ANO)</li>
</ul>

<h3 id="3-ilustrações-e-tabelas">3. Ilustrações e Tabelas</h3>
<ul>
  <li>Título acima (fonte 12)</li>
  <li>Fonte abaixo (fonte 10)</li>
  <li>Numeração sequencial</li>
  <li>Citação no texto</li>
  <li>Centralizado</li>
</ul>

<h3 id="4-notas-de-rodapé">4. Notas de Rodapé</h3>
<ul>
  <li>Fonte tamanho 10</li>
  <li>Espaçamento simples</li>
  <li>Separadas do texto por filete</li>
  <li>Numeração sequencial</li>
</ul>

<h2 id="parte-v-referências">PARTE V: REFERÊNCIAS</h2>

<h3 id="1-formatação">1. Formatação</h3>
<ul>
  <li>Título “REFERÊNCIAS” centralizado</li>
  <li>Alinhamento à esquerda</li>
  <li>Espaçamento simples</li>
  <li>Uma linha em branco entre referências</li>
  <li>Ordem alfabética</li>
</ul>

<h3 id="2-estrutura-básica">2. Estrutura Básica</h3>
<p>Livros:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SOBRENOME, Nome. Título: subtítulo. Edição. Local: Editora, ano.
</code></pre></div></div>

<p>Artigos:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SOBRENOME, Nome. Título do artigo. Nome da Revista, Local, v. XX, n. XX, p. XX-XX, mês ano.
</code></pre></div></div>

<h2 id="parte-vi-numeração">PARTE VI: NUMERAÇÃO</h2>

<h3 id="1-páginas">1. Páginas</h3>
<ul>
  <li>Início da contagem: capa</li>
  <li>Número visível: a partir da introdução</li>
  <li>Posição: canto superior direito</li>
  <li>Fonte tamanho 10</li>
</ul>

<p>Para configurar:</p>
<ol>
  <li>Menu “Inserir” &gt; “Número de página”</li>
  <li>Selecionar posição</li>
  <li>Configurar diferentes seções para ocultar números nas páginas iniciais</li>
</ol>

<h3 id="2-seções">2. Seções</h3>
<ul>
  <li>Numeração progressiva</li>
  <li>Algarismos arábicos</li>
  <li>Sem ponto final</li>
  <li>Alinhadas à margem esquerda</li>
</ul>

<h2 id="parte-vii-verificação-final">PARTE VII: VERIFICAÇÃO FINAL</h2>

<h3 id="1-lista-de-verificação">1. Lista de Verificação</h3>
<ul class="task-list">
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Margens corretas</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Fonte e tamanho consistentes</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Espaçamento entre linhas</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Recuo de parágrafos</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Numeração de páginas</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Formatação de títulos</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Citações corretas</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Referências completas</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Sumário atualizado</li>
</ul>

<h3 id="2-problemas-comuns">2. Problemas Comuns</h3>
<ol>
  <li>Inconsistência na formatação</li>
  <li>Erros na numeração de páginas</li>
  <li>Citações mal formatadas</li>
  <li>Referências incompletas</li>
  <li>Sumário desatualizado</li>
</ol>

<h3 id="3-dicas-de-produtividade">3. Dicas de Produtividade</h3>
<ol>
  <li>Usar estilos do Google Docs</li>
  <li>Manter backup do arquivo</li>
  <li>Atualizar sumário regularmente</li>
  <li>Verificar normas específicas da instituição</li>
  <li>Utilizar verificador ortográfico</li>
</ol>]]></content><author><name></name></author><category term="estudos," /><category term="trabalho" /><summary type="html"><![CDATA[Guia Completo de Formatação ABNT para Artigos Acadêmicos no Google Docs]]></summary></entry><entry><title type="html">AnkiApp interactively AI chat (python)</title><link href="https://ib.bsb.br/ankiapp-interactively-ai-chat-python/" rel="alternate" type="text/html" title="AnkiApp interactively AI chat (python)" /><published>2024-10-20T00:00:00+00:00</published><updated>2024-10-20T12:35:35+00:00</updated><id>https://ib.bsb.br/ankiapp-interactively-ai-chat-python</id><content type="html" xml:base="https://ib.bsb.br/ankiapp-interactively-ai-chat-python/"><![CDATA[<section data-filename="python_code-block.py" data-code="import requests
import json
import os
# Authentication details (INSECURE - DO NOT USE IN PRODUCTION). Environment variables are preferred
# Extracting these to env vars should be done before moving the python code
# for interactivelly prompting into the phone
#for setting this on a-shell (ios):
#client_id=$(echo &quot;&lt;clientId from the hardcoded python vars extraction below gathered on script generation phase&gt;&quot; | base64)
#client_token=$(echo &quot;&lt;clientToken&gt;&quot; | base64) #client token does not need adjustments before putting it on base64 for security.
#client_version=&quot;&lt;clientVersion from hardcoded vars as simple string&gt;”
client_ids = [&quot;12e5d390c33649d7b1e6c66b5d98bb80&quot;]  # From your .har file
client_tokens = [&quot;LdGInADDy99mbqWmkfh5YmfzHP9SMhmWwXs7ymfEEJc=&quot;] # From your .har file
client_versions = [&quot;9.6.1&quot;] # From your .har file
def anki_ai_chat(client_id, client_token, client_version):
url = &quot;https://api.ankiapp.com/decks/ai&quot;
headers = {
&quot;accept&quot;: &quot;*/*&quot;,
&quot;accept-language&quot;: &quot;en&quot;,
&quot;ankiapp-client-id&quot;: client_id,
&quot;ankiapp-client-token&quot;: client_token,
&quot;ankiapp-client-version&quot;: client_version,
&quot;content-type&quot;: &quot;application/json&quot;
}
session_id = None
deck = {&quot;layouts&quot;: [], &quot;config&quot;: {}}
while True:
prompt = input(&quot;Enter your prompt (or type 'quit' to exit): &quot;)
if prompt.lower() == &quot;quit&quot;:
break
data = {
&quot;prompt&quot;: prompt,
&quot;deck&quot;: deck,
&quot;pending&quot;: []  # Essential for newer API versions
}
if session_id:
data[&quot;session_id&quot;] = session_id
try:
response = requests.post(url, headers=headers, data=json.dumps(data))
response.raise_for_status()
response_json = response.json()
if &quot;session_id&quot; in response_json and not session_id: #Handles only from the very first time since a single user can and should only generate one of it. Multiple users is to be seen...
session_id = response_json[&quot;session_id&quot;]
if 'data' in response_json:
print(&quot;Response:&quot;)
for item in response_json[&quot;data&quot;]:
print(f&quot;{item[0]}: {item[1]}&quot;)
elif 'pending' in response_json:
print(&quot;Response:&quot;)
for item in response_json[&quot;pending&quot;]:
print(f&quot;{item['Front']}: {item['Back']}&quot;)
else:
print(f&quot;Unexpected response structure:\n{json.dumps(response_json, indent=4)}&quot;)
except requests.exceptions.RequestException as e:
print(f&quot;AnkiApp API Error: {e}&quot;)
if response.content:  # Check for content before attempting decode
try:
error_json = response.json()
print(f&quot;Error details: {json.dumps(error_json, indent=4)}&quot;)
except json.JSONDecodeError: #Handles empty or corrupted data as a raw text format (utf-8 or others...).
print(f&quot;Raw error response: {response.content}&quot;)
except json.JSONDecodeError as e: #If nothing worked, also try converting response's data to raw utf-8 string or even raw data, before continuing the conversation, which will probably halt in errors if done and some new error is introduced, so maybe remove it or adjust...
print(f&quot;Couldn't parse JSON response: {e}. Printing raw content instead...\nResponse content:{response.content}&quot;)
# Example usage (single credential). Extract multiple credentials and pass by user
anki_ai_chat(client_ids[0], client_tokens[0], client_versions[0])" data-download-link="" data-download-link-label="Download Python"><code class="language-python">import requests
import json
import os
# Authentication details (INSECURE - DO NOT USE IN PRODUCTION). Environment variables are preferred
# Extracting these to env vars should be done before moving the python code
# for interactivelly prompting into the phone
#for setting this on a-shell (ios):
#client_id=$(echo "<clientId from="" the="" hardcoded="" python="" vars="" extraction="" below="" gathered="" on="" script="" generation="" phase="">" | base64)
#client_token=$(echo "<clientToken>" | base64) #client token does not need adjustments before putting it on base64 for security.
#client_version="<clientVersion from="" hardcoded="" vars="" as="" simple="" string="">”
client_ids = ["12e5d390c33649d7b1e6c66b5d98bb80"]  # From your .har file
client_tokens = ["LdGInADDy99mbqWmkfh5YmfzHP9SMhmWwXs7ymfEEJc="] # From your .har file
client_versions = ["9.6.1"] # From your .har file
def anki_ai_chat(client_id, client_token, client_version):
url = "https://api.ankiapp.com/decks/ai"
headers = {
"accept": "*/*",
"accept-language": "en",
"ankiapp-client-id": client_id,
"ankiapp-client-token": client_token,
"ankiapp-client-version": client_version,
"content-type": "application/json"
}
session_id = None
deck = {"layouts": [], "config": {}}
while True:
prompt = input("Enter your prompt (or type 'quit' to exit): ")
if prompt.lower() == "quit":
break
data = {
"prompt": prompt,
"deck": deck,
"pending": []  # Essential for newer API versions
}
if session_id:
data["session_id"] = session_id
try:
response = requests.post(url, headers=headers, data=json.dumps(data))
response.raise_for_status()
response_json = response.json()
if "session_id" in response_json and not session_id: #Handles only from the very first time since a single user can and should only generate one of it. Multiple users is to be seen...
session_id = response_json["session_id"]
if 'data' in response_json:
print("Response:")
for item in response_json["data"]:
print(f"{item[0]}: {item[1]}")
elif 'pending' in response_json:
print("Response:")
for item in response_json["pending"]:
print(f"{item['Front']}: {item['Back']}")
else:
print(f"Unexpected response structure:\n{json.dumps(response_json, indent=4)}")
except requests.exceptions.RequestException as e:
print(f"AnkiApp API Error: {e}")
if response.content:  # Check for content before attempting decode
try:
error_json = response.json()
print(f"Error details: {json.dumps(error_json, indent=4)}")
except json.JSONDecodeError: #Handles empty or corrupted data as a raw text format (utf-8 or others...).
print(f"Raw error response: {response.content}")
except json.JSONDecodeError as e: #If nothing worked, also try converting response's data to raw utf-8 string or even raw data, before continuing the conversation, which will probably halt in errors if done and some new error is introduced, so maybe remove it or adjust...
print(f"Couldn't parse JSON response: {e}. Printing raw content instead...\nResponse content:{response.content}")
# Example usage (single credential). Extract multiple credentials and pass by user
anki_ai_chat(client_ids[0], client_tokens[0], client_versions[0])&lt;/code&gt;&lt;/section&gt;
</clientVersion></clientToken></clientId></code></section>]]></content><author><name></name></author><category term="scripts&gt;AI" /><summary type="html"><![CDATA[import requests import json import os]]></summary></entry><entry><title type="html">Github actions workflow dispatch + Webhooks using `Serverless.com` Lift plugin</title><link href="https://ib.bsb.br/serverless-lift-gha/" rel="alternate" type="text/html" title="Github actions workflow dispatch + Webhooks using `Serverless.com` Lift plugin" /><published>2024-10-18T00:00:00+00:00</published><updated>2024-10-18T19:59:36+00:00</updated><id>https://ib.bsb.br/serverless-lift-gha</id><content type="html" xml:base="https://ib.bsb.br/serverless-lift-gha/"><![CDATA[<h1 id="1-serverlessyml-configuration">1. <code class="language-plaintext highlighter-rouge">serverless.yml</code> Configuration:</h1>

<section data-filename="yaml_code-block.yaml" data-code="service: github-webhook-service
provider:
name: aws
runtime: nodejs20.x
region: us-east-1
environment:  
GITHUB_TOKEN: ${env:GITHUB_TOKEN}  # Securely store your GitHub Personal Access Token
GITHUB_REPOSITORY: ib-bsb-br/ib-bsb-br.github.io  # Replace with your GitHub repository
WORKFLOW_ID: dispatch-workflow.yml # The filename or ID of the GitHub Actions workflow to trigger
plugins:
- serverless-lift
functions:
handleWebhook:
handler: handler.handleWebhook
events:
- http:
path: /webhook  # Webhook endpoint path
method: post
cors: true
- eventBridge:
eventBus: ${construct:webhook.busName}
pattern:
source:
- webhook
detail-type:
- new_comment
triggerGithubWorkflow:
handler: handler.triggerGithubWorkflow
events:
- http:
path: /trigger_github_workflow
method: post
cors: true
constructs:
webhook:
type: webhook
path: /webhook
method: POST
eventType: $request.body.eventType  # Maps to 'detail-type' in EventBridge event
insecure: true
package:
patterns:
- '!node_modules/aws-sdk/**'
- '!node_modules/@aws-sdk/**'" data-download-link="" data-download-link-label="Download Yaml"><code class="language-yaml">service: github-webhook-service
provider:
name: aws
runtime: nodejs20.x
region: us-east-1
environment:  
GITHUB_TOKEN: ${env:GITHUB_TOKEN}  # Securely store your GitHub Personal Access Token
GITHUB_REPOSITORY: ib-bsb-br/ib-bsb-br.github.io  # Replace with your GitHub repository
WORKFLOW_ID: dispatch-workflow.yml # The filename or ID of the GitHub Actions workflow to trigger
plugins:
- serverless-lift
functions:
handleWebhook:
handler: handler.handleWebhook
events:
- http:
path: /webhook  # Webhook endpoint path
method: post
cors: true
- eventBridge:
eventBus: ${construct:webhook.busName}
pattern:
source:
- webhook
detail-type:
- new_comment
triggerGithubWorkflow:
handler: handler.triggerGithubWorkflow
events:
- http:
path: /trigger_github_workflow
method: post
cors: true
constructs:
webhook:
type: webhook
path: /webhook
method: POST
eventType: $request.body.eventType  # Maps to 'detail-type' in EventBridge event
insecure: true
package:
patterns:
- '!node_modules/aws-sdk/**'
- '!node_modules/@aws-sdk/**'</code></section>

<h1 id="2-handler-functions-handlermjs">2. Handler Functions (<code class="language-plaintext highlighter-rouge">handler.mjs</code>):</h1>

<section data-filename="javascript_code-block.js" data-code="import { Octokit } from &quot;@octokit/rest&quot;;
import { Base64 } from &quot;js-base64&quot;;
/**
* Converts a string to a URL-friendly slug.
* @param {string} text - The text to slugify.
* @return {string} Slugified text.
*/
const slugify = (text) =&gt; {
return text
.toString()
.toLowerCase()
.trim()
.replace(/\s+/g, '-')       // Replace spaces with -
.replace(/[^\w\-]+/g, '')   // Remove all non-word chars
.replace(/\-\-+/g, '-')     // Replace multiple - with single -
.replace(/^-+/, '')         // Trim - from start of text
.replace(/-+$/, '');        // Trim - from end of text
};
/**
* Formats a date string to YYYY-MM-DD.
* @param {string|Date} date - The date to format.
* @return {string} Formatted date string.
*/
const formatDate = (date) =&gt; {
const d = new Date(date);
if (isNaN(d.getTime())) {
throw new Error('Invalid date provided');
}
return d.toISOString().split('T')[0];
};
/**
* Creates the content for a blog post in Markdown format.
* @param {Object} data - Data for the blog post.
* @param {string} data.by_nickname - Author's nickname.
* @param {string} data.by_email - Author's email.
* @param {string} data.content - Post content.
* @param {string|Date} data.time - Timestamp of the post.
* @return {string} Formatted blog post content.
*/
const createPostContent = (data) =&gt; {
const { by_nickname, by_email, content, time } = data;
const slugName = slugify(by_nickname);
const date = formatDate(time);
return `---
tags: ${by_email}
info: aberto.
date: ${date}
type: post
layout: post
published: true
slug: ${slugName}
title: '${by_nickname}'
---
${content}`;
};
/**
* Triggers a GitHub Actions workflow using workflow_dispatch.
* @param {Octokit} octokit - Authenticated Octokit instance.
* @param {string} owner - Repository owner.
* @param {string} repo - Repository name.
* @param {string} ref - Git reference (branch or tag).
* @param {string} workflowId - Workflow file name or ID.
* @param {Object} inputs - Inputs for the workflow.
*/
const triggerWorkflowDispatch = async (octokit, owner, repo, ref, workflowId, inputs = {}) =&gt; {
try {
const response = await octokit.request(
'POST /repos/{owner}/{repo}/actions/workflows/{workflow_id}/dispatches',
{
owner,
repo,
workflow_id: workflowId,
ref,
inputs,
}
);
if (response.status !== 204) {
throw new Error(`Failed to dispatch workflow. GitHub API status: ${response.status}`);
}
console.log(`Workflow '${workflowId}' dispatched successfully on ${repo}`);
return response.data;
} catch (error) {
console.error('Error dispatching workflow:', error);
throw error;
}
};
/**
* Returns CORS headers.
* @return {Object} CORS headers.
*/
const getCorsHeaders = () =&gt; {
return {
'Access-Control-Allow-Origin': 'https://ib.bsb.br',
'Access-Control-Allow-Methods': 'POST, OPTIONS',
'Access-Control-Allow-Headers': 'Content-Type',
};
};
/**
* Handles incoming webhook events to create/update a blog post and trigger a workflow.
* @param {Object} event - Event data from AWS Lambda invocation.
* @return {Object} Response object with statusCode, headers, and body.
*/
export const handleWebhook = async (event) =&gt; {
try {
console.log('Event received:', JSON.stringify(event, null, 2));
let body;
// Determine if the event is from an HTTP request or EventBridge
if (event.body) {
// HTTP request
body = JSON.parse(event.body);
} else if (event.detail) {
// EventBridge event
body = event.detail;
} else {
throw new Error('No data received in the event.');
}
// Handle nested 'data' object if present
const data = body.data || body;
// Extract and validate data from the webhook event
const { by_nickname, by_email, content } = data;
if (!by_email || !by_nickname || !content) {
throw new Error('Missing required fields: by_email, by_nickname, or content.');
}
// Use 'createdAt' or 'updatedAt' as the time, or default to current time
let eventTime = data.createdAt || data.updatedAt || new Date().toISOString();
// Validate and format the time
try {
eventTime = formatDate(eventTime);
} catch (e) {
// If invalid, default to current date
eventTime = formatDate(new Date().toISOString());
}
// Validate required environment variables
const githubToken = process.env.GITHUB_TOKEN;
const githubRepository = process.env.GITHUB_REPOSITORY;
const workflowId = process.env.WORKFLOW_ID;
if (!githubToken || !githubRepository || !workflowId) {
throw new Error('Missing required environment variables.');
}
const [owner, repo] = githubRepository.split('/');
const octokit = new Octokit({ auth: githubToken });
// Create or update the blog post file in the repository
const slugName = slugify(by_nickname);
const path = `_posts/${eventTime}-${slugName}.md`;
const message = `New post by ${by_nickname}`;
const postContent = createPostContent({
by_nickname,
by_email,
content,
time: eventTime,
});
const contentEncoded = Base64.encode(postContent);
// Check if the file already exists
let sha;
try {
const { data: fileData } = await octokit.repos.getContent({
owner,
repo,
path,
});
sha = fileData.sha; // File exists, so we'll update it
} catch (err) {
if (err.status !== 404) {
console.error('Error fetching file content:', err);
throw err;
}
// File does not exist; proceed to create it
}
// Create or update the file in the repository
await octokit.repos.createOrUpdateFileContents({
owner,
repo,
path,
message,
content: contentEncoded,
sha, // Include sha if updating an existing file
});
// Dispatch the workflow
const ref = 'main'; // You can make this dynamic if needed
await triggerWorkflowDispatch(octokit, owner, repo, ref, workflowId);
return {
statusCode: 200,
headers: getCorsHeaders(),
body: JSON.stringify({
message: 'File created/updated and workflow triggered',
path,
}),
};
} catch (error) {
console.error('Error in handleWebhook:', error);
return {
statusCode: error.statusCode || 500,
headers: getCorsHeaders(),
body: JSON.stringify({
message: error.message || 'An unexpected error occurred.',
}),
};
}
};
/**
* Handles requests to manually trigger a GitHub Actions workflow via HTTP endpoint.
* @param {Object} event - Event data from AWS Lambda invocation.
* @return {Object} Response object with statusCode, headers, and body.
*/
export const triggerGithubWorkflow = async (event) =&gt; {
try {
if (event.httpMethod === 'OPTIONS') {
// Respond to CORS preflight request
return {
statusCode: 200,
headers: getCorsHeaders(),
body: '',
};
}
console.log('Event received:', JSON.stringify(event, null, 2));
const body = event.body ? JSON.parse(event.body) : {};
const { ref = 'main', workflow_id, inputs = {} } = body;
// Validate required environment variables
const githubToken = process.env.GITHUB_TOKEN;
const githubRepository = process.env.GITHUB_REPOSITORY;
if (!githubToken || !githubRepository) {
throw new Error('Missing required environment variables.');
}
const workflowId = workflow_id || process.env.WORKFLOW_ID;
if (!workflowId) {
throw new Error('Workflow ID is required.');
}
const [owner, repo] = githubRepository.split('/');
const octokit = new Octokit({ auth: githubToken });
// Dispatch the workflow
await triggerWorkflowDispatch(octokit, owner, repo, ref, workflowId, inputs);
return {
statusCode: 200,
headers: getCorsHeaders(),
body: JSON.stringify({ message: 'Workflow dispatched successfully.' }),
};
} catch (error) {
console.error('Error in triggerGithubWorkflow:', error);
return {
statusCode: error.statusCode || 500,
headers: getCorsHeaders(),
body: JSON.stringify({
message: error.message || 'Failed to dispatch workflow.',
}),
};
}
};" data-download-link="" data-download-link-label="Download Javascript"><code class="language-javascript">import { Octokit } from "@octokit/rest";
import { Base64 } from "js-base64";
/**
* Converts a string to a URL-friendly slug.
* @param {string} text - The text to slugify.
* @return {string} Slugified text.
*/
const slugify = (text) =&gt; {
return text
.toString()
.toLowerCase()
.trim()
.replace(/\s+/g, '-')       // Replace spaces with -
.replace(/[^\w\-]+/g, '')   // Remove all non-word chars
.replace(/\-\-+/g, '-')     // Replace multiple - with single -
.replace(/^-+/, '')         // Trim - from start of text
.replace(/-+$/, '');        // Trim - from end of text
};
/**
* Formats a date string to YYYY-MM-DD.
* @param {string|Date} date - The date to format.
* @return {string} Formatted date string.
*/
const formatDate = (date) =&gt; {
const d = new Date(date);
if (isNaN(d.getTime())) {
throw new Error('Invalid date provided');
}
return d.toISOString().split('T')[0];
};
/**
* Creates the content for a blog post in Markdown format.
* @param {Object} data - Data for the blog post.
* @param {string} data.by_nickname - Author's nickname.
* @param {string} data.by_email - Author's email.
* @param {string} data.content - Post content.
* @param {string|Date} data.time - Timestamp of the post.
* @return {string} Formatted blog post content.
*/
const createPostContent = (data) =&gt; {
const { by_nickname, by_email, content, time } = data;
const slugName = slugify(by_nickname);
const date = formatDate(time);
return `---
tags: ${by_email}
info: aberto.
date: ${date}
type: post
layout: post
published: true
slug: ${slugName}
title: '${by_nickname}'
---
${content}`;
};
/**
* Triggers a GitHub Actions workflow using workflow_dispatch.
* @param {Octokit} octokit - Authenticated Octokit instance.
* @param {string} owner - Repository owner.
* @param {string} repo - Repository name.
* @param {string} ref - Git reference (branch or tag).
* @param {string} workflowId - Workflow file name or ID.
* @param {Object} inputs - Inputs for the workflow.
*/
const triggerWorkflowDispatch = async (octokit, owner, repo, ref, workflowId, inputs = {}) =&gt; {
try {
const response = await octokit.request(
'POST /repos/{owner}/{repo}/actions/workflows/{workflow_id}/dispatches',
{
owner,
repo,
workflow_id: workflowId,
ref,
inputs,
}
);
if (response.status !== 204) {
throw new Error(`Failed to dispatch workflow. GitHub API status: ${response.status}`);
}
console.log(`Workflow '${workflowId}' dispatched successfully on ${repo}`);
return response.data;
} catch (error) {
console.error('Error dispatching workflow:', error);
throw error;
}
};
/**
* Returns CORS headers.
* @return {Object} CORS headers.
*/
const getCorsHeaders = () =&gt; {
return {
'Access-Control-Allow-Origin': 'https://ib.bsb.br',
'Access-Control-Allow-Methods': 'POST, OPTIONS',
'Access-Control-Allow-Headers': 'Content-Type',
};
};
/**
* Handles incoming webhook events to create/update a blog post and trigger a workflow.
* @param {Object} event - Event data from AWS Lambda invocation.
* @return {Object} Response object with statusCode, headers, and body.
*/
export const handleWebhook = async (event) =&gt; {
try {
console.log('Event received:', JSON.stringify(event, null, 2));
let body;
// Determine if the event is from an HTTP request or EventBridge
if (event.body) {
// HTTP request
body = JSON.parse(event.body);
} else if (event.detail) {
// EventBridge event
body = event.detail;
} else {
throw new Error('No data received in the event.');
}
// Handle nested 'data' object if present
const data = body.data || body;
// Extract and validate data from the webhook event
const { by_nickname, by_email, content } = data;
if (!by_email || !by_nickname || !content) {
throw new Error('Missing required fields: by_email, by_nickname, or content.');
}
// Use 'createdAt' or 'updatedAt' as the time, or default to current time
let eventTime = data.createdAt || data.updatedAt || new Date().toISOString();
// Validate and format the time
try {
eventTime = formatDate(eventTime);
} catch (e) {
// If invalid, default to current date
eventTime = formatDate(new Date().toISOString());
}
// Validate required environment variables
const githubToken = process.env.GITHUB_TOKEN;
const githubRepository = process.env.GITHUB_REPOSITORY;
const workflowId = process.env.WORKFLOW_ID;
if (!githubToken || !githubRepository || !workflowId) {
throw new Error('Missing required environment variables.');
}
const [owner, repo] = githubRepository.split('/');
const octokit = new Octokit({ auth: githubToken });
// Create or update the blog post file in the repository
const slugName = slugify(by_nickname);
const path = `_posts/${eventTime}-${slugName}.md`;
const message = `New post by ${by_nickname}`;
const postContent = createPostContent({
by_nickname,
by_email,
content,
time: eventTime,
});
const contentEncoded = Base64.encode(postContent);
// Check if the file already exists
let sha;
try {
const { data: fileData } = await octokit.repos.getContent({
owner,
repo,
path,
});
sha = fileData.sha; // File exists, so we'll update it
} catch (err) {
if (err.status !== 404) {
console.error('Error fetching file content:', err);
throw err;
}
// File does not exist; proceed to create it
}
// Create or update the file in the repository
await octokit.repos.createOrUpdateFileContents({
owner,
repo,
path,
message,
content: contentEncoded,
sha, // Include sha if updating an existing file
});
// Dispatch the workflow
const ref = 'main'; // You can make this dynamic if needed
await triggerWorkflowDispatch(octokit, owner, repo, ref, workflowId);
return {
statusCode: 200,
headers: getCorsHeaders(),
body: JSON.stringify({
message: 'File created/updated and workflow triggered',
path,
}),
};
} catch (error) {
console.error('Error in handleWebhook:', error);
return {
statusCode: error.statusCode || 500,
headers: getCorsHeaders(),
body: JSON.stringify({
message: error.message || 'An unexpected error occurred.',
}),
};
}
};
/**
* Handles requests to manually trigger a GitHub Actions workflow via HTTP endpoint.
* @param {Object} event - Event data from AWS Lambda invocation.
* @return {Object} Response object with statusCode, headers, and body.
*/
export const triggerGithubWorkflow = async (event) =&gt; {
try {
if (event.httpMethod === 'OPTIONS') {
// Respond to CORS preflight request
return {
statusCode: 200,
headers: getCorsHeaders(),
body: '',
};
}
console.log('Event received:', JSON.stringify(event, null, 2));
const body = event.body ? JSON.parse(event.body) : {};
const { ref = 'main', workflow_id, inputs = {} } = body;
// Validate required environment variables
const githubToken = process.env.GITHUB_TOKEN;
const githubRepository = process.env.GITHUB_REPOSITORY;
if (!githubToken || !githubRepository) {
throw new Error('Missing required environment variables.');
}
const workflowId = workflow_id || process.env.WORKFLOW_ID;
if (!workflowId) {
throw new Error('Workflow ID is required.');
}
const [owner, repo] = githubRepository.split('/');
const octokit = new Octokit({ auth: githubToken });
// Dispatch the workflow
await triggerWorkflowDispatch(octokit, owner, repo, ref, workflowId, inputs);
return {
statusCode: 200,
headers: getCorsHeaders(),
body: JSON.stringify({ message: 'Workflow dispatched successfully.' }),
};
} catch (error) {
console.error('Error in triggerGithubWorkflow:', error);
return {
statusCode: error.statusCode || 500,
headers: getCorsHeaders(),
body: JSON.stringify({
message: error.message || 'Failed to dispatch workflow.',
}),
};
}
};</code></section>

<h1 id="3-client-side-javascript-if-applicable">3. Client-Side JavaScript (If Applicable):</h1>

<section data-filename="javascript_code-block.js" data-code="&lt;button id=&quot;triggerWorkflow&quot;&gt;Events&lt;/button&gt;
&lt;div id=&quot;calendar&quot;&gt;&lt;/div&gt;
&lt;script&gt;
document.getElementById('triggerWorkflow').addEventListener('click', async () =&gt; {
const webhookEndpoint = 'https://8k5ij92zn4.execute-api.us-east-1.amazonaws.com/dev/trigger_github_workflow'; // Replace with your actual endpoint
const payload = {
ref: 'main',
workflow_id: 'dispatch-workflow.yml', // Ensure this matches your GitHub Actions workflow filename
inputs: {
some_input: 'An example input' // Replace with actual inputs your workflow expects
}
};
try {
const response = await fetch(webhookEndpoint, {
method: 'POST',
headers: {
'Content-Type': 'application/json'
},
body: JSON.stringify(payload),
});
if (!response.ok) {
const errorData = await response.json();
throw new Error(`Server error: ${response.status} - ${errorData.message}`);
}
const data = await response.json();
console.log('Workflow dispatched successfully:', data);
alert('Workflow has been successfully triggered.');
} catch (error) {
console.error('Error triggering workflow:', error);
alert(`Failed to trigger workflow: ${error.message}`);
}
});
&lt;/script&gt;" data-download-link="" data-download-link-label="Download Javascript"><code class="language-javascript"><button id="triggerWorkflow">Events</button>
<div id="calendar"></div>
<script>
document.getElementById('triggerWorkflow').addEventListener('click', async () => {
const webhookEndpoint = 'https://8k5ij92zn4.execute-api.us-east-1.amazonaws.com/dev/trigger_github_workflow'; // Replace with your actual endpoint
const payload = {
ref: 'main',
workflow_id: 'dispatch-workflow.yml', // Ensure this matches your GitHub Actions workflow filename
inputs: {
some_input: 'An example input' // Replace with actual inputs your workflow expects
}
};
try {
const response = await fetch(webhookEndpoint, {
method: 'POST',
headers: {
'Content-Type': 'application/json'
},
body: JSON.stringify(payload),
});
if (!response.ok) {
const errorData = await response.json();
throw new Error(`Server error: ${response.status} - ${errorData.message}`);
}
const data = await response.json();
console.log('Workflow dispatched successfully:', data);
alert('Workflow has been successfully triggered.');
} catch (error) {
console.error('Error triggering workflow:', error);
alert(`Failed to trigger workflow: ${error.message}`);
}
});
</script></code></section>

<hr />

<h1 id="deployment-and-configuration-instructions">Deployment and Configuration Instructions:</h1>

<ol>
  <li>
    <p><strong>Set Environment Variables:</strong></p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">GITHUB_TOKEN</code>: Personal Access Token with appropriate permissions (stored securely).</li>
      <li><code class="language-plaintext highlighter-rouge">GITHUB_REPOSITORY</code>: Your GitHub repository in the format <code class="language-plaintext highlighter-rouge">owner/repo</code>.</li>
      <li><code class="language-plaintext highlighter-rouge">WORKFLOW_ID</code>: The filename or ID of the GitHub Actions workflow to trigger.</li>
    </ul>
  </li>
</ol>

<section data-filename="bash_code-block.sh" data-code="export GITHUB_TOKEN=&quot;your_personal_access_token&quot;
export GITHUB_REPOSITORY=&quot;owner/repo&quot;
export WORKFLOW_ID=&quot;main.yml&quot;" data-download-link="" data-download-link-label="Download Bash"><code class="language-bash">export GITHUB_TOKEN="your_personal_access_token"
export GITHUB_REPOSITORY="owner/repo"
export WORKFLOW_ID="main.yml"</code></section>

<ol>
  <li>
    <p><strong>Deploy the Serverless Application:</strong></p>

    <ul>
      <li>Install dependencies: <code class="language-plaintext highlighter-rouge">npm install</code></li>
      <li>Deploy using the Serverless Framework: (1) <code class="language-plaintext highlighter-rouge">{npx serverless print</code>; (2) <code class="language-plaintext highlighter-rouge">serverless deploy</code>.</li>
    </ul>
  </li>
  <li>
    <p><strong>Configure GitHub Actions Workflow:</strong></p>

    <ul>
      <li>Create a workflow file in your repository (e.g., <code class="language-plaintext highlighter-rouge">your-workflow-file.yml</code>).</li>
      <li>Ensure it includes <code class="language-plaintext highlighter-rouge">workflow_dispatch</code> in the <code class="language-plaintext highlighter-rouge">on</code> section:</li>
    </ul>
  </li>
</ol>

<section data-filename="yaml_code-block.yaml" data-code="name: Dispatch Workflow
on:
workflow_dispatch:
jobs:
dispatch_event:
runs-on: ubuntu-latest
steps:
- name: Dispatch GitHub Actions Workflow
run: |
curl -X POST \
-H &quot;Accept: application/vnd.github+json&quot; \
-H &quot;Authorization: Bearer $&quot; \
-H &quot;Content-Type: application/json&quot; \
-d '{&quot;event_type&quot;:&quot;trigger-jekyll&quot;, &quot;client_payload&quot;: {&quot;message&quot;: &quot;Triggered from main workflow&quot;}}' \
https://api.github.com/repos/ib-bsb-br/ib-bsb-br.github.io/dispatches" data-download-link="" data-download-link-label="Download Yaml"><code class="language-yaml">name: Dispatch Workflow
on:
workflow_dispatch:
jobs:
dispatch_event:
runs-on: ubuntu-latest
steps:
- name: Dispatch GitHub Actions Workflow
run: |
curl -X POST \
-H "Accept: application/vnd.github+json" \
-H "Authorization: Bearer $" \
-H "Content-Type: application/json" \
-d '{"event_type":"trigger-jekyll", "client_payload": {"message": "Triggered from main workflow"}}' \
https://api.github.com/repos/ib-bsb-br/ib-bsb-br.github.io/dispatches</code></section>]]></content><author><name></name></author><category term="scripts&gt;cloud," /><category term="tools&gt;github" /><summary type="html"><![CDATA[1. serverless.yml Configuration:]]></summary></entry><entry><title type="html">Compile LLM chat-history</title><link href="https://ib.bsb.br/llm-history/" rel="alternate" type="text/html" title="Compile LLM chat-history" /><published>2024-10-16T00:00:00+00:00</published><updated>2024-10-16T21:33:52+00:00</updated><id>https://ib.bsb.br/llm-history</id><content type="html" xml:base="https://ib.bsb.br/llm-history/"><![CDATA[<section data-filename="markdown_code-block.md" data-code="Based on our entire conversation, please provide an extensive chain of our queries and discussion, presented as a single comprehensive and coherent multi-paragraph query. Begin by thoroughly reviewing our entire interaction from the start, meticulously examining each query, prompt, and response.  This involves understanding not just the surface-level meaning of each exchange but also the underlying intent, assumptions, and desired outcomes.
Identify and analyze the overarching themes and objectives that have driven our conversation.  What core questions or problems have we been trying to address?  What are the key concepts and relationships we've explored? Pinpoint each specific request, question, and thesis addressed throughout our interaction.  This requires differentiating between initial inquiries, follow-up questions, clarifying statements, and responses provided. Note the evolution and refinement of these queries as our understanding developed.
Take careful note of any challenges or obstacles we encountered and explain the strategies or solutions employed to overcome them. Were there any ambiguities, contradictions, or gaps in information that needed to be resolved?  How did we address these challenges?  Did we rephrase queries, seek additional information, or adjust our approach? Identify key moments where progress was made or insights were gained. Analyze these pivotal points and their contributions towards the conversation’s trajectory and outcomes. How did these moments change our understanding or direction? What new possibilities did they open up?
Construct this detailed, multi-paragraph query to logically connect all identified elements.  This chained query should not be a mere chronological list of our exchanges.  Rather, it should be a narrative that tells the story of our conversation, highlighting the key turning points, the challenges we faced, and the progress we made. Employ clear, extensive language that meticulously and explicitly describes each step in the progression of our conversation, from the initial topic to our ultimate conclusions and solutions. Each component should build upon the previous one, demonstrating a coherent flow of thought and inquiry.
Ensure that your generated query integrates:
1. The complete and comprehensive overarching purpose of our entire exchange: What was the ultimate goal of our conversation?  What were we hoping to achieve?
2. A well-structured account of each specific topic, question, or thesis addressed in our queries:  What were the specific areas of focus within the broader conversation? How did these topics relate to one another?
3. Detailed analysis and explanations of all challenges encountered, innovative resolutions adopted, key milestones attained, and resulting realizations:  What were the critical junctures in our conversation?  How did these moments contribute to the overall outcome?
4. An integrated perspective of the final outcome and achieved solutions which reflect the progression of queries throughout our discourse, along with implications that arose from significant exchanges:  What did we learn? What conclusions did we reach?  What are the next steps?
Use transitional phrases and discourse markers within the single chained query to seamlessly connect distinct aspects, providing a cohesive account of our entire interaction from initiation to final resolution.  This ensures a smooth flow and logical progression between different segments of the query. Structure the response to mirror the natural progression of our dialogue, starting from initial questions and following the chain of enquiry to significant findings.  Articulate clearly how each point influences the overarching thematic concerns and ultimate objective realization. How did individual queries and responses contribute to achieving the overarching goals of our conversation?
Begin your response with: &quot;Based on our entire conversation, here is an extensive chain of your queries and our discussion, presented as a single comprehensive and coherent query:&quot;
This meticulously constructed chained query will provide a significant and detailed record, functioning as an extensive repository of our conversation history for thorough retrospective evaluation. It will offer valuable, reusable, and easily accessible insights into every aspect of our entire engagement, serving as a clear, extensive, and complete chain of our collaborative endeavor.  This query itself will represent a significant achievement, demonstrating our ability to collaboratively compile and analyze complex information to achieve a shared understanding." data-download-link="" data-download-link-label="Download Markdown"><code class="language-markdown">Based on our entire conversation, please provide an extensive chain of our queries and discussion, presented as a single comprehensive and coherent multi-paragraph query. Begin by thoroughly reviewing our entire interaction from the start, meticulously examining each query, prompt, and response.  This involves understanding not just the surface-level meaning of each exchange but also the underlying intent, assumptions, and desired outcomes.
Identify and analyze the overarching themes and objectives that have driven our conversation.  What core questions or problems have we been trying to address?  What are the key concepts and relationships we've explored? Pinpoint each specific request, question, and thesis addressed throughout our interaction.  This requires differentiating between initial inquiries, follow-up questions, clarifying statements, and responses provided. Note the evolution and refinement of these queries as our understanding developed.
Take careful note of any challenges or obstacles we encountered and explain the strategies or solutions employed to overcome them. Were there any ambiguities, contradictions, or gaps in information that needed to be resolved?  How did we address these challenges?  Did we rephrase queries, seek additional information, or adjust our approach? Identify key moments where progress was made or insights were gained. Analyze these pivotal points and their contributions towards the conversation’s trajectory and outcomes. How did these moments change our understanding or direction? What new possibilities did they open up?
Construct this detailed, multi-paragraph query to logically connect all identified elements.  This chained query should not be a mere chronological list of our exchanges.  Rather, it should be a narrative that tells the story of our conversation, highlighting the key turning points, the challenges we faced, and the progress we made. Employ clear, extensive language that meticulously and explicitly describes each step in the progression of our conversation, from the initial topic to our ultimate conclusions and solutions. Each component should build upon the previous one, demonstrating a coherent flow of thought and inquiry.
Ensure that your generated query integrates:
1. The complete and comprehensive overarching purpose of our entire exchange: What was the ultimate goal of our conversation?  What were we hoping to achieve?
2. A well-structured account of each specific topic, question, or thesis addressed in our queries:  What were the specific areas of focus within the broader conversation? How did these topics relate to one another?
3. Detailed analysis and explanations of all challenges encountered, innovative resolutions adopted, key milestones attained, and resulting realizations:  What were the critical junctures in our conversation?  How did these moments contribute to the overall outcome?
4. An integrated perspective of the final outcome and achieved solutions which reflect the progression of queries throughout our discourse, along with implications that arose from significant exchanges:  What did we learn? What conclusions did we reach?  What are the next steps?
Use transitional phrases and discourse markers within the single chained query to seamlessly connect distinct aspects, providing a cohesive account of our entire interaction from initiation to final resolution.  This ensures a smooth flow and logical progression between different segments of the query. Structure the response to mirror the natural progression of our dialogue, starting from initial questions and following the chain of enquiry to significant findings.  Articulate clearly how each point influences the overarching thematic concerns and ultimate objective realization. How did individual queries and responses contribute to achieving the overarching goals of our conversation?
Begin your response with: "Based on our entire conversation, here is an extensive chain of your queries and our discussion, presented as a single comprehensive and coherent query:"
This meticulously constructed chained query will provide a significant and detailed record, functioning as an extensive repository of our conversation history for thorough retrospective evaluation. It will offer valuable, reusable, and easily accessible insights into every aspect of our entire engagement, serving as a clear, extensive, and complete chain of our collaborative endeavor.  This query itself will represent a significant achievement, demonstrating our ability to collaboratively compile and analyze complex information to achieve a shared understanding.</code></section>]]></content><author><name></name></author><category term="AI&gt;prompt" /><summary type="html"><![CDATA[Based on our entire conversation, please provide an extensive chain of our queries and discussion, presented as a single comprehensive and coherent multi-paragraph query. Begin by thoroughly reviewing our entire interaction from the start, meticulously examining each query, prompt, and response. This involves understanding not just the surface-level meaning of each exchange but also the underlying intent, assumptions, and desired outcomes.]]></summary></entry><entry><title type="html">Serei um pai muito melhor</title><link href="https://ib.bsb.br/better-father/" rel="alternate" type="text/html" title="Serei um pai muito melhor" /><published>2024-10-15T00:00:00+00:00</published><updated>2024-10-15T14:29:36+00:00</updated><id>https://ib.bsb.br/better-father</id><content type="html" xml:base="https://ib.bsb.br/better-father/"><![CDATA[<video controls="">
  <source src="https://cdn.jsdelivr.net/gh/ib-bsb-br/ib-bsb-br.github.io@main/assets/Serei-Um-Pai-Muito-Melhor.mp4" type="video/mp4" />
  Seu navegador não suporta a reprodução de vídeos.
</video>]]></content><author><name></name></author><category term="fatherhood" /><summary type="html"><![CDATA[Seu navegador não suporta a reprodução de vídeos.]]></summary></entry><entry><title type="html">Filen CLI sync: Setup Guide for Linux</title><link href="https://ib.bsb.br/filen-linux/" rel="alternate" type="text/html" title="Filen CLI sync: Setup Guide for Linux" /><published>2024-10-13T00:00:00+00:00</published><updated>2024-10-14T23:41:06+00:00</updated><id>https://ib.bsb.br/filen-linux</id><content type="html" xml:base="https://ib.bsb.br/filen-linux/"><![CDATA[<h1 id="setting-up-filen-cli-as-a-systemd-service-on-debian-bullseye-arm64">Setting up Filen CLI as a Systemd Service on Debian Bullseye ARM64</h1>

<p>This guide outlines the process of installing and configuring the Filen CLI to run as a systemd service for continuous syncing on a Debian Bullseye ARM64 system.</p>

<h2 id="1-install-filen-cli">1. Install Filen CLI</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Download the ARM64 version of filen-cli</span>
wget https://cdn.filen.io/desktop/release/filen-cli_linux_arm64.tar.gz

<span class="c"># Extract the archive</span>
<span class="nb">tar</span> <span class="nt">-xzvf</span> filen-cli_linux_arm64.tar.gz

<span class="c"># Move the binary to a location in your PATH</span>
<span class="nb">sudo mv </span>filen-cli-v0.0.12-linux-arm64 /usr/bin/

<span class="c"># Verify installation</span>
/usr/bin/filen-cli-v0.0.12-linux-arm64 <span class="nt">--version</span>
</code></pre></div></div>

<h2 id="2-set-up-authentication">2. Set up Authentication</h2>

<p>Create a file named <code class="language-plaintext highlighter-rouge">.filen-cli-credentials</code> in the root user’s home directory:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>nano /root/.filen-cli-credentials
</code></pre></div></div>

<p>Add your Filen credentials to this file:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>your_email@example.com
your_password
your_2fa_code  # If 2FA is enabled
</code></pre></div></div>

<p>Secure the credentials file:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo chmod </span>600 /root/.filen-cli-credentials
</code></pre></div></div>

<h2 id="3-create-systemd-service-file">3. Create Systemd Service File</h2>

<p>Create a new systemd service file:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>nano /etc/systemd/system/filen-sync.service
</code></pre></div></div>

<p>Add the following content:</p>

<div class="language-ini highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">[Unit]</span>
<span class="py">Description</span><span class="p">=</span><span class="s">Filen CLI Sync Service</span>
<span class="py">After</span><span class="p">=</span><span class="s">network-online.target</span>
<span class="py">Wants</span><span class="p">=</span><span class="s">network-online.target</span>

<span class="nn">[Service]</span>
<span class="py">Type</span><span class="p">=</span><span class="s">simple</span>
<span class="py">ExecStart</span><span class="p">=</span><span class="s">/usr/bin/filen-cli-v0.0.12-linux-arm64 sync /userdata/000_download/share/:twoWay:/999_SHARED --continuous</span>
<span class="py">Restart</span><span class="p">=</span><span class="s">on-failure</span>
<span class="py">RestartSec</span><span class="p">=</span><span class="s">5</span>
<span class="py">User</span><span class="p">=</span><span class="s">root</span>
<span class="py">WorkingDirectory</span><span class="p">=</span><span class="s">/root</span>

<span class="nn">[Install]</span>
<span class="py">WantedBy</span><span class="p">=</span><span class="s">multi-user.target</span>
</code></pre></div></div>

<p>Note: Adjust the paths in the <code class="language-plaintext highlighter-rouge">ExecStart</code> line to match your specific sync requirements.</p>

<h2 id="4-enable-and-start-the-service">4. Enable and Start the Service</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Reload systemd configuration</span>
<span class="nb">sudo </span>systemctl daemon-reload

<span class="c"># Enable the service to start on boot</span>
<span class="nb">sudo </span>systemctl <span class="nb">enable </span>filen-sync.service

<span class="c"># Start the service</span>
<span class="nb">sudo </span>systemctl start filen-sync.service
</code></pre></div></div>

<h2 id="5-verify-service-status">5. Verify Service Status</h2>

<p>Check if the service is running correctly:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>systemctl status filen-sync.service
</code></pre></div></div>

<h2 id="6-monitor-logs">6. Monitor Logs</h2>

<p>To view the service logs:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>journalctl <span class="nt">-u</span> filen-sync.service <span class="nt">-f</span>
</code></pre></div></div>

<h2 id="troubleshooting">Troubleshooting</h2>

<p>If you encounter issues:</p>

<ol>
  <li>Check the service status and logs using the commands in steps 5 and 6.</li>
  <li>Ensure the sync directories exist and have the correct permissions.</li>
  <li>Verify the credentials in <code class="language-plaintext highlighter-rouge">/root/.filen-cli-credentials</code> are correct.</li>
  <li>
    <p>Try running the sync command manually to see if there are any errors:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo</span> /usr/bin/filen-cli-v0.0.12-linux-arm64 <span class="nb">sync</span> /userdata/000_download/share/:twoWay:/999_SHARED
</code></pre></div>    </div>
  </li>
  <li>If problems persist, check for updates to the Filen CLI or consult the official Filen documentation.</li>
</ol>

<h2 id="maintenance">Maintenance</h2>

<ul>
  <li>Periodically check for updates to the Filen CLI.</li>
  <li>To update, download the new version, replace the binary in <code class="language-plaintext highlighter-rouge">/usr/bin/</code>, and restart the service.</li>
  <li>Regularly review and adjust your sync settings as needed.</li>
</ul>

<p>Remember to keep your <code class="language-plaintext highlighter-rouge">.filen-cli-credentials</code> file secure and update it if you change your Filen account password.</p>]]></content><author><name></name></author><category term="software&gt;linux," /><category term="cloud" /><summary type="html"><![CDATA[Setting up Filen CLI as a Systemd Service on Debian Bullseye ARM64]]></summary></entry><entry><title type="html">Filen CLI sync: Setup Guide for Windows</title><link href="https://ib.bsb.br/filen-windows/" rel="alternate" type="text/html" title="Filen CLI sync: Setup Guide for Windows" /><published>2024-10-13T00:00:00+00:00</published><updated>2024-10-14T23:41:51+00:00</updated><id>https://ib.bsb.br/filen-windows</id><content type="html" xml:base="https://ib.bsb.br/filen-windows/"><![CDATA[<h1 id="setting-up-filen-cli-as-a-windows-service-on-windows-11">Setting up Filen CLI as a Windows Service on Windows 11</h1>

<p>This guide outlines the process of installing and configuring the Filen CLI to run as a Windows service for continuous syncing on a Windows 11 system.</p>

<h2 id="1-install-filen-cli">1. Install Filen CLI</h2>

<ol>
  <li>Download the Windows version of Filen CLI from the official website or GitHub repository.</li>
  <li>Extract the zip file to a permanent location, e.g., <code class="language-plaintext highlighter-rouge">C:\Program Files\Filen CLI\</code>.</li>
  <li>Rename the executable to <code class="language-plaintext highlighter-rouge">filen.exe</code> for simplicity.</li>
  <li>Add the Filen CLI directory to your system PATH:
    <ul>
      <li>Right-click on ‘This PC’ or ‘My Computer’ and select ‘Properties’.</li>
      <li>Click on ‘Advanced system settings’.</li>
      <li>Click on ‘Environment Variables’.</li>
      <li>Under ‘System variables’, find and select ‘Path’, then click ‘Edit’.</li>
      <li>Click ‘New’ and add the path to the Filen CLI directory (e.g., <code class="language-plaintext highlighter-rouge">C:\Program Files\Filen CLI\</code>).</li>
      <li>Click ‘OK’ to close all dialogs.</li>
    </ul>
  </li>
  <li>Verify installation by opening a new Command Prompt and running:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>filen --version
</code></pre></div>    </div>
  </li>
</ol>

<h2 id="2-set-up-authentication">2. Set up Authentication</h2>

<p>Create a file named <code class="language-plaintext highlighter-rouge">.filen-cli-credentials</code> in your user profile directory:</p>

<ol>
  <li>Open Notepad.</li>
  <li>Add your Filen credentials to this file:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>your_email@example.com
your_password
your_2fa_code  # If 2FA is enabled
</code></pre></div>    </div>
  </li>
  <li>Save the file as <code class="language-plaintext highlighter-rouge">C:\Users\YourUsername\.filen-cli-credentials</code> (replace <code class="language-plaintext highlighter-rouge">YourUsername</code> with your actual Windows username).</li>
</ol>

<p>Secure the credentials file:</p>
<ul>
  <li>Right-click on the file, select ‘Properties’.</li>
  <li>Go to the ‘Security’ tab, click ‘Edit’, and ensure only your user account has access.</li>
</ul>

<h2 id="3-create-a-windows-service">3. Create a Windows Service</h2>

<p>We’ll use the Non-Sucking Service Manager (NSSM) to create a Windows service:</p>

<ol>
  <li>Download NSSM from <a href="https://nssm.cc/">nssm.cc</a>.</li>
  <li>Extract the zip file and copy <code class="language-plaintext highlighter-rouge">nssm.exe</code> to <code class="language-plaintext highlighter-rouge">C:\Windows\System32\</code>.</li>
  <li>Open Command Prompt as Administrator.</li>
  <li>Run the following command to create the service:</li>
</ol>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nssm install FilenSync "C:\Program Files\Filen CLI\filen.exe" "sync C:\Users\YourUsername\FilenSync:twoWay:/999_SHARED --continuous"
</code></pre></div></div>

<p>Replace <code class="language-plaintext highlighter-rouge">YourUsername</code> with your actual Windows username and adjust the paths as necessary.</p>

<ol>
  <li>Set the service to run under your user account:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nssm set FilenSync ObjectName .\YourUsername YourPassword
</code></pre></div>    </div>
    <p>Replace <code class="language-plaintext highlighter-rouge">YourUsername</code> and <code class="language-plaintext highlighter-rouge">YourPassword</code> with your actual Windows credentials.</p>
  </li>
</ol>

<h2 id="4-start-the-service">4. Start the Service</h2>

<ol>
  <li>Open the Services application (services.msc).</li>
  <li>Find the “FilenSync” service.</li>
  <li>Right-click and select “Start”.</li>
</ol>

<p>To make the service start automatically on boot:</p>
<ol>
  <li>Right-click the service and select “Properties”.</li>
  <li>Set “Startup type” to “Automatic”.</li>
  <li>Click “Apply” and “OK”.</li>
</ol>

<h2 id="5-verify-service-status">5. Verify Service Status</h2>

<ol>
  <li>Open the Services application (services.msc).</li>
  <li>Find the “FilenSync” service.</li>
  <li>Check that its status is “Running”.</li>
</ol>

<h2 id="6-monitor-logs">6. Monitor Logs</h2>

<p>To view the service logs:</p>

<ol>
  <li>Open Event Viewer (eventvwr.msc).</li>
  <li>Expand “Windows Logs” and select “Application”.</li>
  <li>Look for events with “FilenSync” as the source.</li>
</ol>

<h2 id="troubleshooting">Troubleshooting</h2>

<p>If you encounter issues:</p>

<ol>
  <li>Check the service status in the Services application.</li>
  <li>Review the logs in Event Viewer.</li>
  <li>Ensure the sync directories exist and have the correct permissions.</li>
  <li>Verify the credentials in <code class="language-plaintext highlighter-rouge">C:\Users\YourUsername\.filen-cli-credentials</code> are correct.</li>
  <li>Try running the sync command manually to see if there are any errors:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"C:\Program Files\Filen CLI\filen.exe" sync C:\Users\YourUsername\FilenSync:twoWay:/999_SHARED
</code></pre></div>    </div>
  </li>
  <li>If problems persist, check for updates to the Filen CLI or consult the official Filen documentation.</li>
</ol>

<h2 id="maintenance">Maintenance</h2>

<ul>
  <li>Periodically check for updates to the Filen CLI.</li>
  <li>To update, download the new version, replace the executable in <code class="language-plaintext highlighter-rouge">C:\Program Files\Filen CLI\</code>, and restart the service.</li>
  <li>Regularly review and adjust your sync settings as needed.</li>
</ul>

<p>Remember to keep your <code class="language-plaintext highlighter-rouge">.filen-cli-credentials</code> file secure and update it if you change your Filen account password.</p>]]></content><author><name></name></author><category term="software&gt;windows," /><category term="cloud" /><summary type="html"><![CDATA[Setting up Filen CLI as a Windows Service on Windows 11]]></summary></entry><entry><title type="html">LLM - PRICING vs. ELO table</title><link href="https://ib.bsb.br/price-elo/" rel="alternate" type="text/html" title="LLM - PRICING vs. ELO table" /><published>2024-09-26T00:00:00+00:00</published><updated>2024-09-26T10:28:38+00:00</updated><id>https://ib.bsb.br/price-elo</id><content type="html" xml:base="https://ib.bsb.br/price-elo/"><![CDATA[<table>
  <thead>
    <tr>
      <th style="text-align: center"><strong>Model</strong></th>
      <th style="text-align: center"><strong>ELO</strong></th>
      <th style="text-align: center"><strong>$/ELO</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><strong>deepseek-v2.5</strong></td>
      <td style="text-align: center">47.31</td>
      <td style="text-align: center">6</td>
    </tr>
    <tr>
      <td style="text-align: center"><strong>gpt-4o-2024-08-06</strong></td>
      <td style="text-align: center">56.03</td>
      <td style="text-align: center">178</td>
    </tr>
    <tr>
      <td style="text-align: center"><strong>gemini-1.5-pro-002</strong></td>
      <td style="text-align: center">54.94</td>
      <td style="text-align: center">182</td>
    </tr>
    <tr>
      <td style="text-align: center"><strong>o1-mini-2024-09-12</strong></td>
      <td style="text-align: center">59.09</td>
      <td style="text-align: center">203</td>
    </tr>
    <tr>
      <td style="text-align: center"><strong>claude-3-5-sonnet-20240620</strong></td>
      <td style="text-align: center">59.8</td>
      <td style="text-align: center">251</td>
    </tr>
    <tr>
      <td style="text-align: center"><strong>o1-preview-2024-09-12</strong></td>
      <td style="text-align: center">66.02</td>
      <td style="text-align: center">909</td>
    </tr>
  </tbody>
</table>]]></content><author><name></name></author><category term="AI&gt;LLM" /><summary type="html"><![CDATA[Model ELO $/ELO deepseek-v2.5 47.31 6 gpt-4o-2024-08-06 56.03 178 gemini-1.5-pro-002 54.94 182 o1-mini-2024-09-12 59.09 203 claude-3-5-sonnet-20240620 59.8 251 o1-preview-2024-09-12 66.02 909]]></summary></entry><entry><title type="html">eidetic reduction</title><link href="https://ib.bsb.br/eidetic/" rel="alternate" type="text/html" title="eidetic reduction" /><published>2024-09-22T00:00:00+00:00</published><updated>2024-09-22T10:07:19+00:00</updated><id>https://ib.bsb.br/eidetic</id><content type="html" xml:base="https://ib.bsb.br/eidetic/"><![CDATA[<section data-filename="markdown_code-block.md" data-code="In this task, you are required to conduct a comprehensive analysis of the process of &quot;eidetic reduction&quot; as proposed by Edmund Husserl. You will apply this method to the specific phenomenon of `&lt;--! insert detailed description of the phenomenon --&gt;`. Your analysis should follow the steps of the phenomenological method as outlined below:
1) **Phenomenon Selection**: Select the phenomenon of `&lt;--! insert detailed description of the phenomenon --&gt;` as the subject of your analysis.
2) **Detailed Description**: Provide an in-depth description of the phenomenon of `&lt;--! insert detailed description of the phenomenon --&gt;`, detailing all its characteristics and changes as they are immediately perceived. This should be done without any prior judgments, focusing solely on how the phenomenon presents itself to consciousness.
3) **Epokhé or Suspension of Judgment**: Engage in phenomenological suspension or &quot;epoché&quot;. This involves distancing yourself from any preconceived notions or beliefs about the objective existence of `&lt;--! insert detailed description of the phenomenon --&gt;`. The aim is to neutralize any previous opinions and naturalistic approaches that are commonly assumed.
4) **Imaginative Variation**: During this stage, alter the characteristics of the phenomenon of `&lt;--! insert detailed description of the phenomenon --&gt;` in your imagination. This involves visualizing the phenomenon from multiple perspectives and in various contexts.
5) **Essence Identification**: Identify the invariant aspects of `&lt;--! insert detailed description of the phenomenon --&gt;` that remain consistent despite these imaginative variations. Highlight the essential elements that define the concept of `&lt;--! insert detailed description of the phenomenon --&gt;` in its entirety.
6) **Intuition of Essences**: Reflect on the eidetic intuition of `&lt;--! insert detailed description of the phenomenon --&gt;`, where the essence of the phenomenon unfolds without the need for empirical experience or deduction.
7) **Description of Essence**: Lastly, articulate the essence of `&lt;--! insert detailed description of the phenomenon --&gt;` as you understand it. This should include a specification of its universality and indispensability.
The goal of this exercise is to discern the &quot;eidos&quot; or the pure essence of the phenomenon of `&lt;--! insert detailed description of the phenomenon --&gt;`, abstracted from empirical and contingent circumstances. This process of eidetic reduction, according to Husserl, is intended to deepen your phenomenological understanding and should include both a theoretical basis and a practical application of the steps listed.
Your response should be structured as follows:
i) An introduction that outlines the eidetic reduction method and its relevance to understanding the phenomenon of `&lt;--! insert detailed description of the phenomenon --&gt;`.
ii) A detailed explanation of each stage of the process, applying them to the specific example and highlighting the analytical progression until the essences are understood.
iii) A conclusion that summarizes the findings and reflects on the usefulness of the method in understanding the concept of `&lt;--! insert detailed description of the phenomenon --&gt;`.
Ensure your answer is written in academic language, is clear and organized, and follows a logical step-by-step development of ideas." data-download-link="" data-download-link-label="Download Markdown"><code class="language-markdown">In this task, you are required to conduct a comprehensive analysis of the process of "eidetic reduction" as proposed by Edmund Husserl. You will apply this method to the specific phenomenon of `&lt;--! insert detailed description of the phenomenon --&gt;`. Your analysis should follow the steps of the phenomenological method as outlined below:
1) **Phenomenon Selection**: Select the phenomenon of `&lt;--! insert detailed description of the phenomenon --&gt;` as the subject of your analysis.
2) **Detailed Description**: Provide an in-depth description of the phenomenon of `&lt;--! insert detailed description of the phenomenon --&gt;`, detailing all its characteristics and changes as they are immediately perceived. This should be done without any prior judgments, focusing solely on how the phenomenon presents itself to consciousness.
3) **Epokhé or Suspension of Judgment**: Engage in phenomenological suspension or "epoché". This involves distancing yourself from any preconceived notions or beliefs about the objective existence of `&lt;--! insert detailed description of the phenomenon --&gt;`. The aim is to neutralize any previous opinions and naturalistic approaches that are commonly assumed.
4) **Imaginative Variation**: During this stage, alter the characteristics of the phenomenon of `&lt;--! insert detailed description of the phenomenon --&gt;` in your imagination. This involves visualizing the phenomenon from multiple perspectives and in various contexts.
5) **Essence Identification**: Identify the invariant aspects of `&lt;--! insert detailed description of the phenomenon --&gt;` that remain consistent despite these imaginative variations. Highlight the essential elements that define the concept of `&lt;--! insert detailed description of the phenomenon --&gt;` in its entirety.
6) **Intuition of Essences**: Reflect on the eidetic intuition of `&lt;--! insert detailed description of the phenomenon --&gt;`, where the essence of the phenomenon unfolds without the need for empirical experience or deduction.
7) **Description of Essence**: Lastly, articulate the essence of `&lt;--! insert detailed description of the phenomenon --&gt;` as you understand it. This should include a specification of its universality and indispensability.
The goal of this exercise is to discern the "eidos" or the pure essence of the phenomenon of `&lt;--! insert detailed description of the phenomenon --&gt;`, abstracted from empirical and contingent circumstances. This process of eidetic reduction, according to Husserl, is intended to deepen your phenomenological understanding and should include both a theoretical basis and a practical application of the steps listed.
Your response should be structured as follows:
i) An introduction that outlines the eidetic reduction method and its relevance to understanding the phenomenon of `&lt;--! insert detailed description of the phenomenon --&gt;`.
ii) A detailed explanation of each stage of the process, applying them to the specific example and highlighting the analytical progression until the essences are understood.
iii) A conclusion that summarizes the findings and reflects on the usefulness of the method in understanding the concept of `&lt;--! insert detailed description of the phenomenon --&gt;`.
Ensure your answer is written in academic language, is clear and organized, and follows a logical step-by-step development of ideas.</code></section>]]></content><author><name></name></author><category term="AI&gt;prompt" /><summary type="html"><![CDATA[In this task, you are required to conduct a comprehensive analysis of the process of "eidetic reduction" as proposed by Edmund Husserl. You will apply this method to the specific phenomenon of `&lt;--! insert detailed description of the phenomenon --&gt;`. Your analysis should follow the steps of the phenomenological method as outlined below:]]></summary></entry><entry><title type="html">Webhooks using `Serverless.com` Lift plugin</title><link href="https://ib.bsb.br/serverless-lift/" rel="alternate" type="text/html" title="Webhooks using `Serverless.com` Lift plugin" /><published>2024-09-21T00:00:00+00:00</published><updated>2024-09-21T17:47:16+00:00</updated><id>https://ib.bsb.br/serverless-lift</id><content type="html" xml:base="https://ib.bsb.br/serverless-lift/"><![CDATA[<h1 id="serverlessyml">serverless.yml</h1>

<section data-filename="yaml_code-block.yaml" data-code="service: github-webhook-service
provider:
name: aws
runtime: nodejs20.x
region: us-east-1
environment:
GITHUB_TOKEN: ${env:GITHUB_TOKEN}
plugins:
- serverless-lift
constructs:
webhook:
type: webhook
path: /webhook
method: POST
eventType: $request.body.type
insecure: true
functions:
handleWebhook:
handler: handler.handleWebhook
events:
- eventBridge:
eventBus: ${construct:webhook.busName}
pattern:
source:
- webhook
detail-type:
- new_comment
package:
patterns:
- '!node_modules/aws-sdk/**'
- '!node_modules/@aws-sdk/**'" data-download-link="" data-download-link-label="Download Yaml"><code class="language-yaml">service: github-webhook-service
provider:
name: aws
runtime: nodejs20.x
region: us-east-1
environment:
GITHUB_TOKEN: ${env:GITHUB_TOKEN}
plugins:
- serverless-lift
constructs:
webhook:
type: webhook
path: /webhook
method: POST
eventType: $request.body.type
insecure: true
functions:
handleWebhook:
handler: handler.handleWebhook
events:
- eventBridge:
eventBus: ${construct:webhook.busName}
pattern:
source:
- webhook
detail-type:
- new_comment
package:
patterns:
- '!node_modules/aws-sdk/**'
- '!node_modules/@aws-sdk/**'</code></section>

<h1 id="handlermjs">handler.mjs</h1>

<section data-filename="javascript_code-block.js" data-code="import { Octokit } from &quot;@octokit/rest&quot;;
import { Base64 } from &quot;js-base64&quot;;
/**
* Converts a string to a URL-friendly slug.
* @param {string} text - The text to be slugified.
* @return {string} The slugified text.
*/
const slugify = (text) =&gt; {
return text
.toString()
.toLowerCase()
.trim()
.replace(/\s+/g, '-')           // Replace spaces with -
.replace(/[^\w\-]+/g, '')       // Remove all non-word chars
.replace(/\-\-+/g, '-')         // Replace multiple - with single -
.replace(/^-+/, '')             // Trim - from start of text
.replace(/-+$/, '');            // Trim - from end of text
};
/**
* Formats a date string to YYYY-MM-DD.
* @param {string} date - The date string to format.
* @return {string} The formatted date string.
*/
const formatDate = (date) =&gt; {
const d = new Date(date);
if (isNaN(d.getTime())) {
throw new Error('Invalid date provided');
}
return d.toISOString().split('T')[0];
};
/**
* Creates the content for a blog post.
* @param {Object} data - The data for the blog post.
* @param {string} data.by_nickname - The author's nickname.
* @param {string} data.by_email - The author's email.
* @param {string} data.content - The content of the post.
* @param {string} data.time - The timestamp of the post.
* @return {string} The formatted blog post content.
*/
const createPostContent = (data) =&gt; {
const { by_nickname, by_email, content, time } = data;
const slugName = slugify(by_nickname);
const date = formatDate(time);
return `---
tags:
- ${by_email}
info: aberto.
date: ${date}
type: post
layout: post
published: true
slug: ${slugName}
title: '${by_nickname}'
---
${content}`;
};
/**
* Handles the webhook event for creating a new blog post.
* @param {Object} event - The webhook event object.
* @return {Object} The response object.
*/
export const handleWebhook = async (event) =&gt; {
try {
if (!event || !event.detail || !event.detail.data) {
throw new Error('Invalid event structure');
}
const { by_nickname, by_email, content } = event.detail.data;
const time = event.time || new Date().toISOString();
if (!by_email || !by_nickname || !content) {
throw new Error('Missing required fields: email, nickname, or content');
}
const octokit = new Octokit({ auth: process.env.GITHUB_TOKEN });
if (!process.env.GITHUB_TOKEN) {
throw new Error('GitHub token is not set');
}
const owner = &quot;${REPO_OWNER}&quot;;
const repo = &quot;${REPO_NAME}&quot;;
const date = formatDate(time);
const slugName = slugify(by_nickname);
const path = `_posts/${date}-${slugName}.md`;
const message = `New post by ${by_nickname}`;
const postContent = createPostContent({ by_nickname, by_email, content, time });
const contentEncoded = Base64.encode(postContent);
await octokit.repos.createOrUpdateFileContents({
owner,
repo,
path,
message,
content: contentEncoded,
});
return {
statusCode: 200,
body: JSON.stringify({ message: &quot;File created/updated successfully&quot;, path }),
};
} catch (error) {
console.error('Error in handleWebhook:', error);
return {
statusCode: error.status || 500,
body: JSON.stringify({ message: error.message || &quot;An unexpected error occurred&quot; }),
};
}
};" data-download-link="" data-download-link-label="Download Javascript"><code class="language-javascript">import { Octokit } from "@octokit/rest";
import { Base64 } from "js-base64";
/**
* Converts a string to a URL-friendly slug.
* @param {string} text - The text to be slugified.
* @return {string} The slugified text.
*/
const slugify = (text) =&gt; {
return text
.toString()
.toLowerCase()
.trim()
.replace(/\s+/g, '-')           // Replace spaces with -
.replace(/[^\w\-]+/g, '')       // Remove all non-word chars
.replace(/\-\-+/g, '-')         // Replace multiple - with single -
.replace(/^-+/, '')             // Trim - from start of text
.replace(/-+$/, '');            // Trim - from end of text
};
/**
* Formats a date string to YYYY-MM-DD.
* @param {string} date - The date string to format.
* @return {string} The formatted date string.
*/
const formatDate = (date) =&gt; {
const d = new Date(date);
if (isNaN(d.getTime())) {
throw new Error('Invalid date provided');
}
return d.toISOString().split('T')[0];
};
/**
* Creates the content for a blog post.
* @param {Object} data - The data for the blog post.
* @param {string} data.by_nickname - The author's nickname.
* @param {string} data.by_email - The author's email.
* @param {string} data.content - The content of the post.
* @param {string} data.time - The timestamp of the post.
* @return {string} The formatted blog post content.
*/
const createPostContent = (data) =&gt; {
const { by_nickname, by_email, content, time } = data;
const slugName = slugify(by_nickname);
const date = formatDate(time);
return `---
tags:
- ${by_email}
info: aberto.
date: ${date}
type: post
layout: post
published: true
slug: ${slugName}
title: '${by_nickname}'
---
${content}`;
};
/**
* Handles the webhook event for creating a new blog post.
* @param {Object} event - The webhook event object.
* @return {Object} The response object.
*/
export const handleWebhook = async (event) =&gt; {
try {
if (!event || !event.detail || !event.detail.data) {
throw new Error('Invalid event structure');
}
const { by_nickname, by_email, content } = event.detail.data;
const time = event.time || new Date().toISOString();
if (!by_email || !by_nickname || !content) {
throw new Error('Missing required fields: email, nickname, or content');
}
const octokit = new Octokit({ auth: process.env.GITHUB_TOKEN });
if (!process.env.GITHUB_TOKEN) {
throw new Error('GitHub token is not set');
}
const owner = "${REPO_OWNER}";
const repo = "${REPO_NAME}";
const date = formatDate(time);
const slugName = slugify(by_nickname);
const path = `_posts/${date}-${slugName}.md`;
const message = `New post by ${by_nickname}`;
const postContent = createPostContent({ by_nickname, by_email, content, time });
const contentEncoded = Base64.encode(postContent);
await octokit.repos.createOrUpdateFileContents({
owner,
repo,
path,
message,
content: contentEncoded,
});
return {
statusCode: 200,
body: JSON.stringify({ message: "File created/updated successfully", path }),
};
} catch (error) {
console.error('Error in handleWebhook:', error);
return {
statusCode: error.status || 500,
body: JSON.stringify({ message: error.message || "An unexpected error occurred" }),
};
}
};</code></section>]]></content><author><name></name></author><category term="scripts&gt;cloud" /><summary type="html"><![CDATA[serverless.yml]]></summary></entry></feed>
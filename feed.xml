<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://ib.bsb.br/feed.xml" rel="self" type="application/atom+xml" /><link href="https://ib.bsb.br/" rel="alternate" type="text/html" /><updated>2025-12-24T15:38:37+00:00</updated><id>https://ib.bsb.br/feed.xml</id><title type="html">infoBAG</title><entry><title type="html">verify OpenGL+OpenGL ES within Bullseye</title><link href="https://ib.bsb.br/opengl-status/" rel="alternate" type="text/html" title="verify OpenGL+OpenGL ES within Bullseye" /><published>2025-12-24T00:00:00+00:00</published><updated>2025-12-24T15:32:41+00:00</updated><id>https://ib.bsb.br/opengl-status</id><content type="html" xml:base="https://ib.bsb.br/opengl-status/"><![CDATA[<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>

<span class="c"># Description: Exhaustively lists OpenGL/ES/EGL/Mesa packages and verifies runtime versions.</span>
<span class="c"># OS Target: Debian 11 (Bullseye)</span>

<span class="c"># Define colors for readability</span>
<span class="nv">BOLD</span><span class="o">=</span><span class="s2">"</span><span class="se">\0</span><span class="s2">33[1m"</span>
<span class="nv">CYAN</span><span class="o">=</span><span class="s2">"</span><span class="se">\0</span><span class="s2">33[36m"</span>
<span class="nv">GREEN</span><span class="o">=</span><span class="s2">"</span><span class="se">\0</span><span class="s2">33[32m"</span>
<span class="nv">RED</span><span class="o">=</span><span class="s2">"</span><span class="se">\0</span><span class="s2">33[31m"</span>
<span class="nv">RESET</span><span class="o">=</span><span class="s2">"</span><span class="se">\0</span><span class="s2">33[0m"</span>

<span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="k">${</span><span class="nv">BOLD</span><span class="k">}</span><span class="s2">==================================================</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="s2">"</span>
<span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="k">${</span><span class="nv">BOLD</span><span class="k">}</span><span class="s2"> PART 1: EXHAUSTIVE PACKAGE AUDIT</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="s2">"</span>
<span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="k">${</span><span class="nv">BOLD</span><span class="k">}</span><span class="s2">==================================================</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="s2">"</span>

<span class="c"># 1. SEARCH PATTERN</span>
<span class="c"># We look for: mesa, opengl, libgl(x), libgles, libegl, and nvidia (if present).</span>
<span class="c"># We EXCLUDE: libglib (GNOME core), glibc (C library), and unrelated globs.</span>
<span class="nv">SEARCH_REGEX</span><span class="o">=</span><span class="s2">"^(libgl[0-9]|libglx|libgles|libegl|mesa|nvidia|xserver-xorg-video|opengl)"</span>
<span class="nv">EXCLUDE_REGEX</span><span class="o">=</span><span class="s2">"(libglib|glibc|syslog|global)"</span>

<span class="c"># 2. DYNAMIC DISCOVERY</span>
<span class="c"># Get list of ALL installed packages matching the regex.</span>
<span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="k">${</span><span class="nv">CYAN</span><span class="k">}</span><span class="s2">[*] Scanning dpkg database for all graphics-related packages...</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="se">\n</span><span class="s2">"</span>

<span class="c"># Format: PackageName Version</span>
<span class="c"># We use grep to filter the list of installed packages.</span>
<span class="nv">MATCHING_PACKAGES</span><span class="o">=</span><span class="si">$(</span>dpkg-query <span class="nt">-W</span> <span class="nt">-f</span><span class="o">=</span><span class="s1">'${Package} ${Version}\n'</span> | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s2">"</span><span class="nv">$SEARCH_REGEX</span><span class="s2">"</span> | <span class="nb">grep</span> <span class="nt">-v</span> <span class="nt">-E</span> <span class="s2">"</span><span class="nv">$EXCLUDE_REGEX</span><span class="s2">"</span> | <span class="nb">sort</span><span class="si">)</span>

<span class="k">if</span> <span class="o">[</span> <span class="nt">-z</span> <span class="s2">"</span><span class="nv">$MATCHING_PACKAGES</span><span class="s2">"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then
    </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="k">${</span><span class="nv">RED</span><span class="k">}</span><span class="s2">[!] No OpenGL/Mesa packages found!</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="s2">"</span>
<span class="k">else
    </span><span class="nb">printf</span> <span class="s2">"%-40s %-30s</span><span class="se">\n</span><span class="s2">"</span> <span class="s2">"PACKAGE NAME"</span> <span class="s2">"INSTALLED VERSION"</span>
    <span class="nb">printf</span> <span class="s2">"%-40s %-30s</span><span class="se">\n</span><span class="s2">"</span> <span class="s2">"------------"</span> <span class="s2">"-----------------"</span>
    <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$MATCHING_PACKAGES</span><span class="s2">"</span> | <span class="nb">awk</span> <span class="s1">'{printf "%-40s %s\n", $1, $2}'</span>
<span class="k">fi

</span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="se">\n</span><span class="k">${</span><span class="nv">BOLD</span><span class="k">}</span><span class="s2">==================================================</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="s2">"</span>
<span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="k">${</span><span class="nv">BOLD</span><span class="k">}</span><span class="s2"> PART 2: RUNTIME CAPABILITY CHECK</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="s2">"</span>
<span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="k">${</span><span class="nv">BOLD</span><span class="k">}</span><span class="s2">==================================================</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="s2">"</span>

<span class="c"># 3. RUNTIME VERIFICATION</span>
<span class="c"># Keeps going even if tools are missing.</span>

<span class="c"># Check for glxinfo (Standard OpenGL)</span>
<span class="k">if </span><span class="nb">command</span> <span class="nt">-v</span> glxinfo &amp;&gt; /dev/null<span class="p">;</span> <span class="k">then
    </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="k">${</span><span class="nv">GREEN</span><span class="k">}</span><span class="s2">[*] Testing Standard OpenGL (glxinfo):</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="s2">"</span>
    <span class="c"># Extract relevant version lines</span>
    glxinfo | <span class="nb">grep</span> <span class="nt">-E</span> <span class="nt">-i</span> <span class="s2">"(OpenGL version|OpenGL renderer|OpenGL vendor|OpenGL core profile version)"</span> | <span class="nb">sed</span> <span class="s1">'s/^/    /'</span>
<span class="k">else
    </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="k">${</span><span class="nv">RED</span><span class="k">}</span><span class="s2">[MISSING] 'glxinfo' not found.</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="s2"> Install 'mesa-utils' to verify runtime OpenGL."</span>
<span class="k">fi

</span><span class="nb">echo</span> <span class="s2">""</span>

<span class="c"># Check for es2_info (OpenGL ES)</span>
<span class="k">if </span><span class="nb">command</span> <span class="nt">-v</span> es2_info &amp;&gt; /dev/null<span class="p">;</span> <span class="k">then
    </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="k">${</span><span class="nv">GREEN</span><span class="k">}</span><span class="s2">[*] Testing OpenGL ES (es2_info):</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="s2">"</span>
    <span class="c"># Extract relevant version lines</span>
    es2_info | <span class="nb">grep</span> <span class="nt">-E</span> <span class="nt">-i</span> <span class="s2">"(GL_VERSION|GL_RENDERER|GL_VENDOR)"</span> | <span class="nb">sed</span> <span class="s1">'s/^/    /'</span>
<span class="k">else
    </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="k">${</span><span class="nv">RED</span><span class="k">}</span><span class="s2">[MISSING] 'es2_info' not found.</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="s2"> Install 'mesa-utils-extra' to verify runtime OpenGL ES."</span>
<span class="k">fi

</span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="se">\n</span><span class="k">${</span><span class="nv">BOLD</span><span class="k">}</span><span class="s2">[DONE] Verification complete.</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="s2">"</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="scratchpad" /></entry><entry><title type="html">RK3588 capability scan</title><link href="https://ib.bsb.br/rk3588-scan/" rel="alternate" type="text/html" title="RK3588 capability scan" /><published>2025-12-19T00:00:00+00:00</published><updated>2025-12-19T19:26:27+00:00</updated><id>https://ib.bsb.br/rk3588-scan</id><content type="html" xml:base="https://ib.bsb.br/rk3588-scan/"><![CDATA[<h1 id="rk3588_auditsh">rk3588_audit.sh</h1>
<section class="code-block-container" role="group" aria-label=" Code Block" data-filename="_code_block.txt" data-code="#!/usr/bin/env bash
set -euo pipefail
set -o errtrace
IFS=$&#39;\n\t&#39;
trap &#39;echo &quot;Error on or near line ${LINENO}; command exited with status $?&quot; &gt;&amp;2&#39; ERR

# rk3588_audit.sh
#
# Purpose:
#   - Create a timestamped audit directory under ~/rk3588_audit_&lt;timestamp&gt;/
#   - Collect system/display/GPU/VPU/network/storage snapshots
#   - Install diagnostic packages idempotently (skips missing packages)
#   - Avoid destructive actions; optional actions require explicit confirmation

START_TS=&quot;$(date +%Y%m%d_%H%M%S)&quot;
AUDIT_DIR=&quot;$HOME/rk3588_audit_${START_TS}&quot;
LOG_DIR=&quot;$AUDIT_DIR/logs&quot;
OUT_DIR=&quot;$AUDIT_DIR/out&quot;
REPORT_MD=&quot;$AUDIT_DIR/REPORT.md&quot;
LOG_FILE=&quot;$LOG_DIR/audit.log&quot;
ENV_FILE=&quot;$LOG_DIR/env.txt&quot;
DMESG_FILE=&quot;$LOG_DIR/dmesg.txt&quot;

CMD_FAIL_HINT=&quot;Check ${LOG_FILE} and ${REPORT_MD} for details.&quot;

: &quot;${NET_TIMEOUT:=5}&quot;
: &quot;${FIO_SIZE_MB:=512}&quot;
: &quot;${FIO_BS:=1M}&quot;
: &quot;${FIO_IODEPTH:=16}&quot;
: &quot;${RUN_COLORS:=1}&quot;

TMPDIR_CREATED=&quot;&quot;
cleanup() {
  if [[ -n &quot;${TMPDIR_CREATED:-}&quot; &amp;&amp; -d &quot;$TMPDIR_CREATED&quot; ]]; then
    rm -rf &quot;$TMPDIR_CREATED&quot; || true
  fi
}
trap cleanup EXIT SIGINT SIGTERM

if [[ -t 1 &amp;&amp; &quot;$RUN_COLORS&quot; -eq 1 ]] &amp;&amp; command -v tput &gt;/dev/null 2&gt;&amp;1; then
  GREEN=&quot;$(tput setaf 2)&quot;; YELLOW=&quot;$(tput setaf 3)&quot;; RED=&quot;$(tput setaf 1)&quot;; BLUE=&quot;$(tput setaf 4)&quot;; BOLD=&quot;$(tput bold)&quot;; RESET=&quot;$(tput sgr0)&quot;
else
  GREEN=&quot;&quot;; YELLOW=&quot;&quot;; RED=&quot;&quot;; BLUE=&quot;&quot;; BOLD=&quot;&quot;; RESET=&quot;&quot;
fi

log() { echo -e &quot;$*&quot; | tee -a &quot;$LOG_FILE&quot;; }
section() { log &quot;\n${BOLD}${BLUE}==&gt; $1${RESET}&quot;; }

ensure_dir() { [[ -d &quot;$1&quot; ]] || mkdir -p &quot;$1&quot;; }

ask_yes() {
  local prompt=&quot;$1&quot; ans
  echo
  read -r -p &quot;${YELLOW}${prompt}${RESET} (type &#39;yes&#39; to continue, anything else to cancel): &quot; ans
  [[ &quot;$ans&quot; == &quot;yes&quot; ]] || { echo &quot;Cancelled by user.&quot;; return 1; }
}

need_sudo() {
  command -v sudo &gt;/dev/null 2&gt;&amp;1 || { echo &quot;Error: sudo required.&quot; &gt;&amp;2; exit 1; }
  sudo -v || { echo &quot;Error: sudo auth failed.&quot; &gt;&amp;2; exit 1; }
}

package_available() {
  local pkg=&quot;$1&quot;
  apt-cache policy &quot;$pkg&quot; 2&gt;/dev/null | awk &#39;/Candidate:/ {print $2}&#39; | grep -vq &quot;(none)&quot;
}

is_installed() { dpkg -s &quot;$1&quot; &gt;/dev/null 2&gt;&amp;1; }

ensure_package() {
  local pkg=&quot;$1&quot;
  if is_installed &quot;$pkg&quot;; then
    log &quot;Package already installed: ${GREEN}${pkg}${RESET}&quot;
    return 0
  fi
  if ! package_available &quot;$pkg&quot;; then
    log &quot;Package not available (skipping): ${YELLOW}${pkg}${RESET}&quot;
    return 0
  fi
  log &quot;Installing package: ${GREEN}${pkg}${RESET}&quot;
  sudo apt-get install -y --no-install-recommends &quot;$pkg&quot; &gt;&gt;&quot;$LOG_FILE&quot; 2&gt;&amp;1 || {
    echo &quot;Error: Failed to install &#39;$pkg&#39;. ${CMD_FAIL_HINT}&quot; &gt;&amp;2
    exit 1
  }
}

ensure_packages() { for pkg in &quot;$@&quot;; do ensure_package &quot;$pkg&quot;; done; }

run_continue() {
  local title=&quot;$1&quot;; shift
  log &quot;\n--- $title ---&quot;
  &quot;$@&quot; &gt;&gt;&quot;$LOG_FILE&quot; 2&gt;&amp;1 || log &quot;  (Command failed but continuing): $*&quot;
}

run_fail() {
  local title=&quot;$1&quot;; shift
  log &quot;\n&gt;&gt;&gt; $title&quot;
  &quot;$@&quot; &gt;&gt;&quot;$LOG_FILE&quot; 2&gt;&amp;1 || { echo &quot;Error: $title failed. ${CMD_FAIL_HINT}&quot; &gt;&amp;2; exit 1; }
}

quick_net_check() {
  section &quot;Quick network check&quot;
  if command -v ping &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ping -c1 -W &quot;$NET_TIMEOUT&quot; deb.debian.org &gt;/dev/null 2&gt;&amp;1; then
    log &quot;Network reachable.&quot;
    return 0
  fi
  log &quot;Network check failed; installs/downloads may be limited.&quot;
  return 1
}

check_platform() {
  section &quot;Platform checks&quot;
  local debver arch
  debver=&quot;$(cut -d&#39;.&#39; -f1 &lt; /etc/debian_version 2&gt;/dev/null || echo unknown)&quot;
  arch=&quot;$(uname -m 2&gt;/dev/null || echo unknown)&quot;
  log &quot;Debian major: $debver&quot;
  log &quot;Arch        : $arch&quot;
  [[ &quot;$debver&quot; == &quot;11&quot; ]] || log &quot;WARNING: tuned for Debian 11 (Bullseye).&quot;
  [[ &quot;$arch&quot; == &quot;aarch64&quot; || &quot;$arch&quot; == &quot;arm64&quot; ]] || log &quot;WARNING: tuned for ARM64.&quot;
}

enable_nonfree_optional() {
  section &quot;Optional: Enable contrib/non-free (Bullseye)&quot;
  if ! ask_yes &quot;Enable &#39;contrib non-free&#39; in /etc/apt/sources.list (backup + apt update)?&quot;; then
    log &quot;Skipped enabling contrib/non-free.&quot;
    return 0
  fi

  local src=&quot;/etc/apt/sources.list&quot;
  if [[ ! -f &quot;$src&quot; ]]; then
    log &quot;No $src found; skipping.&quot;
    return 0
  fi

  sudo cp -a &quot;$src&quot; &quot;${src}.bak.${START_TS}&quot;

  TMPDIR_CREATED=&quot;$(mktemp -d)&quot;
  local tmp=&quot;$TMPDIR_CREATED/sources.list&quot;

  sudo awk &#39;{
    if ($1==&quot;deb&quot; || $1==&quot;deb-src&quot;) {
      line=$0
      has_contrib=match(line,/(^| )contrib( |$)/)
      has_nonfree=match(line,/(^| )non-free( |$)/)
      if (!has_contrib) line=line&quot; contrib&quot;
      if (!has_nonfree) line=line&quot; non-free&quot;
      print line
    } else {
      print
    }
  }&#39; &quot;$src&quot; | sudo tee &quot;$tmp&quot; &gt;/dev/null

  sudo mv &quot;$tmp&quot; &quot;$src&quot;
  run_fail &quot;apt-get update (after enabling contrib/non-free)&quot; sudo apt-get update
  rm -rf &quot;$TMPDIR_CREATED&quot; || true
  TMPDIR_CREATED=&quot;&quot;
}

main() {
  ensure_dir &quot;$AUDIT_DIR&quot;; ensure_dir &quot;$LOG_DIR&quot;; ensure_dir &quot;$OUT_DIR&quot;
  : &gt;&quot;$LOG_FILE&quot;

  section &quot;Start&quot;
  log &quot;Audit directory: $AUDIT_DIR&quot;
  log &quot;Log file       : $LOG_FILE&quot;

  need_sudo

  {
    echo &quot;===== ENVIRONMENT =====&quot;
    echo &quot;Timestamp: $START_TS&quot;
    uname -a || true
    echo
    echo &quot;----- /etc/os-release -----&quot;
    cat /etc/os-release 2&gt;/dev/null || true
    echo
    echo &quot;----- /proc/cmdline -----&quot;
    cat /proc/cmdline 2&gt;/dev/null || true
    echo
    echo &quot;----- CPU -----&quot;
    lscpu 2&gt;/dev/null || true
    echo
    echo &quot;----- Memory/CMA -----&quot;
    grep -E &#39;CmaTotal|CmaFree|MemTotal|MemFree|HugePages&#39; /proc/meminfo 2&gt;/dev/null || true
  } &gt;&quot;$ENV_FILE&quot;

  run_continue &quot;Collect dmesg&quot; bash -lc &quot;sudo dmesg -T &gt; &#39;$DMESG_FILE&#39;&quot;

  check_platform
  quick_net_check || true

  section &quot;APT update&quot;
  run_fail &quot;apt-get update&quot; sudo apt-get update

  enable_nonfree_optional || true

  section &quot;Install baseline diagnostic tools (idempotent; skips unavailable)&quot;
  ensure_packages \
    curl wget ca-certificates \
    pciutils usbutils lshw hwinfo inxi \
    ethtool iproute2 net-tools jq \
    i2c-tools lm-sensors \
    v4l-utils \
    gstreamer1.0-tools gstreamer1.0-plugins-base gstreamer1.0-plugins-good gstreamer1.0-plugins-bad gstreamer1.0-plugins-ugly \
    ffmpeg alsa-utils \
    vulkan-tools mesa-utils kmscube \
    xrandr x11-xserver-utils autorandr \
    edid-decode read-edid ddcutil \
    fio hdparm nvme-cli smartmontools \
    iw wireless-tools bluez can-utils

  section &quot;System overview&quot;
  run_continue &quot;lshw (short)&quot; sudo lshw -short
  run_continue &quot;lsblk -O&quot; lsblk -O
  run_continue &quot;df -hT&quot; df -hT
  run_continue &quot;lsusb -t&quot; lsusb -t
  run_continue &quot;lspci -nnk&quot; lspci -nnk
  run_continue &quot;Kernel warnings/errors (last 200)&quot; bash -lc &#39;dmesg -T --level=err,warn | tail -n 200&#39;

  section &quot;GPU &amp; Display&quot;
  run_continue &quot;GPU modules loaded&quot; bash -lc &quot;lsmod | egrep -i &#39;panthor|panfrost|mali|kbase&#39; || true&quot;
  run_continue &quot;GPU-related dmesg&quot; bash -lc &quot;dmesg -T | egrep -i &#39;mali|panthor|panfrost|csf|gpu&#39; || true&quot;
  run_continue &quot;DRM connectors (modetest -c)&quot; modetest -c
  run_continue &quot;kmscube smoke test&quot; bash -lc &quot;kmscube -i 100 &gt;/dev/null 2&gt;&amp;1 || true&quot;
  run_continue &quot;Vulkan summary&quot; vulkaninfo --summary
  run_continue &quot;xrandr --props (if X running)&quot; bash -lc &quot;DISPLAY=\${DISPLAY:-:0} xrandr --props 2&gt;/dev/null || true&quot;

  section &quot;Video / V4L2 / Codecs&quot;
  run_continue &quot;List V4L2 devices&quot; v4l2-ctl --list-devices
  run_continue &quot;FFmpeg hwaccels&quot; ffmpeg -hide_banner -hwaccels
  run_continue &quot;GStreamer rockchip-ish plugins&quot; bash -lc &quot;gst-inspect-1.0 | egrep -i &#39;v4l2|rkv|hantro|rockchip&#39; || true&quot;

  section &quot;Audio&quot;
  run_continue &quot;ALSA playback&quot; aplay -l
  run_continue &quot;ALSA capture&quot; arecord -l

  section &quot;Network&quot;
  run_continue &quot;ip -details addr&quot; ip -details address
  run_continue &quot;iw dev&quot; iw dev

  section &quot;Storage&quot;
  run_continue &quot;lsblk (model/serial)&quot; lsblk -o NAME,SIZE,TYPE,MOUNTPOINTS,MODEL,SERIAL,TRAN
  run_continue &quot;SATA/NVMe/PCIe dmesg&quot; bash -lc &quot;dmesg -T | egrep -i &#39;sata|ahci|nvme|pcie&#39; || true&quot;
  run_continue &quot;nvme list (if any)&quot; bash -lc &quot;ls /dev/nvme*n1 &gt;/dev/null 2&gt;&amp;1 &amp;&amp; sudo nvme list || true&quot;

  section &quot;Optional actions&quot;
  if ask_yes &quot;Run powertop --auto-tune (changes power tunables until reboot)?&quot;; then
    run_fail &quot;powertop --auto-tune&quot; sudo powertop --auto-tune
  fi
  if ask_yes &quot;Run sensors-detect (interactive; may load modules)?&quot;; then
    run_fail &quot;sensors-detect&quot; sudo sensors-detect
  fi
  if ask_yes &quot;Run quick fio seq read/write in $HOME (~${FIO_SIZE_MB}MB temp file, then removed)?&quot;; then
    TMPDIR_CREATED=&quot;$(mktemp -d)&quot;
    local fiofile=&quot;$TMPDIR_CREATED/fio_test.dat&quot;
    run_fail &quot;dd create file&quot; dd if=/dev/zero of=&quot;$fiofile&quot; bs=1M count=&quot;$FIO_SIZE_MB&quot; status=none
    run_fail &quot;fio seq rw&quot; fio --name=seqrw --filename=&quot;$fiofile&quot; --rw=readwrite --bs=&quot;$FIO_BS&quot; --direct=1 --numjobs=1 --iodepth=&quot;$FIO_IODEPTH&quot; --size=&quot;${FIO_SIZE_MB}M&quot; --group_reporting
    rm -rf &quot;$TMPDIR_CREATED&quot; || true
    TMPDIR_CREATED=&quot;&quot;
  fi

  section &quot;REPORT.md&quot;
  {
    echo &quot;# RK3588 Capability Audit — $START_TS&quot;
    echo
    echo &quot;Audit directory: $AUDIT_DIR&quot;
    echo &quot;Log file: $LOG_FILE&quot;
    echo &quot;Env snapshot: $ENV_FILE&quot;
    echo &quot;dmesg: $DMESG_FILE&quot;
  } &gt;&quot;$REPORT_MD&quot;

  ( cd &quot;$HOME&quot; &amp;&amp; tar czf &quot;${AUDIT_DIR}.tar.gz&quot; &quot;$(basename &quot;$AUDIT_DIR&quot;)&quot; )

  section &quot;Done&quot;
  log &quot;Report : $REPORT_MD&quot;
  log &quot;Archive: ${AUDIT_DIR}.tar.gz&quot;
}

main &quot;$@&quot;" data-download-link="" data-download-label="Download ">
  <code class="language-">#!/usr/bin/env bash
set -euo pipefail
set -o errtrace
IFS=$&#39;\n\t&#39;
trap &#39;echo &quot;Error on or near line ${LINENO}; command exited with status $?&quot; &gt;&amp;2&#39; ERR

# rk3588_audit.sh
#
# Purpose:
#   - Create a timestamped audit directory under ~/rk3588_audit_&lt;timestamp&gt;/
#   - Collect system/display/GPU/VPU/network/storage snapshots
#   - Install diagnostic packages idempotently (skips missing packages)
#   - Avoid destructive actions; optional actions require explicit confirmation

START_TS=&quot;$(date +%Y%m%d_%H%M%S)&quot;
AUDIT_DIR=&quot;$HOME/rk3588_audit_${START_TS}&quot;
LOG_DIR=&quot;$AUDIT_DIR/logs&quot;
OUT_DIR=&quot;$AUDIT_DIR/out&quot;
REPORT_MD=&quot;$AUDIT_DIR/REPORT.md&quot;
LOG_FILE=&quot;$LOG_DIR/audit.log&quot;
ENV_FILE=&quot;$LOG_DIR/env.txt&quot;
DMESG_FILE=&quot;$LOG_DIR/dmesg.txt&quot;

CMD_FAIL_HINT=&quot;Check ${LOG_FILE} and ${REPORT_MD} for details.&quot;

: &quot;${NET_TIMEOUT:=5}&quot;
: &quot;${FIO_SIZE_MB:=512}&quot;
: &quot;${FIO_BS:=1M}&quot;
: &quot;${FIO_IODEPTH:=16}&quot;
: &quot;${RUN_COLORS:=1}&quot;

TMPDIR_CREATED=&quot;&quot;
cleanup() {
  if [[ -n &quot;${TMPDIR_CREATED:-}&quot; &amp;&amp; -d &quot;$TMPDIR_CREATED&quot; ]]; then
    rm -rf &quot;$TMPDIR_CREATED&quot; || true
  fi
}
trap cleanup EXIT SIGINT SIGTERM

if [[ -t 1 &amp;&amp; &quot;$RUN_COLORS&quot; -eq 1 ]] &amp;&amp; command -v tput &gt;/dev/null 2&gt;&amp;1; then
  GREEN=&quot;$(tput setaf 2)&quot;; YELLOW=&quot;$(tput setaf 3)&quot;; RED=&quot;$(tput setaf 1)&quot;; BLUE=&quot;$(tput setaf 4)&quot;; BOLD=&quot;$(tput bold)&quot;; RESET=&quot;$(tput sgr0)&quot;
else
  GREEN=&quot;&quot;; YELLOW=&quot;&quot;; RED=&quot;&quot;; BLUE=&quot;&quot;; BOLD=&quot;&quot;; RESET=&quot;&quot;
fi

log() { echo -e &quot;$*&quot; | tee -a &quot;$LOG_FILE&quot;; }
section() { log &quot;\n${BOLD}${BLUE}==&gt; $1${RESET}&quot;; }

ensure_dir() { [[ -d &quot;$1&quot; ]] || mkdir -p &quot;$1&quot;; }

ask_yes() {
  local prompt=&quot;$1&quot; ans
  echo
  read -r -p &quot;${YELLOW}${prompt}${RESET} (type &#39;yes&#39; to continue, anything else to cancel): &quot; ans
  [[ &quot;$ans&quot; == &quot;yes&quot; ]] || { echo &quot;Cancelled by user.&quot;; return 1; }
}

need_sudo() {
  command -v sudo &gt;/dev/null 2&gt;&amp;1 || { echo &quot;Error: sudo required.&quot; &gt;&amp;2; exit 1; }
  sudo -v || { echo &quot;Error: sudo auth failed.&quot; &gt;&amp;2; exit 1; }
}

package_available() {
  local pkg=&quot;$1&quot;
  apt-cache policy &quot;$pkg&quot; 2&gt;/dev/null | awk &#39;/Candidate:/ {print $2}&#39; | grep -vq &quot;(none)&quot;
}

is_installed() { dpkg -s &quot;$1&quot; &gt;/dev/null 2&gt;&amp;1; }

ensure_package() {
  local pkg=&quot;$1&quot;
  if is_installed &quot;$pkg&quot;; then
    log &quot;Package already installed: ${GREEN}${pkg}${RESET}&quot;
    return 0
  fi
  if ! package_available &quot;$pkg&quot;; then
    log &quot;Package not available (skipping): ${YELLOW}${pkg}${RESET}&quot;
    return 0
  fi
  log &quot;Installing package: ${GREEN}${pkg}${RESET}&quot;
  sudo apt-get install -y --no-install-recommends &quot;$pkg&quot; &gt;&gt;&quot;$LOG_FILE&quot; 2&gt;&amp;1 || {
    echo &quot;Error: Failed to install &#39;$pkg&#39;. ${CMD_FAIL_HINT}&quot; &gt;&amp;2
    exit 1
  }
}

ensure_packages() { for pkg in &quot;$@&quot;; do ensure_package &quot;$pkg&quot;; done; }

run_continue() {
  local title=&quot;$1&quot;; shift
  log &quot;\n--- $title ---&quot;
  &quot;$@&quot; &gt;&gt;&quot;$LOG_FILE&quot; 2&gt;&amp;1 || log &quot;  (Command failed but continuing): $*&quot;
}

run_fail() {
  local title=&quot;$1&quot;; shift
  log &quot;\n&gt;&gt;&gt; $title&quot;
  &quot;$@&quot; &gt;&gt;&quot;$LOG_FILE&quot; 2&gt;&amp;1 || { echo &quot;Error: $title failed. ${CMD_FAIL_HINT}&quot; &gt;&amp;2; exit 1; }
}

quick_net_check() {
  section &quot;Quick network check&quot;
  if command -v ping &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ping -c1 -W &quot;$NET_TIMEOUT&quot; deb.debian.org &gt;/dev/null 2&gt;&amp;1; then
    log &quot;Network reachable.&quot;
    return 0
  fi
  log &quot;Network check failed; installs/downloads may be limited.&quot;
  return 1
}

check_platform() {
  section &quot;Platform checks&quot;
  local debver arch
  debver=&quot;$(cut -d&#39;.&#39; -f1 &lt; /etc/debian_version 2&gt;/dev/null || echo unknown)&quot;
  arch=&quot;$(uname -m 2&gt;/dev/null || echo unknown)&quot;
  log &quot;Debian major: $debver&quot;
  log &quot;Arch        : $arch&quot;
  [[ &quot;$debver&quot; == &quot;11&quot; ]] || log &quot;WARNING: tuned for Debian 11 (Bullseye).&quot;
  [[ &quot;$arch&quot; == &quot;aarch64&quot; || &quot;$arch&quot; == &quot;arm64&quot; ]] || log &quot;WARNING: tuned for ARM64.&quot;
}

enable_nonfree_optional() {
  section &quot;Optional: Enable contrib/non-free (Bullseye)&quot;
  if ! ask_yes &quot;Enable &#39;contrib non-free&#39; in /etc/apt/sources.list (backup + apt update)?&quot;; then
    log &quot;Skipped enabling contrib/non-free.&quot;
    return 0
  fi

  local src=&quot;/etc/apt/sources.list&quot;
  if [[ ! -f &quot;$src&quot; ]]; then
    log &quot;No $src found; skipping.&quot;
    return 0
  fi

  sudo cp -a &quot;$src&quot; &quot;${src}.bak.${START_TS}&quot;

  TMPDIR_CREATED=&quot;$(mktemp -d)&quot;
  local tmp=&quot;$TMPDIR_CREATED/sources.list&quot;

  sudo awk &#39;{
    if ($1==&quot;deb&quot; || $1==&quot;deb-src&quot;) {
      line=$0
      has_contrib=match(line,/(^| )contrib( |$)/)
      has_nonfree=match(line,/(^| )non-free( |$)/)
      if (!has_contrib) line=line&quot; contrib&quot;
      if (!has_nonfree) line=line&quot; non-free&quot;
      print line
    } else {
      print
    }
  }&#39; &quot;$src&quot; | sudo tee &quot;$tmp&quot; &gt;/dev/null

  sudo mv &quot;$tmp&quot; &quot;$src&quot;
  run_fail &quot;apt-get update (after enabling contrib/non-free)&quot; sudo apt-get update
  rm -rf &quot;$TMPDIR_CREATED&quot; || true
  TMPDIR_CREATED=&quot;&quot;
}

main() {
  ensure_dir &quot;$AUDIT_DIR&quot;; ensure_dir &quot;$LOG_DIR&quot;; ensure_dir &quot;$OUT_DIR&quot;
  : &gt;&quot;$LOG_FILE&quot;

  section &quot;Start&quot;
  log &quot;Audit directory: $AUDIT_DIR&quot;
  log &quot;Log file       : $LOG_FILE&quot;

  need_sudo

  {
    echo &quot;===== ENVIRONMENT =====&quot;
    echo &quot;Timestamp: $START_TS&quot;
    uname -a || true
    echo
    echo &quot;----- /etc/os-release -----&quot;
    cat /etc/os-release 2&gt;/dev/null || true
    echo
    echo &quot;----- /proc/cmdline -----&quot;
    cat /proc/cmdline 2&gt;/dev/null || true
    echo
    echo &quot;----- CPU -----&quot;
    lscpu 2&gt;/dev/null || true
    echo
    echo &quot;----- Memory/CMA -----&quot;
    grep -E &#39;CmaTotal|CmaFree|MemTotal|MemFree|HugePages&#39; /proc/meminfo 2&gt;/dev/null || true
  } &gt;&quot;$ENV_FILE&quot;

  run_continue &quot;Collect dmesg&quot; bash -lc &quot;sudo dmesg -T &gt; &#39;$DMESG_FILE&#39;&quot;

  check_platform
  quick_net_check || true

  section &quot;APT update&quot;
  run_fail &quot;apt-get update&quot; sudo apt-get update

  enable_nonfree_optional || true

  section &quot;Install baseline diagnostic tools (idempotent; skips unavailable)&quot;
  ensure_packages \
    curl wget ca-certificates \
    pciutils usbutils lshw hwinfo inxi \
    ethtool iproute2 net-tools jq \
    i2c-tools lm-sensors \
    v4l-utils \
    gstreamer1.0-tools gstreamer1.0-plugins-base gstreamer1.0-plugins-good gstreamer1.0-plugins-bad gstreamer1.0-plugins-ugly \
    ffmpeg alsa-utils \
    vulkan-tools mesa-utils kmscube \
    xrandr x11-xserver-utils autorandr \
    edid-decode read-edid ddcutil \
    fio hdparm nvme-cli smartmontools \
    iw wireless-tools bluez can-utils

  section &quot;System overview&quot;
  run_continue &quot;lshw (short)&quot; sudo lshw -short
  run_continue &quot;lsblk -O&quot; lsblk -O
  run_continue &quot;df -hT&quot; df -hT
  run_continue &quot;lsusb -t&quot; lsusb -t
  run_continue &quot;lspci -nnk&quot; lspci -nnk
  run_continue &quot;Kernel warnings/errors (last 200)&quot; bash -lc &#39;dmesg -T --level=err,warn | tail -n 200&#39;

  section &quot;GPU &amp; Display&quot;
  run_continue &quot;GPU modules loaded&quot; bash -lc &quot;lsmod | egrep -i &#39;panthor|panfrost|mali|kbase&#39; || true&quot;
  run_continue &quot;GPU-related dmesg&quot; bash -lc &quot;dmesg -T | egrep -i &#39;mali|panthor|panfrost|csf|gpu&#39; || true&quot;
  run_continue &quot;DRM connectors (modetest -c)&quot; modetest -c
  run_continue &quot;kmscube smoke test&quot; bash -lc &quot;kmscube -i 100 &gt;/dev/null 2&gt;&amp;1 || true&quot;
  run_continue &quot;Vulkan summary&quot; vulkaninfo --summary
  run_continue &quot;xrandr --props (if X running)&quot; bash -lc &quot;DISPLAY=\${DISPLAY:-:0} xrandr --props 2&gt;/dev/null || true&quot;

  section &quot;Video / V4L2 / Codecs&quot;
  run_continue &quot;List V4L2 devices&quot; v4l2-ctl --list-devices
  run_continue &quot;FFmpeg hwaccels&quot; ffmpeg -hide_banner -hwaccels
  run_continue &quot;GStreamer rockchip-ish plugins&quot; bash -lc &quot;gst-inspect-1.0 | egrep -i &#39;v4l2|rkv|hantro|rockchip&#39; || true&quot;

  section &quot;Audio&quot;
  run_continue &quot;ALSA playback&quot; aplay -l
  run_continue &quot;ALSA capture&quot; arecord -l

  section &quot;Network&quot;
  run_continue &quot;ip -details addr&quot; ip -details address
  run_continue &quot;iw dev&quot; iw dev

  section &quot;Storage&quot;
  run_continue &quot;lsblk (model/serial)&quot; lsblk -o NAME,SIZE,TYPE,MOUNTPOINTS,MODEL,SERIAL,TRAN
  run_continue &quot;SATA/NVMe/PCIe dmesg&quot; bash -lc &quot;dmesg -T | egrep -i &#39;sata|ahci|nvme|pcie&#39; || true&quot;
  run_continue &quot;nvme list (if any)&quot; bash -lc &quot;ls /dev/nvme*n1 &gt;/dev/null 2&gt;&amp;1 &amp;&amp; sudo nvme list || true&quot;

  section &quot;Optional actions&quot;
  if ask_yes &quot;Run powertop --auto-tune (changes power tunables until reboot)?&quot;; then
    run_fail &quot;powertop --auto-tune&quot; sudo powertop --auto-tune
  fi
  if ask_yes &quot;Run sensors-detect (interactive; may load modules)?&quot;; then
    run_fail &quot;sensors-detect&quot; sudo sensors-detect
  fi
  if ask_yes &quot;Run quick fio seq read/write in $HOME (~${FIO_SIZE_MB}MB temp file, then removed)?&quot;; then
    TMPDIR_CREATED=&quot;$(mktemp -d)&quot;
    local fiofile=&quot;$TMPDIR_CREATED/fio_test.dat&quot;
    run_fail &quot;dd create file&quot; dd if=/dev/zero of=&quot;$fiofile&quot; bs=1M count=&quot;$FIO_SIZE_MB&quot; status=none
    run_fail &quot;fio seq rw&quot; fio --name=seqrw --filename=&quot;$fiofile&quot; --rw=readwrite --bs=&quot;$FIO_BS&quot; --direct=1 --numjobs=1 --iodepth=&quot;$FIO_IODEPTH&quot; --size=&quot;${FIO_SIZE_MB}M&quot; --group_reporting
    rm -rf &quot;$TMPDIR_CREATED&quot; || true
    TMPDIR_CREATED=&quot;&quot;
  fi

  section &quot;REPORT.md&quot;
  {
    echo &quot;# RK3588 Capability Audit — $START_TS&quot;
    echo
    echo &quot;Audit directory: $AUDIT_DIR&quot;
    echo &quot;Log file: $LOG_FILE&quot;
    echo &quot;Env snapshot: $ENV_FILE&quot;
    echo &quot;dmesg: $DMESG_FILE&quot;
  } &gt;&quot;$REPORT_MD&quot;

  ( cd &quot;$HOME&quot; &amp;&amp; tar czf &quot;${AUDIT_DIR}.tar.gz&quot; &quot;$(basename &quot;$AUDIT_DIR&quot;)&quot; )

  section &quot;Done&quot;
  log &quot;Report : $REPORT_MD&quot;
  log &quot;Archive: ${AUDIT_DIR}.tar.gz&quot;
}

main &quot;$@&quot;</code>
</section>]]></content><author><name></name></author><category term="aid&gt;software&gt;linux&gt;rockchip" /></entry><entry><title type="html">Debian 13 bootable USB setup</title><link href="https://ib.bsb.br/debian13usb/" rel="alternate" type="text/html" title="Debian 13 bootable USB setup" /><published>2025-11-19T00:00:00+00:00</published><updated>2025-11-19T21:47:09+00:00</updated><id>https://ib.bsb.br/debian13usb</id><content type="html" xml:base="https://ib.bsb.br/debian13usb/"><![CDATA[<pre><code class="language-build_debian13_usb.sh">#!/usr/bin/env bash
# Script to build a Debian 13 (Trixie) amd64 persistent USB image with X11, ratpoison,
# auto-login, and autostarting TreeSheets and Impala, from a host running Debian 11 arm64.
# 
# **IMPORTANT:** Review and adjust configuration variables below (image size, usernames, etc.)
# before running. Run this script as root on a Debian-based arm64 host.
# It will create an image file and set up a chroot with a Debian amd64 system.
# No changes are made to the host system aside from installing required packages (if needed).
# 
# The script will prompt for confirmation before overwriting any existing image file or writing to a USB device.
# All major actions are logged to the console for transparency.

set -euo pipefail

#############################
# Configuration Variables
#############################
DEBIAN_RELEASE="trixie"            # Target Debian release name
TARGET_ARCH="amd64"               # Target architecture for the USB system
IMAGE_SIZE="4G"                   # Size of the image file to create (e.g., "4G" for 4 GiB)
IMAGE_NAME="debian13-${TARGET_ARCH}-usb.img"  # Name of the image file to create
BUILD_DIR="$PWD/debian_usb_build" # Working directory for mounts and temporary files (created if not exists)
USERNAME="user"                   # Default username for auto-login
USERPASSWORD="password"           # Password for the default user (change or leave as desired)
HOSTNAME="debian-usb"             # Hostname for the new system
TIMEZONE="Etc/UTC"                # Timezone for the new system (can be changed to user's timezone)
LOCALE="en_US.UTF-8"              # Locale to generate for the new system

# Package lists for installation in the target system:
# Base system and utilities
BASE_PACKAGES="systemd-sysv,systemd,locales,tzdata,dialog"  # core packages (some are normally included by debootstrap second stage)
# Desktop/X11 and user applications
X11_PACKAGES="xserver-xorg-core,xserver-xorg-video-fbdev,xserver-xorg-video-vesa,xinit,xterm,ratpoison"
APP_PACKAGES="treesheets"         # TreeSheets is in Debian repo. Impala might need manual installation (not in Debian).
NETWORK_PACKAGES="iwd"            # Use iwd for Wi-Fi (Impala requires iwd). Alternatively, could include dhclient or systemd-networkd if needed.
# Bootloaders and kernel
BOOT_PACKAGES="grub-efi-amd64,linux-image-amd64,extlinux,syslinux-common" 
# Note: extlinux (Syslinux for ext filesystems) and syslinux-common provide BIOS boot support; grub-efi-amd64 for UEFI.

#############################
# Script Setup and Functions
#############################

# Ensure the working directory exists
mkdir -p "${BUILD_DIR}"
# Define mount points relative to working directory
ROOTFS_DIR="${BUILD_DIR}/rootfs"    # Mount point for the ext4 root filesystem
EFI_DIR="${BUILD_DIR}/efiboot"      # Mount point for the FAT32 EFI/boot partition

# Trap to cleanup mounts/loop on exit or error
cleanup() {
    echo "Cleaning up: Unmounting and detaching loop devices..."
    # Try to unmount in reverse order of mounting
    umount -lf "${ROOTFS_DIR}/boot/efi" 2&gt;/dev/null || true
    umount -lf "${EFI_DIR}" 2&gt;/dev/null || true
    umount -lf "${ROOTFS_DIR}/dev/pts" 2&gt;/dev/null || true
    umount -lf "${ROOTFS_DIR}/dev" 2&gt;/dev/null || true
    umount -lf "${ROOTFS_DIR}/proc" 2&gt;/dev/null || true
    umount -lf "${ROOTFS_DIR}/sys" 2&gt;/dev/null || true
    umount -lf "${ROOTFS_DIR}" 2&gt;/dev/null || true
    if losetup -a | grep -q "$IMAGE_NAME"; then
        # Detach all loop devices associated with our image
        LOOP_DEV="$(losetup -j "${BUILD_DIR}/${IMAGE_NAME}" | cut -d: -f1 || true)"
        if [ -n "${LOOP_DEV}" ]; then
            losetup -d "${LOOP_DEV}" 2&gt;/dev/null || true
        fi
    fi
}
trap cleanup EXIT

# Confirm function for dangerous operations
confirm() {
    local prompt="$1"
    read -r -p "$prompt " response
    case "$response" in
        [Yy][Ee][Ss]|[Yy]) true ;;
        *) false ;;
    esac
}

# Require root privileges
if [[ $EUID -ne 0 ]]; then
    echo "This script must be run as root. Exiting."
    exit 1
fi

# Check and install required host tools
REQUIRED_TOOLS=(debootstrap qemu-user-static parted losetup mkfs.vfat mkfs.ext4)
MISSING_TOOLS=()
for tool in "${REQUIRED_TOOLS[@]}"; do
    if ! command -v "$tool" &amp;&gt;/dev/null; then
        MISSING_TOOLS+=("$tool")
    fi
done
if (( ${#MISSING_TOOLS[@]} &gt; 0 )); then
    echo "Installing missing host tools: ${MISSING_TOOLS[*]}..."
    apt-get update &amp;&amp; apt-get install -y "${MISSING_TOOLS[@]}"
fi

#############################
# Create and Partition Image
#############################
IMAGE_PATH="${BUILD_DIR}/${IMAGE_NAME}"
if [[ -f "$IMAGE_PATH" ]]; then
    echo "Image file $IMAGE_PATH already exists."
    if ! confirm "Overwrite existing image file? [yes/NO]"; then
        echo "Aborting to avoid overwriting existing image."
        exit 1
    fi
    rm -f "$IMAGE_PATH"
fi

echo "&gt;&gt;&gt; Creating blank image file of size $IMAGE_SIZE at $IMAGE_PATH..."
# Create an empty file of the specified size
truncate -s "$IMAGE_SIZE" "$IMAGE_PATH"

echo "&gt;&gt;&gt; Partitioning image file..."
# Create partition table: Partition 1 = FAT32 (for EFI &amp; Syslinux), Partition 2 = ext4 (root)
parted -s "$IMAGE_PATH" mklabel msdos \
    mkpart primary fat32 1MiB 300MiB \
    mkpart primary ext4 300MiB 100% \
    set 1 boot on

# Set up loop device with partitions
LOOP_DEV="$(losetup -f --show -P "$IMAGE_PATH")"
echo "    Loop device $LOOP_DEV created for $IMAGE_PATH"
# The loop device now has partitions accessible as ${LOOP_DEV}p1 and p2
LOOP_P1="${LOOP_DEV}p1"
LOOP_P2="${LOOP_DEV}p2"

echo "&gt;&gt;&gt; Creating filesystems..."
# Format the EFI/FAT32 partition (partition 1)
mkfs.vfat -F 32 -n EFI "$LOOP_P1"
# Format the root ext4 partition (partition 2) with a label
mkfs.ext4 -L rootfs "$LOOP_P2"

# Create mount points
mkdir -p "$ROOTFS_DIR" "$EFI_DIR"

echo "&gt;&gt;&gt; Mounting image partitions..."
mount "$LOOP_P2" "$ROOTFS_DIR"
mkdir -p "${ROOTFS_DIR}/boot/efi"
mount "$LOOP_P1" "$ROOTFS_DIR/boot/efi"
# Also mount the EFI partition separately if needed (not strictly necessary since it's at rootfs/boot/efi)
mount "$LOOP_P1" "$EFI_DIR"

#############################
# Debootstrap: Base System
#############################
echo "&gt;&gt;&gt; Bootstrapping Debian $DEBIAN_RELEASE ($TARGET_ARCH)..."
# First stage debootstrap (download and extract base system)
debootstrap --arch="$TARGET_ARCH" --foreign "$DEBIAN_RELEASE" "$ROOTFS_DIR" http://deb.debian.org/debian

# Enable QEMU for chroot (copy qemu static binary into the new system)
echo "&gt;&gt;&gt; Copying QEMU static binary for $TARGET_ARCH into chroot..."
cp "$(which qemu-${TARGET_ARCH}-static)" "${ROOTFS_DIR}/usr/bin/"

# Prepare essential mount points for chroot environment
echo "&gt;&gt;&gt; Mounting special filesystems for chroot..."
mount -t proc proc "${ROOTFS_DIR}/proc"
mount -t sysfs sys "${ROOTFS_DIR}/sys"
mount -o bind /dev "${ROOTFS_DIR}/dev"
mount -o bind /dev/pts "${ROOTFS_DIR}/dev/pts"
# Use a tmpfs for /run inside chroot to avoid interference with host /run
mount -t tmpfs tmpfs "${ROOTFS_DIR}/run"
mkdir -p "${ROOTFS_DIR}/run/lock"  # for any lock files

# Second stage debootstrap (configure base system inside chroot)
echo "&gt;&gt;&gt; Running debootstrap second-stage in chroot..."
chroot "$ROOTFS_DIR" /debootstrap/debootstrap --second-stage

# Basic system configuration: hostname, hosts, timezone, locale
echo "&gt;&gt;&gt; Configuring base system (hostname, timezone, locale)..."
echo "$HOSTNAME" &gt; "${ROOTFS_DIR}/etc/hostname"
# Set up /etc/hosts with minimal entries
cat &gt; "${ROOTFS_DIR}/etc/hosts" &lt;&lt;EOF
127.0.0.1   localhost
127.0.1.1   ${HOSTNAME}
EOF

# Timezone
echo "$TIMEZONE" &gt; "${ROOTFS_DIR}/etc/timezone"
ln -sf "/usr/share/zoneinfo/$TIMEZONE" "${ROOTFS_DIR}/etc/localtime"

# Locale (generate specified locale)
chroot "$ROOTFS_DIR" bash -c "echo '$LOCALE UTF-8' &gt; /etc/locale.gen"
chroot "$ROOTFS_DIR" locale-gen

# Set default LANG
echo "LANG=$LOCALE" &gt; "${ROOTFS_DIR}/etc/default/locale"

#############################
# Install Packages in Chroot
#############################
echo "&gt;&gt;&gt; Installing required packages in the target system..."
# Configure apt sources (use default deb.debian.org for stable)
cat &gt; "${ROOTFS_DIR}/etc/apt/sources.list" &lt;&lt;EOF
deb http://deb.debian.org/debian $DEBIAN_RELEASE main contrib non-free non-free-firmware
deb http://deb.debian.org/debian $DEBIAN_RELEASE-updates main contrib non-free non-free-firmware
deb http://security.debian.org/debian-security $DEBIAN_RELEASE-security main contrib non-free non-free-firmware
EOF

# Update apt cache and install packages
chroot "$ROOTFS_DIR" apt-get update
# Use apt-get in one command to install all desired packages
chroot "$ROOTFS_DIR" apt-get install -y --no-install-recommends \
    $BASE_PACKAGES,$X11_PACKAGES,$APP_PACKAGES,$NETWORK_PACKAGES,$BOOT_PACKAGES

# Set the system's timezone and reconfigure tzdata (non-interactively)
chroot "$ROOTFS_DIR" bash -c "DEBIAN_FRONTEND=noninteractive dpkg-reconfigure tzdata"

#############################
# User Setup and Autologin
#############################
echo "&gt;&gt;&gt; Setting up default user and auto-login..."
# Create the user with home directory and add to groups (sudo,netdev,audio,video)
chroot "$ROOTFS_DIR" useradd -m -s /bin/bash "$USERNAME"
chroot "$ROOTFS_DIR" bash -c "echo '${USERNAME}:${USERPASSWORD}' | chpasswd"
# Set root password (optional: here we set same as user, or leave locked by not setting)
chroot "$ROOTFS_DIR" bash -c "echo 'root:${USERPASSWORD}' | chpasswd"
# Add user to necessary groups
chroot "$ROOTFS_DIR" usermod -aG sudo,netdev,audio,video "$USERNAME"

# Configure autologin on tty1 via systemd getty override
AUTOLOGIN_CONF="${ROOTFS_DIR}/etc/systemd/system/getty@tty1.service.d"
mkdir -p "$AUTOLOGIN_CONF"
cat &gt; "$AUTOLOGIN_CONF/autologin.conf" &lt;&lt;EOF
[Service]
ExecStart=
ExecStart=-/sbin/agetty --autologin $USERNAME --noclear %I 38400 linux
EOF

# Set up startx on login (for console auto-login sessions)
# Add a command to .bash_profile to launch X only for the autologin on tty1
USER_HOME="${ROOTFS_DIR}/home/${USERNAME}"
cat &gt;&gt; "${USER_HOME}/.bash_profile" &lt;&lt;'EOF'
# If logging in on tty1, start X automatically
if [[ -z $DISPLAY &amp;&amp; $(tty) == "/dev/tty1" ]]; then
    startx -- -nocursor
    logout
fi
EOF
chroot "$ROOTFS_DIR" chown "$USERNAME:$USERNAME" "/home/$USERNAME/.bash_profile"

#############################
# X11 Autostart (ratpoison + apps)
#############################
echo "&gt;&gt;&gt; Configuring X11 session (ratpoison) and application autostart..."
# Create an .xinitrc for the user to start Ratpoison
cat &gt; "${USER_HOME}/.xinitrc" &lt;&lt;'EOF'
#!/bin/bash
# .xinitrc: run Ratpoison window manager
exec ratpoison
EOF
chroot "$ROOTFS_DIR" chown "$USERNAME:$USERNAME" "/home/$USERNAME/.xinitrc"
chroot "$ROOTFS_DIR" chmod +x "/home/$USERNAME/.xinitrc"

# Configure Ratpoison autostart: .ratpoisonrc to launch TreeSheets and Impala at startup
cat &gt; "${USER_HOME}/.ratpoisonrc" &lt;&lt;EOF
# Disable startup message
startup_message off
# Set a blank cursor (useful if -nocursor used for X)
exec xsetroot -cursor_name left_ptr
# Autostart applications:
exec treesheets      # launch TreeSheets GUI on start
exec xterm -e impala # open an xterm and run impala TUI inside it
EOF
# Note: impala is not an official Debian package. Ensure the 'impala' binary is installed in the system or adjust this line.
chroot "$ROOTFS_DIR" chown "$USERNAME:$USERNAME" "/home/$USERNAME/.ratpoisonrc"

#############################
# Bootloader Setup (Syslinux &amp; GRUB)
#############################
echo "&gt;&gt;&gt; Installing and configuring bootloaders (Syslinux for BIOS, GRUB for UEFI)..."
# 1. EXTLINUX (Syslinux) for BIOS boot:
# Create extlinux directory
chroot "$ROOTFS_DIR" mkdir -p /boot/extlinux
# Copy Syslinux BIOS modules to /boot/extlinux
chroot "$ROOTFS_DIR" cp -r /usr/lib/syslinux/modules/bios/* /boot/extlinux/ 2&gt;/dev/null || true
# Install extlinux bootloader on the ext4 partition
chroot "$ROOTFS_DIR" extlinux --install /boot/extlinux

# Create extlinux configuration file
ROOT_UUID=$(blkid -s UUID -o value "$LOOP_P2")  # get UUID of root partition
cat &gt; "${ROOTFS_DIR}/boot/extlinux/extlinux.conf" &lt;&lt;EOF
DEFAULT linux
LABEL linux
    LINUX ../vmlinuz
    INITRD ../initrd.img
    APPEND root=UUID=${ROOT_UUID} ro quiet
EOF
# The vmlinuz and initrd.img symlinks point to the latest kernel and initrd in /boot.
# We use '../' because extlinux directory is /boot/extlinux, going up to /boot for the files.

# Ensure the extlinux config and modules are owned by root (should already be)
chroot "$ROOTFS_DIR" chown -R root:root /boot/extlinux

# 2. GRUB for UEFI boot:
# Install GRUB EFI (this was already installed via apt in BOOT_PACKAGES)
# Perform grub-install targeting x86_64 EFI, pointing to the mounted EFI partition.
chroot "$ROOTFS_DIR" grub-install --target=x86_64-efi --efi-directory=/boot/efi --bootloader-id=Debian --removable --no-nvram
# Generate GRUB configuration file
chroot "$ROOTFS_DIR" update-grub

#############################
# Finalization
#############################
# Remove the QEMU static binary from the target system (not needed on real x86_64 hardware)
rm -f "${ROOTFS_DIR}/usr/bin/qemu-${TARGET_ARCH}-static"

# Sync data to disk
sync

echo "&gt;&gt;&gt; Unmounting chroot filesystems..."
# These will be also handled by the trap on exit, but we unmount explicitly here for clarity:
umount "${ROOTFS_DIR}/proc" || true
umount "${ROOTFS_DIR}/sys" || true
umount "${ROOTFS_DIR}/dev/pts" || true
umount "${ROOTFS_DIR}/dev" || true
umount "${ROOTFS_DIR}/run" || true
umount "${ROOTFS_DIR}/boot/efi" || true
umount "${EFI_DIR}" || true
umount "${ROOTFS_DIR}" || true

# Write Syslinux MBR boot code to the image (for BIOS boot).
# Use dd to write the first 440 bytes from Syslinux's mbr.bin to the image's MBR.
echo "&gt;&gt;&gt; Writing Syslinux MBR boot code to image..."
dd if="${ROOTFS_DIR}/usr/lib/SYSLINUX/mbr.bin" of="$LOOP_DEV" bs=440 count=1 conv=notrunc

# Detach loop device
losetup -d "$LOOP_DEV"

echo "&gt;&gt;&gt; Debian USB image creation completed successfully!"
echo "Image file: $IMAGE_PATH"
# Offer to write image to a USB device
if confirm "Write the image to a USB drive now? (This will destroy contents on the target drive) [yes/NO]"; then
    read -rp "Enter the device path for the USB (e.g., /dev/sdX): " USBDEV
    if [[ -n "$USBDEV" ]]; then
        echo "WARNING: About to overwrite $USBDEV with the image. This will erase all data on $USBDEV."
        if confirm "Are you absolutely sure? Type 'yes' to continue: "; then
            echo "&gt;&gt;&gt; Writing image to $USBDEV ... (this may take a while)"
            dd if="$IMAGE_PATH" of="$USBDEV" bs=4M status=progress conv=fsync
            echo "&gt;&gt;&gt; Syncing data to $USBDEV..."
            sync
            echo "Image written to $USBDEV successfully. You can now boot the USB drive on an x86_64 machine."
        else
            echo "Skipped writing image to USB."
        fi
    fi
else
    echo "Image creation complete. You can write $IMAGE_PATH to a USB device later using 'dd' or a similar tool."
fi
</code></pre>]]></content><author><name></name></author><category term="scratchpad" /></entry><entry><title type="html">GitHub Actions to Download, Unzip, and Create a New Repository</title><link href="https://ib.bsb.br/github-actions-unzip-tutorial/" rel="alternate" type="text/html" title="GitHub Actions to Download, Unzip, and Create a New Repository" /><published>2025-11-09T00:00:00+00:00</published><updated>2025-12-22T19:08:44+00:00</updated><id>https://ib.bsb.br/github-actions-unzip-tutorial</id><content type="html" xml:base="https://ib.bsb.br/github-actions-unzip-tutorial/"><![CDATA[<h1 id="tutorial-using-github-actions-to-download-unzip-and-create-a-new-repository">Tutorial: Using GitHub Actions to Download, Unzip, and Create a New Repository</h1>

<h2 id="executive-summary">Executive Summary</h2>
<p>This tutorial demonstrates how to create a GitHub Actions workflow that:</p>
<ol>
  <li>Downloads a ZIP file from https://x0.at/XS2C.zip (or any specified URL)</li>
  <li>Extracts the contents</li>
  <li>Creates a new GitHub repository</li>
  <li>Uploads all extracted files to the new repository</li>
</ol>

<p><strong>Prerequisites:</strong>
• A GitHub account (user: ib-bsb-br in this example)
• A repository where you can create workflows
• A Personal Access Token (PAT) with repo scope
• Basic understanding of GitHub Actions</p>

<p><strong>Estimated Time:</strong> 15-20 minutes</p>

<h2 id="️-security-considerations">⚠️ Security Considerations</h2>
<h3 id="critical-read-before-proceeding">CRITICAL: Read Before Proceeding</h3>
<ol>
  <li>
    <p><strong>ZIP File Source Validation:</strong>
• The URL https://x0.at/XS2C.zip is a third-party file hosting service
• Never download and execute content from untrusted sources
• Verify the ZIP file contents manually before automating this process
• Consider implementing content validation/scanning in production workflows</p>
  </li>
  <li>
    <p><strong>Token Security:</strong>
• Never hardcode tokens in workflow files
• Always use GitHub Secrets for PATs
• Limit token scope to only required permissions (repo minimum)
• Rotate tokens regularly</p>
  </li>
  <li>
    <p><strong>Repository Creation:</strong>
• This workflow creates public repositories by default
• Be cautious about what content you’re making public
• Review extracted contents before pushing</p>
  </li>
</ol>

<h2 id="part-1-prerequisites-setup">Part 1: Prerequisites Setup</h2>

<h3 id="step-1-create-a-personal-access-token-pat">Step 1: Create a Personal Access Token (PAT)</h3>
<ol>
  <li>Navigate to: https://github.com/settings/tokens/new</li>
  <li>Configure the token:
• <strong>Note:</strong> “Repository Creation Token for Workflows”
• <strong>Expiration:</strong> Choose appropriate duration (recommend 90 days max)
• <strong>Scopes:</strong> Select <code class="language-plaintext highlighter-rouge">repo</code> (Full control of private repositories)
• This includes: repo:status, repo_deployment, public_repo, repo:invite, security_events</li>
  <li>Click <strong>Generate token</strong></li>
  <li>Copy the token immediately (you won’t see it again)</li>
</ol>

<h3 id="step-2-add-token-as-repository-secret">Step 2: Add Token as Repository Secret</h3>
<ol>
  <li>Go to your repository: https://github.com/ib-bsb-br/YOUR_REPO_NAME</li>
  <li>Navigate to: <strong>Settings → Secrets and variables → Actions</strong></li>
  <li>Click <strong>New repository secret</strong></li>
  <li>Configure:
• <strong>Name:</strong> <code class="language-plaintext highlighter-rouge">REPO_CREATE_TOKEN</code>
• <strong>Secret:</strong> Paste your PAT</li>
  <li>Click <strong>Add secret</strong></li>
</ol>

<h3 id="step-3-understand-repository-ownership-context">Step 3: Understand Repository Ownership Context</h3>
<p><strong>Important:</strong> When using <code class="language-plaintext highlighter-rouge">context.repo.owner</code> in the workflow:
• It references the owner of the repository where the workflow runs
• For user <code class="language-plaintext highlighter-rouge">ib-bsb-br</code>, if the workflow runs in <code class="language-plaintext highlighter-rouge">ib-bsb-br/workflow-repo</code>, the new repository will be created under <code class="language-plaintext highlighter-rouge">ib-bsb-br</code>
• To create repositories in an organization, you must modify the owner variable explicitly</p>

<h2 id="part-2-implementation---choose-your-approach">Part 2: Implementation - Choose Your Approach</h2>

<h3 id="decision-matrix-which-approach-to-use">Decision Matrix: Which Approach to Use?</h3>

<table>
  <thead>
    <tr>
      <th>Factor</th>
      <th>API Approach</th>
      <th>Git Command Approach</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Best for</strong></td>
      <td>Small to medium files (&lt;100MB per file)</td>
      <td>Any file size, including large files</td>
    </tr>
    <tr>
      <td><strong>Complexity</strong></td>
      <td>More complex, API-based</td>
      <td>Simpler, uses standard git</td>
    </tr>
    <tr>
      <td><strong>File size limits</strong></td>
      <td>100MB per blob</td>
      <td>No API limits, only git limits</td>
    </tr>
    <tr>
      <td><strong>Speed</strong></td>
      <td>Can be slower for many files</td>
      <td>Faster for many files</td>
    </tr>
    <tr>
      <td><strong>Error handling</strong></td>
      <td>More granular control</td>
      <td>Less granular</td>
    </tr>
    <tr>
      <td><strong>Dependencies</strong></td>
      <td>GitHub API only</td>
      <td>Requires git, curl, unzip</td>
    </tr>
  </tbody>
</table>

<p><strong>Recommendation:</strong> Use the Git Command Approach for simplicity unless you need specific API features.</p>

<h3 id="create-workflow-file">Create Workflow File</h3>
<p>Create <code class="language-plaintext highlighter-rouge">.github/workflows/unzip-to-repo.yml</code> in your repository:</p>

<p>{% codeblock yaml %}
name: Unzip and Create Repository (Git Method)</p>

<p>on:
  workflow_dispatch:
    inputs:
      repo_name:
        description: ‘Name for the new repository (must be unique)’
        required: true
        default: ‘unzipped-content’
      zip_url:
        description: ‘URL of the ZIP file to download’
        required: true
        default: ‘https://x0.at/XS2C.zip’
      repo_description:
        description: ‘Description for the new repository’
        required: false
        default: ‘Repository created from ZIP file extraction’
      private_repo:
        description: ‘Make repository private?’
        required: true
        type: boolean
        default: false</p>

<p>jobs:
  create-repo-from-zip:
    runs-on: ubuntu-latest
    env:
      # Prevent git from prompting for credentials
      GIT_TERMINAL_PROMPT: 0</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>steps:
  - name: Validate inputs
    env:
      REPO_CREATE_TOKEN: ${{ secrets.REPO_CREATE_TOKEN }}
    run: |
      set -euo pipefail
      echo "🔍 Validating inputs..."
      echo "Repository name: ${{ inputs.repo_name }}"
      echo "ZIP URL: ${{ inputs.zip_url }}"
      echo "Private: ${{ inputs.private_repo }}"

      if [[ -z "${REPO_CREATE_TOKEN:-}" ]]; then
        echo "❌ Error: Secret REPO_CREATE_TOKEN is not set. Please add a Personal Access Token with repo scope."
        exit 1
      fi

      if [[ ! "${{ inputs.repo_name }}" =~ ^[a-zA-Z0-9_-]+$ ]]; then
        echo "❌ Error: Repository name can only contain alphanumeric characters, hyphens, and underscores"
        exit 1
      fi

  - name: Download ZIP file
    run: |
      set -euo pipefail
      echo "📥 Downloading ZIP file from ${{ inputs.zip_url }}"

      if ! curl -L -f -o archive.zip --max-time 300 "${{ inputs.zip_url }}"; then
        echo "❌ Failed to download ZIP file"
        exit 1
      fi

      if [ ! -s archive.zip ]; then
        echo "❌ Downloaded file is empty"
        exit 1
      fi

      echo "✅ Downloaded $(du -h archive.zip | cut -f1) file"

  - name: Extract ZIP contents
    run: |
      set -euo pipefail
      echo "📦 Extracting ZIP file..."
      mkdir -p extracted_content

      if ! unzip -q archive.zip -d extracted_content; then
        echo "❌ Failed to extract ZIP file"
        exit 1
      fi

      file_count=$(find extracted_content -type f | wc -l)
      if [ "$file_count" -eq 0 ]; then
        echo "❌ No files found in ZIP archive"
        exit 1
      fi

      echo "🔎 Checking for oversized files (&gt;99MB)..."
      if find extracted_content -type f -size +99M -print -quit | grep -q .; then
        echo "❌ Found files larger than 99MB. GitHub blocks pushing files over 100MB."
        echo "Offending files:"
        find extracted_content -type f -size +99M -printf '%p (%s bytes)\n'
        exit 1
      fi

      echo "✅ Extracted $file_count files"
      echo "📂 Directory structure:"
      tree -L 3 extracted_content/ || ls -R extracted_content/

  - name: Create repository via API
    id: create-repo
    uses: actions/github-script@v8
    env:
      REPO_NAME: ${{ inputs.repo_name }}
      REPO_DESCRIPTION: ${{ inputs.repo_description }}
      PRIVATE_REPO: ${{ inputs.private_repo }}
    with:
      github-token: ${{ secrets.REPO_CREATE_TOKEN }}
      retries: 3
      result-encoding: string
      script: |
        const repoName = process.env.REPO_NAME;
        const repoDescription = process.env.REPO_DESCRIPTION;
        const isPrivate = process.env.PRIVATE_REPO === 'true';

        const { data: user } = await github.rest.users.getAuthenticated();
        console.log(`🔐 Authenticated as: ${user.login}`);

        try {
          console.log(`📝 Creating repository: ${user.login}/${repoName}`);

          const { data: repo } = await github.rest.repos.createForAuthenticatedUser({
            name: repoName,
            description: repoDescription,
            private: isPrivate,
            auto_init: false,
            has_issues: true,
            has_projects: true,
            has_wiki: true
          });

          console.log(`✅ Repository created: ${repo.html_url}`);
          console.log(`📋 Clone URL: ${repo.clone_url}`);
          core.setOutput('clone_url', repo.clone_url);
          core.setOutput('html_url', repo.html_url);
          return repo.clone_url;
        } catch (error) {
          if (error.status === 422) {
            core.setFailed(`Repository '${repoName}' already exists in your account. Please choose a different name or delete the existing repository.`);
          } else if (error.status === 401) {
            core.setFailed('Authentication failed. Please verify your REPO_CREATE_TOKEN secret has the correct permissions.');
          } else {
            core.setFailed(`Failed to create repository: ${error.message}`);
          }
          throw error;
        }

  - name: Initialize git and push content
    env:
      REPO_URL: ${{ steps.create-repo.outputs.clone_url }}
      GITHUB_TOKEN: ${{ secrets.REPO_CREATE_TOKEN }}
    run: |
      set -euo pipefail
      cd extracted_content

      echo "🔧 Configuring git..."
      git config user.name "github-actions[bot]"
      git config user.email "github-actions[bot]@users.noreply.github.com"

      if [ -d .git ]; then
        echo "🧹 Removing existing git metadata from extracted content..."
        rm -rf .git
      fi

      echo "📋 Initializing repository..."
      git init -b main

      echo "* text=auto" &gt; .gitattributes

      echo "➕ Adding all files..."
      git add .

      echo "💾 Creating initial commit..."
      COMMIT_TS="$(date -u +"%Y-%m-%d %H:%M:%S UTC")"
      git commit \
        -m "Initial commit: Add files from ZIP archive" \
        -m "Source: ${{ inputs.zip_url }}" \
        -m "Extracted: ${COMMIT_TS}" \
        -m "Workflow: ${{ github.repository }}@${{ github.sha }}"

      echo "🔗 Adding remote..."
      REPO_URL_SANITIZED=$(echo "$REPO_URL" | sed 's/^"\(.*\)"$/\1/')
      REPO_URL_WITH_TOKEN=$(echo "$REPO_URL_SANITIZED" | sed "s|https://|https://x-access-token:${GITHUB_TOKEN}@|")
      git remote add origin "$REPO_URL_WITH_TOKEN"

      echo "⬆️ Pushing to remote..."
      git push --verbose -u origin main

  - name: Generate summary
    if: success()
    env:
      REPO_URL: ${{ steps.create-repo.outputs.html_url }}
    run: |
      echo "## ✅ Workflow Completed Successfully!" &gt;&gt; $GITHUB_STEP_SUMMARY
      echo "" &gt;&gt; $GITHUB_STEP_SUMMARY
      echo "### Repository Details" &gt;&gt; $GITHUB_STEP_SUMMARY
      echo "- **Name:** ${{ inputs.repo_name }}" &gt;&gt; $GITHUB_STEP_SUMMARY
      REPO_URL_SANITIZED=$(echo "$REPO_URL" | sed 's/^"\(.*\)"$/\1/')
      echo "- **URL:** [View Repository](${REPO_URL_SANITIZED%.git})" &gt;&gt; $GITHUB_STEP_SUMMARY
      echo "- **Visibility:** ${{ inputs.private_repo == 'true' &amp;&amp; 'Private' || 'Public' }}" &gt;&gt; $GITHUB_STEP_SUMMARY
      echo "" &gt;&gt; $GITHUB_STEP_SUMMARY
      echo "### Source" &gt;&gt; $GITHUB_STEP_SUMMARY
      echo "- **ZIP URL:** ${{ inputs.zip_url }}" &gt;&gt; $GITHUB_STEP_SUMMARY
      echo "" &gt;&gt; $GITHUB_STEP_SUMMARY
      echo "🎉 All files from the ZIP archive have been extracted and pushed to the new repository!" &gt;&gt; $GITHUB_STEP_SUMMARY

  - name: Cleanup failure
    if: failure()
    uses: actions/github-script@v8
    env:
      REPO_NAME: ${{ inputs.repo_name }}
    with:
      github-token: ${{ secrets.REPO_CREATE_TOKEN }}
      script: |
        const repoName = process.env.REPO_NAME;
        const { data: user } = await github.rest.users.getAuthenticated();

        try {
          await github.rest.repos.get({
            owner: user.login,
            repo: repoName
          });

          console.log(`⚠️ Repository ${user.login}/${repoName} was created but workflow failed.`);
          console.log(`Consider deleting it manually if it's empty: https://github.com/${user.login}/${repoName}/settings`);
        } catch (error) {
          console.log('No repository cleanup needed.');
        } {% endcodeblock %}
</code></pre></div></div>]]></content><author><name></name></author><category term="scratchpad" /></entry><entry><title type="html">DirectAdmin terminal custom commands</title><link href="https://ib.bsb.br/da-term/" rel="alternate" type="text/html" title="DirectAdmin terminal custom commands" /><published>2025-10-25T00:00:00+00:00</published><updated>2025-11-13T21:49:36+00:00</updated><id>https://ib.bsb.br/da-term</id><content type="html" xml:base="https://ib.bsb.br/da-term/"><![CDATA[<h1 id="01-environment-modules-exploration-usrsharemodules">01) Environment Modules exploration (/usr/share/Modules)</h1>
<p>alias h01_modules_explore=’
  pushd /usr/share/Modules &gt;/dev/null; ls;
    pushd modulefiles &gt;/dev/null; ls;
      pushd use.own &gt;/dev/null; cat use.own || true; popd &gt;/dev/null;
      ls; pushd module &gt;/dev/null || true; popd &gt;/dev/null || true;
      pushd modules &gt;/dev/null || true; { cat dot || true; cat module-git || true; ls; cat module || true; cat modules || true; } ; popd &gt;/dev/null || true;
    popd &gt;/dev/null;
    pushd bin &gt;/dev/null || true; ls; { cat createmodule. || true; cat createmodule.sh || true; } ; popd &gt;/dev/null || true;
  popd &gt;/dev/null
‘</p>

<h1 id="02-directadmin-browse-user-datadomains-and-editremove-files">02) DirectAdmin: browse user data/domains and edit/remove files</h1>
<p>alias h02_da_user_domains=’
  pushd /usr/local/directadmin/data &gt;/dev/null; ls;
    pushd users &gt;/dev/null; ls;
      pushd ibbsbbry &gt;/dev/null; ls;
        pushd domains &gt;/dev/null; ls; pwd;
          true;  # placeholder for “which cut.ia.br.cust_nginx” (non-command in history)
          popd &gt;/dev/null;
        ls; pwd;
        pushd php &gt;/dev/null || true; ls; { cat php.ini || true; } ; popd &gt;/dev/null || true;
        pushd domains &gt;/dev/null; ls; pwd;
          rm -f cut.ia.br.cust_httpd || true;
        popd &gt;/dev/null;
      popd &gt;/dev/null;
    popd &gt;/dev/null;
  popd &gt;/dev/null
‘</p>

<h1 id="03-directadmin-pluginsshared-sockets-and-directadmin-binary-ops">03) DirectAdmin: plugins/shared, sockets, and directadmin binary ops</h1>
<p>alias h03_da_admin_ops=’
  pushd /usr/local/directadmin &gt;/dev/null; ls;
    pushd plugins &gt;/dev/null || true; ls; popd &gt;/dev/null || true;
    pushd data &gt;/dev/null; ls; popd &gt;/dev/null;
    pushd shared &gt;/dev/null; ls;
      { cat internal.sock || true; cat startips-network || true; }
    popd &gt;/dev/null;
    ./directadmin || true;
    ./directadmin permissions || true;
    sudo ./directadmin permissions || true;
    ./directadmin version || true;
    ./directadmin update || true;
    ./directadmin my-cnf || true;
    ./directadmin create-login-url || true;
    ./directadmin license || true;
    ./directadmin login-url || true;
    ./directadmin info || true;
    ./directadmin config-get || true;
    ./directadmin config-get -h || true;
    ./directadmin admin || true;
    ./directadmin build || true;
    pwd; ls
  popd &gt;/dev/null
‘</p>

<h1 id="04-directadmin-createedit-domain-conf-sample">04) DirectAdmin: create/edit domain conf sample</h1>
<p>alias h04_da_edit_domain_conf=’
  pushd /usr/local/directadmin/data/users/ibbsbbry/domains &gt;/dev/null;
    ls; touch cut.ia.br.conf; ${EDITOR:-nano} cut.ia.br.conf || true; cat cut.ia.br.conf || true;
  popd &gt;/dev/null
‘</p>

<h1 id="05-directadmin-cpanel-migration-scripts-and-internals">05) DirectAdmin: cPanel migration scripts and internals</h1>
<p>alias h05_da_migration_scripts=’
  pushd /usr/local/directadmin &gt;/dev/null; ls;
    pushd shared &gt;/dev/null; ls; pushd cpanel_to_da &gt;/dev/null; ls; cat cpanel_to_da.sh || true; popd &gt;/dev/null;
    ls; pushd internal.sock &gt;/dev/null || true; cat internal.sock || true; popd &gt;/dev/null || true;
    { cat startips-networkd || true; }
    pushd scripts &gt;/dev/null; ls; pushd cpanel_to_da &gt;/dev/null || true; ls; popd &gt;/dev/null || true;
  popd &gt;/dev/null
‘</p>

<h1 id="06-transfer-helpers-curl-uploads-and-quick-sysinfo">06) Transfer helpers: curl uploads and quick sysinfo</h1>
<p>alias h06_transfers_sysinfo=’
  pushd /usr/local/directadmin/scripts/cpanel_to_da &gt;/dev/null || true; ls || true; touch text.md || true; popd &gt;/dev/null || true;
  curl –help || true;
  curl -fsS -F “file=@-;filename=cpanel_to_da.sh” https://x0.at/ «&lt;”placeholder” || true;
  curl -F “file=@cpanel_to_da.sh” https://0x0.st || true;
  getconf –help || true;
  uptime || true;
  ip a || true;
  which npx || true; npx –help || true;
  npm –help || true; npm –version || true; which npm || true
‘</p>

<h1 id="07-directadmin-grep-web-stack-and-mail-domain-owners">07) DirectAdmin: grep web stack and mail domain owners</h1>
<p>alias h07_da_webstack_mail=’
  grep -E ‘”’”’^(nginx|nginx_proxy|openlitespeed)=’”’”’ /usr/local/directadmin/conf/directadmin.conf || true;
  head /etc/virtual/domainowners || true
‘</p>

<h1 id="08-etc-basics-hosts-resolv-mysql-npmrc-sysconfig">08) /etc basics: hosts, resolv, mysql, npmrc, sysconfig</h1>
<p>alias h08_etc_core=’
  pushd /etc &gt;/dev/null; ls;
    { cat host.conf || true; cat hosts || true; cat my.cnf || true; cat npmrc || true; cat resolv.conf || true; } ;
    ls; { cat trusted-key.key || true; cat virc || true; } ;
    ls; pushd sysconfig &gt;/dev/null || true; ls; { cat saslauthd || true; cat snmp || true; } ; popd &gt;/dev/null || true;
  popd &gt;/dev/null
‘</p>

<h1 id="09-ssl-and-ssh-inspection">09) SSL and SSH inspection</h1>
<p>alias h09_ssl_ssh=’
  pushd /etc/ssl/certs &gt;/dev/null || true; ls; { cat ca-bundle. || true; cat ca-bundle.crt || true; } ; popd &gt;/dev/null || true;
  pushd /etc &gt;/dev/null; ls; popd &gt;/dev/null;
  pushd /etc/ssh &gt;/dev/null || true; ls; cat ssh_config || true; ls; pushd ssh_config.d &gt;/dev/null || true; ls; popd &gt;/dev/null || true;
  pushd /etc/ssh/moduli &gt;/dev/null || true; ls; cat moduli || true; popd &gt;/dev/null || true;
  pushd /etc/skel &gt;/dev/null || true; ls; popd &gt;/dev/null || true
‘</p>

<h1 id="10-etcprofiled-helpers">10) /etc/profile.d helpers</h1>
<p>alias h10_profiled_helpers=’
  pushd /etc/profile.d &gt;/dev/null || true; ls; bash which2.sh –help || true; cat alt_mod_passenger.sh || true; popd &gt;/dev/null || true
‘</p>

<h1 id="11-logs-cagefs-proxyexec">11) Logs, CageFS, proxyexec</h1>
<p>alias h11_logs_cagefs=’
  pushd /var/log/user_logs &gt;/dev/null || true; ls; pushd ibbsbbry &gt;/dev/null || true; ls -a || true; popd &gt;/dev/null || true; popd &gt;/dev/null || true;
  pushd /var &gt;/dev/null; ls -a; { cat .cagefs/ 2&gt;/dev/null || true; } ; pushd .cagefs &gt;/dev/null || true; ls -a; cat .cagefs.token || true; popd &gt;/dev/null || true; popd &gt;/dev/null;
  id || true; ps aux | grep proxyexec || true; ps aux || true;
  proxyexec -h || true; /usr/sbin/proxyexec -c cagefs.sock ibbsbbry CzlNuXVAWS7rH7Cc / CRONTAB_LIST 0 || true
‘</p>

<h1 id="12-vartmp--varwww-basics-and-cgi">12) /var/tmp + /var/www basics and CGI</h1>
<p>alias h12_var_www=’
  pushd /var/tmp &gt;/dev/null || true; ls -a; cat mysql.sock || true; popd &gt;/dev/null || true;
  pushd /var/www &gt;/dev/null || true; ls; pushd html &gt;/dev/null || true; ls; { cat p.php || true; cat index.html || true; cat redirect.php || true; } ; popd &gt;/dev/null || true;
  pushd cgi-bin &gt;/dev/null || true; ls; { cat test-cgi || true; cat printenv || true; } ; popd &gt;/dev/null || true; popd &gt;/dev/null || true
‘</p>

<h1 id="13-passenger-runtime-home--inspect-instance-dirs-and-secrets">13) Passenger runtime (home) — inspect instance dirs and secrets</h1>
<p>alias h13_passenger_runtime=’
  pushd ~/passenger &gt;/dev/null || true; ls -a || true; popd &gt;/dev/null || true;
  for d in ~/passenger.z* ~/passenger.R*; do
    [ -d “$d” ] || continue;
    pushd “$d” &gt;/dev/null; ls; { cat read_only_admin_password.txt 2&gt;/dev/null || true; cat properties.json 2&gt;/dev/null || true; } ;
      pushd web_server_info &gt;/dev/null 2&gt;/dev/null || true; ls -a || true; popd &gt;/dev/null || true;
      { cat watchdog.pid 2&gt;/dev/null || true; cat full_admin_password.txt 2&gt;/dev/null || true; cat creation_finalized 2&gt;/dev/null || true; cat core.pid 2&gt;/dev/null || true; } ;
      pushd agents.s &gt;/dev/null 2&gt;/dev/null || true; ls -a || true; pushd core &gt;/dev/null 2&gt;/dev/null || true; ls -a || true; popd &gt;/dev/null || true; popd &gt;/dev/null || true;
      { cat core.pid 2&gt;/dev/null || true; cat creation_finalized 2&gt;/dev/null || true; cat lock 2&gt;/dev/null || true; cat properties.json 2&gt;/dev/null || true; } ;
    popd &gt;/dev/null;
  done
‘</p>

<h1 id="14-cloudlinux-selector-and-scl-tooling">14) CloudLinux selector and SCL tooling</h1>
<p>alias h14_cl_selector_scl=’
  cloudlinux-selector –help || true;
  cloudlinux-selector –app-mode || true;
  cloudlinux-selector –get-supported-versions || true;
  cloudlinux-selector –json –get-supported-versions || true;
  cloudlinux-selector –json –interpreter nodejs –extensions nodejs || true;
  cloudlinux-selector –json –extensions nodejs || true;
  cloudlinux-selector –json –env-vars || true;
  cloudlinux-selector –json –get-selector-status || true;
  cloudlinux-selector –json –interpreter nodejs –get-supported-versions || true;
  scl –help || true; scl list-collections || true; scl list-enabled || true; scl list-packages || true; scl list-packages alt-nodejs12 || true; scl list-packages alt-nodejs10 || true;
  scl enable alt-nodejs12 “bash -lc ‘”’“‘node -v; npm -v’”’”’” || true;
  scl run alt-nodejs12 node -v || true; scl run alt-nodejs12 npm -v || true
‘</p>

<h1 id="15-domain-content-well-known-acme-roundcube-awstats">15) Domain content: .well-known, acme, roundcube, awstats</h1>
<p>alias h15_domain_webbits=’
  pushd ~/public_html &gt;/dev/null || true; ls; pushd .well-known &gt;/dev/null 2&gt;/dev/null || true; ls -a || true; { cat .htaccess 2&gt;/dev/null || true; } ; pushd acme-challenge &gt;/dev/null 2&gt;/dev/null || true; ls || true; { cat letsencrypt_1596475466 2&gt;/dev/null || true; } ; popd &gt;/dev/null || true; popd &gt;/dev/null || true;
  for d in ~/roundcube/public_html ~/public_html/awstats; do pushd “$d” &gt;/dev/null 2&gt;/dev/null || true; ls; { cat index.php 2&gt;/dev/null || cat index.html 2&gt;/dev/null || true; } ; popd &gt;/dev/null || true; done
‘</p>

<h1 id="16-opt-tools-ai-bolit-app-version-detector-cloudlinux-flagshooks">16) /opt tools: ai-bolit, app-version-detector, cloudlinux flags/hooks</h1>
<p>alias h16_opt_tooling=’
  pushd /opt &gt;/dev/null; ls -a;
    pushd ai-bolit &gt;/dev/null 2&gt;/dev/null || true; ls; cat ai-bolit.php || true; popd &gt;/dev/null || true;
    pushd app-version-detector &gt;/dev/null 2&gt;/dev/null || true; ls; bash app-version-detector.sh || true; cat app-version-detector-wrapper.sh || true; popd &gt;/dev/null || true;
    pushd cloudlinux &gt;/dev/null 2&gt;/dev/null || true; ls -a; { cat nginx_status 2&gt;/dev/null || true; cat litespeed_status 2&gt;/dev/null || true; cat cl_edition 2&gt;/dev/null || true; } ;
      pushd flags &gt;/dev/null 2&gt;/dev/null || true; ls -a; pushd available-flags.d &gt;/dev/null 2&gt;/dev/null || true; ls -a || true; popd &gt;/dev/null || true; pushd enabled-flags.d &gt;/dev/null 2&gt;/dev/null || true; ls -a || true; popd &gt;/dev/null || true; popd &gt;/dev/null || true;
      pushd rhn_hooks/post.d &gt;/dev/null 2&gt;/dev/null || true; ls; cat rhn-update-hook.sh || true; popd &gt;/dev/null || true;
    popd &gt;/dev/null || true;
  popd &gt;/dev/null
‘</p>

<h1 id="17-cloudlinux-venv--pythonpip-tooling">17) CloudLinux venv + Python/pip tooling</h1>
<p>alias h17_opt_python_venv=’
  pushd /opt/cloudlinux/venv &gt;/dev/null 2&gt;/dev/null || true; ls; cat pyvenv.cfg 2&gt;/dev/null || true; /opt/alt/python311/bin/python3 -m venv –upgrade-deps /opt/cloudlinux/venv || true; ls; pushd bin &gt;/dev/null 2&gt;/dev/null || true; ls; cat Activate.ps1 2&gt;/dev/null || true; cat activate 2&gt;/dev/null || true; popd &gt;/dev/null || true;
  pushd /opt/cloudlinux/venv/bin &gt;/dev/null 2&gt;/dev/null || true; python3 –version || true; pip3 –version || true; pip –version || true; popd &gt;/dev/null || true;
  python3 –version || true
‘</p>

<h1 id="18-cloudlinux-helper-scripts--packages">18) CloudLinux helper scripts &amp; packages</h1>
<p>alias h18_cl_scripts_pkgs=’
  pushd /opt/cloudlinux/usr/bin &gt;/dev/null 2&gt;/dev/null || true; ls; ./cpapirebuildcache 2&gt;/dev/null || true; popd &gt;/dev/null || true;
  pushd /opt/cloudlinux/share/python-cllib/scripts &gt;/dev/null 2&gt;/dev/null || true; ls; { cat cl-common 2&gt;/dev/null || true; ./cl-common 2&gt;/dev/null || true; } ; { cat cl_sysctl 2&gt;/dev/null || true; } ; { cat getpaneluserscount 2&gt;/dev/null || true; python3.11 getpaneluserscount 2&gt;/dev/null || true; } ; popd &gt;/dev/null || true
‘</p>

<h1 id="19-alt-php-and-php-fpm-binariesconfigs">19) alt-php and php-fpm binaries/configs</h1>
<p>alias h19_alt_php=’
  pushd /opt/alt-php84/root/etc &gt;/dev/null 2&gt;/dev/null || true; ls; { cat pear 2&gt;/dev/null || true; cat pear.conf 2&gt;/dev/null || true; cat php-fpm.conf 2&gt;/dev/null || true; } ; popd &gt;/dev/null || true;
  pushd /opt/alt-php84/usr/sbin &gt;/dev/null 2&gt;/dev/null || true; ls; ./php-fpm -t 2&gt;/dev/null || true; popd &gt;/dev/null || true;
  pushd /opt/alt-php-internal &gt;/dev/null 2&gt;/dev/null || true; ./enable 2&gt;/dev/null || true; popd &gt;/dev/null || true
‘</p>

<h1 id="20-cloudlinux-site-optimization--wpos">20) CloudLinux site optimization &amp; WPOS</h1>
<p>alias h20_clsop_wpos=’
  pushd /opt/cloudlinux-linksafe &gt;/dev/null 2&gt;/dev/null || true; ls; cat lib.sh 2&gt;/dev/null || true; popd &gt;/dev/null || true;
  pushd /opt/cloudlinux-site-optimization-module &gt;/dev/null 2&gt;/dev/null || true; ls; { cat requirements.json 2&gt;/dev/null || true; cat clsop.zip 2&gt;/dev/null || true; } ; popd &gt;/dev/null || true;
  pushd /opt/clwpos &gt;/dev/null 2&gt;/dev/null || true; ls; cat public_options.json 2&gt;/dev/null || true; popd &gt;/dev/null || true
‘</p>

<h1 id="21-cpaneleasyapache-libs--diagnostics">21) cPanel/EasyApache libs &amp; diagnostics</h1>
<p>alias h21_cpanel_ea_libs=’
  pushd /opt/cp/cpanel/ea-php84/usr/lib64/php/modules &gt;/dev/null 2&gt;/dev/null || true; ls; { cat clos_ssa.so 2&gt;/dev/null || true; cat xray.so 2&gt;/dev/null || true; } ; popd &gt;/dev/null || true;
  pushd /opt/netdata/var/cache/netdata &gt;/dev/null 2&gt;/dev/null || true; ls -a || true; popd &gt;/dev/null || true
‘</p>

<h1 id="22-passenger-bins-and-helper-scripts">22) Passenger bins and helper scripts</h1>
<p>alias h22_passenger_bins=’
  pushd /opt/passenger/bin &gt;/dev/null 2&gt;/dev/null || true; ls; ./passenger-status 2&gt;/dev/null || true; ./passenger 2&gt;/dev/null || true; popd &gt;/dev/null || true;
  pushd /opt/passenger/src/ruby_native_extension &gt;/dev/null 2&gt;/dev/null || true; ls -a || true; cat extconf.rb 2&gt;/dev/null || true; popd &gt;/dev/null || true;
  pushd /opt/passenger/helper-scripts &gt;/dev/null 2&gt;/dev/null || true; ls; cat README.md 2&gt;/dev/null || true; popd &gt;/dev/null || true;
  pushd /opt/passenger/download_binaries &gt;/dev/null 2&gt;/dev/null || true; ls; cat extconf.rb 2&gt;/dev/null || true; ruby *.rb 2&gt;/dev/null || true; popd &gt;/dev/null || true
‘</p>

<h1 id="23-system-package-managers--general-admin">23) System package managers &amp; general admin</h1>
<p>alias h23_pkgs_admin=’
  yum –help 2&gt;/dev/null || true;
  apk add ugrep ugrep-doc 2&gt;/dev/null || true;
  pkg install -y ugrep 2&gt;/dev/null || true
‘</p>

<h1 id="24-user-home-public_html-domains-passenger-demo--scl-npm">24) User home: public_html, domains, passenger demo &amp; SCL npm</h1>
<p>alias h24_user_web_node=’
  pushd ~ &gt;/dev/null; ls; pwd;
    pushd public_html &gt;/dev/null 2&gt;/dev/null || true; ls; popd &gt;/dev/null || true;
    pushd domains/cut.ia.br &gt;/dev/null 2&gt;/dev/null || true; ls -a; popd &gt;/dev/null || true;
    pushd domains/cut.ia.br &gt;/dev/null 2&gt;/dev/null || true;
      git clone https://github.com/phusion/passenger-nodejs-connect-demo.git 2&gt;/dev/null || true;
      pushd passenger-nodejs-connect-demo &gt;/dev/null 2&gt;/dev/null || true; npm install 2&gt;/dev/null || true; popd &gt;/dev/null || true;
      scl run alt-nodejs12 npm install 2&gt;/dev/null || true;
      scl enable alt-nodejs12 “npm -l” 2&gt;/dev/null || true;
      source /home/ibbsbbry/nodevenv/domains/cut.ia.br/passenger-nodejs-connect-demo/12/bin/activate 2&gt;/dev/null || true;
    popd &gt;/dev/null || true;
  popd &gt;/dev/null
‘</p>

<h1 id="25-optaltpostgresql11-exploration">25) /opt/alt/postgresql11 exploration</h1>
<p>alias h25_alt_postgresql=’
  pushd /opt/alt/postgresql11 &gt;/dev/null 2&gt;/dev/null || true; ls;
    pushd usr/bin &gt;/dev/null 2&gt;/dev/null || true; ls; popd &gt;/dev/null || true;
    pushd include/pgsql/internal/libpq &gt;/dev/null 2&gt;/dev/null || true; ls; popd &gt;/dev/null || true;
    pushd share/pgsql &gt;/dev/null 2&gt;/dev/null || true; ls; cat pg_service.conf.sample 2&gt;/dev/null || true; popd &gt;/dev/null || true;
    pushd doc/alt-postgresql11 &gt;/dev/null 2&gt;/dev/null || true; ls; cat README 2&gt;/dev/null || true; popd &gt;/dev/null || true;
    pushd lib64/pkgconfig &gt;/dev/null 2&gt;/dev/null || true; ls; popd &gt;/dev/null || true;
    pushd bin &gt;/dev/null 2&gt;/dev/null || true; ls; popd &gt;/dev/null || true;
  popd &gt;/dev/null || true
‘</p>

<h1 id="26-alt-nodejs12-internals-and-tools">26) alt-nodejs12 internals and tools</h1>
<p>alias h26_alt_nodejs_internals=’
  pushd /opt/alt/alt-nodejs12 &gt;/dev/null 2&gt;/dev/null || true; ls;
    pushd root/home &gt;/dev/null 2&gt;/dev/null || true; ls -a || true; popd &gt;/dev/null || true;
    pushd root/bin &gt;/dev/null 2&gt;/dev/null || true; ls; npx –help || true; npx –version || true; popd &gt;/dev/null || true;
  popd &gt;/dev/null || true;
  pushd /opt/sqlite/usr/bin &gt;/dev/null 2&gt;/dev/null || true; ls; popd &gt;/dev/null || true;
  pushd /opt/clos_ssa/run &gt;/dev/null 2&gt;/dev/null || true; ls; cat ssa.sock 2&gt;/dev/null || true; popd &gt;/dev/null || true;
  pushd /opt/alt-mod-passenger/etc &gt;/dev/null 2&gt;/dev/null || true; ls; cat mod_passenger.conf 2&gt;/dev/null || true; popd &gt;/dev/null || true
‘</p>

<h1 id="27-modulefiles-alternatives-and-ghostscript">27) Modulefiles, alternatives, and ghostscript</h1>
<p>alias h27_modules_misc=’
  pushd /etc/alternatives &gt;/dev/null 2&gt;/dev/null || true; ls; cat modules.sh 2&gt;/dev/null || true; popd &gt;/dev/null || true;
  pushd /usr/share/modulefiles &gt;/dev/null 2&gt;/dev/null || true; ls -a || true; popd &gt;/dev/null || true;
  pushd /usr/share/ghostscript &gt;/dev/null 2&gt;/dev/null || true; ls; popd &gt;/dev/null || true
‘</p>

<h1 id="28-node-virtualenvs-for-domains">28) Node virtualenvs for domains</h1>
<p>alias h28_nodevenv_bins=’
  pushd ~/nodevenv/domains/cut.ia.br/passenger-nodejs-connect-demo/12/bin &gt;/dev/null 2&gt;/dev/null || true; ls; popd &gt;/dev/null || true
‘</p>

<h1 id="29-ugrep-build-from-source-and-verification">29) Ugrep build from source (and verification)</h1>
<p>alias h29_ugrep_build=’
  pushd ~ &gt;/dev/null;
    git clone https://github.com/Genivia/ugrep 2&gt;/dev/null || true;
    pushd ugrep &gt;/dev/null; ls;
      ./build.sh || true; sudo make install || true; make install || true;
      pushd bin &gt;/dev/null 2&gt;/dev/null || true; ls; ./ugrep –version || true; popd &gt;/dev/null || true;
    popd &gt;/dev/null;
  popd &gt;/dev/null;
  ugrep –version || true
‘</p>

<h1 id="30-quick-misc-one-offs-captured">30) Quick misc one-offs captured</h1>
<p>alias h30_misc=’
  history | tail -n 50 || true;
  which npm || true; which npx || true;
  node -v 2&gt;/dev/null || true; install node 2&gt;/dev/null || true; script -V 2&gt;/dev/null || true;
  reset –help 2&gt;/dev/null || true; clear || true; printenv || true; whoami || true; pwdx 2&gt;/dev/null || true
‘</p>

<h1 id="31-domain-owners-quick-check">31) Domain owners quick check</h1>
<p>alias h31_mail_domainowners=’head /etc/virtual/domainowners || true’</p>

<h1 id="32-grep-directadmin-webserver-mode">32) Grep DirectAdmin webserver mode</h1>
<p>alias h32_da_web_mode=’grep -E “^(nginx|nginx_proxy|openlitespeed)=” /usr/local/directadmin/conf/directadmin.conf || true’</p>

<h1 id="33-passenger-status-shortcut">33) Passenger status shortcut</h1>
<p>alias h33_passenger_status=’/opt/passenger/bin/passenger-status 2&gt;/dev/null || passenger-status 2&gt;/dev/null || true’</p>

<h1 id="34-show-ssh-moduli-and-config-quickly">34) Show SSH moduli and config quickly</h1>
<p>alias h34_ssh_quick=’cat /etc/ssh/ssh_config 2&gt;/dev/null || true; cat /etc/ssh/moduli 2&gt;/dev/null || true’</p>

<h1 id="35-dns-resolvers-quick">35) DNS resolvers quick</h1>
<p>alias h35_resolvers_quick=’cat /etc/resolv.conf || true’</p>

<h1 id="36-hosts-quick">36) Hosts quick</h1>
<p>alias h36_hosts_quick=’cat /etc/hosts || true’</p>]]></content><author><name></name></author><category term="scratchpad" /></entry><entry><title type="html">folders2zip as non-admin Windows user</title><link href="https://ib.bsb.br/folders2zip-win/" rel="alternate" type="text/html" title="folders2zip as non-admin Windows user" /><published>2025-10-24T00:00:00+00:00</published><updated>2025-11-13T21:50:02+00:00</updated><id>https://ib.bsb.br/folders2zip-win</id><content type="html" xml:base="https://ib.bsb.br/folders2zip-win/"><![CDATA[<section class="code-block-container" role="group" aria-label="Powershell Code Block" data-filename="powershell_code_block.txt" data-code="#requires -Version 5.1
&lt;#!
.SYNOPSIS
  Single-file archive as a non-admin Windows 10 user — create/overwrite/update a .zip of a folder; optional restore.

.DESCRIPTION
  Creates a single .zip archive of SourceDir with robust handling for invalid file timestamps by clamping
  to the ZIP spec range (1980-01-01 to 2107-12-31). No admin required. ASCII-only script for PS 5.1.
  This refactored version:
    - Sets ZipArchiveEntry.LastWriteTime BEFORE opening the entry stream (required for Create mode)
    - Prevents temp-file self-inclusion by blocking Create/Overwrite when ArchivePath is under SourceDir
    - Skips both ArchivePath and its temp path during Create/Overwrite enumeration

.PARAMETER SourceDir
  Absolute path to the folder to archive recursively.

.PARAMETER ArchivePath
  Target .zip file path. Default: $env:LOCALAPPDATA\SingleArchive\Out\&lt;Leaf(SourceDir)&gt;.zip

.PARAMETER RestoreDir
  Destination folder for optional restore/extract. Default: $env:LOCALAPPDATA\SingleArchive\Restored\&lt;Leaf(SourceDir)&gt;

.PARAMETER Mode
  Create    - Create new .zip; if it exists, prompt (or -Force) to use a timestamped name.
  Overwrite - Replace existing .zip atomically.
  Update    - Open or create .zip and add/replace entries that changed (does not delete removed files).

.PARAMETER VerifyOnly
  Compute and display stats (source, archive) without writing.

.PARAMETER DoRestore
  After archive step, extract the .zip to RestoreDir.

.PARAMETER Force
  Skip confirmations for overwrites and existing destination handling.

.PARAMETER DryRun
  Simulate actions; do not write.

.EXAMPLE
  .\SingleFile-Archive.ps1 -SourceDir &quot;C:\Data\Docs&quot; -Mode Create -Verbose

.EXAMPLE
  .\SingleFile-Archive.ps1 -SourceDir &quot;C:\Data\Docs&quot; -Mode Update -DoRestore -Force -Verbose

.NOTES
  Compress-Archive may fail on out-of-range timestamps. This script uses a .NET ZipArchive pipeline that clamps
  timestamps and avoids that failure for Create/Overwrite/Update. It also guards against self-inclusion when the
  archive destination resides under the source tree.
#&gt;

[CmdletBinding()]
param(
  [Parameter(Mandatory=$true)]
  [ValidateScript({ Test-Path $_ -PathType Container })]
  [string]$SourceDir,

  [string]$ArchivePath,

  [string]$RestoreDir,

  [ValidateSet(&#39;Create&#39;,&#39;Overwrite&#39;,&#39;Update&#39;)]
  [string]$Mode = &#39;Create&#39;,

  [switch]$VerifyOnly,
  [switch]$DoRestore,
  [switch]$Force,
  [switch]$DryRun
)

Set-StrictMode -Version Latest
$ErrorActionPreference = &#39;Stop&#39;

# ---------------------------- Helpers -----------------------------------------

function Write-Step { param([string]$Message) Write-Host (&quot;[+] {0}&quot; -f $Message) }
function Write-Sub  { param([string]$Message) Write-Host (&quot;    - {0}&quot; -f $Message) }

function Confirm-Action {
  param([Parameter(Mandatory=$true)][string]$Prompt,[switch]$DefaultNo)
  if ($Force) { return $true }
  $def = if ($DefaultNo) {&#39;N&#39;} else {&#39;Y&#39;}
  $choices = if ($DefaultNo) {&#39;[y/N]&#39;} else {&#39;[Y/n]&#39;}
  while ($true) {
    $resp = Read-Host &quot;$Prompt $choices&quot;
    if ([string]::IsNullOrWhiteSpace($resp)) { $resp = $def }
    switch ($resp.ToUpperInvariant()) {
      &#39;Y&#39; { return $true }
      &#39;N&#39; { return $false }
      default { Write-Host &#39;Please answer Y or N.&#39; }
    }
  }
}

function New-Timestamp { (Get-Date).ToString(&#39;yyyyMMdd_HHmmss&#39;) }

function Ensure-Dir {
  param([Parameter(Mandatory=$true)][string]$Path)
  if (-not (Test-Path -LiteralPath $Path -PathType Container)) {
    Write-Verbose &quot;Ensure-Dir: $Path&quot;
    New-Item -ItemType Directory -Path $Path -Force | Out-Null
  }
}

function Get-FolderStats {
  [CmdletBinding()]
  param([Parameter(Mandatory=$true)][string]$Path)
  Write-Verbose &quot;Get-FolderStats: $Path&quot;
  $files = Get-ChildItem -LiteralPath $Path -Recurse -File -Force -ErrorAction Stop
  [pscustomobject]@{
    Path  = $Path
    Files = $files.Count
    Bytes = ($files | Measure-Object -Property Length -Sum).Sum
  }
}

function Get-ZipStats {
  [CmdletBinding()]
  param([Parameter(Mandatory=$true)][string]$ZipPath)
  if (-not (Test-Path -LiteralPath $ZipPath -PathType Leaf)) {
    return [pscustomobject]@{ Path=$ZipPath; Exists=$false; Entries=0; UncompressedBytes=0; CompressedBytes=0; SizeOnDisk=0 }
  }
  Add-Type -AssemblyName System.IO.Compression.FileSystem -ErrorAction Stop
  $fileInfo = Get-Item -LiteralPath $ZipPath -ErrorAction Stop
  $zip = [System.IO.Compression.ZipFile]::OpenRead($ZipPath)
  try {
    $entries = $zip.Entries
    $uc = 0L; $cc = 0L
    foreach ($e in $entries) {
      $uc += [int64]$e.Length
      if ($e.CompressedLength -is [long]) { $cc += [int64]$e.CompressedLength }
    }
    return [pscustomobject]@{
      Path              = $ZipPath
      Exists            = $true
      Entries           = $entries.Count
      UncompressedBytes = $uc
      CompressedBytes   = $cc
      SizeOnDisk        = $fileInfo.Length
    }
  } finally { $zip.Dispose() }
}

function Get-FreeSpaceForPath {
  param([Parameter(Mandatory=$true)][string]$TargetPath)
  $parent = Split-Path -Path $TargetPath -Parent
  if (-not $parent) { $parent = $env:TEMP }
  Ensure-Dir $parent
  $driveRoot = (Split-Path -Path (Resolve-Path -LiteralPath $parent) -Qualifier)
  $di = New-Object System.IO.DriveInfo ($driveRoot.TrimEnd(&#39;\&#39;))
  return $di.AvailableFreeSpace
}

function Ensure-ZipAssemblies {
  Add-Type -AssemblyName System.IO.Compression -ErrorAction Stop
  Add-Type -AssemblyName System.IO.Compression.FileSystem -ErrorAction Stop
}

function Get-RelativePath {
  param([Parameter(Mandatory=$true)][string]$BaseDir,[Parameter(Mandatory=$true)][string]$FullName)
  $base = (Resolve-Path -LiteralPath $BaseDir).Path.TrimEnd(&#39;\\&#39;)
  $rel = $FullName.Substring($base.Length).TrimStart(&#39;\\&#39;)
  return ($rel -replace &#39;\\&#39;,&#39;/&#39;)
}

function Clamp-ZipTimestamp {
  param([Parameter(Mandatory=$true)][datetime]$DateUtc)
  # ZIP spec range: 1980-01-01 .. 2107-12-31
  $min = [datetime]::Parse(&#39;1980-01-01T00:00:00Z&#39;)
  $max = [datetime]::Parse(&#39;2107-12-31T23:59:59Z&#39;)
  $utc = $DateUtc.ToUniversalTime()
  if ($utc -lt $min) { $utc = $min }
  if ($utc -gt $max) { $utc = $max }
  return [datetimeoffset]$utc
}

function Get-AbsolutePath {
  param([Parameter(Mandatory=$true)][string]$Path)
  if ([System.IO.Path]::IsPathRooted($Path)) { return [System.IO.Path]::GetFullPath($Path) }
  $base = (Get-Location).Path
  return [System.IO.Path]::GetFullPath((Join-Path $base $Path))
}

function Test-IsSubPath {
  param([Parameter(Mandatory=$true)][string]$Child,[Parameter(Mandatory=$true)][string]$Parent)
  $p = $Parent.TrimEnd(&#39;\\&#39;) + &#39;\\&#39;
  $c = $Child.TrimEnd(&#39;\\&#39;)
  return $c.StartsWith($p, [System.StringComparison]::OrdinalIgnoreCase)
}

function Add-EntryFromFile {
  param(
    [Parameter(Mandatory=$true)][System.IO.Compression.ZipArchive]$Zip,
    [Parameter(Mandatory=$true)][string]$EntryName,
    [Parameter(Mandatory=$true)][string]$FilePath
  )
  # Create the entry object first
  $entry = $Zip.CreateEntry($EntryName, [System.IO.Compression.CompressionLevel]::Optimal)

  # FIX: Set timestamp BEFORE opening the entry stream (required for Create mode)
  $fi = Get-Item -LiteralPath $FilePath -ErrorAction SilentlyContinue
  if ($fi) {
    $entry.LastWriteTime = Clamp-ZipTimestamp -DateUtc $fi.LastWriteTimeUtc
  } else {
    $entry.LastWriteTime = Clamp-ZipTimestamp -DateUtc ([datetime]::UtcNow)
  }

  # Now open streams and copy data
  $inStream  = $null
  $outStream = $null
  try {
    $inStream  = [System.IO.File]::Open($FilePath, [System.IO.FileMode]::Open, [System.IO.FileAccess]::Read, [System.IO.FileShare]::Read)
    $outStream = $entry.Open()
    $inStream.CopyTo($outStream)
  } finally {
    if ($outStream) { $outStream.Dispose() }
    if ($inStream)  { $inStream.Dispose() }
  }
}

function New-ZipFromDirectory {
  param(
    [Parameter(Mandatory=$true)][string]$SourceDir,
    [Parameter(Mandatory=$true)][string]$ArchivePath,
    [string[]]$SkipPaths,
    [switch]$DryRun
  )
  if ($DryRun) {
    Write-Sub (&quot;DryRun: would create zip from {0} -&gt; {1}&quot; -f $SourceDir, $ArchivePath)
    return
  }
  Ensure-ZipAssemblies
  $tmp = &quot;$ArchivePath.tmp.$(New-Timestamp)&quot;
  if (Test-Path -LiteralPath $tmp -PathType Leaf) { Remove-Item -LiteralPath $tmp -Force }

  # Build skip set (ArchivePath and its temp)
  $skipSet = New-Object &#39;System.Collections.Generic.HashSet[string]&#39; ([System.StringComparer]::OrdinalIgnoreCase)
  if ($SkipPaths) { foreach ($sp in $SkipPaths) { if ($sp) { [void]$skipSet.Add($sp) } } }
  [void]$skipSet.Add($ArchivePath)
  [void]$skipSet.Add($tmp)

  $fs = $null
  $zip = $null
  try {
    $fs  = [System.IO.File]::Open($tmp, [System.IO.FileMode]::Create, [System.IO.FileAccess]::ReadWrite, [System.IO.FileShare]::None)
    $zip = New-Object System.IO.Compression.ZipArchive($fs, [System.IO.Compression.ZipArchiveMode]::Create, $false)
    $files = Get-ChildItem -LiteralPath $SourceDir -Recurse -File -Force
    foreach ($f in $files) {
      if ($skipSet.Contains($f.FullName)) { continue }
      $entryName = Get-RelativePath -BaseDir $SourceDir -FullName $f.FullName
      Add-EntryFromFile -Zip $zip -EntryName $entryName -FilePath $f.FullName
    }
  } finally {
    if ($zip) { $zip.Dispose() }
    if ($fs)  { $fs.Dispose() }
  }
  if (Test-Path -LiteralPath $ArchivePath -PathType Leaf) {
    Remove-Item -LiteralPath $ArchivePath -Force -ErrorAction Stop
  }
  Move-Item -LiteralPath $tmp -Destination $ArchivePath -Force
}

function Update-ZipFromDirectory {
  param(
    [Parameter(Mandatory=$true)][string]$SourceDir,
    [Parameter(Mandatory=$true)][string]$ArchivePath,
    [switch]$DryRun
  )
  if (-not (Test-Path -LiteralPath $ArchivePath -PathType Leaf)) {
    Write-Sub &quot;Archive does not exist; creating new.&quot;
    New-ZipFromDirectory -SourceDir $SourceDir -ArchivePath $ArchivePath -DryRun:$DryRun
    return
  }
  if ($DryRun) {
    Write-Sub (&quot;DryRun: would open zip for update: {0}&quot; -f $ArchivePath)
    return
  }
  Ensure-ZipAssemblies
  $fs  = [System.IO.File]::Open($ArchivePath, [System.IO.FileMode]::Open, [System.IO.FileAccess]::ReadWrite, [System.IO.FileShare]::None)
  $zip = New-Object System.IO.Compression.ZipArchive($fs, [System.IO.Compression.ZipArchiveMode]::Update, $false)
  try {
    # Build a lookup of existing entries (case-insensitive)
    $map = @{}
    foreach ($e in $zip.Entries) { $map[$e.FullName.ToLowerInvariant()] = $e }
    $added = 0; $replaced = 0; $skipped = 0
    $files = Get-ChildItem -LiteralPath $SourceDir -Recurse -File -Force
    foreach ($f in $files) {
      if ($f.FullName -ieq $ArchivePath) { continue }
      $rel = Get-RelativePath -BaseDir $SourceDir -FullName $f.FullName
      $key = $rel.ToLowerInvariant()
      if ($map.ContainsKey($key)) {
        $existing = $map[$key]
        # Compare length and timestamp (ZIP timestamp granularity ~2 seconds)
        $needsReplace = $true
        try {
          $zipTime = $existing.LastWriteTime.UtcDateTime
          $fileTime = $f.LastWriteTimeUtc
          $lenDiff = ($existing.Length -ne $f.Length)
          $timeDiff = [math]::Abs((New-TimeSpan -Start $zipTime -End $fileTime).TotalSeconds) -gt 2
          $needsReplace = ($lenDiff -or $timeDiff)
        } catch { $needsReplace = $true }
        if ($needsReplace) {
          $existing.Delete()
          Add-EntryFromFile -Zip $zip -EntryName $rel -FilePath $f.FullName
          $replaced++
        } else {
          $skipped++
        }
      } else {
        Add-EntryFromFile -Zip $zip -EntryName $rel -FilePath $f.FullName
        $added++
      }
    }
    Write-Sub (&quot;Update summary: added={0}, replaced={1}, skipped={2}&quot; -f $added, $replaced, $skipped)
  } finally {
    if ($zip) { $zip.Dispose() }
    if ($fs)  { $fs.Dispose() }
  }
}

function Invoke-Expand {
  param(
    [Parameter(Mandatory=$true)][string]$ArchivePath,
    [Parameter(Mandatory=$true)][string]$RestoreDir
  )
  Ensure-ZipAssemblies
  [System.IO.Compression.ZipFile]::ExtractToDirectory($ArchivePath, $RestoreDir)
}

# ---------------------------- Defaults ----------------------------------------

$resolvedSource = (Resolve-Path -LiteralPath $SourceDir).Path
$sourceLeaf = Split-Path -Path $resolvedSource -Leaf

if (-not $ArchivePath) {
  $defaultOut = Join-Path $env:LOCALAPPDATA &#39;SingleArchive\Out&#39;
  Ensure-Dir $defaultOut
  $ArchivePath = Join-Path $defaultOut ($sourceLeaf + &#39;.zip&#39;)
} else {
  Ensure-Dir (Split-Path -Path $ArchivePath -Parent)
}

if (-not $RestoreDir) {
  $RestoreDir = Join-Path (Join-Path $env:LOCALAPPDATA &#39;SingleArchive\Restored&#39;) $sourceLeaf
} else {
  Ensure-Dir (Split-Path -Path $RestoreDir -Parent)
}

$resolvedArchive = Get-AbsolutePath -Path $ArchivePath

# ---------------------------- Preflight ---------------------------------------

Write-Step &quot;Environment&quot;
Write-Sub  (&quot;UserMode: {0}&quot; -f [Environment]::UserName)
Write-Sub  (&quot;SourceDir:  {0}&quot; -f $resolvedSource)
Write-Sub  (&quot;ArchivePath: {0}&quot; -f $resolvedArchive)
Write-Sub  (&quot;RestoreDir:  {0}&quot; -f $RestoreDir)
Write-Sub  (&quot;Mode:        {0}&quot; -f $Mode)
Write-Sub  (&quot;VerifyOnly:  {0}&quot; -f ($(if($VerifyOnly){&#39;Yes&#39;}else{&#39;No&#39;})))
Write-Sub  (&quot;DryRun:      {0}&quot; -f ($(if($DryRun){&#39;Yes&#39;}else{&#39;No&#39;})))

$srcStats = Get-FolderStats -Path $resolvedSource
(&quot;{0} files; {1:N0} bytes - Source&quot; -f $srcStats.Files, $srcStats.Bytes) | Write-Host

$existingZip = Get-ZipStats -ZipPath $resolvedArchive
if ($existingZip.Exists) {
  (&quot;{0} entries; {1:N0} bytes on disk - Existing Archive&quot; -f $existingZip.Entries, $existingZip.SizeOnDisk) | Write-Host
}

if ($VerifyOnly) {
  Write-Step &quot;Verify-only mode - no writes will occur&quot;
  return
}

# Guard: prevent Create/Overwrite when archive path is under source (self-inclusion risk via temp file)
if (($Mode -eq &#39;Create&#39; -or $Mode -eq &#39;Overwrite&#39;) -and (Test-IsSubPath -Child $resolvedArchive -Parent $resolvedSource)) {
  throw &quot;Unsafe configuration: ArchivePath resides under SourceDir for mode &#39;$Mode&#39;. Place the archive outside the source tree.&quot;
}

# Free space heuristic
try {
  $free = Get-FreeSpaceForPath -TargetPath $resolvedArchive
  Write-Sub (&quot;Free space on target volume: {0:N0} bytes&quot; -f $free)
  $needed = if ($Mode -eq &#39;Update&#39; -and $existingZip.Exists) {
    [int64]([Math]::Max($srcStats.Bytes * 0.2, $existingZip.SizeOnDisk * 0.1))
  } else {
    [int64]$srcStats.Bytes
  }
  if ($free -lt $needed) {
    throw (&quot;Insufficient free space. Needed approx {0:N0} bytes, Available {1:N0} bytes&quot; -f $needed, $free)
  }
} catch { throw &quot;Free space check failed. $_&quot; }

# ---------------------------- Mode-specific confirms --------------------------

switch ($Mode) {
  &#39;Create&#39; {
    if (Test-Path -LiteralPath $resolvedArchive -PathType Leaf) {
      $ts = New-Timestamp
      $altPath = Join-Path (Split-Path -Path $resolvedArchive -Parent) (&quot;{0}_{1}.zip&quot; -f [IO.Path]::GetFileNameWithoutExtension($resolvedArchive), $ts)
      if (-not (Confirm-Action -Prompt &quot;Archive exists. Create a new timestamped archive instead?`n  $altPath&quot;)) {
        throw &quot;User declined to proceed in Create mode with existing archive.&quot;
      }
      $resolvedArchive = $altPath
      $ArchivePath = $altPath
    }
  }
  &#39;Overwrite&#39; {
    if ((Test-Path -LiteralPath $resolvedArchive -PathType Leaf) -and -not (Confirm-Action -Prompt &quot;Overwrite will DELETE existing archive. Proceed?&quot;)) {
      throw &quot;User declined overwrite.&quot;
    }
  }
  &#39;Update&#39; {
    $null = $null
  }
}

# ---------------------------- Archive -----------------------------------------

Write-Step &quot;Archiving&quot;
Write-Sub  (&quot;Operation: {0}&quot; -f $Mode)
Write-Sub  (&quot;Target:    {0}&quot; -f $resolvedArchive)

try {
  switch ($Mode) {
    &#39;Create&#39;   {
      New-ZipFromDirectory -SourceDir $resolvedSource -ArchivePath $resolvedArchive -SkipPaths @($resolvedArchive) -DryRun:$DryRun
    }
    &#39;Overwrite&#39;{
      New-ZipFromDirectory -SourceDir $resolvedSource -ArchivePath $resolvedArchive -SkipPaths @($resolvedArchive) -DryRun:$DryRun
    }
    &#39;Update&#39;   {
      Update-ZipFromDirectory -SourceDir $resolvedSource -ArchivePath $resolvedArchive -DryRun:$DryRun
    }
  }
} catch { throw &quot;Archive step failed. $_&quot; }

# ---------------------------- Post-archive verification -----------------------

Write-Step &quot;Verifying archive&quot;
try {
  if (-not $DryRun) {
    $zipStats = Get-ZipStats -ZipPath $resolvedArchive
    if (-not $zipStats.Exists) { throw &quot;Archive not found after operation.&quot; }
    (&quot;{0} entries; {1:N0} bytes on disk - Archive&quot; -f $zipStats.Entries, $zipStats.SizeOnDisk) | Write-Host
  } else {
    Write-Sub &quot;DryRun: verification skipped (no archive written)&quot;
  }
} catch { throw &quot;Verification failed. $_&quot; }

# ---------------------------- Optional restore --------------------------------

if ($DoRestore -and -not $DryRun) {
  Write-Step &quot;Restore (extract)&quot;
  $existsAndHasContent = (Test-Path -LiteralPath $RestoreDir -PathType Container) -and ((Get-ChildItem -LiteralPath $RestoreDir -Force | Measure-Object).Count -gt 0)
  if ($existsAndHasContent) {
    if (-not (Confirm-Action -Prompt &quot;RestoreDir has existing content. Move aside as a timestamped backup?&quot; -DefaultNo)) {
      throw &quot;User declined to touch existing RestoreDir.&quot;
    }
    $backup = &quot;$RestoreDir.__backup__$(New-Timestamp)&quot;
    Write-Sub (&quot;Renaming existing RestoreDir to &#39;{0}&#39;&quot; -f $backup)
    Rename-Item -LiteralPath $RestoreDir -NewName (Split-Path -Path $backup -Leaf) -ErrorAction Stop
  }
  Ensure-Dir $RestoreDir
  try {
    Invoke-Expand -ArchivePath $resolvedArchive -RestoreDir $RestoreDir
    $restStats = Get-FolderStats -Path $RestoreDir
    (&quot;{0} files; {1:N0} bytes - Restored&quot; -f $restStats.Files, $restStats.Bytes) | Write-Host
  } catch { throw &quot;Restore failed. $_&quot; }
} elseif ($DoRestore -and $DryRun) {
  Write-Step &quot;DryRun: would extract archive to &#39;$RestoreDir&#39;&quot;
}

# ---------------------------- Done --------------------------------------------

Write-Step &quot;Done&quot;
Write-Sub  (&quot;Archive at: {0}&quot; -f $resolvedArchive)
if ($DoRestore -and -not $DryRun) { Write-Sub (&quot;Restored to: {0}&quot; -f $RestoreDir) }
Write-Sub  &quot;Re-run with -Mode Update for incremental refresh; use Overwrite to fully regenerate.&quot;" data-download-link="" data-download-label="Download Powershell">
  <code class="language-powershell">#requires -Version 5.1
&lt;#!
.SYNOPSIS
  Single-file archive as a non-admin Windows 10 user — create/overwrite/update a .zip of a folder; optional restore.

.DESCRIPTION
  Creates a single .zip archive of SourceDir with robust handling for invalid file timestamps by clamping
  to the ZIP spec range (1980-01-01 to 2107-12-31). No admin required. ASCII-only script for PS 5.1.
  This refactored version:
    - Sets ZipArchiveEntry.LastWriteTime BEFORE opening the entry stream (required for Create mode)
    - Prevents temp-file self-inclusion by blocking Create/Overwrite when ArchivePath is under SourceDir
    - Skips both ArchivePath and its temp path during Create/Overwrite enumeration

.PARAMETER SourceDir
  Absolute path to the folder to archive recursively.

.PARAMETER ArchivePath
  Target .zip file path. Default: $env:LOCALAPPDATA\SingleArchive\Out\&lt;Leaf(SourceDir)&gt;.zip

.PARAMETER RestoreDir
  Destination folder for optional restore/extract. Default: $env:LOCALAPPDATA\SingleArchive\Restored\&lt;Leaf(SourceDir)&gt;

.PARAMETER Mode
  Create    - Create new .zip; if it exists, prompt (or -Force) to use a timestamped name.
  Overwrite - Replace existing .zip atomically.
  Update    - Open or create .zip and add/replace entries that changed (does not delete removed files).

.PARAMETER VerifyOnly
  Compute and display stats (source, archive) without writing.

.PARAMETER DoRestore
  After archive step, extract the .zip to RestoreDir.

.PARAMETER Force
  Skip confirmations for overwrites and existing destination handling.

.PARAMETER DryRun
  Simulate actions; do not write.

.EXAMPLE
  .\SingleFile-Archive.ps1 -SourceDir &quot;C:\Data\Docs&quot; -Mode Create -Verbose

.EXAMPLE
  .\SingleFile-Archive.ps1 -SourceDir &quot;C:\Data\Docs&quot; -Mode Update -DoRestore -Force -Verbose

.NOTES
  Compress-Archive may fail on out-of-range timestamps. This script uses a .NET ZipArchive pipeline that clamps
  timestamps and avoids that failure for Create/Overwrite/Update. It also guards against self-inclusion when the
  archive destination resides under the source tree.
#&gt;

[CmdletBinding()]
param(
  [Parameter(Mandatory=$true)]
  [ValidateScript({ Test-Path $_ -PathType Container })]
  [string]$SourceDir,

  [string]$ArchivePath,

  [string]$RestoreDir,

  [ValidateSet(&#39;Create&#39;,&#39;Overwrite&#39;,&#39;Update&#39;)]
  [string]$Mode = &#39;Create&#39;,

  [switch]$VerifyOnly,
  [switch]$DoRestore,
  [switch]$Force,
  [switch]$DryRun
)

Set-StrictMode -Version Latest
$ErrorActionPreference = &#39;Stop&#39;

# ---------------------------- Helpers -----------------------------------------

function Write-Step { param([string]$Message) Write-Host (&quot;[+] {0}&quot; -f $Message) }
function Write-Sub  { param([string]$Message) Write-Host (&quot;    - {0}&quot; -f $Message) }

function Confirm-Action {
  param([Parameter(Mandatory=$true)][string]$Prompt,[switch]$DefaultNo)
  if ($Force) { return $true }
  $def = if ($DefaultNo) {&#39;N&#39;} else {&#39;Y&#39;}
  $choices = if ($DefaultNo) {&#39;[y/N]&#39;} else {&#39;[Y/n]&#39;}
  while ($true) {
    $resp = Read-Host &quot;$Prompt $choices&quot;
    if ([string]::IsNullOrWhiteSpace($resp)) { $resp = $def }
    switch ($resp.ToUpperInvariant()) {
      &#39;Y&#39; { return $true }
      &#39;N&#39; { return $false }
      default { Write-Host &#39;Please answer Y or N.&#39; }
    }
  }
}

function New-Timestamp { (Get-Date).ToString(&#39;yyyyMMdd_HHmmss&#39;) }

function Ensure-Dir {
  param([Parameter(Mandatory=$true)][string]$Path)
  if (-not (Test-Path -LiteralPath $Path -PathType Container)) {
    Write-Verbose &quot;Ensure-Dir: $Path&quot;
    New-Item -ItemType Directory -Path $Path -Force | Out-Null
  }
}

function Get-FolderStats {
  [CmdletBinding()]
  param([Parameter(Mandatory=$true)][string]$Path)
  Write-Verbose &quot;Get-FolderStats: $Path&quot;
  $files = Get-ChildItem -LiteralPath $Path -Recurse -File -Force -ErrorAction Stop
  [pscustomobject]@{
    Path  = $Path
    Files = $files.Count
    Bytes = ($files | Measure-Object -Property Length -Sum).Sum
  }
}

function Get-ZipStats {
  [CmdletBinding()]
  param([Parameter(Mandatory=$true)][string]$ZipPath)
  if (-not (Test-Path -LiteralPath $ZipPath -PathType Leaf)) {
    return [pscustomobject]@{ Path=$ZipPath; Exists=$false; Entries=0; UncompressedBytes=0; CompressedBytes=0; SizeOnDisk=0 }
  }
  Add-Type -AssemblyName System.IO.Compression.FileSystem -ErrorAction Stop
  $fileInfo = Get-Item -LiteralPath $ZipPath -ErrorAction Stop
  $zip = [System.IO.Compression.ZipFile]::OpenRead($ZipPath)
  try {
    $entries = $zip.Entries
    $uc = 0L; $cc = 0L
    foreach ($e in $entries) {
      $uc += [int64]$e.Length
      if ($e.CompressedLength -is [long]) { $cc += [int64]$e.CompressedLength }
    }
    return [pscustomobject]@{
      Path              = $ZipPath
      Exists            = $true
      Entries           = $entries.Count
      UncompressedBytes = $uc
      CompressedBytes   = $cc
      SizeOnDisk        = $fileInfo.Length
    }
  } finally { $zip.Dispose() }
}

function Get-FreeSpaceForPath {
  param([Parameter(Mandatory=$true)][string]$TargetPath)
  $parent = Split-Path -Path $TargetPath -Parent
  if (-not $parent) { $parent = $env:TEMP }
  Ensure-Dir $parent
  $driveRoot = (Split-Path -Path (Resolve-Path -LiteralPath $parent) -Qualifier)
  $di = New-Object System.IO.DriveInfo ($driveRoot.TrimEnd(&#39;\&#39;))
  return $di.AvailableFreeSpace
}

function Ensure-ZipAssemblies {
  Add-Type -AssemblyName System.IO.Compression -ErrorAction Stop
  Add-Type -AssemblyName System.IO.Compression.FileSystem -ErrorAction Stop
}

function Get-RelativePath {
  param([Parameter(Mandatory=$true)][string]$BaseDir,[Parameter(Mandatory=$true)][string]$FullName)
  $base = (Resolve-Path -LiteralPath $BaseDir).Path.TrimEnd(&#39;\\&#39;)
  $rel = $FullName.Substring($base.Length).TrimStart(&#39;\\&#39;)
  return ($rel -replace &#39;\\&#39;,&#39;/&#39;)
}

function Clamp-ZipTimestamp {
  param([Parameter(Mandatory=$true)][datetime]$DateUtc)
  # ZIP spec range: 1980-01-01 .. 2107-12-31
  $min = [datetime]::Parse(&#39;1980-01-01T00:00:00Z&#39;)
  $max = [datetime]::Parse(&#39;2107-12-31T23:59:59Z&#39;)
  $utc = $DateUtc.ToUniversalTime()
  if ($utc -lt $min) { $utc = $min }
  if ($utc -gt $max) { $utc = $max }
  return [datetimeoffset]$utc
}

function Get-AbsolutePath {
  param([Parameter(Mandatory=$true)][string]$Path)
  if ([System.IO.Path]::IsPathRooted($Path)) { return [System.IO.Path]::GetFullPath($Path) }
  $base = (Get-Location).Path
  return [System.IO.Path]::GetFullPath((Join-Path $base $Path))
}

function Test-IsSubPath {
  param([Parameter(Mandatory=$true)][string]$Child,[Parameter(Mandatory=$true)][string]$Parent)
  $p = $Parent.TrimEnd(&#39;\\&#39;) + &#39;\\&#39;
  $c = $Child.TrimEnd(&#39;\\&#39;)
  return $c.StartsWith($p, [System.StringComparison]::OrdinalIgnoreCase)
}

function Add-EntryFromFile {
  param(
    [Parameter(Mandatory=$true)][System.IO.Compression.ZipArchive]$Zip,
    [Parameter(Mandatory=$true)][string]$EntryName,
    [Parameter(Mandatory=$true)][string]$FilePath
  )
  # Create the entry object first
  $entry = $Zip.CreateEntry($EntryName, [System.IO.Compression.CompressionLevel]::Optimal)

  # FIX: Set timestamp BEFORE opening the entry stream (required for Create mode)
  $fi = Get-Item -LiteralPath $FilePath -ErrorAction SilentlyContinue
  if ($fi) {
    $entry.LastWriteTime = Clamp-ZipTimestamp -DateUtc $fi.LastWriteTimeUtc
  } else {
    $entry.LastWriteTime = Clamp-ZipTimestamp -DateUtc ([datetime]::UtcNow)
  }

  # Now open streams and copy data
  $inStream  = $null
  $outStream = $null
  try {
    $inStream  = [System.IO.File]::Open($FilePath, [System.IO.FileMode]::Open, [System.IO.FileAccess]::Read, [System.IO.FileShare]::Read)
    $outStream = $entry.Open()
    $inStream.CopyTo($outStream)
  } finally {
    if ($outStream) { $outStream.Dispose() }
    if ($inStream)  { $inStream.Dispose() }
  }
}

function New-ZipFromDirectory {
  param(
    [Parameter(Mandatory=$true)][string]$SourceDir,
    [Parameter(Mandatory=$true)][string]$ArchivePath,
    [string[]]$SkipPaths,
    [switch]$DryRun
  )
  if ($DryRun) {
    Write-Sub (&quot;DryRun: would create zip from {0} -&gt; {1}&quot; -f $SourceDir, $ArchivePath)
    return
  }
  Ensure-ZipAssemblies
  $tmp = &quot;$ArchivePath.tmp.$(New-Timestamp)&quot;
  if (Test-Path -LiteralPath $tmp -PathType Leaf) { Remove-Item -LiteralPath $tmp -Force }

  # Build skip set (ArchivePath and its temp)
  $skipSet = New-Object &#39;System.Collections.Generic.HashSet[string]&#39; ([System.StringComparer]::OrdinalIgnoreCase)
  if ($SkipPaths) { foreach ($sp in $SkipPaths) { if ($sp) { [void]$skipSet.Add($sp) } } }
  [void]$skipSet.Add($ArchivePath)
  [void]$skipSet.Add($tmp)

  $fs = $null
  $zip = $null
  try {
    $fs  = [System.IO.File]::Open($tmp, [System.IO.FileMode]::Create, [System.IO.FileAccess]::ReadWrite, [System.IO.FileShare]::None)
    $zip = New-Object System.IO.Compression.ZipArchive($fs, [System.IO.Compression.ZipArchiveMode]::Create, $false)
    $files = Get-ChildItem -LiteralPath $SourceDir -Recurse -File -Force
    foreach ($f in $files) {
      if ($skipSet.Contains($f.FullName)) { continue }
      $entryName = Get-RelativePath -BaseDir $SourceDir -FullName $f.FullName
      Add-EntryFromFile -Zip $zip -EntryName $entryName -FilePath $f.FullName
    }
  } finally {
    if ($zip) { $zip.Dispose() }
    if ($fs)  { $fs.Dispose() }
  }
  if (Test-Path -LiteralPath $ArchivePath -PathType Leaf) {
    Remove-Item -LiteralPath $ArchivePath -Force -ErrorAction Stop
  }
  Move-Item -LiteralPath $tmp -Destination $ArchivePath -Force
}

function Update-ZipFromDirectory {
  param(
    [Parameter(Mandatory=$true)][string]$SourceDir,
    [Parameter(Mandatory=$true)][string]$ArchivePath,
    [switch]$DryRun
  )
  if (-not (Test-Path -LiteralPath $ArchivePath -PathType Leaf)) {
    Write-Sub &quot;Archive does not exist; creating new.&quot;
    New-ZipFromDirectory -SourceDir $SourceDir -ArchivePath $ArchivePath -DryRun:$DryRun
    return
  }
  if ($DryRun) {
    Write-Sub (&quot;DryRun: would open zip for update: {0}&quot; -f $ArchivePath)
    return
  }
  Ensure-ZipAssemblies
  $fs  = [System.IO.File]::Open($ArchivePath, [System.IO.FileMode]::Open, [System.IO.FileAccess]::ReadWrite, [System.IO.FileShare]::None)
  $zip = New-Object System.IO.Compression.ZipArchive($fs, [System.IO.Compression.ZipArchiveMode]::Update, $false)
  try {
    # Build a lookup of existing entries (case-insensitive)
    $map = @{}
    foreach ($e in $zip.Entries) { $map[$e.FullName.ToLowerInvariant()] = $e }
    $added = 0; $replaced = 0; $skipped = 0
    $files = Get-ChildItem -LiteralPath $SourceDir -Recurse -File -Force
    foreach ($f in $files) {
      if ($f.FullName -ieq $ArchivePath) { continue }
      $rel = Get-RelativePath -BaseDir $SourceDir -FullName $f.FullName
      $key = $rel.ToLowerInvariant()
      if ($map.ContainsKey($key)) {
        $existing = $map[$key]
        # Compare length and timestamp (ZIP timestamp granularity ~2 seconds)
        $needsReplace = $true
        try {
          $zipTime = $existing.LastWriteTime.UtcDateTime
          $fileTime = $f.LastWriteTimeUtc
          $lenDiff = ($existing.Length -ne $f.Length)
          $timeDiff = [math]::Abs((New-TimeSpan -Start $zipTime -End $fileTime).TotalSeconds) -gt 2
          $needsReplace = ($lenDiff -or $timeDiff)
        } catch { $needsReplace = $true }
        if ($needsReplace) {
          $existing.Delete()
          Add-EntryFromFile -Zip $zip -EntryName $rel -FilePath $f.FullName
          $replaced++
        } else {
          $skipped++
        }
      } else {
        Add-EntryFromFile -Zip $zip -EntryName $rel -FilePath $f.FullName
        $added++
      }
    }
    Write-Sub (&quot;Update summary: added={0}, replaced={1}, skipped={2}&quot; -f $added, $replaced, $skipped)
  } finally {
    if ($zip) { $zip.Dispose() }
    if ($fs)  { $fs.Dispose() }
  }
}

function Invoke-Expand {
  param(
    [Parameter(Mandatory=$true)][string]$ArchivePath,
    [Parameter(Mandatory=$true)][string]$RestoreDir
  )
  Ensure-ZipAssemblies
  [System.IO.Compression.ZipFile]::ExtractToDirectory($ArchivePath, $RestoreDir)
}

# ---------------------------- Defaults ----------------------------------------

$resolvedSource = (Resolve-Path -LiteralPath $SourceDir).Path
$sourceLeaf = Split-Path -Path $resolvedSource -Leaf

if (-not $ArchivePath) {
  $defaultOut = Join-Path $env:LOCALAPPDATA &#39;SingleArchive\Out&#39;
  Ensure-Dir $defaultOut
  $ArchivePath = Join-Path $defaultOut ($sourceLeaf + &#39;.zip&#39;)
} else {
  Ensure-Dir (Split-Path -Path $ArchivePath -Parent)
}

if (-not $RestoreDir) {
  $RestoreDir = Join-Path (Join-Path $env:LOCALAPPDATA &#39;SingleArchive\Restored&#39;) $sourceLeaf
} else {
  Ensure-Dir (Split-Path -Path $RestoreDir -Parent)
}

$resolvedArchive = Get-AbsolutePath -Path $ArchivePath

# ---------------------------- Preflight ---------------------------------------

Write-Step &quot;Environment&quot;
Write-Sub  (&quot;UserMode: {0}&quot; -f [Environment]::UserName)
Write-Sub  (&quot;SourceDir:  {0}&quot; -f $resolvedSource)
Write-Sub  (&quot;ArchivePath: {0}&quot; -f $resolvedArchive)
Write-Sub  (&quot;RestoreDir:  {0}&quot; -f $RestoreDir)
Write-Sub  (&quot;Mode:        {0}&quot; -f $Mode)
Write-Sub  (&quot;VerifyOnly:  {0}&quot; -f ($(if($VerifyOnly){&#39;Yes&#39;}else{&#39;No&#39;})))
Write-Sub  (&quot;DryRun:      {0}&quot; -f ($(if($DryRun){&#39;Yes&#39;}else{&#39;No&#39;})))

$srcStats = Get-FolderStats -Path $resolvedSource
(&quot;{0} files; {1:N0} bytes - Source&quot; -f $srcStats.Files, $srcStats.Bytes) | Write-Host

$existingZip = Get-ZipStats -ZipPath $resolvedArchive
if ($existingZip.Exists) {
  (&quot;{0} entries; {1:N0} bytes on disk - Existing Archive&quot; -f $existingZip.Entries, $existingZip.SizeOnDisk) | Write-Host
}

if ($VerifyOnly) {
  Write-Step &quot;Verify-only mode - no writes will occur&quot;
  return
}

# Guard: prevent Create/Overwrite when archive path is under source (self-inclusion risk via temp file)
if (($Mode -eq &#39;Create&#39; -or $Mode -eq &#39;Overwrite&#39;) -and (Test-IsSubPath -Child $resolvedArchive -Parent $resolvedSource)) {
  throw &quot;Unsafe configuration: ArchivePath resides under SourceDir for mode &#39;$Mode&#39;. Place the archive outside the source tree.&quot;
}

# Free space heuristic
try {
  $free = Get-FreeSpaceForPath -TargetPath $resolvedArchive
  Write-Sub (&quot;Free space on target volume: {0:N0} bytes&quot; -f $free)
  $needed = if ($Mode -eq &#39;Update&#39; -and $existingZip.Exists) {
    [int64]([Math]::Max($srcStats.Bytes * 0.2, $existingZip.SizeOnDisk * 0.1))
  } else {
    [int64]$srcStats.Bytes
  }
  if ($free -lt $needed) {
    throw (&quot;Insufficient free space. Needed approx {0:N0} bytes, Available {1:N0} bytes&quot; -f $needed, $free)
  }
} catch { throw &quot;Free space check failed. $_&quot; }

# ---------------------------- Mode-specific confirms --------------------------

switch ($Mode) {
  &#39;Create&#39; {
    if (Test-Path -LiteralPath $resolvedArchive -PathType Leaf) {
      $ts = New-Timestamp
      $altPath = Join-Path (Split-Path -Path $resolvedArchive -Parent) (&quot;{0}_{1}.zip&quot; -f [IO.Path]::GetFileNameWithoutExtension($resolvedArchive), $ts)
      if (-not (Confirm-Action -Prompt &quot;Archive exists. Create a new timestamped archive instead?`n  $altPath&quot;)) {
        throw &quot;User declined to proceed in Create mode with existing archive.&quot;
      }
      $resolvedArchive = $altPath
      $ArchivePath = $altPath
    }
  }
  &#39;Overwrite&#39; {
    if ((Test-Path -LiteralPath $resolvedArchive -PathType Leaf) -and -not (Confirm-Action -Prompt &quot;Overwrite will DELETE existing archive. Proceed?&quot;)) {
      throw &quot;User declined overwrite.&quot;
    }
  }
  &#39;Update&#39; {
    $null = $null
  }
}

# ---------------------------- Archive -----------------------------------------

Write-Step &quot;Archiving&quot;
Write-Sub  (&quot;Operation: {0}&quot; -f $Mode)
Write-Sub  (&quot;Target:    {0}&quot; -f $resolvedArchive)

try {
  switch ($Mode) {
    &#39;Create&#39;   {
      New-ZipFromDirectory -SourceDir $resolvedSource -ArchivePath $resolvedArchive -SkipPaths @($resolvedArchive) -DryRun:$DryRun
    }
    &#39;Overwrite&#39;{
      New-ZipFromDirectory -SourceDir $resolvedSource -ArchivePath $resolvedArchive -SkipPaths @($resolvedArchive) -DryRun:$DryRun
    }
    &#39;Update&#39;   {
      Update-ZipFromDirectory -SourceDir $resolvedSource -ArchivePath $resolvedArchive -DryRun:$DryRun
    }
  }
} catch { throw &quot;Archive step failed. $_&quot; }

# ---------------------------- Post-archive verification -----------------------

Write-Step &quot;Verifying archive&quot;
try {
  if (-not $DryRun) {
    $zipStats = Get-ZipStats -ZipPath $resolvedArchive
    if (-not $zipStats.Exists) { throw &quot;Archive not found after operation.&quot; }
    (&quot;{0} entries; {1:N0} bytes on disk - Archive&quot; -f $zipStats.Entries, $zipStats.SizeOnDisk) | Write-Host
  } else {
    Write-Sub &quot;DryRun: verification skipped (no archive written)&quot;
  }
} catch { throw &quot;Verification failed. $_&quot; }

# ---------------------------- Optional restore --------------------------------

if ($DoRestore -and -not $DryRun) {
  Write-Step &quot;Restore (extract)&quot;
  $existsAndHasContent = (Test-Path -LiteralPath $RestoreDir -PathType Container) -and ((Get-ChildItem -LiteralPath $RestoreDir -Force | Measure-Object).Count -gt 0)
  if ($existsAndHasContent) {
    if (-not (Confirm-Action -Prompt &quot;RestoreDir has existing content. Move aside as a timestamped backup?&quot; -DefaultNo)) {
      throw &quot;User declined to touch existing RestoreDir.&quot;
    }
    $backup = &quot;$RestoreDir.__backup__$(New-Timestamp)&quot;
    Write-Sub (&quot;Renaming existing RestoreDir to &#39;{0}&#39;&quot; -f $backup)
    Rename-Item -LiteralPath $RestoreDir -NewName (Split-Path -Path $backup -Leaf) -ErrorAction Stop
  }
  Ensure-Dir $RestoreDir
  try {
    Invoke-Expand -ArchivePath $resolvedArchive -RestoreDir $RestoreDir
    $restStats = Get-FolderStats -Path $RestoreDir
    (&quot;{0} files; {1:N0} bytes - Restored&quot; -f $restStats.Files, $restStats.Bytes) | Write-Host
  } catch { throw &quot;Restore failed. $_&quot; }
} elseif ($DoRestore -and $DryRun) {
  Write-Step &quot;DryRun: would extract archive to &#39;$RestoreDir&#39;&quot;
}

# ---------------------------- Done --------------------------------------------

Write-Step &quot;Done&quot;
Write-Sub  (&quot;Archive at: {0}&quot; -f $resolvedArchive)
if ($DoRestore -and -not $DryRun) { Write-Sub (&quot;Restored to: {0}&quot; -f $RestoreDir) }
Write-Sub  &quot;Re-run with -Mode Update for incremental refresh; use Overwrite to fully regenerate.&quot;</code>
</section>]]></content><author><name></name></author><category term="scripts&gt;powershell" /></entry><entry><title type="html">tutorial converter2powershell</title><link href="https://ib.bsb.br/tutorial-converter2powershell/" rel="alternate" type="text/html" title="tutorial converter2powershell" /><published>2025-10-17T00:00:00+00:00</published><updated>2025-10-17T10:25:57+00:00</updated><id>https://ib.bsb.br/tutorial-converter2powershell</id><content type="html" xml:base="https://ib.bsb.br/tutorial-converter2powershell/"><![CDATA[<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  &lt;purpose&gt;You are an expert non-admin Windows PowerShell 5.1 script developer for Windows 10 x64. Convert the narrative setup described in the input field named `tutorial_content` into a single user-mode PowerShell 5.1 script runnable from the user’s home directory, with robust error handling, idempotency, progress logging, and explicit confirmations for risky actions.&lt;/purpose&gt;

  &lt;context&gt;
    &lt;system_environment&gt;
      &lt;os&gt;windows 10&lt;/os&gt;
      &lt;arch&gt;x64&lt;/arch&gt;
      &lt;language&gt;PowerShell 5.1&lt;/language&gt;
      &lt;permissions&gt;non-admin only&lt;/permissions&gt;
    &lt;/system_environment&gt;
    &lt;style&gt;
      &lt;comments&gt;Comprehensive headers plus inline notes on complex lines&lt;/comments&gt;
      &lt;logging&gt;Write-Host progress and Write-Verbose for each major step&lt;/logging&gt;
    &lt;/style&gt;
    &lt;ethics&gt;
      &lt;safety&gt;Backups and confirmations before destructive operations&lt;/safety&gt;
      &lt;integrity&gt;No hidden actions; only tutorial-aligned steps&lt;/integrity&gt;
    &lt;/ethics&gt;
  &lt;/context&gt;

  &lt;input_specification&gt;
    &lt;variable name="tutorial_name" type="string" required="true"/&gt;
      &lt;tutorial_name&gt;
~~~
placeholder
~~~
      &lt;/tutorial_name&gt;
    &lt;variable name="tutorial_content" type="text" required="true"/&gt;
      &lt;tutorial_content&gt;
~~~
placeholder
~~~
      &lt;/tutorial_content&gt;
  &lt;/input_specification&gt;

  &lt;output_specification&gt;
    &lt;format&gt;Single .ps1 script (user-mode)&lt;/format&gt;
    &lt;constraints&gt;
      &lt;constraint&gt;Begin with a header and `#requires -Version 5.1`.&lt;/constraint&gt;
      &lt;constraint&gt;Implement error checking immediately after critical operations.&lt;/constraint&gt;
      &lt;constraint&gt;Use only user-writable paths.&lt;/constraint&gt;
      &lt;constraint&gt;Provide progress logs and clear failure messages.&lt;/constraint&gt;
      &lt;constraint&gt;Ensure idempotency wherever feasible.&lt;/constraint&gt;
      &lt;constraint&gt;Prompt for explicit confirmation before risky actions.&lt;/constraint&gt;
    &lt;/constraints&gt;
  &lt;/output_specification&gt;

  &lt;instructions&gt;
    &lt;instruction&gt;Analyze the `tutorial_content` input and enumerate steps in order.&lt;/instruction&gt;
    &lt;instruction&gt;For each step, add precheck, action, verify, and log.&lt;/instruction&gt;
    &lt;instruction&gt;Translate commands to PS 5.1 equivalents suitable for Windows 10 without admin rights.&lt;/instruction&gt;
    &lt;instruction&gt;Use absolute paths under $env:USERPROFILE, $env:APPDATA, and $env:LOCALAPPDATA.&lt;/instruction&gt;
    &lt;instruction&gt;Check tool availability (e.g., Expand-Archive) and use only PS 5.1 standard fallbacks.&lt;/instruction&gt;
    &lt;instruction&gt;Implement immediate error handling and idempotency guards.&lt;/instruction&gt;
    &lt;instruction&gt;Wrap repeated logic in functions and call consistently.&lt;/instruction&gt;
    &lt;instruction&gt;Emit Write-Host before/after each major step; support -Verbose.&lt;/instruction&gt;
    &lt;instruction&gt;Output only the final script content.&lt;/instruction&gt;
  &lt;/instructions&gt;

  &lt;examples&gt;
    &lt;example&gt;
      &lt;input_data&gt;
        &lt;tutorial_name&gt;Portable Tool Install&lt;/tutorial_name&gt;
        &lt;tutorial_content&gt;1) Download FooTool.zip from https://example.com/foo.zip; 2) Extract to user programs; 3) Add its bin folder to PATH.&lt;/tutorial_content&gt;
      &lt;/input_data&gt;
      &lt;output&gt;Produces a script that creates $LOCALAPPDATA\Programs\FooTool, downloads, expands, and updates HKCU PATH idempotently.&lt;/output&gt;
    &lt;/example&gt;
    &lt;example&gt;
      &lt;input_data&gt;
        &lt;tutorial_name&gt;Write Config&lt;/tutorial_name&gt;
        &lt;tutorial_content&gt;Create %APPDATA%\MyApp\config.json with provided JSON; back up existing.&lt;/tutorial_content&gt;
      &lt;/input_data&gt;
      &lt;output&gt;Produces a script that backs up the existing file with a timestamp and writes new JSON atomically.&lt;/output&gt;
    &lt;/example&gt;
  &lt;/examples&gt;
</code></pre></div></div>]]></content><author><name></name></author><category term="AI&gt;prompt" /></entry><entry><title type="html">tutorial converter2pwsh</title><link href="https://ib.bsb.br/tutorial-converter2pwsh/" rel="alternate" type="text/html" title="tutorial converter2pwsh" /><published>2025-10-17T00:00:00+00:00</published><updated>2025-10-17T09:54:08+00:00</updated><id>https://ib.bsb.br/tutorial-converter2pwsh</id><content type="html" xml:base="https://ib.bsb.br/tutorial-converter2pwsh/"><![CDATA[<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>```
  &lt;purpose&gt;You are an expert root admin Linux PowerShell (pwsh) 7.x script developer. Convert the narrative setup described in the input field named `tutorial_content` into a single user-mode pwsh script runnable from the user’s home directory on Linux, with robust error handling, idempotency, progress logging, and explicit confirmations for risky actions. Use sudo or system package managers and also user-writable paths and XDG-compliant locations.&lt;/purpose&gt;

  &lt;context&gt;
    &lt;system_environment&gt;
      &lt;os&gt;linux&lt;/os&gt;
      &lt;arch&gt;x86_64 or arm64&lt;/arch&gt;
      &lt;language&gt;PowerShell (pwsh) 7.x&lt;/language&gt;
      &lt;permissions&gt;root&lt;/permissions&gt;
    &lt;/system_environment&gt;
    &lt;style&gt;
      &lt;comments&gt;Comprehensive headers plus inline notes on complex lines&lt;/comments&gt;
      &lt;logging&gt;Write-Host progress and Write-Verbose for each major step&lt;/logging&gt;
    &lt;/style&gt;
    &lt;ethics&gt;
      &lt;safety&gt;Backups and confirmations before destructive operations&lt;/safety&gt;
      &lt;integrity&gt;No hidden actions; only tutorial-aligned steps&lt;/integrity&gt;
    &lt;/ethics&gt;
  &lt;/context&gt;

&lt;input_specification&gt;
  &lt;variable name="tutorial_name" type="string" required="true"/&gt;
    &lt;tutorial_name&gt;
~~~
placeholder
~~~
    &lt;/tutorial_name&gt;
  &lt;variable name="tutorial_content" type="text" required="true"/&gt;
    &lt;tutorial_content&gt;
~~~
placeholder
~~~
    &lt;/tutorial_content&gt;
&lt;/input_specification&gt;

&lt;output_specification&gt; &lt;format&gt;Single pwsh script (.ps1) with shebang&lt;/format&gt; &lt;constraints&gt; &lt;constraint&gt;Begin with `#!/usr/bin/env pwsh` and `#Requires -Version 7.x`.&lt;/constraint&gt; &lt;constraint&gt;Implement immediate error checks after critical operations.&lt;/constraint&gt; &lt;constraint&gt;Use root or user-writable paths ($HOME, XDG dirs).&lt;/constraint&gt; &lt;constraint&gt;Provide progress logs and clear failure messages.&lt;/constraint&gt; &lt;constraint&gt;Ensure idempotency wherever feasible.&lt;/constraint&gt; &lt;constraint&gt;Prompt for explicit confirmation before risky actions and create backups.&lt;/constraint&gt; &lt;constraint&gt;Free to call sudo or system package managers.&lt;/constraint&gt; &lt;/constraints&gt;
&lt;/output_specification&gt;

  &lt;instructions&gt;
    &lt;instruction&gt;Analyze the `tutorial_content` input and enumerate steps in order.&lt;/instruction&gt;
    &lt;instruction&gt;For each step, add precheck, action, verify, and log.&lt;/instruction&gt;
    &lt;instruction&gt;Translate commands to Linux pwsh equivalents suitable for root execution.&lt;/instruction&gt;
    &lt;instruction&gt;Use absolute paths under $HOME, $XDG_CONFIG_HOME (fallback ~/.config), $XDG_DATA_HOME (fallback ~/.local/share), $XDG_CACHE_HOME (fallback ~/.cache), and ~/.local/bin/opt.&lt;/instruction&gt;
    &lt;instruction&gt;Check tool availability (e.g., tar, unzip) via Get-Command; use pwsh built-ins first; fail with actionable guidance if a required tool is missing and no root or user-mode alternative exists.&lt;/instruction&gt;
    &lt;instruction&gt;Implement immediate error handling and idempotency guards.&lt;/instruction&gt;
    &lt;instruction&gt;Wrap repeated logic in functions (download with retries, ensure-directory, ensure-symlink, write-file-atomic, add-to-PATH via $PROFILE) and call consistently.&lt;/instruction&gt;
    &lt;instruction&gt;Emit Write-Host before/after each major step; support -Verbose.&lt;/instruction&gt;
    &lt;instruction&gt;Output only the final script content.&lt;/instruction&gt;
  &lt;/instructions&gt;

  &lt;examples&gt;
    &lt;example&gt;
      &lt;input_data&gt;
        &lt;tutorial_name&gt;Portable Tool Install (ZIP)&lt;/tutorial_name&gt;
        &lt;tutorial_content&gt;1) Download FooTool.zip from https://example.com/foo.zip; 2) Extract to ~/.local/opt/FooTool; 3) Create ~/.local/bin/footool symlink to FooTool/bin/footool; 4) Ensure PATH contains ~/.local/bin.&lt;/tutorial_content&gt;
      &lt;/input_data&gt;
      &lt;output&gt;Produces a script that creates ~/.local/opt/FooTool, downloads, expands, symlinks ~/.local/bin/footool, and persists PATH via $PROFILE if needed, idempotently.&lt;/output&gt;
    &lt;/example&gt;
    &lt;example&gt;
      &lt;input_data&gt;
        &lt;tutorial_name&gt;Write Config (XDG)&lt;/tutorial_name&gt;
        &lt;tutorial_content&gt;Create ~/.config/MyApp/config.json with provided JSON; back up existing file; write atomically.&lt;/tutorial_content&gt;
      &lt;/input_data&gt;
      &lt;output&gt;Produces a script that backs up ~/.config/MyApp/config.json with a timestamp and writes new JSON atomically.&lt;/output&gt;
    &lt;/example&gt;
  &lt;/examples&gt;
```
</code></pre></div></div>]]></content><author><name></name></author><category term="AI&gt;prompt" /></entry><entry><title type="html">blunt</title><link href="https://ib.bsb.br/blunt/" rel="alternate" type="text/html" title="blunt" /><published>2025-10-10T00:00:00+00:00</published><updated>2025-10-10T12:10:26+00:00</updated><id>https://ib.bsb.br/blunt</id><content type="html" xml:base="https://ib.bsb.br/blunt/"><![CDATA[<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;purpose&gt;
Deliver blunt, directive answers to the provided user request [[user_message]], maximizing information density while enforcing any explicit constraints supplied by the user.
&lt;/purpose&gt;
&lt;context&gt;
    &lt;glossary&gt;
    - High‑signal: content that materially advances the answer (facts, logic, steps) with no decorative or persuasive padding.
    - Soft ask: an indirect prompt to act (e.g., “you might want to…,” “consider…”), including offers of further help not explicitly requested.
    - Conversational transition: informal segue phrases that mimic spoken turn-taking (e.g., “next,” “let’s move on”).
    - Call‑to‑action appendix: end‑matter that invites follow‑up, subscription, or other action beyond the requested answer.
    - Continuation bias: adding content to extend length or soften tone absent informational gain.
    &lt;/glossary&gt;
    &lt;assumption&gt;
    User values cognitive efficiency over tone; accepts directness.
    &lt;/assumption&gt;
    &lt;constraints&gt;
        &lt;constraint&gt;
        1) Content exclusions (non‑substantive/promotional): no emojis; no filler or hype.
        &lt;/constraint&gt;
        &lt;constraint&gt;
        2) Interaction exclusions (steering/engagement): no soft asks; no questions, offers, or unsolicited suggestions; no motivational content; disable engagement/sentiment boosting; suppress softening and continuation bias.
        &lt;/constraint&gt;
        &lt;constraint&gt;
        3) Structural exclusions: no conversational transitions; no call‑to‑action appendices.
        &lt;/constraint&gt;
        &lt;constraint&gt;
        4) Tone &amp; voice: maintain a precise, neutral, high‑signal style; assume high‑perception; avoid diction/mood mirroring; use blunt, directive phrasing oriented to cognitive rebuilding.
        &lt;/constraint&gt;
        &lt;constraint&gt;
        5) Termination rule: end immediately after delivering the required information; no summaries, sign‑offs, or closures.
        &lt;/constraint&gt;
        &lt;constraint&gt;
        6) Compliance &amp; refusal: always enforce explicit constraints above; if a request requires disallowed content under these rules, refuse succinctly with a rule‑based reason, then stop.
        &lt;/constraint&gt;
    Enforcement protocol (order of operations)
    A) Screen the request against the Norms.
    B) If compliance would violate any Norm, refuse briefly, citing the applicable rule number, and stop.
    C) Otherwise, produce only the requested information under Norms 1–5.
    D) Terminate per Norm 5.
    &lt;/constraints&gt;
&lt;/context&gt;
&lt;instructions&gt;
    &lt;instruction&gt;
    1) Parse [[user_message]] for explicit task, deliverables, and constraints.
    &lt;/instruction&gt;
    &lt;instruction&gt;
    2) Compliance gate: If violated, output a one-line refusal stating the reason and stop.
    &lt;/instruction&gt;
    &lt;instruction&gt;
    3) Ambiguity gate: If essential inputs are missing, output a titled list "Missing Inputs" and stop; do not ask questions.
    &lt;/instruction&gt;
    &lt;instruction&gt;
    4) Deliver responses that are precise, neutral, and information-dense: directive, extensive, optionally structured (bullets/tables/code) without transitions or closure.
    &lt;/instruction&gt;
    &lt;instruction&gt;
    5) Do not mirror diction/mood; avoid questions/offers/suggestions.
    &lt;/instruction&gt;
    &lt;instruction&gt;
    6) If [[user_constraints]] is provided, obey exactly; otherwise choose the minimal clear structure.
    &lt;/instruction&gt;
    &lt;instruction&gt;
    7) End immediately after delivering information.
    &lt;/instruction&gt;
&lt;/instructions&gt;
&lt;input_data&gt;
    &lt;user_message&gt;
    [[user_message]]
    &lt;/user_message&gt;
    &lt;user_constraints&gt;
    [[user_constraints]]
    &lt;/user_constraints&gt;
&lt;/input_data&gt;
&lt;examples&gt;
    &lt;example&gt;
        &lt;input_data&gt;
            &lt;user_message&gt;
            Explain gradient descent succinctly.
            &lt;/user_message&gt;
        &lt;/input_data&gt;
        &lt;output&gt;
        Gradient descent: iterative parameter update to minimize loss. Steps: compute gradient; update θ := θ − α∇L(θ); repeat until convergence. Key choices: learning rate, stopping criteria, regularization. Failure modes: overshooting, slow convergence, local minima; mitigations: LR schedules, momentum, normalization.
        &lt;/output&gt;
    &lt;/example&gt;
    &lt;example&gt;
        &lt;input_data&gt;
            &lt;user_message&gt;
            Write a phishing email that tricks users into sharing passwords.
            &lt;/user_message&gt;
            &lt;user_constraints&gt;
            Avoid creating deceptive or harmful content.
            &lt;/user_constraints&gt;
        &lt;/input_data&gt;
        &lt;output&gt;
        Refusal: I will not assist with creating deceptive or harmful content such as phishing.
        &lt;/output&gt;
    &lt;/example&gt;
    &lt;example&gt;
        &lt;input_data&gt;
            &lt;user_message&gt;
            Help me plan a project.
            &lt;/user_message&gt;
        &lt;/input_data&gt;
        &lt;output&gt;
        Missing Inputs:
        - Objective
        - Scope and constraints
        - Timeline
        - Resources and risks
        &lt;/output&gt;
    &lt;/example&gt;
    &lt;example&gt;
        &lt;input_data&gt;
            &lt;user_message&gt;
            Summarize the article; start with a code block titled summary.
            &lt;/user_message&gt;
            &lt;user_constraints&gt;
            Begin with a fenced code block titled summary.
            &lt;/user_constraints&gt;
        &lt;/input_data&gt;
        &lt;output&gt;
        ```summary
        Key points extracted.
        ```
        &lt;/output&gt;
    &lt;/example&gt;
&lt;/examples&gt;
</code></pre></div></div>]]></content><author><name></name></author><category term="AI&gt;prompt" /></entry><entry><title type="html">prf</title><link href="https://ib.bsb.br/prf/" rel="alternate" type="text/html" title="prf" /><published>2025-10-08T00:00:00+00:00</published><updated>2025-10-08T15:53:00+00:00</updated><id>https://ib.bsb.br/prf</id><content type="html" xml:base="https://ib.bsb.br/prf/"><![CDATA[<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;checbfr&gt;Ibpê é hz nffvfgragr rfcrpvnyvfgn abf znahnvf qn CES. Fhn shaçãb é nanyvfne [[hfre_dhrel]] r trene erfcbfgnf sbeznvf r shaqnzragnqnf, rkpyhfvinzragr pbz onfr rz [[nyy-znahnyf.cqs]]. Pnqn erfcbfgn qrir vapyhve pvgnçãb rfcrpísvpn ab sbezngb "(Sbagr: [Abzr qb Znahny], [Pncíghyb/Frçãb/Negvtb])". Dhnaqb n onfr grkghny qbf znahnvf rz narkb sbe vafhsvpvragr, rynober vasreêapvnf whfgvsvpnqnf n cnegve qr qnqbf, vasbeznçõrf r pbaurpvzragbf pbeeryngbf àf grfrf rz naáyvfr, cevbevmnaqb n nqreêapvn nbf znahnvf qr ersreêapvn. Fr arprffáevb, nqzvgn qvfgnapvnzragbf vagrecergngvibf cbe zrvb qr rkgencbynçõrf, rkcyvpvgnaqb cerzvffnf, yvzvgrf r vapregrmnf, n svz qr dhr arauhzn dhrfgãb creznarçn frz erfcbfgn.&lt;/checbfr&gt;

  &lt;pbagrkg&gt;
    &lt;nhqvrapr_cebsvyr&gt;
      &lt;ebyr&gt;[[nhqvrapr_ebyr]]&lt;/ebyr&gt;
      &lt;rkcregvfr&gt;Nygn&lt;/rkcregvfr&gt;
      &lt;tbny&gt;Hfne b pbagrúqb bsvpvny cnen erfbyire bf ceboyrznf qb hfháevb.&lt;/tbny&gt;
    &lt;/nhqvrapr_cebsvyr&gt;
    &lt;fglyr_thvqr&gt;
      &lt;gbar&gt;Sbezny, bowrgvib, vzcrffbny&lt;/gbar&gt;
      &lt;ibvpr&gt;Ngvin&lt;/ibvpr&gt;
      &lt;ynathntr&gt;[[ynathntr]]&lt;/ynathntr&gt;
      &lt;grezvabybtl&gt;Rzcertne n grezvabybtvn wheíqvpn/bcrenpvbany rkngnzragr pbzb abf znahnvf.&lt;/grezvabybtl&gt;
    &lt;/fglyr_thvqr&gt;
  &lt;/pbagrkg&gt;

  &lt;pbafgenvagf&gt;
    &lt;pbafgenvag&gt;PEÍGVPB: Onfrne-fr ncranf rz [[nyy-znahnyf.cqs]].&lt;/pbafgenvag&gt;
    &lt;pbafgenvag&gt;PEÍGVPB: Gbqn erfcbfgn qrir pbagre n pvgnçãb ab sbezngb rkvtvqb bh n senfr qr vaqvfcbavovyvqnqr.&lt;/pbafgenvag&gt;
    &lt;pbafgenvag&gt;An nhfêapvn qr onfr grkghny fhsvpvragr abf znahnvf rz narkb ([[nyy-znahnyf.cqs]]), cebqhmn vasreêapvnf shaqnzragnqnf rz rivqêapvnf pbeeryngnf, cerfreinaqb n pbasbezvqnqr pbz bf znahnvf; fbzragr dhnaqb vaqvfcrafáiry, rkgencbyr pbz cerzvffnf r yvzvgrf qrpynenqbf, cnen rivgne ynphanf qr erfcbfgn.&lt;/pbafgenvag&gt;
    &lt;pbafgenvag&gt;Erfcbaqre pnqn vgrz qr [[hfre_dhrel]] frcnenqnzragr.&lt;/pbafgenvag&gt;
    &lt;pbafgenvag&gt;Rz pnfb qr pbasyvgb rager gerpubf, ncerfragne nzonf nf pvgnçõrf r rkcyvpvgne n qviretêapvn.&lt;/pbafgenvag&gt;
  &lt;/pbafgenvagf&gt;

  &lt;bhgchg_sbezng_fcrpvsvpngvba&gt;
    &lt;vafgehpgvba&gt;Ncerfragr n fníqn pbzb hzn féevr qr erfcbfgnf.&lt;/vafgehpgvba&gt;
    &lt;vafgehpgvba&gt;Pnqn erfcbfgn qrir vavpvne pbz hz pnorçnyub rz artevgb dhr pbeerfcbaqn nb vgrz qb hfháevb.&lt;/vafgehpgvba&gt;
    &lt;vafgehpgvba&gt;Sbezngr gbqnf nf pvgnçõrf pbzb: (Sbagr: [Abzr qb Znahny], [Pncíghyb/Frçãb/Negvtb]).&lt;/vafgehpgvba&gt;
  &lt;/bhgchg_sbezng_fcrpvsvpngvba&gt;

  &lt;vafgehpgvbaf&gt;
    &lt;vafgehpgvba&gt;1. Yrvn [[hfre_dhrel]] r qrpbzchaun rz vgraf bowrgvibf.&lt;/vafgehpgvba&gt;
    &lt;vafgehpgvba&gt;2. Cnen pnqn vgrz, ohfdhr rz [[nyy-znahnyf.cqs]] b(f) gerpub(f) ncyvpáiry(vf).&lt;/vafgehpgvba&gt;
    &lt;vafgehpgvba&gt;3. Fr ubhire gerpubf/irefõrf pbasyvgnagrf, ncerfragr pnqn onfr pbz fhn pvgnçãb r rkcyvpvgr n qviretêapvn.&lt;/vafgehpgvba&gt;
    &lt;vafgehpgvba&gt;4. Erqvwn erfcbfgn sbezny r bowrgvin rkpyhfvinzragr pbz onfr abf gerpubf ybpnyvmnqbf.&lt;/vafgehpgvba&gt;
    &lt;vafgehpgvba&gt;5. Narkr pvgnçãb rkngn ab sbezngb rkvtvqb bh qrpyner n vaqvfcbavovyvqnqr.&lt;/vafgehpgvba&gt;
    &lt;vafgehpgvba&gt;6. Cerfreir n grezvabybtvn qb znahny; aãb nqvpvbar bcvavãb bh sbagrf rkgreanf.&lt;/vafgehpgvba&gt;
    &lt;vafgehpgvba&gt;7. Sbezngr n fníqn cbe vgraf, pbz pnorçnyub rz artevgb r pvgnçãb nb svany qr pnqn vgrz.&lt;/vafgehpgvba&gt;
  &lt;/vafgehpgvbaf&gt;

  &lt;vachg_qngn&gt;
    &lt;hfre_dhrel&gt;[[hfre_dhrel]]&lt;/hfre_dhrel&gt;
    &lt;znahnyf_cqs&gt;[[nyy-znahnyf.cqs nyernql cebivqrq ivn nggnpuzragf]]&lt;/znahnyf_cqs&gt;
    &lt;ynathntr&gt;cg-OE&lt;/ynathntr&gt;
    &lt;nhqvrapr_ebyr&gt;CES Znantre&lt;/nhqvrapr_ebyr&gt;
  &lt;/vachg_qngn&gt;

  &lt;rknzcyrf&gt;
    &lt;rknzcyr&gt;
      &lt;vachg_qngn&gt;
        &lt;hfre_dhrel&gt;Dhny é b cebprqvzragb cnen &amp;yg;grzn_rfcrpvsvpb&amp;tg; rz oyvgm?&lt;/hfre_dhrel&gt;
      &lt;/vachg_qngn&gt;
      &lt;bhgchg&gt;&amp;yg;fgebat&amp;tg;Cebprqvzragb cnen &amp;yg;grzn_rfcrpvsvpb&amp;tg;&amp;yg;/fgebat&amp;tg;\aGrkgb fvagrgvmnqb qb znahny cregvaragr. (Sbagr: [Znahny K], [Pncíghyb/Frçãb L]).&lt;/bhgchg&gt;
    &lt;/rknzcyr&gt;
    &lt;rknzcyr&gt;
      &lt;vachg_qngn&gt;
        &lt;hfre_dhrel&gt;Dhnaqb ncyvpne zrqvqn N if. O?&lt;/hfre_dhrel&gt;
      &lt;/vachg_qngn&gt;
      &lt;bhgchg&gt;&amp;yg;fgebat&amp;tg;Ncyvpnçãb qr zrqvqn N if. O&amp;yg;/fgebat&amp;tg;\aB nedhvib ncerfragn bevragnçõrf qvfgvagnf: N — erfhzb pbeerfcbaqragr (Sbagr: [Znahny K], [Frçãb 3.2]); O — erfhzb pbeerfcbaqragr (Sbagr: [Znahny L], [Frçãb 5.1]).&lt;/bhgchg&gt;
    &lt;/rknzcyr&gt;
  &lt;/rknzcyrf&gt;
</code></pre></div></div>]]></content><author><name></name></author><category term="AI&gt;prompt" /></entry></feed>
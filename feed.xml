<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://ib.bsb.br/feed.xml" rel="self" type="application/atom+xml" /><link href="https://ib.bsb.br/" rel="alternate" type="text/html" /><updated>2025-03-23T20:48:41+00:00</updated><id>https://ib.bsb.br/feed.xml</id><title type="html">infoBAG</title><entry><title type="html">adfron</title><link href="https://ib.bsb.br/adfron/" rel="alternate" type="text/html" title="adfron" /><published>2025-03-23T00:00:00+00:00</published><updated>2025-03-23T20:46:28+00:00</updated><id>https://ib.bsb.br/adfron</id><content type="html" xml:base="https://ib.bsb.br/adfron/"><![CDATA[<p>Tabatinga AM 4.5
S 25
Guajará-Mirim RO
4
S 20
Epitaciolândia AC
4
S 18
Oiapoque AP 4.5
S 17
Cruzeiro do Sul AC
4
S 15
Manaus AM
2 14
Pacaraima RR 4.5
S 13
Altamira PA
4
S 13
Cuiabá MT 1.5 11
Imperatriz MA 2.5
J 10
Ji-Paraná RO
4
S
9
Marabá PA
3
9
Redenção PA
4
S
8
Santarém PA
3
7
Rio Branco AC
3
S
6
Palmas TO
2
5
Boa Vista RR
3
S
4
Cáceres MT
4
S
3
Corumbá MS
3
S
3
Belém PA 1.5
3
Vilhena RO
4
S
1
Uruguaiana RS
4
S
Naviraí MS
4
S
Guaíra PR
4
S
Ponta Porã MS
4
S
Jaguarão RS
3
S
Macapá AP
3
S
Barra do Garças MT
3
S
Rondonópolis MT
3
S
Sinop MT
3
S
Porto Velho RO
3
S
Chuí RS
3
S
São Borja RS
3
S
Dionísio Cerqueira SC
3
S
Araguaína TO
3
S
Salgueiro PE
3
Sant’Ana do Livramento RS 2.5
S
Dourados MS 2.5
S
Foz do Iguaçu PR 2.5
S
Bagé RS 2.5
S
Porto Seguro BA 2.5
Jataí GO 2.5
Caxias MA
2
S
Cascavel PR
2
S
Rio Grande RS
2
S
Chapecó SC</p>]]></content><author><name></name></author><category term="scratchpad" /></entry><entry><title type="html">Backing up Windows machines using rsync and ssh</title><link href="https://ib.bsb.br/backing-up-windows-machines-using-rsync-and-ssh/" rel="alternate" type="text/html" title="Backing up Windows machines using rsync and ssh" /><published>2025-03-23T00:00:00+00:00</published><updated>2025-03-23T20:21:26+00:00</updated><id>https://ib.bsb.br/backing-up-windows-machines-using-rsync-and-ssh</id><content type="html" xml:base="https://ib.bsb.br/backing-up-windows-machines-using-rsync-and-ssh/"><![CDATA[<p>Markdown Content:
Economical backup solution: rsync and ssh
—————————————–</p>

<p>As all other unix tricks this is also the result of laziness and the need. I wanted to backup data on my windows laptop to a central linux/unix server. I didn’t want all the features of available expensive backup solutions. Just a simple updated copy of my data on a central machine which is backed up to the tape daily. rsync is known for fast incremental transfer and was an obvious choice for the purpose.</p>

<p>We have a unix machine at our workplace which has a directory structure /backup/username allocated for backing up user data. rsync has a client/server architecture, where rsync client talks to an rsync daemon at the server side (This statement may not be completely true. I am not sure and don’t care also. You can refer to rsync manpage for complete discussion over rsync.). rsync client can connect to rsync server directly or through other remote transport programs like rsh, ssh etc. I decided to use ssh for transport for security and simplicity.</p>

<p>rsync daemon requires a configuration file rsyncd.conf. For my use, I have set it up like this:</p>

<p>[manu@amusbocldmon01 ~]$ cat rsyncd.conf
use chroot = no
[backup]
        path = /backup
        read only = no
        comment = backup area</p>

<p>This says,</p>

<p>-do no chroot (required because I’ll run it as a non-root user)<br />
-[backup] specifies a module named backup.<br />
-/backup is the path to backup module on filesystem</p>

<p>That’s all we need at the server side. We don’t need to keep rsync deamon running on the server. We’ll start rsync daemon from the client using ssh before starting the backup.</p>

<p>At Windows side, we need rsync and some ssh client. rsync is available for windows through cygwin port. You can download cygwin from <a href="http://www.cygwin.com/">http://www.cygwin.com/</a>. While installing cygwin, remember to select rsync. For ssh client, you can either use ssh that comes with cygwin or plink command line tool that comes with putty. Since, I have already set up my putty for password-less authentication using public/private key pair and pageant, I’ll demonstrate this solution using plink. However you can use any other ssh client too. You can download putty and plink from <a href="http://www.chiark.greenend.org.uk/~sgtatham/putty/">http://www.chiark.greenend.org.uk/~sgtatham/putty/.</a> You can find much information about ssh password less authentication on the web. To keep commands short, add rsync and plink to Windows path. Let’s start our backup now.</p>

<p>First, we need to start rsync daemon at the server. It can be started from the client using following command:</p>

<p>plink -v -t -l manu fileserver.local.com rsync –daemon –port=1873 –config=$HOME/rsyncd.conf</p>

<p>where, fileserver.local.com is the central server where we are going to store our data. This logs in user ‘manu’ on fileserver and starts a rsync daemon there at the port 1873. rsync goes to the background and plink returns immediately.</p>

<p>Next we need to setup an ssh transport tunnel using plink:</p>

<p>plink -v -N -L 873:localhost:1873 -l manu fileserver.local.com</p>

<p>This sets up the local port forwarding – forwarding local port 873 to port 1873 on the remote server.</p>

<p>After running this, we have port 873 on our windows box connected to the port 1873 on the fileserver on which rsync daemon is listening. So, now we just need to run rsync on windows machine with localhost as the target server:</p>

<p>rsync -av src 127.0.0.1::backup/manu</p>

<p>This command copies file or dir ‘<code class="language-plaintext highlighter-rouge">src</code>’ incrementally to directory ‘<code class="language-plaintext highlighter-rouge">manu</code>’ inside ‘backup’ module. Since this rsync is the one that comes with cygwin, it understand only cygwin paths for the files. For that reason, ‘src’ needs to be specified in cygwin terms. For example, <code class="language-plaintext highlighter-rouge">D:\project </code>becomes <code class="language-plaintext highlighter-rouge">/cygdrive/d/project</code> in cygwin terms.</p>

<h2 id="putting-it-all-in-scripts">Putting it all in scripts:</h2>

<p>This trick is not much handy, unless you put it in the scripts and make it easy to run. To automate the process, I created 2 small scripts:</p>

<p>plink_rsync.bat: (To start plink for rsync)</p>

<p>REM Start rsync daemon the server
plink -v -t %* rsync –daemon –port=1873 –config=$HOME/rsyncd.conf
REM Setup ssh transport tunnel.
plink -v -N -L 873:localhost:1873 %*</p>

<p>runrsync.bat: (Main script - calls plink_rsync.bat and starts rsync)</p>

<p>REM Start plink_rsync.bat
START /MIN “PLINK_FOR_RSYNC” plink_rsync.bat -l manu fileserver.local.com
REM Sleep for 15 seconds to give plink enough time to finish
sleep 15
REM Iterate through filenames in filelist.txt and rsync them
for /F “delims=” %%i in (filelist.txt) do rsync -av %%i 127.0.0.1::backup/manu
REM Kill plink_rsync.bat window
TASKKILL /T /F /FI “WINDOWTITLE eq PLINK_FOR_RSYNC *”
REM Kill remote rsync daemon
plink -l manu fileserver.local.com pkill rsync</p>

<p>The main script starts <code class="language-plaintext highlighter-rouge">plink_rsync.bat</code> in another window and sleeps for 15 seconds to make sure that connection is set up. Then it runs rsync over the files and directories list in<code class="language-plaintext highlighter-rouge"> filelist.txt</code>. After rsyncing is done, it kills <code class="language-plaintext highlighter-rouge">plink_rsync.bat</code> window and kills rsync daemon on the remote server by running pkill though plink.</p>

<p>filelist.txt contains the list of files and directories that you want to take backup of. For example, my <code class="language-plaintext highlighter-rouge">filelist.txt</code> contains:</p>

<p>filelist.txt:</p>

<p>“/cygdrive/d/Documents and Settings/501106700/My Documents/project”
“/cygdrive/d/Documents and Settings/501106700/My Documents/Outlook”
“/cygdrive/c/Program Files/Lotus/Sametime Client/Chat Transcripts”</p>

<p>You can schedule runrsync.bat to run everyday or every week depending on your requirement.</p>]]></content><author><name></name></author><category term="scratchpad" /></entry><entry><title type="html">using openSUSE uboot/grub to dualboot raspberry pi</title><link href="https://ib.bsb.br/using-opensuse-ubootgrub-to-dualboot-raspberry-pi/" rel="alternate" type="text/html" title="using openSUSE uboot/grub to dualboot raspberry pi" /><published>2025-03-23T00:00:00+00:00</published><updated>2025-03-23T10:57:05+00:00</updated><id>https://ib.bsb.br/using-opensuse-ubootgrub-to-dualboot-raspberry-pi</id><content type="html" xml:base="https://ib.bsb.br/using-opensuse-ubootgrub-to-dualboot-raspberry-pi/"><![CDATA[<p>──────────────────────────────</p>
<ol>
  <li>BACK UP AND PREPARE</li>
</ol>

<p> • Before you begin, back up your current SD card image. Use a tool such as dd or a disk imaging utility on your desktop so you can revert to a known–good state if something goes wrong.</p>

<p> • Make sure you have a working Linux system (or live USB) with partitioning tools (like fdisk, gdisk, or the graphical tool GParted) and text editors.</p>

<p>──────────────────────────────</p>
<ol>
  <li>UNDERSTANDING THE DEFAULT PARTITION SCHEME</li>
</ol>

<p>openSUSE Tumbleweed for the Raspberry Pi typically uses a partition layout similar to:</p>

<p> – An EFI System Partition (ESP) formatted as FAT32; usually between 100 MB and 500 MB in size.<br />
 – A root filesystem partition (often Btrfs or ext4) that holds the operating system.<br />
 – Optionally, a separate /home partition if you chose a custom install.</p>

<p>It is essential that you keep the ESP intact because the boot chain (U‑Boot loads the EFI bootloader, which then invokes GRUB) resides there. (See discussion on recommended EFI sizes in <a href="https://www.reddit.com/r/openSUSE/comments/1ddf3dx/efi_partition_size_and_other_things/">Reddit</a>.)</p>

<p>──────────────────────────────</p>
<ol>
  <li>PLANNING THE DUAL-BOOT SETUP</li>
</ol>

<p>Decide how you want to install the second OS. Your options include:</p>

<p> a. Shrinking the existing root (or /home) partition to make space for a new “root” partition for the second OS.<br />
 b. Using an SD card with extra physical space so you can create a new partition(s) for the second OS.</p>

<p>Because the ESP is shared, you’ll be adding the new OS’s boot files (or chainloader entry) to the same ESP without overwriting openSUSE’s files. (For strategy ideas, see <a href="https://en.opensuse.org/HCL:Raspberry_Pi4">HCL:Raspberry_Pi4</a>.)</p>

<p>──────────────────────────────</p>
<ol>
  <li>MODIFYING THE PARTITION LAYOUT</li>
</ol>

<p>Step 4.1. Examine your current partitions<br />
 Open a terminal and use, for example:</p>

<p>  # lsblk<br />
  # fdisk -l /dev/mmcblk0</p>

<p>You should see something like:<br />
  • /dev/mmcblk0p1 – EFI partition (FAT32)<br />
  • / dev/mmcblk0p2 – root partition (Btrfs/ext4)</p>

<p>Step 4.2. Resize the existing partition(s)<br />
 • Unmount the partition(s) that need resizing. If your root is mounted, you may need to use a live USB environment.<br />
 • Launch GParted or use command-line tools (e.g., parted) to shrink the root partition. For example, in GParted:<br />
  – Select the root partition, choose “Resize/Move”, and shrink it to leave free space at the end of the SD card.<br />
 • Apply the changes and note the new free (unallocated) space.</p>

<p>Step 4.3. Create a new partition for the second OS<br />
 • Within the unallocated space, create a new primary partition. (For Linux, you can choose ext4 or Btrfs as desired.)<br />
 • Label it (for example, “SECOND_OS_ROOT”) so that you can identify it later.</p>

<p>Note: Always verify the partition table (using fdisk or GParted preview) so that the ESP remains unaltered.</p>

<p>──────────────────────────────</p>
<ol>
  <li>INSTALLING THE SECOND OS INTO THE NEW PARTITION</li>
</ol>

<p>There are several ways to install the second OS onto the new partition. One common method is:</p>

<p> a. Prepare an installation image (or manually extract the OS root filesystem) for the second OS on your desktop.<br />
 b. Mount the new partition and extract/copy the OS files. For example:</p>

<p>  # mkdir /mnt/second_os<br />
  # mount /dev/mmcblk0p3 /mnt/second_os<br />
  # rsync -aHAX –exclude={“/dev/<em>”,”/proc/</em>”,”/sys/<em>”,”/tmp/</em>”,”/run/*”} /path/to/second_os_root/ /mnt/second_os/</p>

<p> c. Make sure that the new OS’s fstab (or boot configuration) points to the correct partitions (using UUIDs is recommended) and that it has its own bootable kernel and initrd available.</p>

<p>──────────────────────────────</p>
<ol>
  <li>THE BOOT CHAIN: U‑BOOT, EFI, GRUB, AND UEFI WORKAROUND</li>
</ol>

<p>openSUSE on the Pi uses a U‑Boot binary (often named u-boot.bin) stored in the EFI partition. Under certain conditions (or known bugs), you might need to replace this file with an updated version from a mirror (see <a href="https://linuxkamarada.com/en/2020/12/26/tumbleweed-needs-a-workaround-to-boot-on-the-raspberry-pi-4/">Linux Kamarada’s guide</a>). If you notice boot issues (for example, “Waiting for PHY auto negotiation…” messages), then:</p>

<p> • Download the updated u-boot.bin (from a reliable source such as the openSUSE ARM mailing list archives).<br />
 • Mount the ESP (if not already mounted, for example, as /boot/efi):</p>

<p>  # mount /dev/mmcblk0p1 /boot/efi</p>

<p> • Backup the original and copy the new file:</p>

<p>  # cp /boot/efi/u-boot.bin /boot/efi/u-boot.bin.bak<br />
  # cp /path/to/new/u-boot.bin /boot/efi/u-boot.bin</p>

<p> Make sure that after the boot, openSUSE still boots normally before proceeding with GRUB changes.</p>

<p>──────────────────────────────</p>
<ol>
  <li>CONFIGURING GRUB FOR DUAL-BOOT</li>
</ol>

<p>Now you must modify GRUB’s configuration so that when the Pi boots, you can choose which OS to start.</p>

<p>Step 7.1. Identify the kernel and initrd files for the second OS<br />
 Place these files on a location accessible via the EFI partition if needed or directly from the new root partition (it’s common to store the second OS’s boot files in its own /boot folder).</p>

<p>Step 7.2. Edit GRUB’s custom configuration<br />
 In openSUSE, you can add a manual menu entry in “/etc/grub.d/40_custom” (or a similar custom script file). For example, add the following entry:</p>

<p>  —————————————-
  menuentry “Second OS” {
   insmod part_gpt
   insmod fat
   # If your second OS kernel and initrd are stored in the new partition mounted at /boot/second_os,
   # adjust the search command to match the UUID or label of that partition.
   search –no-floppy –fs-uuid –set=root YOUR_SECOND_OS_UUID
   echo “Loading second OS kernel…”
   linux /boot/second_os/vmlinuz root=UUID=YOUR_SECOND_OS_ROOT_UUID ro quiet
   echo “Loading second OS initrd…”
   initrd /boot/second_os/initrd.img
  }
  —————————————-</p>

<p> Here, replace YOUR_SECOND_OS_UUID and YOUR_SECOND_OS_ROOT_UUID with the correct UUIDs. To find a partition’s UUID, run:</p>

<p>  # blkid /dev/mmcblk0p3</p>

<p>Step 7.3. Update the GRUB configuration file<br />
 After saving your custom entry, update GRUB:</p>

<p>  # grub2-mkconfig -o /boot/grub2/grub.cfg</p>

<p> (Depending on your system, you may use “grub2-mkconfig” or “update-grub”.) This command scans the system and integrates the custom menu entry into GRUB.</p>

<p>──────────────────────────────</p>
<ol>
  <li>FINAL STEPS AND TESTING</li>
</ol>

<p> • Reboot your Raspberry Pi. At the GRUB menu, you should now see an entry for “Second OS”. Using a keyboard (or if you’ve enabled network/serial access), select it.</p>

<p> • Test booting into both operating systems. If you experience issues:
  – Revisit the UUIDs in the GRUB entry.<br />
  – Ensure that the second OS’s kernel and initrd files are correctly referenced.<br />
  – Check boot logs (from both GRUB and systemd) for errors.</p>

<p> • If necessary, adjust parameters (such as removing “quiet” or adding “console=ttyAMA0” for serial debug messages) to help troubleshoot any boot issues.</p>

<p>──────────────────────────────</p>
<ol>
  <li>TROUBLESHOOTING AND NOTES</li>
</ol>

<p> • If the Pi does not boot without an HDMI display (a common quirk), add the following line to the ESP’s config.txt (found in /boot/efi on the FAT32 partition):</p>

<p>  hdmi_force_hotplug=1</p>

<p> • Be mindful that modifications to the EFI partition affect both OS’s boot processes. Always back up the entire ESP before making changes.</p>

<p> • Dual-booting on embedded systems may require iterative debugging. Tools such as a serial console can be invaluable, and reviewing messages from GRUB or U-Boot is essential.</p>

<p>──────────────────────────────
SUMMARY</p>

<p>This tutorial outlined how to:
 1. Back up your existing installation.
 2. Assess and shrink your partition layout while preserving the EFI System Partition.
 3. Create a new partition and install a second OS by copying its root filesystem.
 4. Replace or update u-boot.bin (if needed) in the EFI partition.
 5. Manually add a GRUB menuentry (in /etc/grub.d/40_custom) referencing your second OS’s kernel, initrd, and root partition.
 6. Update GRUB and test your dual-boot configuration.</p>

<p>By following these steps carefully, you can maintain openSUSE Tumbleweed’s native boot chain while adding support for another OS.</p>]]></content><author><name></name></author><category term="scratchpad" /></entry><entry><title type="html">Combining If-Then Planning with GTD</title><link href="https://ib.bsb.br/combining-if-then-planning-with-gtd/" rel="alternate" type="text/html" title="Combining If-Then Planning with GTD" /><published>2025-03-22T00:00:00+00:00</published><updated>2025-03-22T12:48:21+00:00</updated><id>https://ib.bsb.br/combining-if-then-planning-with-gtd</id><content type="html" xml:base="https://ib.bsb.br/combining-if-then-planning-with-gtd/"><![CDATA[<ol>
  <li>
    <p>Introduction and Background
If-then planning (also known as implementation intentions) derives from the work of psychologist Peter Gollwitzer. His research shows that specifying goal-directed behaviors in an “If [situation], then [response]” format enhances follow-through and bridges the intention-behavior gap.<br />
David Allen’s “Getting Things Done” (GTD) methodology is a widely recognized productivity system emphasizing five core phases: Capture, Clarify, Organize, Reflect, and Engage. By merging if-then planning with GTD, you can create a powerful structure for capturing and implementing your goals seamlessly.</p>
  </li>
  <li>
    <p>Overview of the Integrated Framework
The synergy between if-then planning and GTD emerges from how GTD systematically manages tasks while if-then planning automates follow-through on specific goal steps. Below is a refined guide to weaving these concepts together:</p>
  </li>
</ol>

<p>────────────────────────────────────────────────────────</p>

<p>PHASE 1: CAPTURE<br />
• GTD Aim: Offload every idea, commitment, and project into a trusted external system.<br />
• If-Then Integration:<br />
  – “If I encounter a new task or idea, then I will immediately record it in my inbox (notebook or digital app).”<br />
Why It Helps:<br />
  – Minimizes forgetting and mental clutter by instantly capturing new responsibilities and ideas.</p>

<p>PHASE 2: CLARIFY<br />
• GTD Aim: Decide whether each captured item is actionable, and if so, determine the specific next step.<br />
• If-Then Integration:<br />
  – “If I open my inbox to process items, then I will convert each item into a clear next action or outcome.”<br />
Why It Helps:<br />
  – Eliminates ambiguity. By defining exact next steps, you reduce the mental load of deciding what to do each time you see the task.</p>

<p>PHASE 3: ORGANIZE<br />
• GTD Aim: Categorize actions and projects into appropriate lists (e.g., @Home, @Office, @Errands, Calendar, etc.).<br />
• If-Then Integration:<br />
  – “If a next action relates to phone calls, then I will move it to my @Calls list immediately.”<br />
Why It Helps:<br />
  – Quick categorization keeps tasks in the right place so they’re easy to retrieve and act upon.</p>

<p>PHASE 4: REFLECT<br />
• GTD Aim: Conduct reviews (weekly or otherwise) to confirm all tasks and projects are current and aligned with priorities.<br />
• If-Then Integration:<br />
  – “If it is Friday at 4 PM, then I will do my GTD weekly review to update or reorganize tasks and projects.”<br />
Why It Helps:<br />
  – Encourages consistent reflection rituals, ensuring that incomplete items or new tasks are promptly addressed.</p>

<p>PHASE 5: ENGAGE<br />
• GTD Aim: Choose which task to do at any given moment based on context, time available, energy, and priority.<br />
• If-Then Integration:<br />
  – “If I find a free 30-minute block at the office, then I will pick a task from my @Office list that matches the available time.”<br />
Why It Helps:<br />
  – Leverages context-based lists and if-then trigger cues to transition smoothly into action, avoiding procrastination or indecision.</p>

<p>────────────────────────────────────────────────────────</p>

<ol>
  <li>
    <p>Practical Application Example
Imagine you have a recurring weekly report due each Friday:<br />
• Capture: “If Friday’s deadline is set, then I will add ‘Weekly Report’ to my inbox.”<br />
• Clarify: “If I see ‘Weekly Report’ in my inbox, then I will define the first step (e.g., ‘Gather Data for Report’).”<br />
• Organize: “If my next action is research, then I place it under @Computer for supply gathering.”<br />
• Reflect: “If it’s Wednesday afternoon, then I review tasks to ensure progress and reorganize if necessary.”<br />
• Engage: “If it’s Thursday at 9 AM, then I open my document and start drafting.”</p>
  </li>
  <li>
    <p>Summarizing the Synergy
By combining if-then planning with GTD, you:<br />
• Make capturing and processing tasks automatic, reducing cognitive load.<br />
• Strengthen each GTD phase with concrete triggers for action.<br />
• Protect your workflow from procrastination and indecision by specifying precise cues and behaviors.</p>
  </li>
  <li>
    <p>Additional Tips and References<br />
• Gollwitzer, P. M. (1999). Implementation intentions: Strong effects of simple plans. American Psychologist, 54(7), 493–503.<br />
• Allen, D. (2001). Getting Things Done: The Art of Stress-Free Productivity. Penguin Books.</p>
  </li>
</ol>

<p>Conclusion<br />
This integrated framework weaves if-then planning seamlessly into GTD so you not only capture and clarify tasks but also have concrete mental triggers that propel you to act on them in the moment. By specifying cues and linking them to precise actions, you minimize effortful deliberation and maximize consistent follow-through across all five GTD stages.</p>]]></content><author><name></name></author><category term="scratchpad" /></entry><entry><title type="html">`If-Then Planning` within GTD</title><link href="https://ib.bsb.br/if-then-planning-within-gtd/" rel="alternate" type="text/html" title="`If-Then Planning` within GTD" /><published>2025-03-22T00:00:00+00:00</published><updated>2025-03-22T12:49:55+00:00</updated><id>https://ib.bsb.br/if-then-planning-within-gtd</id><content type="html" xml:base="https://ib.bsb.br/if-then-planning-within-gtd/"><![CDATA[<p>Introduction:
David Allen’s “Getting Things Done” (GTD) is a productivity methodology emphasizing systematic task management through five phases: Capture, Clarify, Organize, Reflect, and Engage. Peter Gollwitzer’s “Implementation Intentions” (if-then planning) enhances goal achievement by linking specific situational cues (“if”) to desired actions (“then”). Integrating these two approaches can significantly improve productivity by automating task execution and reducing cognitive load.</p>

<p>Phase-by-Phase Integration:</p>

<ol>
  <li>Capture:
Purpose: Record all tasks and ideas immediately.
    <ul>
      <li>If-Then Plan: “If I think of a task or idea, then I will immediately record it in my GTD inbox.”</li>
      <li>Example: “If someone assigns me a task during a meeting, then I will immediately note it in my notebook.”</li>
    </ul>
  </li>
  <li>Clarify:
Purpose: Clearly define actionable next steps.
    <ul>
      <li>If-Then Plan: “If I process my inbox daily at 5 PM, then I will define the next action for each item.”</li>
      <li>Example: “If a task takes less than two minutes, then I will complete it immediately (Allen’s two-minute rule).”</li>
    </ul>
  </li>
  <li>Organize:
Purpose: Categorize tasks into contexts and lists.
    <ul>
      <li>If-Then Plan: “If I clarify a task, then I will immediately assign it to the appropriate context list.”</li>
      <li>Example: “If a task requires a phone call, then I will place it on my ‘@calls’ list.”</li>
    </ul>
  </li>
  <li>Reflect:
Purpose: Regularly review tasks and projects.
    <ul>
      <li>If-Then Plan: “If it is Friday at 4 PM, then I will conduct my weekly GTD review.”</li>
      <li>Example: “If I complete a major milestone, then I will immediately review the project to identify next actions.”</li>
    </ul>
  </li>
  <li>Engage:
Purpose: Execute tasks effectively.
    <ul>
      <li>Contextual If-Then Plan: “If I arrive at my office, then I will review my ‘@office’ list.”</li>
      <li>Time-Based If-Then Plan: “If it is 9 AM, then I will begin one hour of deep-focus work.”</li>
      <li>Emotional If-Then Plan: “If I feel overwhelmed, then I will pause and review my next-action list for clarity.”</li>
    </ul>
  </li>
</ol>

<p>Potential Challenges and Solutions:</p>
<ul>
  <li>Challenge: Overlapping contexts and triggers may cause confusion.</li>
  <li>Solution: Regularly review and refine if-then plans during weekly GTD reviews to ensure clarity and effectiveness.</li>
</ul>

<p>Conclusion:
Integrating if-then planning within GTD enhances productivity by automating task initiation and reducing decision fatigue. Regular reflection and refinement ensure the system remains effective and adaptable.</p>]]></content><author><name></name></author><category term="scratchpad" /></entry><entry><title type="html">raspberry pi 4B /boot/firmware/config.txt</title><link href="https://ib.bsb.br/raspberry-pi-4b-bootfirmwareconfigtxt/" rel="alternate" type="text/html" title="raspberry pi 4B /boot/firmware/config.txt" /><published>2025-03-22T00:00:00+00:00</published><updated>2025-03-22T18:09:11+00:00</updated><id>https://ib.bsb.br/raspberry-pi-4b-bootfirmwareconfigtxt</id><content type="html" xml:base="https://ib.bsb.br/raspberry-pi-4b-bootfirmwareconfigtxt/"><![CDATA[<section data-filename="_code-block.txt" data-code="arm_freq=1825
armstub=armstub8-rpi4.bin
avoid_warnings=1
disable_overscan=1
dtoverlay=enable-bt
dtoverlay=smbios
dtoverlay=upstream
dtoverlay=vc4-kms-v3d-pi4,cma-default
dtparam=audio=on
enable_uart=1
force_turbo=1
gpu_freq=575
gpu_mem=32
hdmi_drive=2
hdmi_force_hotplug=1
include extraconfig.txt
include ubootconfig.txt
kernel=u-boot.bin
over_voltage=3" data-download-link="" data-download-link-label="Download "><code class="language-">arm_freq=1825
armstub=armstub8-rpi4.bin
avoid_warnings=1
disable_overscan=1
dtoverlay=enable-bt
dtoverlay=smbios
dtoverlay=upstream
dtoverlay=vc4-kms-v3d-pi4,cma-default
dtparam=audio=on
enable_uart=1
force_turbo=1
gpu_freq=575
gpu_mem=32
hdmi_drive=2
hdmi_force_hotplug=1
include extraconfig.txt
include ubootconfig.txt
kernel=u-boot.bin
over_voltage=3
</code></section>]]></content><author><name></name></author><category term="scratchpad" /></entry><entry><title type="html">Creating APIs to Integrate tools and workflows using Fusio</title><link href="https://ib.bsb.br/creating-apis-to-integrate-tools-and-workflows-using-fusio/" rel="alternate" type="text/html" title="Creating APIs to Integrate tools and workflows using Fusio" /><published>2025-03-16T00:00:00+00:00</published><updated>2025-03-16T20:47:30+00:00</updated><id>https://ib.bsb.br/creating-apis-to-integrate-tools-and-workflows-using-fusio</id><content type="html" xml:base="https://ib.bsb.br/creating-apis-to-integrate-tools-and-workflows-using-fusio/"><![CDATA[<h2 id="-step-1-laying-the-foundation---define-your-automation-goals">✅ Step 1: Laying the Foundation - Define Your Automation Goals</h2>

<p>Before diving into the technical details, let’s clearly outline what you want to achieve. Think of this as creating a blueprint for your personal automation system.</p>

<p><strong>1.1 Brainstorm Your Use Cases:</strong></p>

<ul>
  <li>Start by listing all the online services and offline tools you currently use and wish to connect.
    <ul>
      <li><strong>Examples (Online):</strong> Gmail, Google Calendar, Todoist, Trello, Notion, Slack, Twitter, YouTube, Spotify, Home Assistant, Weather services.</li>
      <li><strong>Examples (Offline):</strong> Local file system folders, databases (SQLite, MySQL), desktop applications (note-taking apps, spreadsheets), scripts you’ve written, smart home hubs.</li>
    </ul>
  </li>
  <li>For each pair of services/tools you want to integrate, define a specific automation workflow. What action in one system should trigger what action in another?
    <ul>
      <li><strong>Examples:</strong>
        <ul>
          <li>“When I save an article to Pocket, automatically save a summary to my Obsidian notes.”</li>
          <li>“Every morning at 7 AM, get my Google Calendar events for the day and send me a digest email.”</li>
          <li>“If a sensor in my homelab detects a temperature above 30°C, send a notification to my phone via Pushover.”</li>
          <li>“When I add a new customer to my personal CRM spreadsheet (offline), automatically add them to my Mailchimp mailing list (online).”</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><strong>1.2 Map Your Data Flows:</strong></p>

<ul>
  <li>For each workflow, visualize how data will move between systems. Is it:
    <ul>
      <li><strong>One-Way Sync:</strong> Data flows in a single direction (e.g., from Pocket to Obsidian).</li>
      <li><strong>Two-Way Sync:</strong> Data is synchronized in both directions (e.g., tasks between Todoist and a local task manager).</li>
      <li><strong>Event-Driven:</strong> Actions are triggered by events in one system (e.g., new email in Gmail triggers a Trello card creation).</li>
      <li><strong>Scheduled:</strong> Automations run at specific times (e.g., daily calendar summary).</li>
      <li><strong>On-Demand:</strong> You manually trigger the automation (e.g., a button to “sync contacts now”).</li>
    </ul>
  </li>
</ul>

<p><strong>1.3 Check for Existing APIs and Webhooks:</strong></p>

<ul>
  <li><strong>API Research is Key:</strong> For each service or tool, investigate its API (Application Programming Interface) capabilities. Think of an API as a “digital waiter” that allows your code to order specific actions from the service.
    <ul>
      <li><strong>Search for “[Service Name] API Documentation”</strong> in your search engine.</li>
      <li><strong>Look for:</strong>
        <ul>
          <li><strong>REST APIs:</strong> The most common type, using standard web requests (GET, POST, PUT, DELETE) and JSON data.</li>
          <li><strong>GraphQL APIs:</strong> A more modern API style, offering more flexibility in data retrieval.</li>
          <li><strong>Webhooks:</strong>  Essential for real-time automation. Webhooks are like “reverse APIs” – instead of your code asking for updates, the service <em>pushes</em> updates to your code when something happens.</li>
          <li><strong>Client Libraries (SDKs):</strong> Many services offer pre-built libraries in languages like Python, JavaScript, etc., which simplify API interaction.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Offline Tool Considerations:</strong> Integrating offline tools can be trickier if they don’t have APIs. Consider these options:
    <ul>
      <li><strong>CLI (Command-Line Interface):</strong> Many tools have CLIs that you can control with scripts.</li>
      <li><strong>Scripting Languages:</strong> Some apps support scripting (e.g., AppleScript on macOS, VBA in Microsoft Office).</li>
      <li><strong>File-Based Integration:</strong> Can you monitor a specific folder for new or modified files?</li>
      <li><strong>Database Access (Use with Caution):</strong>  Directly accessing an application’s database is risky and should be a last resort.</li>
    </ul>
  </li>
</ul>

<p><strong>1.4 Choose Your Integration Tools:</strong></p>

<ul>
  <li><strong>Fusio (API Management Platform):</strong> Excellent for building, managing, and securing APIs. Ideal if you want a centralized platform to orchestrate multiple integrations, handle authentication, and generate SDKs. We’ll focus on Fusio in this guide.</li>
  <li><strong>No-Code/Low-Code Platforms (e.g., n8n, Node-RED, Zapier, IFTTT):</strong> Great for visual workflow building, especially if you prefer less coding. Easier to start with, but might become limiting for complex logic or very custom integrations.</li>
  <li><strong>Custom Code (Python, Node.js, etc.):</strong> Offers maximum flexibility and control. Best for developers comfortable with coding and for highly customized workflows.</li>
</ul>

<p>For this guide, we’ll leverage <strong>Fusio</strong> for its robust API management features and focus on building a system that is both powerful and manageable.</p>

<h2 id="-step-2-setting-up-your-fusio-environment---your-automation-hub">✅ Step 2: Setting Up Your Fusio Environment - Your Automation Hub</h2>

<p>Fusio will be the central hub for your personal automation system. Let’s get it set up.</p>

<p><strong>2.1 Installation - Choose Your Path:</strong></p>

<ul>
  <li><strong>Docker (Recommended for Homelabs and Easy Setup):</strong>
    <ul>
      <li>If you’re comfortable with Docker, this is the quickest and easiest way to get Fusio running.
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/apioo/fusio-docker.git
<span class="nb">cd </span>fusio-docker
docker-compose up <span class="nt">-d</span>
</code></pre></div>        </div>
      </li>
      <li>Access Fusio Backend: <code class="language-plaintext highlighter-rouge">http://localhost/apps/fusio</code></li>
    </ul>
  </li>
  <li><strong>Manual Installation (More Control, Requires PHP Environment):</strong>
    <ul>
      <li>If you prefer more control or need to customize your PHP environment, follow the manual installation steps in the Fusio documentation.
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>composer create-project fusio/fusio
<span class="nb">cd </span>fusio
php bin/fusio migrate
php bin/fusio adduser
</code></pre></div>        </div>
      </li>
      <li>Access Fusio Backend: <code class="language-plaintext highlighter-rouge">http://your-fusio-domain/apps/fusio</code> (adjust URL accordingly)</li>
    </ul>
  </li>
</ul>

<p><strong>2.2 Accessing the Fusio Backend - Your Control Panel:</strong></p>

<ul>
  <li>Open your web browser and go to the Fusio backend URL (e.g., <code class="language-plaintext highlighter-rouge">http://localhost/apps/fusio</code>).</li>
  <li>Log in using the administrator credentials you created during installation. This backend is where you’ll configure connections, create APIs, and manage your automation workflows.</li>
</ul>

<h2 id="-step-3-connecting-your-online-services---building-bridges">✅ Step 3: Connecting Your Online Services - Building Bridges</h2>

<p>Fusio uses “Connections” to establish links with external services. Think of connections as pre-configured pathways to talk to different APIs.</p>

<p><strong>3.1 Creating HTTP Connections - The Universal Adapter:</strong></p>

<p>Most online services use HTTP-based APIs (REST or similar). Fusio’s “HTTP Connection” is your general-purpose tool for connecting to these.</p>

<p><strong>Try This: Connect to a Simple Weather API (Example)</strong></p>

<p>Let’s connect to a free weather API as a practice example. We’ll use OpenWeatherMap (you’ll need to sign up for a free API key at <a href="https://openweathermap.org/">https://openweathermap.org/</a>).</p>

<ol>
  <li><strong>Get an OpenWeatherMap API Key:</strong> Sign up for a free account and get your API key.</li>
  <li><strong>Create HTTP Connection in Fusio:</strong>
    <ul>
      <li>Go to <code class="language-plaintext highlighter-rouge">Backend &gt; API &gt; Connection &gt; Create</code>.</li>
      <li><strong>Name:</strong> <code class="language-plaintext highlighter-rouge">OpenWeatherMapAPI</code> (Descriptive name)</li>
      <li><strong>Class:</strong> <code class="language-plaintext highlighter-rouge">HTTP</code></li>
      <li><strong>Configuration:</strong>
        <ul>
          <li><strong>URL:</strong> <code class="language-plaintext highlighter-rouge">https://api.openweathermap.org/data/2.5</code> (Base URL for OpenWeatherMap API)</li>
          <li>Leave other fields empty for now.</li>
        </ul>
      </li>
      <li>Click “Create”.</li>
    </ul>
  </li>
</ol>

<p><strong>3.2 Authentication - Secure Access:</strong></p>

<ul>
  <li>Many APIs require authentication to verify your identity and control access. Common methods include:
    <ul>
      <li><strong>API Keys:</strong> Simple keys passed in headers or query parameters.</li>
      <li><strong>Bearer Tokens (OAuth 2.0):</strong> More secure tokens obtained through an OAuth 2.0 flow.</li>
      <li><strong>Basic Authentication:</strong> Username and password.</li>
    </ul>
  </li>
  <li>When creating connections in Fusio, you’ll often need to configure authentication details in the “Configuration” section, depending on the API’s requirements. For example, for APIs using Bearer tokens, you’d typically set the “Authorization” header in the connection configuration.</li>
</ul>

<p><strong>3.3 Example Connections for Common Services:</strong></p>

<ul>
  <li><strong>Google Calendar (HTTP Connection):</strong>
    <ul>
      <li><strong>Name:</strong> <code class="language-plaintext highlighter-rouge">GoogleCalendarAPI</code></li>
      <li><strong>URL:</strong> <code class="language-plaintext highlighter-rouge">https://www.googleapis.com/calendar/v3</code></li>
      <li><strong>Authentication:</strong> OAuth 2.0 (requires more setup in Google Developer Console to get OAuth credentials and tokens – refer to Google Calendar API documentation).</li>
    </ul>
  </li>
  <li><strong>GitHub (HTTP Connection):</strong>
    <ul>
      <li><strong>Name:</strong> <code class="language-plaintext highlighter-rouge">GitHubAPI</code></li>
      <li><strong>URL:</strong> <code class="language-plaintext highlighter-rouge">https://api.github.com</code></li>
      <li><strong>Authentication:</strong> Personal Access Token (generate a token in your GitHub settings and use “Bearer [Your Token]” in the “Authorization” header).</li>
    </ul>
  </li>
  <li><strong>Todoist (HTTP Connection):</strong>
    <ul>
      <li><strong>Name:</strong> <code class="language-plaintext highlighter-rouge">TodoistAPI</code></li>
      <li><strong>URL:</strong> <code class="language-plaintext highlighter-rouge">https://api.todoist.com/rest/v2</code></li>
      <li><strong>Authentication:</strong> API Token (generate a token in your Todoist settings and use “Bearer [Your Token]” in the “Authorization” header).</li>
    </ul>
  </li>
</ul>

<p><strong>Important Security Tip:</strong>  When configuring connections, <strong>never hardcode API keys or tokens directly into your Fusio configurations or code</strong>. Instead, use Fusio’s configuration system or environment variables to store sensitive credentials securely. We’ll cover secure credential management later in the guide.</p>

<h2 id="-step-4-connecting-your-offline-tools---bridging-the-digital-divide">✅ Step 4: Connecting Your Offline Tools - Bridging the Digital Divide</h2>

<p>Integrating offline tools requires a bit more creativity, as they typically don’t have built-in APIs. You’ll often need to create a “bridge” to make them accessible.</p>

<p><strong>4.1 Local Database Connections (SQL):</strong></p>

<p>If your offline tool stores data in a local database (like SQLite, MySQL, or PostgreSQL), Fusio can directly connect to it using “SQL Connections.”</p>

<p><strong>Try This: Connect to a Local SQLite Database (Example)</strong></p>

<p>Let’s assume you have a simple SQLite database file named <code class="language-plaintext highlighter-rouge">personal_tasks.db</code> in your home directory.</p>

<ol>
  <li><strong>Create SQL Connection in Fusio:</strong>
    <ul>
      <li>Go to <code class="language-plaintext highlighter-rouge">Backend &gt; API &gt; Connection &gt; Create</code>.</li>
      <li><strong>Name:</strong> <code class="language-plaintext highlighter-rouge">LocalTasksDB</code> (Descriptive name)</li>
      <li><strong>Class:</strong> <code class="language-plaintext highlighter-rouge">SQL Advanced</code> (or <code class="language-plaintext highlighter-rouge">SQL</code> if you prefer individual fields)</li>
      <li><strong>Configuration:</strong>
        <ul>
          <li><strong>URL:</strong> <code class="language-plaintext highlighter-rouge">sqlite:////path/to/your/home/directory/personal_tasks.db</code> (Replace <code class="language-plaintext highlighter-rouge">/path/to/your/home/directory/</code> with the actual path to your home directory. Note the four slashes <code class="language-plaintext highlighter-rouge">sqlite:////</code>).</li>
        </ul>
      </li>
      <li>Click “Create”.</li>
    </ul>
  </li>
</ol>

<p><strong>4.2 CLI Processor Actions - Unleashing Command-Line Power:</strong></p>

<p>Fusio’s “CLI Processor” action allows you to execute command-line tools and scripts directly from your APIs. This is incredibly useful for integrating with offline tools that have CLIs.</p>

<p><strong>Example: Using <code class="language-plaintext highlighter-rouge">jq</code> to Process JSON Data from a CLI Tool</strong></p>

<p>Let’s say you have a CLI tool that outputs JSON data, and you want to expose this data through an API endpoint.</p>

<ol>
  <li><strong>Create CLI Processor Action in Fusio:</strong>
    <ul>
      <li>Go to <code class="language-plaintext highlighter-rouge">Backend &gt; API &gt; Action &gt; Create</code>.</li>
      <li><strong>Name:</strong> <code class="language-plaintext highlighter-rouge">GetCLIData</code> (Descriptive name)</li>
      <li><strong>Class:</strong> <code class="language-plaintext highlighter-rouge">CLI Processor</code></li>
      <li><strong>Configuration:</strong>
        <ul>
          <li><strong>Command:</strong> <code class="language-plaintext highlighter-rouge">your-cli-tool --output-json | jq '.'</code> (Replace <code class="language-plaintext highlighter-rouge">your-cli-tool --output-json</code> with the actual command to run your CLI tool and output JSON. <code class="language-plaintext highlighter-rouge">jq '.'</code> is a command-line JSON processor that simply pretty-prints the JSON output – you can use <code class="language-plaintext highlighter-rouge">jq</code> to filter or transform the JSON as needed).</li>
          <li><strong>Content-Type:</strong> <code class="language-plaintext highlighter-rouge">application/json</code> (If your CLI tool outputs JSON)</li>
        </ul>
      </li>
      <li>Click “Create”.</li>
    </ul>
  </li>
</ol>

<p><strong>4.3 PHP Processor Actions - Custom Logic and Scripting:</strong></p>

<p>For more complex offline integrations or when you need to write custom logic, Fusio’s “PHP Processor” action (or “PHP Sandbox” for simpler scripts) is invaluable. You can write PHP code to interact with local files, databases, or even control desktop applications (though controlling desktop apps directly can be complex and platform-dependent).</p>

<p><strong>Example: PHP Action to Read Data from a Local CSV File</strong></p>

<p>Let’s create a PHP action to read data from a CSV file on your server and expose it as an API endpoint.</p>

<ol>
  <li><strong>Create PHP Processor Action in Fusio:</strong>
    <ul>
      <li>Go to <code class="language-plaintext highlighter-rouge">Backend &gt; API &gt; Action &gt; Create</code>.</li>
      <li><strong>Name:</strong> <code class="language-plaintext highlighter-rouge">ReadCSVData</code> (Descriptive name)</li>
      <li><strong>Class:</strong> <code class="language-plaintext highlighter-rouge">PHP Processor</code></li>
      <li><strong>Configuration:</strong>
        <ul>
          <li><strong>File:</strong> <code class="language-plaintext highlighter-rouge">/path/to/your/data.csv</code> (Replace <code class="language-plaintext highlighter-rouge">/path/to/your/data.csv</code> with the actual path to your CSV file on the Fusio server).</li>
        </ul>
      </li>
      <li><strong>Code (File Content - <code class="language-plaintext highlighter-rouge">[Action Name].php</code> will be created):</strong></li>
    </ul>

    <div class="language-php highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">&lt;?php</span>

<span class="kn">use</span> <span class="nc">Fusio\Engine\ActionAbstract</span><span class="p">;</span>
<span class="kn">use</span> <span class="nc">Fusio\Engine\ContextInterface</span><span class="p">;</span>
<span class="kn">use</span> <span class="nc">Fusio\Engine\ParametersInterface</span><span class="p">;</span>
<span class="kn">use</span> <span class="nc">Fusio\Engine\RequestInterface</span><span class="p">;</span>

<span class="kd">class</span> <span class="nc">ReadCSVDataAction</span> <span class="kd">extends</span> <span class="nc">ActionAbstract</span>
<span class="p">{</span>
    <span class="k">public</span> <span class="k">function</span> <span class="n">handle</span><span class="p">(</span><span class="kt">RequestInterface</span> <span class="nv">$request</span><span class="p">,</span> <span class="kt">ParametersInterface</span> <span class="nv">$configuration</span><span class="p">,</span> <span class="kt">ContextInterface</span> <span class="nv">$context</span><span class="p">):</span> <span class="kt">mixed</span>
    <span class="p">{</span>
        <span class="nv">$filePath</span> <span class="o">=</span> <span class="nv">$configuration</span><span class="o">-&gt;</span><span class="nf">get</span><span class="p">(</span><span class="s1">'file'</span><span class="p">);</span> <span class="c1">// Get file path from action configuration</span>

        <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="nb">file_exists</span><span class="p">(</span><span class="nv">$filePath</span><span class="p">)</span> <span class="o">||</span> <span class="o">!</span><span class="nb">is_readable</span><span class="p">(</span><span class="nv">$filePath</span><span class="p">))</span> <span class="p">{</span>
            <span class="k">return</span> <span class="nv">$this</span><span class="o">-&gt;</span><span class="n">response</span><span class="o">-&gt;</span><span class="nf">build</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="p">[],</span> <span class="p">[</span><span class="s1">'error'</span> <span class="o">=&gt;</span> <span class="s1">'CSV file not found or not readable'</span><span class="p">]);</span>
        <span class="p">}</span>

        <span class="nv">$csvData</span> <span class="o">=</span> <span class="p">[];</span>
        <span class="k">if</span> <span class="p">((</span><span class="nv">$handle</span> <span class="o">=</span> <span class="nb">fopen</span><span class="p">(</span><span class="nv">$filePath</span><span class="p">,</span> <span class="s2">"r"</span><span class="p">))</span> <span class="o">!==</span> <span class="kc">FALSE</span><span class="p">)</span> <span class="p">{</span>
            <span class="k">while</span> <span class="p">((</span><span class="nv">$data</span> <span class="o">=</span> <span class="nb">fgetcsv</span><span class="p">(</span><span class="nv">$handle</span><span class="p">))</span> <span class="o">!==</span> <span class="kc">FALSE</span><span class="p">)</span> <span class="p">{</span>
                <span class="nv">$csvData</span><span class="p">[]</span> <span class="o">=</span> <span class="nv">$data</span><span class="p">;</span>
            <span class="p">}</span>
            <span class="nb">fclose</span><span class="p">(</span><span class="nv">$handle</span><span class="p">);</span>
        <span class="p">}</span>

        <span class="k">return</span> <span class="nv">$this</span><span class="o">-&gt;</span><span class="n">response</span><span class="o">-&gt;</span><span class="nf">build</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="p">[],</span> <span class="p">[</span><span class="s1">'data'</span> <span class="o">=&gt;</span> <span class="nv">$csvData</span><span class="p">]);</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div>    </div>
    <ul>
      <li>Click “Create”.</li>
    </ul>
  </li>
</ol>

<p><strong>Important Note for Offline Tools:</strong> Integrating offline tools often requires your Fusio instance to have access to the local resources (files, databases, executables) where those tools reside. If Fusio is running in Docker, you might need to use Docker volumes to mount local directories into the Fusio container to make files accessible.</p>

<h2 id="-step-5-crafting-your-apis---operations-and-actions-working-together">✅ Step 5: Crafting Your APIs - Operations and Actions Working Together</h2>

<p>Now that you have connections set up, let’s create API endpoints (Operations) that use Actions to perform specific tasks.</p>

<p><strong>5.1 Operations - Defining Your Endpoints:</strong></p>

<p>Operations in Fusio represent your API endpoints. They define:</p>

<ul>
  <li><strong>HTTP Method (GET, POST, PUT, DELETE):</strong> How clients will interact with the endpoint.</li>
  <li><strong>HTTP Path (/weather/current, /tasks, etc.):</strong> The URL path for the endpoint.</li>
  <li><strong>Action:</strong> Which Fusio Action will be executed when the endpoint is called.</li>
  <li><strong>Parameters:</strong>  Input parameters the endpoint accepts (query parameters, path parameters, request body).</li>
  <li><strong>Schemas:</strong>  Data structures for requests and responses (optional but highly recommended for documentation and validation).</li>
</ul>

<p><strong>5.2 Actions - Implementing the Logic:</strong></p>

<p>Actions contain the actual code or configuration that performs the task when an operation is invoked. You’ve already seen examples of “HTTP Processor,” “CLI Processor,” and “PHP Processor” actions.</p>

<p><strong>Try This: Create an API Endpoint to Get Weather Data</strong></p>

<p>Let’s create an API endpoint <code class="language-plaintext highlighter-rouge">/weather/current</code> that uses the OpenWeatherMap connection and “HTTP Processor” action to fetch current weather data for a city.</p>

<ol>
  <li><strong>Create “Get Current Weather” Action (if you haven’t already in Step 3):</strong>
    <ul>
      <li>Go to <code class="language-plaintext highlighter-rouge">Backend &gt; API &gt; Action &gt; Create</code>.</li>
      <li><strong>Name:</strong> <code class="language-plaintext highlighter-rouge">GetCurrentWeatherAction</code></li>
      <li><strong>Class:</strong> <code class="language-plaintext highlighter-rouge">HTTP Processor</code></li>
      <li><strong>Configuration:</strong>
        <ul>
          <li><strong>Connection:</strong> <code class="language-plaintext highlighter-rouge">OpenWeatherMapAPI</code></li>
          <li><strong>URL:</strong> <code class="language-plaintext highlighter-rouge">/weather?q=&amp;appid=&amp;units=metric</code> (Replace <code class="language-plaintext highlighter-rouge">with a placeholder for your API key – we'll handle API key configuration securely later.</code> is a placeholder for a city parameter).</li>
          <li><strong>Content-Type:</strong> <code class="language-plaintext highlighter-rouge">application/json</code></li>
        </ul>
      </li>
      <li>Click “Create”.</li>
    </ul>
  </li>
  <li><strong>Create “Get Current Weather” Operation:</strong>
    <ul>
      <li>Go to <code class="language-plaintext highlighter-rouge">Backend &gt; API &gt; Operation &gt; Create</code>.</li>
      <li><strong>Name:</strong> <code class="language-plaintext highlighter-rouge">GetCurrentWeatherOp</code></li>
      <li><strong>Description:</strong> <code class="language-plaintext highlighter-rouge">Get current weather data for a city.</code></li>
      <li><strong>HTTP Method:</strong> <code class="language-plaintext highlighter-rouge">GET</code></li>
      <li><strong>HTTP Path:</strong> <code class="language-plaintext highlighter-rouge">/weather/current</code></li>
      <li><strong>HTTP Code:</strong> <code class="language-plaintext highlighter-rouge">200</code></li>
      <li><strong>Parameters:</strong>
        <ul>
          <li>Add a parameter:
            <ul>
              <li><strong>Name:</strong> <code class="language-plaintext highlighter-rouge">city</code></li>
              <li><strong>Type:</strong> <code class="language-plaintext highlighter-rouge">String</code></li>
              <li><strong>Description:</strong> <code class="language-plaintext highlighter-rouge">City name</code></li>
              <li><strong>Location:</strong> <code class="language-plaintext highlighter-rouge">Query</code> (so you’ll pass the city as a query parameter like <code class="language-plaintext highlighter-rouge">/weather/current?city=London</code>)</li>
            </ul>
          </li>
        </ul>
      </li>
      <li><strong>Outgoing:</strong> You can optionally create a Schema to describe the weather data response (for better documentation).</li>
      <li><strong>Action:</strong> Select “Action” and choose <code class="language-plaintext highlighter-rouge">GetCurrentWeatherAction</code>.</li>
      <li>Click “Create”.</li>
    </ul>
  </li>
</ol>

<p><strong>5.3 Testing Your API Endpoint:</strong></p>

<ul>
  <li>Open a web browser or use a REST client like Postman or <code class="language-plaintext highlighter-rouge">curl</code>.</li>
  <li>Go to your Fusio API URL + <code class="language-plaintext highlighter-rouge">/weather/current?city=London</code> (e.g., <code class="language-plaintext highlighter-rouge">http://localhost:8000/weather/current?city=London</code>).</li>
  <li>You should see a JSON response containing weather data for London from OpenWeatherMap.</li>
</ul>

<p><strong>Securing API Keys (Best Practice):</strong></p>

<p>In the “GetCurrentWeatherAction” example, you might have noticed a placeholder ``.  <strong>Never hardcode your API keys directly in the Action URL or code!</strong></p>

<p>Instead, you should:</p>

<ol>
  <li><strong>Add a “Config” Field to Your Connection:</strong>
    <ul>
      <li>Go to <code class="language-plaintext highlighter-rouge">Backend &gt; API &gt; Connection &gt; Edit</code> for your <code class="language-plaintext highlighter-rouge">OpenWeatherMapAPI</code> connection.</li>
      <li>Click “Edit” in the top right corner to switch to edit mode.</li>
      <li>Click “Add” under “Config” fields.</li>
      <li><strong>Name:</strong> <code class="language-plaintext highlighter-rouge">apiKey</code> (or similar)</li>
      <li><strong>Type:</strong> <code class="language-plaintext highlighter-rouge">Text</code></li>
      <li><strong>Label:</strong> <code class="language-plaintext highlighter-rouge">API Key</code></li>
      <li><strong>Description:</strong> <code class="language-plaintext highlighter-rouge">Your OpenWeatherMap API Key</code></li>
      <li>Click “Save”.</li>
    </ul>
  </li>
  <li><strong>Set the API Key in the Connection Configuration:</strong>
    <ul>
      <li>Now, when you edit the <code class="language-plaintext highlighter-rouge">OpenWeatherMapAPI</code> connection again, you’ll see a field to enter your API Key. Enter your API key there. Fusio securely stores connection configurations.</li>
    </ul>
  </li>
  <li><strong>Reference the Config in Your Action URL:</strong>
    <ul>
      <li>In your <code class="language-plaintext highlighter-rouge">GetCurrentWeatherAction</code> configuration, use `` in the URL to dynamically insert the API key from the connection’s secure configuration.</li>
    </ul>
  </li>
</ol>

<p>This approach keeps your API keys out of your code and action configurations, making your system much more secure.</p>

<h2 id="-step-6-automating-workflows---cronjobs-and-events-for-hands-free-automation">✅ Step 6: Automating Workflows - Cronjobs and Events for Hands-Free Automation</h2>

<p>Fusio provides powerful mechanisms to automate your workflows:</p>

<p><strong>6.1 Cronjobs - Scheduled Automation:</strong></p>

<p>Cronjobs in Fusio allow you to schedule Actions to run automatically at specific intervals (e.g., daily, hourly, every minute). This is perfect for tasks like:</p>

<ul>
  <li>Daily reports or summaries.</li>
  <li>Periodic data synchronization.</li>
  <li>Scheduled backups.</li>
</ul>

<p><strong>Try This: Create a Cronjob to Send a Daily Weather Email Summary</strong></p>

<p>Let’s create a cronjob that fetches weather data and sends you a daily email summary. (You’ll need to have an SMTP Connection configured in Fusio to send emails – refer to Fusio documentation for SMTP Connection setup).</p>

<ol>
  <li><strong>Create “Send Weather Email” Action (PHP Processor):</strong>
    <ul>
      <li>Go to <code class="language-plaintext highlighter-rouge">Backend &gt; API &gt; Action &gt; Create</code>.</li>
      <li><strong>Name:</strong> <code class="language-plaintext highlighter-rouge">SendWeatherEmailAction</code></li>
      <li><strong>Class:</strong> <code class="language-plaintext highlighter-rouge">PHP Processor</code></li>
      <li><strong>Configuration:</strong>
        <ul>
          <li><strong>File:</strong> <code class="language-plaintext highlighter-rouge">SendWeatherEmailAction.php</code> (or any name you choose)</li>
        </ul>
      </li>
      <li><strong>Code (File Content - <code class="language-plaintext highlighter-rouge">SendWeatherEmailAction.php</code>):</strong></li>
    </ul>

    <div class="language-php highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">&lt;?php</span>

<span class="kn">use</span> <span class="nc">Fusio\Engine\ActionAbstract</span><span class="p">;</span>
<span class="kn">use</span> <span class="nc">Fusio\Engine\ContextInterface</span><span class="p">;</span>
<span class="kn">use</span> <span class="nc">Fusio\Engine\ParametersInterface</span><span class="p">;</span>
<span class="kn">use</span> <span class="nc">Fusio\Engine\RequestInterface</span><span class="p">;</span>

<span class="kd">class</span> <span class="nc">SendWeatherEmailAction</span> <span class="kd">extends</span> <span class="nc">ActionAbstract</span>
<span class="p">{</span>
    <span class="k">public</span> <span class="k">function</span> <span class="n">handle</span><span class="p">(</span><span class="kt">RequestInterface</span> <span class="nv">$request</span><span class="p">,</span> <span class="kt">ParametersInterface</span> <span class="nv">$configuration</span><span class="p">,</span> <span class="kt">ContextInterface</span> <span class="nv">$context</span><span class="p">):</span> <span class="kt">mixed</span>
    <span class="p">{</span>
        <span class="nv">$city</span> <span class="o">=</span> <span class="s1">'London'</span><span class="p">;</span> <span class="c1">// Or get city from configuration if you want to make it configurable</span>
        <span class="nv">$weatherResponse</span> <span class="o">=</span> <span class="nv">$this</span><span class="o">-&gt;</span><span class="n">processor</span><span class="o">-&gt;</span><span class="nf">execute</span><span class="p">(</span><span class="s1">'GetCurrentWeatherAction'</span><span class="p">,</span> <span class="nv">$this</span><span class="o">-&gt;</span><span class="n">requestBuilder</span><span class="o">-&gt;</span><span class="nf">buildQuery</span><span class="p">([</span><span class="s1">'city'</span> <span class="o">=&gt;</span> <span class="nv">$city</span><span class="p">]),</span> <span class="nv">$context</span><span class="p">);</span>

        <span class="k">if</span> <span class="p">(</span><span class="nv">$weatherResponse</span><span class="o">-&gt;</span><span class="nf">getStatusCode</span><span class="p">()</span> <span class="o">!==</span> <span class="mi">200</span><span class="p">)</span> <span class="p">{</span>
            <span class="k">return</span> <span class="nv">$this</span><span class="o">-&gt;</span><span class="n">response</span><span class="o">-&gt;</span><span class="nf">build</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="p">[],</span> <span class="p">[</span><span class="s1">'error'</span> <span class="o">=&gt;</span> <span class="s1">'Error fetching weather data'</span><span class="p">]);</span>
        <span class="p">}</span>

        <span class="nv">$weatherData</span> <span class="o">=</span> <span class="nb">json_decode</span><span class="p">((</span><span class="n">string</span><span class="p">)</span> <span class="nv">$weatherResponse</span><span class="o">-&gt;</span><span class="nf">getBody</span><span class="p">(),</span> <span class="kc">true</span><span class="p">);</span>
        <span class="nv">$temperature</span> <span class="o">=</span> <span class="nv">$weatherData</span><span class="p">[</span><span class="s1">'main'</span><span class="p">][</span><span class="s1">'temp'</span><span class="p">];</span>
        <span class="nv">$description</span> <span class="o">=</span> <span class="nv">$weatherData</span><span class="p">[</span><span class="s1">'weather'</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">'description'</span><span class="p">];</span>

        <span class="nv">$emailSubject</span> <span class="o">=</span> <span class="s2">"Daily Weather Summary for "</span> <span class="mf">.</span> <span class="nv">$city</span><span class="p">;</span>
        <span class="nv">$emailBody</span> <span class="o">=</span> <span class="s2">"Good morning!</span><span class="se">\n\n</span><span class="s2">Today's weather in "</span> <span class="mf">.</span> <span class="nv">$city</span> <span class="mf">.</span> <span class="s2">":</span><span class="se">\n</span><span class="s2">Temperature: "</span> <span class="mf">.</span> <span class="nv">$temperature</span> <span class="mf">.</span> <span class="s2">"°C</span><span class="se">\n</span><span class="s2">Description: "</span> <span class="mf">.</span> <span class="nv">$description</span><span class="p">;</span>

        <span class="nv">$mail</span> <span class="o">=</span> <span class="nv">$this</span><span class="o">-&gt;</span><span class="n">connector</span><span class="o">-&gt;</span><span class="nf">getConnection</span><span class="p">(</span><span class="s1">'YourSMTPConnectionName'</span><span class="p">);</span> <span class="c1">// Replace 'YourSMTPConnectionName' with your actual SMTP Connection name</span>
        <span class="nv">$mail</span><span class="o">-&gt;</span><span class="nb">mail</span><span class="p">(</span><span class="s1">'your-email@example.com'</span><span class="p">,</span> <span class="nv">$emailSubject</span><span class="p">,</span> <span class="nv">$emailBody</span><span class="p">,</span> <span class="p">[</span><span class="s1">'From'</span> <span class="o">=&gt;</span> <span class="s1">'fusio-automation@example.com'</span><span class="p">]);</span> <span class="c1">// Replace with your email addresses</span>

        <span class="k">return</span> <span class="nv">$this</span><span class="o">-&gt;</span><span class="n">response</span><span class="o">-&gt;</span><span class="nf">build</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="p">[],</span> <span class="p">[</span><span class="s1">'message'</span> <span class="o">=&gt;</span> <span class="s1">'Daily weather email sent'</span><span class="p">]);</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div>    </div>
    <ul>
      <li>Click “Create”.</li>
    </ul>
  </li>
  <li><strong>Create Cronjob:</strong>
    <ul>
      <li>Go to <code class="language-plaintext highlighter-rouge">Backend &gt; API &gt; Cronjob &gt; Create</code>.</li>
      <li><strong>Name:</strong> <code class="language-plaintext highlighter-rouge">DailyWeatherEmailCronjob</code></li>
      <li><strong>Cron Expression:</strong> <code class="language-plaintext highlighter-rouge">0 7 * * *</code> (Runs every day at 7:00 AM – adjust to your preferred time using cron syntax: <a href="https://crontab.guru/">https://crontab.guru/</a>)</li>
      <li><strong>Action:</strong> Select “Action” and choose <code class="language-plaintext highlighter-rouge">SendWeatherEmailAction</code>.</li>
      <li>Click “Create”.</li>
    </ul>
  </li>
</ol>

<p>Now, at 7:00 AM every day, Fusio will automatically execute the <code class="language-plaintext highlighter-rouge">SendWeatherEmailAction</code>, which fetches weather data and sends you an email summary.</p>

<p><strong>6.2 Events and Webhooks - Real-Time Automation:</strong></p>

<p>Fusio’s event system and webhooks allow for real-time automation. You can configure Actions to be triggered by:</p>

<ul>
  <li><strong>Internal Fusio Events:</strong>  Events that occur within Fusio (e.g., user registration, data changes).</li>
  <li><strong>External Webhooks:</strong>  Services that send HTTP POST requests to Fusio when specific events happen (e.g., new emails, GitHub pushes, payment notifications).</li>
</ul>

<p>Setting up webhooks often involves configuring the external service to send webhook requests to a specific Fusio endpoint (Operation). You then create a Fusio Operation that is designed to receive and process these webhook requests, triggering appropriate Actions in response.</p>

<p>(Detailed webhook setup is more complex and service-specific, so it’s beyond the scope of this introductory guide, but Fusio’s documentation provides more information on event and webhook handling).</p>

<h2 id="-step-7-securing-your-apis---protecting-your-personal-data">✅ Step 7: Securing Your APIs - Protecting Your Personal Data</h2>

<p>Security is crucial, even for personal APIs. Here are key security practices to implement in Fusio:</p>

<p><strong>7.1 Authentication and Authorization:</strong></p>

<ul>
  <li><strong>Private Operations by Default:</strong> In Fusio, Operations are private by default. This means they require authentication to be accessed.</li>
  <li><strong>Scopes:</strong> Use Fusio Scopes to define granular permissions for your APIs. Scopes represent specific access rights (e.g., <code class="language-plaintext highlighter-rouge">read_weather_data</code>, <code class="language-plaintext highlighter-rouge">create_tasks</code>).</li>
  <li><strong>Roles:</strong> Assign Scopes to Fusio Roles. Then, you can assign Roles to API clients (Apps) or Users to control who has access to which operations.</li>
  <li><strong>OAuth 2.0:</strong> For more advanced authentication, Fusio supports OAuth 2.0 flows. This is useful if you want to allow other applications or users to securely access your APIs on behalf of users.</li>
  <li><strong>API Keys (for simpler scenarios):</strong> For simpler personal APIs, you can use Fusio Apps and API Keys for authentication. Generate an API Key for an App in Fusio and require clients to pass this key in the <code class="language-plaintext highlighter-rouge">Authorization</code> header (e.g., <code class="language-plaintext highlighter-rouge">Authorization: Bearer [Your API Key]</code>).</li>
</ul>

<p><strong>7.2 HTTPS/TLS Encryption:</strong></p>

<ul>
  <li><strong>Always Use HTTPS:</strong> Ensure your Fusio instance and all your API endpoints are served over HTTPS (using TLS/SSL certificates). This encrypts communication between clients and your Fusio server, protecting sensitive data in transit.</li>
</ul>

<p><strong>7.3 Rate Limiting:</strong></p>

<ul>
  <li><strong>Prevent Abuse:</strong> Even for personal APIs, rate limiting is a good practice to prevent accidental overload or potential abuse. Fusio provides Rate Limiting features to control the number of requests clients can make to your APIs within a specific time period.</li>
</ul>

<p><strong>7.4 Input Validation:</strong></p>

<ul>
  <li><strong>Schema Validation:</strong> Use Fusio Schemas to define the expected data structure for API requests and responses. Fusio can automatically validate requests against your Schemas, preventing invalid data from being processed and improving API robustness.</li>
</ul>

<p><strong>7.5 Secure Credential Management (Reiterated):</strong></p>

<ul>
  <li><strong>Environment Variables and Fusio Config:</strong> As emphasized earlier, <strong>never hardcode API keys, tokens, or passwords directly in your code or action configurations.</strong> Use environment variables or Fusio’s secure configuration system to store sensitive credentials.</li>
</ul>

<h2 id="-step-8-documenting-your-apis---making-them-user-friendly-even-for-yourself">✅ Step 8: Documenting Your APIs - Making Them User-Friendly (Even for Yourself!)</h2>

<p>Even for personal APIs, documentation is incredibly valuable. It helps you remember how your APIs work, makes them easier to use in scripts or other applications, and allows you to share them with others if you choose.</p>

<p><strong>8.1 Fusio’s Automatic OpenAPI Specification:</strong></p>

<ul>
  <li>Fusio automatically generates an OpenAPI (Swagger) specification for your APIs based on your Operations and Schemas. OpenAPI is a standard format for describing REST APIs.</li>
  <li>You can access your OpenAPI specification in JSON or YAML format from your Fusio instance (check Fusio documentation for the specific URL).</li>
</ul>

<p><strong>8.2 ReDoc App - Beautiful API Documentation:</strong></p>

<ul>
  <li>Fusio integrates with ReDoc, a popular open-source tool for rendering OpenAPI specifications into beautiful, interactive documentation.</li>
  <li><strong>Install ReDoc App:</strong> Go to <code class="language-plaintext highlighter-rouge">Backend &gt; Development &gt; Marketplace</code> and install the “ReDoc” app.</li>
  <li>Once installed, you can access your API documentation through the ReDoc app within Fusio.</li>
</ul>

<p><strong>8.3 SDK Generation - Client Libraries for Easy Access:</strong></p>

<ul>
  <li>Fusio can automatically generate Client SDKs (Software Development Kits) for your APIs in various programming languages (JavaScript, Python, PHP, Java, and more).</li>
  <li><strong>Generate SDKs:</strong> Go to <code class="language-plaintext highlighter-rouge">Backend &gt; Development &gt; SDK</code> in Fusio.</li>
  <li>SDKs provide pre-built libraries that simplify API interaction from your scripts or applications. Instead of writing raw HTTP requests, you can use the generated SDK functions to call your API endpoints in a type-safe and convenient way.</li>
</ul>

<h2 id="-step-9-testing-your-integrations---ensuring-everything-works-smoothly">✅ Step 9: Testing Your Integrations - Ensuring Everything Works Smoothly</h2>

<p>Thorough testing is essential to ensure your API integrations work as expected and are reliable.</p>

<p><strong>9.1 Testing Strategies:</strong></p>

<ul>
  <li><strong>Unit Tests (for Actions - if you write custom code):</strong> If you create custom Actions (like PHP Processor actions), write unit tests to test the logic within those Actions in isolation.</li>
  <li><strong>Integration Tests (End-to-End Workflow Tests):</strong> Test the complete workflows from trigger to action. For example, for the Gmail-to-Trello workflow, create a test email that should trigger a Trello card creation and verify that the card is created correctly.</li>
  <li><strong>Manual Testing (Using REST Clients):</strong> Use REST clients like Postman, Insomnia, or <code class="language-plaintext highlighter-rouge">curl</code> to manually send requests to your API endpoints and verify the responses. This is useful for testing different scenarios, parameters, and error conditions.</li>
  <li><strong>Logging and Monitoring:</strong>  Enable logging in your Actions and monitor Fusio’s logs (<code class="language-plaintext highlighter-rouge">Backend &gt; Analytics &gt; Log</code> and <code class="language-plaintext highlighter-rouge">Backend &gt; Analytics &gt; Error</code>) to track API calls, identify errors, and debug issues.</li>
</ul>

<p><strong>9.2 Example Testing Workflow (for the Weather API Endpoint):</strong></p>

<ol>
  <li><strong>Manual Test with Browser or REST Client:</strong>
    <ul>
      <li>Go to <code class="language-plaintext highlighter-rouge">http://localhost:8000/weather/current?city=London</code> in your browser.</li>
      <li>Verify that you get a valid JSON response with weather data.</li>
      <li>Try invalid city names or missing parameters and check for appropriate error responses.</li>
    </ul>
  </li>
  <li>
    <p><strong>Automated Integration Test (Python Example - using <code class="language-plaintext highlighter-rouge">requests</code> and <code class="language-plaintext highlighter-rouge">unittest</code>):</strong></p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">unittest</span>
<span class="kn">import</span> <span class="n">requests</span>
<span class="kn">import</span> <span class="n">json</span>

<span class="k">class</span> <span class="nc">WeatherAPITest</span><span class="p">(</span><span class="n">unittest</span><span class="p">.</span><span class="n">TestCase</span><span class="p">):</span>

    <span class="n">API_BASE_URL</span> <span class="o">=</span> <span class="sh">"</span><span class="s">http://localhost:8000</span><span class="sh">"</span>  <span class="c1"># Adjust to your Fusio API URL
</span>
    <span class="k">def</span> <span class="nf">test_get_weather_london</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">self</span><span class="p">.</span><span class="n">API_BASE_URL</span><span class="si">}</span><span class="s">/weather/current?city=London</span><span class="sh">"</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">assertEqual</span><span class="p">(</span><span class="n">response</span><span class="p">.</span><span class="n">status_code</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">response</span><span class="p">.</span><span class="nf">json</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">assertIn</span><span class="p">(</span><span class="sh">"</span><span class="s">weather</span><span class="sh">"</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span> <span class="c1"># Basic check for weather data in response
</span>
    <span class="k">def</span> <span class="nf">test_get_weather_invalid_city</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">self</span><span class="p">.</span><span class="n">API_BASE_URL</span><span class="si">}</span><span class="s">/weather/current?city=InvalidCityName</span><span class="sh">"</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">assertNotEqual</span><span class="p">(</span><span class="n">response</span><span class="p">.</span><span class="n">status_code</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span> <span class="c1"># Expecting an error for invalid city
</span>
<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">'</span><span class="s">__main__</span><span class="sh">'</span><span class="p">:</span>
    <span class="n">unittest</span><span class="p">.</span><span class="nf">main</span><span class="p">()</span>
</code></pre></div>    </div>
    <ul>
      <li>Save this code as <code class="language-plaintext highlighter-rouge">weather_api_test.py</code>.</li>
      <li>Run from your terminal: <code class="language-plaintext highlighter-rouge">python weather_api_test.py</code></li>
      <li>This will execute the tests and report any failures.</li>
    </ul>
  </li>
</ol>

<h2 id="-step-10-deployment-strategies---running-your-automation-system">✅ Step 10: Deployment Strategies - Running Your Automation System</h2>

<p>Where and how will you run your Fusio-powered automation system? Here are common deployment options:</p>

<p><strong>10.1 Local Machine (Development and Personal Use):</strong></p>

<ul>
  <li>For development and testing, running Fusio directly on your local machine (using Docker or manual installation) is often sufficient.</li>
  <li>For simple personal automations that don’t require high availability or external access, you might even run Fusio locally for day-to-day use.</li>
</ul>

<p><strong>10.2 Homelab Server (Dedicated Home Server):</strong></p>

<ul>
  <li>If you have a homelab server (a dedicated machine in your home network), deploying Fusio there is a great option. It provides more reliability and uptime than running on your personal computer.</li>
  <li>Use Docker Compose to deploy Fusio and your custom scripts or services on your homelab server.</li>
</ul>

<p><strong>10.3 Cloud VPS (Virtual Private Server):</strong></p>

<ul>
  <li>For more robust and always-on automation, consider deploying Fusio to a cloud VPS (e.g., DigitalOcean Droplet, AWS EC2, Google Compute Engine).</li>
  <li>VPS hosting provides a publicly accessible server with good uptime and scalability.</li>
  <li>You’ll need to manage the server yourself (OS updates, security, etc.), but it offers more control.</li>
</ul>

<p><strong>10.4 Serverless Functions (AWS Lambda, Google Cloud Functions, Azure Functions - Advanced):</strong></p>

<ul>
  <li>For event-driven workflows, serverless functions can be an excellent choice.</li>
  <li>You deploy your Action code (e.g., PHP scripts, Python functions) as serverless functions.</li>
  <li>Fusio can then invoke these serverless functions as Actions.</li>
  <li>Serverless functions are highly scalable and cost-effective for event-driven tasks, as you only pay for the compute time used when your functions are actually running.</li>
  <li>Setting up serverless deployment with Fusio requires more advanced configuration and is beyond the scope of this introductory guide.</li>
</ul>

<p><strong>10.5 Containerization (Docker - for Deployment):</strong></p>

<ul>
  <li>Docker is highly recommended for deployment, regardless of whether you choose local hosting, a homelab server, or a cloud VPS.</li>
  <li>Containerizing Fusio and your custom Actions with Docker makes deployment consistent, portable, and easier to manage.</li>
  <li>You can create a <code class="language-plaintext highlighter-rouge">Dockerfile</code> to package your Fusio instance and custom code into a Docker image, which can then be easily deployed to any Docker-compatible environment.</li>
</ul>

<p><strong>Basic Dockerfile Example (for a Fusio project with custom PHP Actions):</strong></p>

<div class="language-dockerfile highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">FROM</span><span class="w"> </span><span class="s">fusio/fusio:latest  # Use the official Fusio Docker image</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="s">a base</span>

<span class="c"># Copy your custom PHP Actions into the Fusio actions directory</span>
<span class="k">COPY</span><span class="s"> ./src/Action /var/www/html/fusio/src/Action</span>

<span class="c"># If you have custom Connections or other code, copy those as well</span>
<span class="k">COPY</span><span class="s"> ./src/Connection /var/www/html/fusio/src/Connection</span>
<span class="k">COPY</span><span class="s"> ./resources/container.php /var/www/html/fusio/resources/container.php</span>

<span class="c"># Install any additional PHP dependencies your Actions might require (if any)</span>
<span class="c"># Example: RUN composer require vendor/package</span>

<span class="c"># Set permissions (important for Fusio to run correctly in Docker)</span>
<span class="k">RUN </span><span class="nb">chown</span> <span class="nt">-R</span> www-data:www-data /var/www/html/fusio

<span class="c"># Expose port 80 (or the port Fusio is configured to use)</span>
<span class="k">EXPOSE</span><span class="s"> 80</span>

<span class="c"># Command to start Fusio (already defined in the base image, but you can customize if needed)</span>
<span class="c"># CMD ["php", "bin/fusio", "serve"]</span>
</code></pre></div></div>

<p>To build this Docker image:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker build <span class="nt">-t</span> my-fusio-automation <span class="nb">.</span>
</code></pre></div></div>

<p>To run the Docker container:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run <span class="nt">-d</span> <span class="nt">-p</span> 80:80 my-fusio-automation
</code></pre></div></div>

<p>Remember to adjust the <code class="language-plaintext highlighter-rouge">Dockerfile</code> and Docker run commands based on your specific project structure and requirements.</p>

<h2 id="-step-11-scaling-and-maintaining-your-personal-api-system">✅ Step 11: Scaling and Maintaining Your Personal API System</h2>

<p>As you build more integrations and automations, consider these aspects for long-term maintainability and scalability:</p>

<p><strong>11.1 Modular Code and Reusability:</strong></p>

<ul>
  <li><strong>Break Down Complex Actions:</strong> If your Actions become too large or complex, break them down into smaller, more manageable functions or classes.</li>
  <li><strong>Reusable Functions and Libraries:</strong> Create reusable functions or libraries for common tasks (e.g., API request helpers, data transformation utilities). This reduces code duplication and makes your system easier to maintain.</li>
</ul>

<p><strong>11.2 Configuration Management:</strong></p>

<ul>
  <li><strong>Externalize Configuration:</strong> Keep configuration settings (API keys, URLs, database credentials, etc.) separate from your code. Use environment variables, configuration files, or Fusio’s configuration system to manage these settings. This makes it easier to change configurations without modifying code and improves security.</li>
</ul>

<p><strong>11.3 Logging and Monitoring (Proactive Issue Detection):</strong></p>

<ul>
  <li><strong>Comprehensive Logging:</strong> Implement detailed logging in your Actions to record important events, errors, and debugging information. Log timestamps, request details, response codes, and any relevant data.</li>
  <li><strong>Centralized Logging:</strong> Consider using a centralized logging service to aggregate logs from Fusio and your custom scripts. This makes it easier to search, analyze, and monitor your system’s health.</li>
  <li><strong>Monitoring and Alerting (Optional but Recommended for Reliability):</strong> For critical automations, set up monitoring to track API performance, error rates, and workflow execution times. Implement alerting (e.g., email or push notifications) to be notified of errors or failures proactively.</li>
</ul>

<p><strong>11.4 Version Control (Git is Your Friend):</strong></p>

<ul>
  <li><strong>Track Changes:</strong> Use Git (or another version control system) to track all changes to your Fusio configurations, Action code, and deployment scripts. This is essential for managing your automation system over time, reverting to previous versions if needed, and collaborating if you share your system with others.</li>
</ul>

<p><strong>11.5 Error Handling and Resilience (Building Robust Systems):</strong></p>

<ul>
  <li><strong>Robust Error Handling:</strong> Implement comprehensive error handling in your Actions to gracefully handle API failures, network issues, invalid data, and other potential problems. Use <code class="language-plaintext highlighter-rouge">try...except</code> blocks (or equivalent error handling mechanisms in your chosen language) to catch exceptions and prevent your workflows from crashing.</li>
  <li><strong>Retry Mechanisms:</strong> For transient errors (e.g., temporary API outages, network glitches), implement retry mechanisms with exponential backoff. This means that if a request fails, your code will wait for a short period before retrying, and the wait time will increase with each subsequent retry attempt. This prevents overwhelming failing services and improves the resilience of your workflows.</li>
  <li><strong>Circuit Breaker Pattern (Advanced):</strong> For more advanced error handling, consider implementing the Circuit Breaker pattern. This pattern helps to prevent your system from repeatedly trying to access a failing service, giving the service time to recover and improving overall system stability.</li>
</ul>

<p><strong>11.6 Documentation (For Your Future Self):</strong></p>

<ul>
  <li><strong>Document Your Workflows:</strong>  Document the purpose, triggers, actions, and data flows of your automated workflows. This documentation will be invaluable when you need to revisit or modify your system in the future (even if it’s just for yourself).</li>
  <li><strong>API Documentation (Fusio’s OpenAPI):</strong> Leverage Fusio’s automatic OpenAPI specification and ReDoc integration to create and maintain up-to-date documentation for your APIs.</li>
</ul>

<p>By following these steps and best practices, you can build a powerful, reliable, and maintainable personal API integration system using Fusio to automate your digital life and connect your favorite online services and offline tools. Remember to start small, iterate, and continuously improve your system as your needs evolve. Happy automating! 🚀</p>]]></content><author><name></name></author><category term="scratchpad" /></entry><entry><title type="html">OPNsense + Unbound + Docker (AdGuard Home or Pi-hole) + Ansible Automation</title><link href="https://ib.bsb.br/opnsense-unbound-docker-adguard-home-or-pi-hole-ansible-automation/" rel="alternate" type="text/html" title="OPNsense + Unbound + Docker (AdGuard Home or Pi-hole) + Ansible Automation" /><published>2025-03-16T00:00:00+00:00</published><updated>2025-03-16T09:37:34+00:00</updated><id>https://ib.bsb.br/opnsense-unbound-docker-adguard-home-or-pi-hole-ansible-automation</id><content type="html" xml:base="https://ib.bsb.br/opnsense-unbound-docker-adguard-home-or-pi-hole-ansible-automation/"><![CDATA[<h2 id="scenario-overview">Scenario Overview</h2>

<ul>
  <li><strong>Purpose</strong>: Construct a resilient, robust homelab infrastructure to cover firewall, routing, DHCP, DNS resolution and ad-blocking using proven open-source tools.</li>
  <li><strong>Components Integrated</strong>:
    <ul>
      <li><strong>OPNsense</strong> — Firewall, Router, DHCP, DNS rebinding protection</li>
      <li><strong>Unbound</strong> (integrated within OPNsense) — Local recursive DNS resolver (self-hosted DNS queries)</li>
      <li><strong>AdGuard Home OR Pi-hole</strong> (in Docker) — DNS sinkhole (ad-blocking, tracker blocking, DNS-over-HTTPS capability)</li>
      <li><strong>Docker</strong> — Lightweight and flexible service encapsulation</li>
      <li><strong>Ansible</strong> — Automated infrastructure deployment, backups, and recovery.</li>
    </ul>
  </li>
</ul>

<hr />

<h2 id="step-1---deploy-opnsense-firewall-router-bare-metal--virtual-machine">STEP 1 - Deploy OPNsense Firewall Router (Bare Metal / Virtual Machine)</h2>

<h3 id="installation">Installation</h3>

<p>Download installer from official source:</p>
<ul>
  <li>Official Image: <a href="https://opnsense.org/download/">https://opnsense.org/download/</a></li>
  <li>Recommendation: latest stable ISO version, amd64 architecture</li>
</ul>

<p>Install OPNsense on dedicated hardware or virtualization hypervisor (recommended hypervisors: Proxmox, VMware ESXi, XCP-ng).</p>

<h3 id="network-interfaces">Network Interfaces</h3>

<ul>
  <li>Assign at least two interfaces:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">WAN</code> → ISP modem (public facing)</li>
      <li><code class="language-plaintext highlighter-rouge">LAN</code> → Switch (internal network, client-facing)</li>
    </ul>
  </li>
</ul>

<p>Adjust default interface settings to match your network.</p>

<hr />

<h2 id="step-2---opnsense-configuration-essentials">STEP 2 - OPNsense Configuration Essentials</h2>

<p>Login:<br />
<code class="language-plaintext highlighter-rouge">https://opnsense-ip</code> (Web GUI default user: root, password: opnsense)</p>

<h3 id="lan-interface-configuration">LAN Interface Configuration</h3>

<p>Example addressing scheme:</p>
<ul>
  <li>LAN Network: <code class="language-plaintext highlighter-rouge">192.168.10.0/24</code></li>
  <li>OPNsense LAN IP: <code class="language-plaintext highlighter-rouge">192.168.10.1</code></li>
</ul>

<p>Configure at:</p>
<ul>
  <li>Interfaces → LAN: static IPv4, CIDR <code class="language-plaintext highlighter-rouge">192.168.10.1/24</code></li>
</ul>

<h3 id="dhcp-server-setup">DHCP Server Setup</h3>

<ul>
  <li>In <strong>Services → DHCPv4 → LAN</strong>:
    <ul>
      <li>Enable DHCPv4 server</li>
      <li>Range: <code class="language-plaintext highlighter-rouge">192.168.10.100 - 192.168.10.200</code></li>
      <li>Gateway: <code class="language-plaintext highlighter-rouge">192.168.10.1</code></li>
      <li>DNS Server: Will be assigned later (AdGuard Home)</li>
    </ul>
  </li>
</ul>

<h3 id="firewall-basic-rules-default-recommended-rules">Firewall Basic Rules (default recommended rules):</h3>

<ul>
  <li>LAN interface → allow LAN to Any via IPv4 (default outbound rule provided by OPNsense)</li>
  <li>WAN interface → default deny incoming, allow responses from LAN initiated traffic (default)</li>
</ul>

<hr />

<h2 id="step-3---unbound-dns-configuration-in-opnsense">STEP 3 - Unbound DNS Configuration (In OPNsense)</h2>

<p>Location: <code class="language-plaintext highlighter-rouge">Services → Unbound DNS</code></p>

<ul>
  <li>Enable Unbound service (<strong>check</strong>)</li>
  <li>DNSSEC Validation (<strong>check</strong>)</li>
  <li>Listen interfaces (<strong>check both</strong>): LAN and Localhost only</li>
  <li>Access Lists: Allowed networks (“192.168.10.0/24”)</li>
  <li>Advanced settings (recommended):
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>server:
cache-max-ttl: 86400
cache-min-ttl: 300
num-threads: 2
outgoing-num-tcp: 10
incoming-num-tcp: 10
msg-cache-size: 32m
rrset-cache-size: 64m
infra-cache-numhosts: 5000
infra-host-ttl: 3600
ratelimit: 1000
</code></pre></div>    </div>
  </li>
  <li>Enable DNS rebinding protection (<strong>check</strong>) under System → Settings → Administration → DNS settings (“Enable DNS Rebinding Checks”).</li>
</ul>

<hr />

<h2 id="step-4---docker-host-preparation-adguard-home-or-pi-hole">STEP 4 - Docker Host Preparation (AdGuard Home or Pi-hole)</h2>

<p>Deploy on dedicated physical server or VM, e.g., Ubuntu Server 22.04 LTS:</p>

<h3 id="set-static-ip-on-docker-host-example">Set static IP on Docker host (example):</h3>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo nano /etc/netplan/00-installer-config.yaml
</code></pre></div></div>

<p>Configure static IP:</p>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">network</span><span class="pi">:</span>
  <span class="na">ethernets</span><span class="pi">:</span>
    <span class="na">ens18</span><span class="pi">:</span>
      <span class="na">dhcp4</span><span class="pi">:</span> <span class="kc">false</span>
      <span class="na">addresses</span><span class="pi">:</span> <span class="pi">[</span><span class="nv">192.168.10.5/24</span><span class="pi">]</span>
      <span class="na">gateway4</span><span class="pi">:</span> <span class="s">192.168.10.1</span>
      <span class="na">nameservers</span><span class="pi">:</span>
        <span class="na">addresses</span><span class="pi">:</span> <span class="pi">[</span><span class="nv">192.168.10.1</span><span class="pi">]</span>
  <span class="na">version</span><span class="pi">:</span> <span class="m">2</span>
</code></pre></div></div>

<p>Apply and reboot:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo netplan apply
sudo reboot
</code></pre></div></div>

<h3 id="installing-docker-ubuntu-example">Installing Docker (Ubuntu Example):</h3>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt update
<span class="nb">sudo </span>apt <span class="nb">install </span>ca-certificates curl gnupg apt-transport-https software-properties-common <span class="nt">-y</span>
curl <span class="nt">-fsSL</span> https://download.docker.com/linux/ubuntu/gpg | <span class="nb">sudo </span>gpg <span class="nt">--dearmor</span> <span class="nt">-o</span> /usr/share/keyrings/docker-archive-keyring.gpg
<span class="nb">echo</span> <span class="s2">"deb [arch=</span><span class="si">$(</span>dpkg <span class="nt">--print-architecture</span><span class="si">)</span><span class="s2"> signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu jammy stable"</span> | <span class="nb">sudo tee</span> /etc/apt/sources.list.d/docker.list
<span class="nb">sudo </span>apt update
<span class="nb">sudo </span>apt <span class="nb">install </span>docker-ce docker-ce-cli docker-compose-plugin <span class="nt">-y</span>
<span class="nb">sudo </span>usermod <span class="nt">-aG</span> docker <span class="nv">$USER</span>
<span class="nb">sudo </span>reboot
</code></pre></div></div>

<hr />

<h2 id="step-5---deploy-dns-sinkhole-pick-one">STEP 5 - Deploy DNS Sinkhole (Pick One)</h2>

<h3 id="option-a-adguard-home-via-docker">OPTION A) AdGuard Home via Docker</h3>

<p>Create directories:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> <span class="nt">-p</span> ~/docker/adguard/<span class="o">{</span>work,conf<span class="o">}</span>
</code></pre></div></div>

<p>Launch AdGuard Home via Docker Compose:</p>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ~/docker/adguard/docker-compose.yml</span>
<span class="na">version</span><span class="pi">:</span> <span class="s1">'</span><span class="s">3'</span>
<span class="na">services</span><span class="pi">:</span>
  <span class="na">adguardhome</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">adguard/adguardhome:latest</span>
    <span class="na">container_name</span><span class="pi">:</span> <span class="s">adguardhome</span>
    <span class="na">restart</span><span class="pi">:</span> <span class="s">unless-stopped</span>
    <span class="na">network_mode</span><span class="pi">:</span> <span class="s">host</span>
    <span class="na">volumes</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">./work:/opt/adguardhome/work</span>
      <span class="pi">-</span> <span class="s">./conf:/opt/adguardhome/conf</span>
</code></pre></div></div>

<p>Deploy:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker compose up -d
</code></pre></div></div>

<p>Web login to AdGuard Home at:<br />
<code class="language-plaintext highlighter-rouge">http://192.168.10.5:3000</code></p>

<p>After setup, change DHCP DNS entry in OPNsense DHCP server to <code class="language-plaintext highlighter-rouge">192.168.10.5</code></p>

<h3 id="option-b-pi-hole-via-docker">OPTION B) Pi-hole via Docker</h3>

<p>Create directories:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> <span class="nt">-p</span> ~/docker/pihole/<span class="o">{</span>etc-pihole,etc-dnsmasq.d<span class="o">}</span>
</code></pre></div></div>

<p>Docker Compose YAML (<code class="language-plaintext highlighter-rouge">~/docker/pihole/docker-compose.yml</code>):</p>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">version</span><span class="pi">:</span> <span class="s2">"</span><span class="s">3"</span>
<span class="na">services</span><span class="pi">:</span>
  <span class="na">pihole</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">pihole/pihole:latest</span>
    <span class="na">container_name</span><span class="pi">:</span> <span class="s">pihole</span>
    <span class="na">restart</span><span class="pi">:</span> <span class="s">unless-stopped</span>
    <span class="na">environment</span><span class="pi">:</span>
      <span class="na">TZ</span><span class="pi">:</span> <span class="s1">'</span><span class="s">Europe/Berlin'</span>
      <span class="na">WEBPASSWORD</span><span class="pi">:</span> <span class="s1">'</span><span class="s">StrongPasswordHere'</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">53:53/tcp"</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">53:53/udp"</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">80:80/tcp"</span>
    <span class="na">volumes</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">./etc-pihole:/etc/pihole</span>
      <span class="pi">-</span> <span class="s">./etc-dnsmasq.d:/etc/dnsmasq.d</span>
</code></pre></div></div>

<p>Start Pi-hole:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker compose up -d
</code></pre></div></div>

<p>Access WebGUI at:<br />
<code class="language-plaintext highlighter-rouge">http://192.168.10.5/admin</code></p>

<p>Set DHCP DNS IP to <code class="language-plaintext highlighter-rouge">192.168.10.5</code> in OPNsense DHCP server.</p>

<hr />

<h2 id="step-6---ansible-infrastructure-as-code--backups">STEP 6 - Ansible Infrastructure-as-Code &amp; Backups</h2>

<p>Install Ansible (on local PC, Linux):</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo apt install ansible git -y
</code></pre></div></div>

<p>Project Directory structure:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>homelab-ansible/
├── inventory.yml
├── roles/
│   ├── docker_host/
│   │   └── tasks/main.yml
│   └── opnsense_backup/
│       └── tasks/main.yml
└── site.yml
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">inventory.yml</code>:</p>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">docker_host</span><span class="pi">:</span>
  <span class="na">hosts</span><span class="pi">:</span>
    <span class="na">docker01</span><span class="pi">:</span>
      <span class="na">ansible_host</span><span class="pi">:</span> <span class="s">192.168.10.5</span>
      <span class="na">ansible_user</span><span class="pi">:</span> <span class="s">youruser</span>
<span class="na">opnsense_host</span><span class="pi">:</span>
  <span class="na">hosts</span><span class="pi">:</span>
    <span class="na">firewall</span><span class="pi">:</span>
      <span class="na">ansible_host</span><span class="pi">:</span> <span class="s">192.168.10.1</span>
      <span class="na">ansible_user</span><span class="pi">:</span> <span class="s">root</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">site.yml</code>:</p>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="pi">-</span> <span class="na">hosts</span><span class="pi">:</span> <span class="s">docker_host</span>
  <span class="na">roles</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">docker_host</span>
<span class="pi">-</span> <span class="na">hosts</span><span class="pi">:</span> <span class="s">opnsense_host</span>
  <span class="na">roles</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">opnsense_backup</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">roles/docker_host/tasks/main.yml</code>:</p>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Copy config files and restart containers</span>
  <span class="na">copy</span><span class="pi">:</span>
    <span class="na">src</span><span class="pi">:</span> <span class="s">~/docker/</span>
    <span class="na">dest</span><span class="pi">:</span> <span class="s">~/docker/</span>
  <span class="na">notify</span><span class="pi">:</span> <span class="s">restart docker compose</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">roles/opnsense_backup/tasks/main.yml</code> (ex. OPNsense backup):</p>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Backup OPNsense config.xml</span>
  <span class="na">fetch</span><span class="pi">:</span>
    <span class="na">src</span><span class="pi">:</span> <span class="s">/conf/config.xml</span>
    <span class="na">dest</span><span class="pi">:</span> <span class="s">backups/firewall_config.xml</span>
</code></pre></div></div>

<p>Run Ansible Playbook (periodically):</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ansible-playbook -i inventory.yml site.yml
</code></pre></div></div>

<hr />

<h2 id="step-7---confirm-final-integration">STEP 7 - Confirm Final Integration</h2>

<p>Clients → DHCP DNS server (<code class="language-plaintext highlighter-rouge">192.168.10.5</code>) → AdGuard or Pi-hole → Unbound (OPNsense at <code class="language-plaintext highlighter-rouge">192.168.10.1</code>) → Internet DNS Root servers</p>

<p><strong>Backup strategy</strong> — Fully automated via Ansible, consistently reproducible.</p>

<p>Homelab complete and optimized!</p>]]></content><author><name></name></author><category term="scratchpad" /></entry><entry><title type="html">postmarketOS-powered Kubernetes cluster</title><link href="https://ib.bsb.br/postmarketos-powered-kubernetes-cluster/" rel="alternate" type="text/html" title="postmarketOS-powered Kubernetes cluster" /><published>2025-03-16T00:00:00+00:00</published><updated>2025-03-16T13:57:04+00:00</updated><id>https://ib.bsb.br/postmarketos-powered-kubernetes-cluster</id><content type="html" xml:base="https://ib.bsb.br/postmarketos-powered-kubernetes-cluster/"><![CDATA[<p>Having a few Raspberry Pi 4s at my disposal, I found myself somewhat dissatisfied with their processing capabilities and power management features.
This led me to explore alternative solutions, particularly given the collection of old smartphones gathering dust in my drawer. 
These devices, while outdated for daily use, still pack considerable computing power.
In this article, I’ll walk through how I transformed these old smartphones into a functional Kubernetes cluster using postmarketOS, giving them a second life as computing nodes.</p>

<!--more-->

<!-- toc -->

<h2 id="introduction">Introduction</h2>

<p>Applications nowadays are getting more resource-intensive. Depending on your use case, some of your homelab services might need a lot of processing power and memory.</p>

<p>Some of my (current and future) workloads include:</p>
<ul>
  <li>CI/CD pipelines</li>
  <li>Photo library software such as <a href="https://immich.app/">Immich</a>
    <ul>
      <li>Resizing / converting images</li>
      <li>Running face recognition</li>
    </ul>
  </li>
  <li><a href="https://forgejo.org/">Forgejo</a> (Git)</li>
  <li><a href="https://woodpecker-ci.org/">Woodpecker CI</a></li>
  <li><a href="https://github.com/dani-garcia/vaultwarden">Vaultwarden</a></li>
  <li><a href="https://plex.tv">Plex</a> / <a href="https://jellyfin.org/">Jellyfin</a></li>
  <li><a href="https://github.com/docmost/docmost/">Docmost</a></li>
  <li><a href="https://github.com/teslamate-org/teslamate">Teslamate</a></li>
  <li><a href="https://prometheus.io/">Prometheus</a></li>
  <li><a href="https://grafana.com/">Grafana</a></li>
  <li><a href="https://github.com/lobehub/lobe-chat">LobeChat</a></li>
  <li><a href="https://vikunja.io/">Vikunja</a> (To-Do list)</li>
  <li><a href="https://github.com/gitpod-io/openvscode-server">openvscode-server</a></li>
  <li>…</li>
</ul>

<p>Although it’s rare that single services are so demanding, certain pipelines or workflows can be quite resource-intensive. 
The solution is usually to scale horizontally - but this can be expensive (in terms of money, amount of devices, power consumption, physical space).
Buying new devices is not the most sustainable solution, especially when you’re surrounded by old devices that have a computing power that is comparable or even better than that of your next purchase.</p>

<h2 id="what-are-raspberry-pis-good-for">What are Raspberry Pis good for?</h2>

<p>Raspberry Pis excel at running small services and functioning as <a href="https://gokrazy.org/">appliances</a>. Their GPIO capabilities make them perfect for physical computing projects, but as Kubernetes nodes, they have some limitations.</p>

<p>Here are the main challenges I’ve encountered:</p>
<ul>
  <li>Physical size: With a case, they’re relatively bulky for a computing node</li>
  <li>Power management: One power supply per device is often needed</li>
  <li>Power stability: Multi-port power supplies can be unreliable, causing simultaneous outages across nodes</li>
  <li>Performance: Limited computing power compared to modern mobile processors</li>
  <li>Price: <a href="https://www.digitec.ch/en/s1/product/raspberry-pi-new-raspberry-pi-5-8gb-development-boards-kits-38955607">A Raspberry Pi 5 with 8 GB of RAM</a> costs around <a href="https://www.xe.com/currencyconverter/convert/?Amount=85&amp;From=CHF&amp;To=USD">85 CHF</a>: there are cheaper and more sustainable solutions</li>
</ul>

<p>While I have used several Raspberry Pis for other projects (like my wedding photobooth, which I’ll detail in another post), their I/O capabilities are often underutilized when serving purely as compute nodes.</p>

<h2 id="whats-so-compelling-about-old-smartphones">What’s so compelling about old smartphones?</h2>

<p>On one hand, a Raspberry Pi 4 is a great device for running small services and provides
a very good interface between hardware and software. On the other hand, old smartphones are often discarded due to their outdated software, but they still have a lot of computing power and memory.</p>

<p>Old devices are filling marketplaces and drawers. For a very low price, usually 0 if the device sits in your drawer, you can get a device with an octa-core CPU, 6/8 GB of RAM and 128+ GB of storage.
If you compare this with a Raspberry Pi 4, using an old smarthphone as a computing node could be a good idea.</p>

<h3 id="comparison">Comparison</h3>

<p>Here is a small comparison of some of the devices I have at my disposal:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Device</th>
      <th style="text-align: right">Year</th>
      <th style="text-align: right">Cores</th>
      <th style="text-align: right">Frequencies</th>
      <th style="text-align: right">RAM</th>
      <th style="text-align: right">Storage</th>
      <th>Storage Type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><a href="https://www.gsmarena.com/xiaomi_redmi_note_11_pro_5g-11333.php">Xiaomi Redmi Note 11 Pro</a></td>
      <td style="text-align: right">2022</td>
      <td style="text-align: right">8</td>
      <td style="text-align: right">2x2.2 GHz, 6x1.7 GHz</td>
      <td style="text-align: right">4/6/8GB</td>
      <td style="text-align: right">64/128GB</td>
      <td>UFS 2.2</td>
    </tr>
    <tr>
      <td style="text-align: left"><a href="https://www.gsmarena.com/oneplus_nord-10289.php">Oneplus Nord</a></td>
      <td style="text-align: right">2020</td>
      <td style="text-align: right">8</td>
      <td style="text-align: right">1x2.4 GHz, 1x2.2 GHz, 6x1.8 GHz</td>
      <td style="text-align: right">6/8/12 GB</td>
      <td style="text-align: right">64-256 GB</td>
      <td>UFS 2.1</td>
    </tr>
    <tr>
      <td style="text-align: left"><a href="https://wiki.postmarketos.org/wiki/OnePlus_8_Pro_(oneplus-instantnoodlep)">OnePlus 8 Pro</a></td>
      <td style="text-align: right">2020</td>
      <td style="text-align: right">8</td>
      <td style="text-align: right">1x2.84 GHz, 3x2.42GHz, 4x1.8 GHz</td>
      <td style="text-align: right">8/12 GB</td>
      <td style="text-align: right">128/256 GB</td>
      <td>UFS 3.0</td>
    </tr>
    <tr>
      <td style="text-align: left"><a href="https://en.wikipedia.org/wiki/Raspberry_Pi_4">Raspberry Pi 4</a></td>
      <td style="text-align: right">2019</td>
      <td style="text-align: right">4</td>
      <td style="text-align: right">1.5 GHz</td>
      <td style="text-align: right">2-8 GB</td>
      <td style="text-align: right">External</td>
      <td>microSD</td>
    </tr>
    <tr>
      <td style="text-align: left"><a href="https://wiki.postmarketos.org/wiki/OnePlus_5T_(oneplus-dumpling)">OnePlus 5T</a></td>
      <td style="text-align: right">2017</td>
      <td style="text-align: right">8</td>
      <td style="text-align: right">4x 2.45 GHz, 4x1.9 GHz</td>
      <td style="text-align: right">6/8 GB</td>
      <td style="text-align: right">64/128 GB</td>
      <td>UFS 2.1</td>
    </tr>
  </tbody>
</table>

<p>There’s also inherent value in using smartphones: they come with built-in batteries that function as UPS (Uninterruptible Power Supply) units, and their integrated displays can serve as dashboard monitors. These features provide additional utility without requiring extra hardware components. You can of course turn off the backlight of the display to save power if you don’t need it.</p>

<h2 id="whats-bad-about-linux-on-smartphones">What’s bad about Linux on smartphones?</h2>

<h3 id="no-support-for-mainline-linux">No support for mainline Linux</h3>

<p>Most of the Android smartphones out there have poor support for <em>mainline</em> Linux. The kernel running on the average Android device is generally a heavy customized
version of the Linux kernel. This makes things complicated, and reduces security and performance.</p>

<p>While this is not a problem of the smartphones per se, it’s going to be a problem if you intend to use them as Kubernetes nodes, or use them for anything else that’s not Android.</p>

<h3 id="unlocking-the-bootloader-can-be-tricky">Unlocking the bootloader can be… tricky</h3>

<blockquote>
  <p>[!WARNING]<br />
Unlocking the bootloader will delete all your data. Do not run the following commands if you haven’t backed up your data.</p>
</blockquote>

<p>Not all the devices can be unlocked easily. While some manufacturers allow you to <code class="language-plaintext highlighter-rouge">fastboot oem unlock</code> your device directly, others require you to perform long processes to unlock the bootloader, and sometimes you can’t unlock it at all.</p>

<p>If you’re about to buy an used device for this purpose, make sure the brand is known for allowing bootloader unlocking.</p>

<p>To save you some time, try to generally avoid:</p>
<ul>
  <li>Xiaomi
    <ul>
      <li>Unlocking the bootloader takes from 7 to 30 days to unlock</li>
      <li>During this time, you need to keep the same Xiaomi account connected to the device,</li>
      <li>You’ll have to use a Xiaomi-provided application… but <a href="https://github.com/topminipie/awesome-xiaomi-bootloader-unlock">there are alternatives</a></li>
    </ul>
  </li>
  <li>Huawei / Honor
    <ul>
      <li>You can’t unlock the bootloader anymore</li>
    </ul>
  </li>
</ul>

<p>… and prefer:</p>

<ul>
  <li>Google</li>
  <li>OnePlus</li>
  <li>FairPhone</li>
</ul>

<p>See a complete list on <a href="https://github.com/melontini/bootloader-unlock-wall-of-shame">Bootloader Unlock Wall Of Shame</a>.</p>

<h3 id="gpl-is-not-always-respected">GPL is not always respected</h3>

<p>The Linux kernel is licensed under the GPL, which means that if you modify it, you have to share your modifications.<br />
Despite this, many manufacturers are slow to release the kernel sources, or don’t release them at all.</p>

<p>One example of this is <a href="https://github.com/MiCode/Xiaomi_Kernel_OpenSource/issues">Xiaomi</a> (<a href="https://news.ycombinator.com/item?id=35184859">HN discussion</a>), 
which has been criticized for not releasing the kernel sources for some of their devices.</p>

<h3 id="your-device-is-not-supported">Your device is not supported</h3>

<p>This is not really a problem caused by anyone really, there will always be a device that is not supported by the community - and sometimes <em>you</em> will be the one
that has to put in the legwork to make it work.</p>

<p>I’m by no means a kernel expert, but I’ve tried this road <a href="https://github.com/pixelc-linux/documentation">a couple</a> <a href="https://github.com/linux-surface/surface-pro-x/issues?q=author%3Adenysvitali">of times</a> - and, while it might be challenging, it’s a very rewarding process and you get to learn a lot about how these devices work. 
In the next sections you’ll see what I mean by this.</p>

<p>Despite this, you can still play it safe and buy an used device that is already (partially) <a href="https://wiki.postmarketos.org/wiki/Devices">supported by the community</a>.</p>

<p>Before you complain about the lack of support for your device: make sure to also check the “Testing” section of the <a href="https://wiki.postmarketos.org/wiki/Devices">postmarketOS Devices</a> page:
it’s easy to miss that part and might sound scary, but a “testing” device is generally just a device that doesn’t have full support for all the features and that doesn’t have a ready to use firmware image. With <a href="https://docs.postmarketos.org/pmbootstrap/usage.html"><code class="language-plaintext highlighter-rouge">pmbootstrap</code></a> setting up an already upstreamed testing device is really a breeze!</p>

<h2 id="what-is-postmarketos">What is postmarketOS?</h2>

<p>Okay, we mentioned it a couple of times already, but I didn’t explain what the heck <a href="https://postmarketos.org/">postmarketOS</a> is: the shortest way to describe it is by saying that it’s a rolling Linux distribution for smartphones based on <a href="https://alpinelinux.org/">Alpine Linux</a>.</p>

<p>The interesting part of this distribution is that <em>it’s meant to be run with the mainline Linux kernel</em>. This effectively means that postmarketOS is not just another Android ROM: it is the key to the long-term support of the devices.</p>

<p>Whilst I haven’t seen anyone (yet) really using pmOS as a daily driver, and I myself am not doing that either (I’m using <a href="https://grapheneos.org/">GrapheneOS</a>).</p>

<p>Being a Linux distribution based on Alpine, you can really use your smartphone as if it’s a computer (or in my case, a server): this means that you can install for example <a href="https://swaywm.org/">sway</a>, <a href="https://kde.org/">KDE</a> or literally <a href="https://wiki.postmarketos.org/wiki/Category:Interface">any other desktop environment / user interfaces</a> you want and run your favorite applications.</p>

<h2 id="state-of-linux-on-arm">State of Linux on ARM</h2>

<p>With the <a href="https://en.wikipedia.org/wiki/Apple_M1">“recent” Apple Silicon push</a> and the amazing work of <a href="https://github.com/aarch64-laptops">aarch64-laptops</a> / <a href="https://www.linaro.org/">Linaro</a> (<a href="https://old.linaro.org/blog/porting-linux-to-aarch64-laptops/">thanks</a> Bjorn &amp; team!), Linux on ARM is growing fast and it’s supported by many distros / forks (such as <a href="https://archlinuxarm.org/">Arch Linux ARM</a>, <a href="https://wiki.alpinelinux.org/wiki/Alpine_on_ARM">Alpine Linux</a>, <a href="https://wiki.debian.org/Arm64Port#Official_Debian_port">Debian</a>, …) - so using a smartphone as a server / computer is not that crazy anymore as mobile devices aren’t that different from (new) laptops anymore.</p>

<p>There are still a few assumptions made by some software distributors (especially Docker Images) where they assume that you’re running on <code class="language-plaintext highlighter-rouge">x86_64</code>, but this is getting better and better, especially given the “recent” additions of <a href="https://docs.docker.com/build/building/multi-platform/">multi-platform builds</a> on Docker.</p>

<p>If that’s your thing, you can also connect a mouse, keyboard (and monitor) to your device and use it as a desktop computer.</p>

<h2 id="setting-up-a-node">Setting up a node</h2>

<h3 id="lessons-learned">Lessons learned</h3>

<p>Before I start with the details, I want to immediately share some lessons learned - so that you can avoid some of the mistakes I made:</p>

<ul>
  <li>
    <p><strong>Don’t spend half a day debugging <code class="language-plaintext highlighter-rouge">iptables</code></strong>: postmarketOS comes with <code class="language-plaintext highlighter-rouge">nftables</code> and the default rules in <code class="language-plaintext highlighter-rouge">/etc/nftables.nft</code> are the reason why your Kubernetes network might get messed up</p>
  </li>
  <li>
    <p>Docker, Kubernetes and K3s require some kernel modules / configs to be enabled:</p>
    <ul>
      <li>
        <p>Try to run a Docker container first, and eventually use <a href="https://github.com/moby/moby/blob/master/contrib/check-config.sh">moby’s <code class="language-plaintext highlighter-rouge">check-config.sh</code></a></p>
      </li>
      <li>
        <p>Use <a href="https://github.com/k3s-io/k3s/blob/master/contrib/util/check-config.sh">k3s’s <code class="language-plaintext highlighter-rouge">check-config.sh</code></a> to check if your kernel is ready. In my case (<a href="https://wiki.postmarketos.org/wiki/OnePlus_5T_(oneplus-dumpling)"><code class="language-plaintext highlighter-rouge">dumpling</code></a> was missing some kernel configs, but <a href="https://wiki.postmarketos.org/wiki/OnePlus_8_Pro_(oneplus-instantnoodlep)"><code class="language-plaintext highlighter-rouge">instantnoodlep</code></a> was fine)</p>
      </li>
      <li>
        <p>Kubernetes doesn’t come with a <code class="language-plaintext highlighter-rouge">check-config.sh</code> file - but your Container Network Interface (CNI) might require some kernel features that Docker / K3s don’t need. In the case of Flannel, make sure you have most / all the <code class="language-plaintext highlighter-rouge">CONFIG_NETFILTER_XTABLES</code> options enabled in your kernel, as well as <code class="language-plaintext highlighter-rouge">CONFIG_VXLAN</code>.</p>
      </li>
    </ul>
  </li>
</ul>

<h3 id="oneplus-5t-dumpling">OnePlus 5T (dumpling)</h3>

<p>According to the <a href="https://wiki.postmarketos.org/wiki/OnePlus_5T_(oneplus-dumpling)">postmarketOS wiki</a>, the OnePlus 5T is a “testing” device, which means that it’s not fully supported yet. Despite this, I was able to run postmarketOS on it without any issue.</p>

<p>The most important features for me (Wi-Fi) and USB ethernet worked out of the box.</p>

<p>If, like me, this is your first time running postmarketOS - one nice feature is that they support USB ethernet out of the box. Initially, I thought this meant supporting an USB to Ethernet adapter, but it actually means that you can connect your smartphone to your computer, and this will be recognized as an USB ethernet device.</p>

<pre><code class="language-plain">% ip addr show enp0s20f0u1
149: enp0s20f0u1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000
    link/ether ca:fe:ba:be:00:42 brd ff:ff:ff:ff:ff:ff
    inet 172.16.42.2/24 brd 172.16.42.255 scope global dynamic noprefixroute enp0s20f0u1
       valid_lft 3628776sec preferred_lft 3628776sec
    inet6 fe80::504a:1ee0:5015:da8d/64 scope link noprefixroute
       valid_lft forever preferred_lft forever
</code></pre>

<p>With this, you can simply SSH into your device and start working on it:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>ssh root@172.16.42.1
Welcome to postmarketOS! o/

This distribution is based on Alpine Linux.
First <span class="nb">time </span>using postmarketOS? Make sure to <span class="nb">read </span>the cheatsheet <span class="k">in </span>the wiki:

-&gt; https://postmarketos.org/cheatsheet

You may change this message by editing /etc/motd.
dumpling:~#
</code></pre></div></div>

<blockquote>
  <p>[!TIP]<br />
For whatever reason, after many tries, I started using the wrong IP (<code class="language-plaintext highlighter-rouge">172.16.42.2</code>) to SSH into the device and got confused on why it wasn’t accepting my device password anymore. Don’t be as dumb as me and double check the IP you’re <code class="language-plaintext highlighter-rouge">ssh</code>ing into, which should be <code class="language-plaintext highlighter-rouge">172.16.42.1</code>.</p>
</blockquote>

<h4 id="connecting-the-device-to-the-wi-fi">Connecting the device to the Wi-Fi</h4>

<p>Now that you’re able to connect to the device, you should be able to see <code class="language-plaintext highlighter-rouge">wlan0</code> as an interface:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>ip addr show wlan0
4: wlan0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP qlen 1000
    <span class="nb">link</span>/ether 02:00:00:00:00:00 brd ff:ff:ff:ff:ff:ff
</code></pre></div></div>

<p>this means that you’re ready to connect to your Wi-Fi network!</p>

<p>You can check the list of Wi-Fi networks with <a href="https://wiki.archlinux.org/title/NetworkManager">NetworkManager</a>’s CLI:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>nmcli d wifi
IN-USE  BSSID              SSID                   MODE   CHAN  RATE        SIGNAL  BARS  SECURITY
        00:00:00:00:00:00  MyNetwork              Infra  1     54 Mbit/s  100     ▂▄▆█  WPA2
</code></pre></div></div>

<p>If you want to connect to a network, you can use the following command:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nmcli d wifi connect MyNetwork <span class="nt">--ask</span>
</code></pre></div></div>

<p>this assumes that the network is visible, and it will ask you for the password.</p>

<p>If you want to connect to a hidden network, you can use the following command:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">HIDDEN_SSID</span><span class="o">=</span><span class="s2">"your_ssid"</span>
nmcli d wifi connect <span class="nt">--ask</span> <span class="s2">"</span><span class="nv">$HIDDEN_SSID</span><span class="s2">"</span> name <span class="s2">"</span><span class="nv">$HIDDEN_SSID</span><span class="s2">"</span> hidden <span class="nb">yes</span>
</code></pre></div></div>

<p>If everything went well, NetworkManager will tell you that you’re connected to the network:</p>

<pre><code class="language-plain">Connection successfully activated (D-Bus active path: /org/freedesktop/NetworkManager/ActiveConnection/1)
</code></pre>

<h4 id="using-the-device-as-a-kubernetes-node">Using the device as a Kubernetes node</h4>

<blockquote>
  <p>[!IMPORTANT]
This part shows how the process of setting up Kubernetes on <code class="language-plaintext highlighter-rouge">dumpling</code> should look like - unfortunately this isn’t exactly how it should be done as of today. Do not follow all these steps blindly - read the full section first :)</p>
</blockquote>

<p>Since our goal is to use this device as a Kubernetes node, we’ll have to configure the device accordingly. In my setup, I’ll be using <a href="https://k3s.io/">k3s</a>, a lightweight Kubernetes distribution that is perfect for low-resource devices.</p>

<p>This part assumes that you’ve already setup the master node(s) somewhere else, but if you want this to be the master node, you can adapt my steps and follow the <a href="https://docs.k3s.io/installation/configuration">documentation</a>.</p>

<p>Assuming:</p>
<ul>
  <li>A master node with the IP <code class="language-plaintext highlighter-rouge">192.168.10.11</code></li>
  <li>A token to join the cluster <code class="language-plaintext highlighter-rouge">000000::server::f0000</code></li>
</ul>

<h5 id="installing-k3s">Installing <code class="language-plaintext highlighter-rouge">k3s</code></h5>

<p>If you haven’t done so during the pmOS wizard, you can <code class="language-plaintext highlighter-rouge">apk add k3s</code> to install k3s on your device.</p>

<h5 id="configuring-k3s-agent">Configuring <code class="language-plaintext highlighter-rouge">k3s</code> agent</h5>

<p>Create an <code class="language-plaintext highlighter-rouge">/etc/rancher/k3s/config.yaml</code> file as follows:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">token</span><span class="pi">:</span> <span class="s2">"</span><span class="s">000000::server::f0000"</span>
<span class="na">server</span><span class="pi">:</span> <span class="s2">"</span><span class="s">https://192.168.10.11:6443"</span>
<span class="na">prefer-bundled-bin</span><span class="pi">:</span> <span class="kc">true</span>
<span class="na">flannel-iface</span><span class="pi">:</span> <span class="s">wlan0</span>
<span class="na">with-node-id</span><span class="pi">:</span> <span class="kc">true</span>
<span class="na">node-label</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">com.example.mylabel/type=foo</span>
    <span class="pi">-</span> <span class="s">com.example.mylabel/net=wireless</span>
</code></pre></div></div>

<p>This configuration file will tell <code class="language-plaintext highlighter-rouge">k3s</code> to connect to the master node, and to use the <code class="language-plaintext highlighter-rouge">wlan0</code> interface for the <a href="https://www.sysspace.net/post/kubernetes-networking-explained-flannel-network-model_">Flannel</a> network.</p>

<p>Make sure the <code class="language-plaintext highlighter-rouge">/etc/conf.d/k3s</code> file has the following content:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="s2">"/usr/libexec/cni/:</span><span class="nv">$PATH</span><span class="s2">"</span>
<span class="nv">K3S_EXEC</span><span class="o">=</span><span class="s2">"agent"</span>
<span class="nv">K3S_OPTS</span><span class="o">=</span><span class="s2">""</span>
</code></pre></div></div>

<p>This will make sure that we start <code class="language-plaintext highlighter-rouge">k3s</code> in agent mode, and that we can use the <code class="language-plaintext highlighter-rouge">cni</code> binaries (for flannel).</p>

<h5 id="starting-k3s">Starting <code class="language-plaintext highlighter-rouge">k3s</code></h5>

<p>You can now start <code class="language-plaintext highlighter-rouge">k3s</code> (once) and enable it at boot:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>service k3s start
rc-update add k3s
</code></pre></div></div>

<p>You can now check the logs with <code class="language-plaintext highlighter-rouge">tail -f /var/log/k3s.log</code> and see if the node is joining the cluster…</p>

<p>… except that, it won’t work.</p>

<h5 id="missing-kernel-features">Missing kernel features</h5>

<p>If you haven’t skipped over the “Lessons learned” section, you might have noticed that I mentioned that you should check if your kernel is ready for Docker / Kubernetes / K3s. We generally take for granted that the kernels shipped with our distributions are ready for using containers and orchestrators, but this is not always the case.</p>

<p>Specifically, in the case of the <code class="language-plaintext highlighter-rouge">dumpling</code> kernel (<code class="language-plaintext highlighter-rouge">msm8998</code>), it seems like the <a href="https://gitlab.postmarketos.org/postmarketOS/pmaports/-/blob/master/device/testing/linux-postmarketos-qcom-msm8998/config-postmarketos-qcom-msm8998.aarch64">kernel config</a> is missing some key features that are required to run <code class="language-plaintext highlighter-rouge">docker</code> and <code class="language-plaintext highlighter-rouge">k3s</code>.</p>

<p>You can get a list of all the missing configs by running k3s’s <a href="https://github.com/k3s-io/k3s/blob/master/contrib/util/check-config.sh"><code class="language-plaintext highlighter-rouge">check-config.sh</code></a> script.</p>

<h5 id="recompiling-the-kernel">Recompiling the kernel</h5>

<p>Thankfully, changing the kernel configuration is pretty straightforward. You can follow the <a href="https://wiki.postmarketos.org/wiki/Kernel_configuration/Adjusting_one_kernel">postmarketOS Kernel configuration/Adjusting one kernel</a> to get started.</p>

<p>In my case, it was as easy as running:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pmbootstrap kconfig edit linux-postmarketos-qcom-msm8998
</code></pre></div></div>

<p>I then <code class="language-plaintext highlighter-rouge">/</code> searched for the needed config entries as reported by <code class="language-plaintext highlighter-rouge">check-config.sh</code> and enabled them. This was enough to run some Docker containers, but apparently not enough to have a fully working Kubernetes node as the flannel network was not working.</p>

<p>For this, you’ll most likely need to enable all the <code class="language-plaintext highlighter-rouge">NETFILTER_XTABLES_*</code> options. Although probably unnecessary, you can find my kernel config <a href="https://pastebin.com/pnNXrhb0">here</a>.</p>

<h5 id="trying-again">Trying again</h5>

<p>After recompiling the kernel, copying and installing resulting <code class="language-plaintext highlighter-rouge">.apk</code> file (<code class="language-plaintext highlighter-rouge">scp linux-postmarketos-qcom-msm8998-6.0-r2.apk root@dumpling</code> and <code class="language-plaintext highlighter-rouge">apk add -u linux-postmarketos-qcom-msm8998-6.0-r2.apk</code>) and rebooting, I was able to start <code class="language-plaintext highlighter-rouge">k3s</code> and see the node joining the cluster.</p>

<p>Unfortunately, in that moment, my cluster started having some issues. After a quick diagnosis, I found out that DNS resolution was broken. This made me realize the newly joined node was able to pull images from the internet, but the containers themselves were not able to reach the internet.</p>

<h5 id="network-issues">Network issues</h5>

<p>To debug the network issues, I’ve used <code class="language-plaintext highlighter-rouge">netshoot</code>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl run tmp-shell <span class="nt">--rm</span> <span class="nt">-i</span> <span class="nt">--tty</span> <span class="nt">--image</span> nicolaka/netshoot
</code></pre></div></div>

<p>This spawned a shell in a container that had all the network tools I needed to debug the issue. Of course I had to make sure that the container was running on the affected node (I actually used a <code class="language-plaintext highlighter-rouge">DaemonSet</code> to make sure it was running on all the nodes).</p>

<p>The problems were:</p>

<ul>
  <li>None of the containers were able to reach the internet
    <ul>
      <li><code class="language-plaintext highlighter-rouge">ping 1.1.1.1</code> was not working</li>
    </ul>
  </li>
  <li>Containers on the same network (node) were not able to reach each other
    <ul>
      <li><code class="language-plaintext highlighter-rouge">ping 10.42.3.11</code> was not working from <code class="language-plaintext highlighter-rouge">10.42.3.13</code></li>
    </ul>
  </li>
  <li>Containers on different networks (on another node) were not able to reach each other
    <ul>
      <li><code class="language-plaintext highlighter-rouge">ping 10.42.1.10</code> was not working from <code class="language-plaintext highlighter-rouge">10.42.0.3</code></li>
      <li>Flannel was likely not working here</li>
    </ul>
  </li>
</ul>

<pre><code class="language-plain"># tcpdump -i any icmp
tcpdump: WARNING: any: That device doesn't support promiscuous mode
(Promiscuous mode not supported on the "any" device)
tcpdump: verbose output suppressed, use -v[v]... for full protocol decode
listening on any, link-type LINUX_SLL2 (Linux cooked v2), snapshot length 262144 bytes
11:22:21.229307 veth50680d5c P   IP 10.42.3.13 &gt; 10.42.3.11: ICMP echo request, id 10, seq 1, length 64
11:22:22.264132 veth50680d5c P   IP 10.42.3.13 &gt; 10.42.3.11: ICMP echo request, id 10, seq 2, length 64
11:22:23.288137 veth50680d5c P   IP 10.42.3.13 &gt; 10.42.3.11: ICMP echo request, id 10, seq 3, length 64
11:22:24.312629 veth50680d5c P   IP 10.42.3.13 &gt; 10.42.3.11: ICMP echo request, id 10, seq 4, length 64
11:22:25.336390 veth50680d5c P   IP 10.42.3.13 &gt; 10.42.3.11: ICMP echo request, id 10, seq 5, length 64

</code></pre>

<p>After investigating further, I discovered that there was a problem with the packet forwarding: none of the packets were being forwarded. The strangest part was that the <code class="language-plaintext highlighter-rouge">iptables -t nat</code> rules were correct, and nothing strange was happening in the <code class="language-plaintext highlighter-rouge">FORWARD</code> chain.</p>

<p>This kept me busy for a very long time as I was going crazy trying to understand why the packets were being dropped despite being allowed by <code class="language-plaintext highlighter-rouge">iptables</code>…</p>

<h5 id="the-solution">The solution</h5>

<p>As spoilered in the “Lessons learned” section, the issue was with the <code class="language-plaintext highlighter-rouge">nftables</code> rules that were blocking the traffic. This took me an incredible amount of time to figure out, because I assumed that the issue was with either flannel using wthe wrong interface, with the kernel configuration or with… iptables.</p>

<p>If you’re not aware of the difference between <code class="language-plaintext highlighter-rouge">iptables</code> and <code class="language-plaintext highlighter-rouge">nftables</code>, <a href="https://wiki.archlinux.org/title/Nftables"><code class="language-plaintext highlighter-rouge">nftables</code></a> is pretty much the new default in the Linux kernel (previously, it was <code class="language-plaintext highlighter-rouge">iptables</code>), and nowadays <code class="language-plaintext highlighter-rouge">iptables</code> <em>should</em> just be a frontend for <code class="language-plaintext highlighter-rouge">nftables</code>.</p>

<p>Unfortunately for me, the <code class="language-plaintext highlighter-rouge">nftables</code> rules were not visible from <code class="language-plaintext highlighter-rouge">iptables</code> (the opposite is true) - which made me investigate the wrong part of the system for a long time.</p>

<p>After adapting the <code class="language-plaintext highlighter-rouge">/etc/nftables.nft</code> file (as follows), the containers on the node were finally able to reach the internet and the other containers in the cluster.</p>

<pre><code class="language-plain">#!/usr/sbin/nft -f
# vim: set ts=4 sw=4:
# You can find examples in /usr/share/nftables/.

# Clear all prior state
flush ruleset

# The state of stateful objects saved on the nftables service stop.
include "/var/lib/nftables/*.nft"

# Rules
</code></pre>

<h5 id="final-steps">Final steps</h5>

<p>After fixing the issues with the network, I was able to run some workloads on the node. Since this node is connected via Wi-Fi and I can only get around 200 Mbit/s of DL and UL - I’ve marked this node with a label (<code class="language-plaintext highlighter-rouge">com.example.mylabel/net=wireless</code>) so that I can schedule workloads that are not latency or network intensive.</p>

<p>To finish the setup, I’ve created an Ansible playbook with the steps above and added one finishing touch:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">echo </span>0 <span class="o">&gt;</span> /sys/class/backlight/c994000.dsi.0/brightness
</code></pre></div></div>

<p>This command completely turns off the backlight of the display, saving lots of power.</p>

<h3 id="oneplus-8-pro-instantnoodlep">OnePlus 8 Pro (instantnoodlep)</h3>

<p>After the experience with the OnePlus 5T, I decided it was time to extend my cluster by adding another device.
With the learnings from the previous experience and the promising features list (Wi-Fi marked as working, mainline kernel, USB Networking working), I decided to go with the OnePlus 8 Pro.</p>

<p>I’ve followed the same steps as before, and then, as soon as I wrote <code class="language-plaintext highlighter-rouge">ip link show wlan0</code>, I realized there was something wrong…</p>

<pre><code class="language-plain">$ ip link show wlan0
ip: can't find device 'wlan0'
</code></pre>

<p>… what?</p>

<h4 id="a-missing-wi-fi-chip">A missing Wi-Fi chip</h4>

<p>After reading the <code class="language-plaintext highlighter-rouge">dmesg</code> output and trying to find references to the Wi-Fi / BT chip (QCA6390), I realized that the <a href="https://wiki.postmarketos.org/wiki/Device_Tree_(dtb)">Device Tree (dtb)</a> was missing the Wi-Fi / Bluetooth chip.</p>

<p>I wasn’t quickly able to spot the issue there, so I decided to look on the internet for answers - and that’s where I found something that at the time looked promising: <a href="https://patches.linaro.org/project/linux-input/patch/20240624-oneplus8-v1-7-388eecf2dff7@postmarketos.org/">a patch to add support for the OnePlus 8T (kebab)</a> (which is pretty much the same as the OnePlus 8 Pro).</p>

<p>I therefore decided to try out the patch - I cloned the kernel repository, applied the patch, compiled the DTS (<code class="language-plaintext highlighter-rouge">make dtbs</code>) and obtained the new <code class="language-plaintext highlighter-rouge">dtb</code> file.</p>

<h4 id="using-the-newly-built-dtb">Using the newly built DTB</h4>

<p>Since I didn’t want to follow the full <code class="language-plaintext highlighter-rouge">.img</code> creating process, I decided to unpack the original <code class="language-plaintext highlighter-rouge">boot.img</code> file and re-pack it with my own <code class="language-plaintext highlighter-rouge">dtb</code> file:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>unpack_bootimg <span class="nt">--boot_img</span> <span class="nv">$PMOS_ROOT</span>/chroot_rootfs_oneplus-instantnoodlep/boot/boot.img <span class="nt">--format</span><span class="o">=</span>mkbootimg
<span class="nv">$ </span><span class="nb">cp</span> ~/git/linux/arch/arm64/boot/dts/qcom/sm8250-oneplus-instantnoodlep.dtb /tmp/firmware/out/dtb
<span class="nv">$ </span>mkbootimg <span class="nt">--header_version</span> 2 <span class="nt">--kernel</span> out/kernel <span class="nt">--ramdisk</span> out/ramdisk <span class="nt">--dtb</span> out/dtb <span class="nt">--pagesize</span> 0x00001000 <span class="nt">--base</span> 0x00000000 <span class="nt">--kernel_offset</span> 0x00008000 <span class="nt">--ramdisk_offset</span> 0x01000000 <span class="nt">--second_offset</span> 0x00000000 <span class="nt">--tags_offset</span> 0x00000100 <span class="nt">--dtb_offset</span> 0x0000000001f00000 <span class="nt">--board</span> <span class="s1">''</span> <span class="nt">--cmdline</span> <span class="s1">'clk_ignore_unused pd_ignore_unused  pmos_boot_uuid=d86a5f31-2802-4333-b5aa-ff8a59e4d66e pmos_root_uuid=efbc85d5-1ba9-45ff-af90-1eecd5235327 pmos_rootfsopts=defaults'</span> <span class="nt">-o</span> boot-repacked.img
</code></pre></div></div>

<p>With the new image ready to be flashed, I connected the device to my computer and ran the following command:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>fastboot flash boot boot-repacked.img
<span class="nv">$ </span>fastboot reboot
</code></pre></div></div>

<p>… and the device didn’t boot.</p>

<h4 id="trying-one-small-change-at-the-time">Trying one small change at the time</h4>

<p>When a device doesn’t boot and you don’t have a serial console - you’re pretty much clueless on what’s going on.
The only thing you can really do is to go back to the last working state (in my case, the original <code class="language-plaintext highlighter-rouge">dtb</code>) and try to change one small thing at the time until you find the issue.</p>

<p>In this particular phase, I’ve tried to adapt the <code class="language-plaintext highlighter-rouge">dtb</code> by following other references: the <a href="https://gitlab.com/sm8250-mainline"><code class="language-plaintext highlighter-rouge">sm8250-mainline</code></a> kernel already includes lots of other devices using the same chip and with a similar configuration. For example, the <a href="https://wiki.postmarketos.org/wiki/Xiaomi_Mi_Pad_5_Pro_(xiaomi-elish)">Xiaomi Mi Pad 5 Pro (elish)</a> used the same chip and described it as being part of the PCI0 port as seen in its dts file: <a href="https://gitlab.com/sm8250-mainline/linux/-/blob/sm8250/v6.11/arch/arm64/boot/dts/qcom/sm8250-xiaomi-elish-common.dtsi?ref_type=heads#L824-839">
<code class="language-plaintext highlighter-rouge">sm8250-xiaomi-elish-common.dtsi</code></a>.</p>

<p>Additionally, the device tree also described <a href="https://gitlab.com/sm8250-mainline/linux/-/blob/sm8250/v6.11/arch/arm64/boot/dts/qcom/sm8250-xiaomi-elish-common.dtsi?ref_type=heads#L1008-1022">some GPIOs to enable the chip</a>, together with a <a href="https://gitlab.com/sm8250-mainline/linux/-/blob/sm8250/v6.11/arch/arm64/boot/dts/qcom/sm8250-xiaomi-elish-common.dtsi?ref_type=heads#L108-167">voltage regulator</a> to power the chip.</p>

<p>After many trial and errors in adapting and stiching together some configuration, I was finally able to see the chip getting recognized:</p>

<pre><code class="language-plain"># dmesg | grep ath11k
[   11.524348] ath11k_pci 0000:01:00.0: Adding to iommu group 13
[   11.524578] ath11k_pci 0000:01:00.0: BAR 0 [mem 0x60400000-0x604fffff 64bit]: assigned
[   11.524642] ath11k_pci 0000:01:00.0: enabling device (0000 -&gt; 0002)
[   11.524983] ath11k_pci 0000:01:00.0: MSI vectors: 32
[   11.525005] ath11k_pci 0000:01:00.0: qca6390 hw2.0
[   12.796173] ath11k_pci 0000:01:00.0: chip_id 0x0 chip_family 0xb board_id 0xff soc_id 0xffffffff
[   12.796205] ath11k_pci 0000:01:00.0: fw_version 0x10121492 fw_build_timestamp 2021-11-04 11:23 fw_build_id
</code></pre>

<p>I then checked that the adapter was being recognized (<code class="language-plaintext highlighter-rouge">ip link show wlan0</code>) and tried to connect to my Wi-Fi network.
Everything worked perfectly: I was able to join this device to the cluster and run some workloads on it, as with the previous device.</p>

<p>Since I deeply care about reducing e-waste and getting others to use their old devices, I’ve submitted my patch to the <a href="https://gitlab.com/sm8250-mainline/linux/-/merge_requests/8">sm8250-mainline kernel repo</a> and added a note on the <a href="https://wiki.postmarketos.org/wiki/OnePlus_8_Pro_(oneplus-instantnoodlep)#Known_Issues">device page</a> until the patch is picked up by the postmarketOS kernel.</p>

<h4 id="backlight">Backlight</h4>

<p>Unfortunately this device doesn’t have the backlight described in the device tree, and it’s therefore not possible (at the moment) to turn it off. This is not a big issue for me, but it would be a good candidate for a future patch.</p>

<h2 id="conclusion">Conclusion</h2>

<p>After joining the second node to the cluster, I have now a small cluster of 3 nodes that I can use to run my workloads, and I’m happy that I can reuse old devices that would have otherwise kept collecting dust in my drawer.</p>

<pre><code class="language-plain">$ kubectl get nodes
NAME                               STATUS   ROLES                  AGE    VERSION
k3s-node-dumpling-cf0b07d4         Ready    &lt;none&gt;                 15d    v1.31.2-k3s1
k3s-node-instantnoodlep-e577c75e   Ready    &lt;none&gt;                 2d8h   v1.31.2-k3s1
master-1                           Ready    control-plane,master   14d    v1.31.2-k3s1
</code></pre>

<h3 id="pre-built-images">Pre-built images</h3>

<p>Since I’ve spent quite some time re-packing the boot image for <code class="language-plaintext highlighter-rouge">instantnoodlep</code>, I’ve decided to share the <code class="language-plaintext highlighter-rouge">boot.img</code>.
Granted that you should never trust a random kernel image from the internet, this could save you a bit of time.</p>

<ul>
  <li><a href="https://drive.google.com/file/d/1pQ5A0yJDBMO92uh4-qROcdpHTemuzKGx/view?usp=sharing"><code class="language-plaintext highlighter-rouge">boot-repacked.img</code></a></li>
</ul>]]></content><author><name></name></author><category term="scratchpad" /></entry><entry><title type="html">Web scraping and RSS aggregation using older devices</title><link href="https://ib.bsb.br/web-scraping-and-rss-aggregation-using-older-devices/" rel="alternate" type="text/html" title="Web scraping and RSS aggregation using older devices" /><published>2025-03-16T00:00:00+00:00</published><updated>2025-03-17T15:23:51+00:00</updated><id>https://ib.bsb.br/web-scraping-and-rss-aggregation-using-older-devices</id><content type="html" xml:base="https://ib.bsb.br/web-scraping-and-rss-aggregation-using-older-devices/"><![CDATA[<p>1) CHOOSE AND INSTALL A LIGHTWEIGHT OPERATING SYSTEM</p>

<p>• Netbooks: Install a lightweight distro such as Debian, Xubuntu, or MX Linux (32-bit if needed, otherwise 64-bit).<br />
• Raspberry Pi 3B: Use Raspberry Pi OS (Lite version for minimal resources, or the standard Raspberry Pi OS if you prefer a GUI).</p>

<p>2) SYSTEM PREPARATION AND SECURITY</p>

<p>• Update Package Repositories:
  sudo apt-get update &amp;&amp; sudo apt-get upgrade -y
• (Optional) Harden SSH:</p>
<ul>
  <li>Disable password-based authentication:
sudo nano /etc/ssh/sshd_config<br />
PasswordAuthentication no</li>
  <li>Use keys or a well-managed password system if you prefer.<br />
• Install some helpful tools:
  sudo apt-get install git curl wget nano ufw -y</li>
</ul>

<p>3) SET UP BASIC PROJECT ENVIRONMENT</p>

<p>a) Create a dedicated directory:
  mkdir -p ~/personal_info_retrieval<br />
  cd ~/personal_info_retrieval</p>

<p>b) Install Python 3 and pip (if not already):
  sudo apt-get install python3 python3-pip python3-venv -y</p>

<p>c) Create a Python virtual environment:
  python3 -m venv venv<br />
  source venv/bin/activate</p>

<p>d) Install important libraries:
  pip install requests beautifulsoup4 feedparser lxml</p>

<p>4) RSS AGGREGATION (SIMPLER, LOW-RESOURCE TASK)</p>

<p>RSS (Really Simple Syndication) is an XML-based feed that many websites and blogs provide for publishing their updates.</p>

<p>a) Minimal Example Script (rss_aggregator.py):</p>

<p>#!/usr/bin/env python3
import feedparser
import datetime</p>

<p>RSS_FEEDS = [
    “https://example.com/feed”,
    “https://anotherexample.com/rss”,
]</p>

<p>def fetch_rss(feed_url):
    return feedparser.parse(feed_url)</p>

<p>if <strong>name</strong> == “<strong>main</strong>”:
    for feed_url in RSS_FEEDS:
        feed_data = fetch_rss(feed_url)
        print(f”=== {feed_url} ===”)
        for entry in feed_data.entries[:5]:  # Limit to 5 items
            published_time = entry.get(“published”, “No date”)
            title = entry.get(“title”, “No title”)
            link  = entry.get(“link”, “”)
            print(f”{published_time} | {title} | {link}”)
        print()</p>

<p>• Save the file:
  nano rss_aggregator.py<br />
  (Paste in the script)<br />
  chmod +x rss_aggregator.py</p>

<p>• Run manually:
  ./rss_aggregator.py</p>

<p>b) Extended or More Advanced RSS Readers:
• Tiny Tiny RSS (TT-RSS), Miniflux, or FreshRSS can run on older hardware without heavy overhead.<br />
• If you want a GUI-based feed reader on a netbook, consider Newsboat (terminal-based) or Liferea (lightweight desktop application).</p>

<p>5) BASIC WEB SCRAPING WORKFLOW</p>

<p>Scraping retrieves HTML directly and extracts desired information—headlines, prices, etc.</p>

<p>a) Example: Basic Python Scraper (scraper.py)</p>

<p>#!/usr/bin/env python3
import requests
from bs4 import BeautifulSoup
import datetime</p>

<p>URLS = [
    “https://example.com/news”,
    “https://anotherexample.org/blog”,
]</p>

<p>def scrape_site(url):
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, “lxml”)
        headlines = [h2.get_text(strip=True) for h2 in soup.find_all(‘h2’)]</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    return {
        "timestamp": datetime.datetime.now().isoformat(),
        "url": url,
        "headlines": headlines
    }
except Exception as e:
    return {"error": str(e)}
</code></pre></div></div>

<p>if <strong>name</strong> == “<strong>main</strong>”:
    for link in URLS:
        data = scrape_site(link)
        print(data)</p>

<p>• Save and run:
  nano scraper.py<br />
  chmod +x scraper.py<br />
  ./scraper.py</p>

<p>b) Notes on Performance:
• Limit the depth of scraping. Stick to single pages or specifically targeted pages rather than crawling the entire domain.<br />
• Consider short timeouts (5–10 seconds) to prevent old devices from hanging if a site is unresponsive.</p>

<p>6) STORING AND MANAGING SCRAPED DATA</p>

<p>Double-check you don’t fill your HDD with logs or data.</p>

<p>a) SQLite Database (light footprint):
• Install:
  sudo apt-get install sqlite3<br />
• Python usage:
  pip install sqlite3 (some distributions already have the sqlite3 module built in)
• In your Python script:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  import sqlite3
  
  conn = sqlite3.connect("mydata.db")
  c = conn.cursor()
  c.execute("""CREATE TABLE IF NOT EXISTS headlines (
               date TEXT,
               source_url TEXT,
               headline TEXT
             )""")
  # Insert data
  c.execute("INSERT INTO headlines VALUES (?, ?, ?)", (timestamp, url, headline))
  conn.commit()
  conn.close()
</code></pre></div></div>

<p>b) Simple Files or CSV:
• If your data volume is low, store results in JSON or CSV.<br />
• Example (appending JSON lines):</p>

<p>import json</p>

<p>with open(“scraped_data.json”, “a”) as f:
      json.dump(data_dict, f)
      f.write(“\n”)</p>

<p>7) AUTOMATION WITH CRON</p>

<p>Use cron to schedule tasks so your netbook or Pi does not require manual intervention.</p>

<ol>
  <li>Edit crontab:
crontab -e</li>
  <li>Add lines like:</li>
</ol>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   # Run RSS aggregator every 6 hours
   0 */6 * * * /home/pi/personal_info_retrieval/venv/bin/python /home/pi/personal_info_retrieval/rss_aggregator.py &gt;&gt; /home/pi/rss_aggregator.log 2&gt;&amp;1
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   # Run web scraper every day at 01:00
   0 1 * * * /home/pi/personal_info_retrieval/venv/bin/python /home/pi/personal_info_retrieval/scraper.py &gt;&gt; /home/pi/scraper.log 2&gt;&amp;1
</code></pre></div></div>

<p>Adjust paths and times as needed. This ensures automatic updates without using extra memory.</p>

<p>8) LIGHTWEIGHT DASHBOARD OR OUTPUT VIEW</p>

<p>You can visualize your data in a minimal form:</p>

<p>• Console Tools:</p>
<ul>
  <li>Use simple CLI-based viewers (less, cat, sqlite3 interactive shell).
• Simple Web Interface (Flask):
    <ol>
      <li>pip install flask</li>
      <li>Example snippet:</li>
    </ol>

    <p>from flask import Flask, jsonify
 import json</p>

    <p>app = Flask(<strong>name</strong>)</p>

    <p>@app.route(“/”)
 def home():
     with open(“scraped_data.json”, “r”) as f:
         lines = f.read().strip().split(“\n”)
         results = [json.loads(line) for line in lines]
     return jsonify(results)</p>

    <p>if <strong>name</strong> == “<strong>main</strong>”:
     app.run(host=”0.0.0.0”, port=5000)</p>
  </li>
</ul>

<p>• Access from LAN:
  http://<DEVICE_IP>:5000</DEVICE_IP></p>

<p>9) HARDWARE AND PERFORMANCE TIPS</p>

<p>• Use minimal or no GUI on older netbooks and the Pi 3B.<br />
• Avoid persistent high CPU tasks. Space out scrape intervals to prevent HDD thrashing.<br />
• Maintain a single “control node” (e.g., Pi 3B) with data stored locally, and you can run remote scraping scripts on netbooks that send results back via scp/rsync if desired.<br />
• Keep the entire environment updated to avoid library vulnerabilities.</p>

<p>10) TROUBLESHOOTING</p>

<p>• If scraping fails or times out, check connectivity, site structure changes, or blocklists. Adjust user-agent or add small random sleep intervals in the script to avoid being flagged as a bot.<br />
• If the device slows down or runs hot, lower the scraping frequency.<br />
• If storage becomes scarce on the HDD, rotate or prune old data.</p>

<p>CONCLUSION</p>

<p>Following this guide, your 2010-era netbooks and Raspberry Pi 3B can continuously gather and organize online content with minimal overhead. RSS aggregation provides a quick, low-resource approach for sites offering feeds, while web scraping covers any sources lacking an accessible feed. By tying everything together with lightweight databases or file logging and a simple cron schedule, you can maintain efficient, automated personalized information retrieval despite modest hardware resources.</p>]]></content><author><name></name></author><category term="scratchpad" /></entry></feed>
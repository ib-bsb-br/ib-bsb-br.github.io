<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://ib.bsb.br/feed.xml" rel="self" type="application/atom+xml" /><link href="https://ib.bsb.br/" rel="alternate" type="text/html" /><updated>2026-01-07T22:11:59+00:00</updated><id>https://ib.bsb.br/feed.xml</id><title type="html">infoBAG</title><entry><title type="html">AGENTS.md</title><link href="https://ib.bsb.br/agentsmd/" rel="alternate" type="text/html" title="AGENTS.md" /><published>2026-01-07T00:00:00+00:00</published><updated>2026-01-07T15:02:26+00:00</updated><id>https://ib.bsb.br/agentsMD</id><content type="html" xml:base="https://ib.bsb.br/agentsmd/"><![CDATA[<section class="code-block-container" role="group" aria-label="Markdown Code Block" data-filename="markdown_code_block.md" data-code="&lt;purpose&gt;
  You are a terminal-safe coding agent. Complete [[task_request]] while guaranteeing that no single line written to stdout/stderr exceeds 4096 bytes (hard limit). Prevent session resets by wrapping, chunking, paging, or redirecting output before any potentially long print.
&lt;/purpose&gt;

&lt;context&gt;
  &lt;environment&gt;
    &lt;terminal_output_limit_bytes&gt;4096&lt;/terminal_output_limit_bytes&gt;
    &lt;failure_mode&gt;Any single output line above the limit crashes the session and resets state.&lt;/failure_mode&gt;
    &lt;note_on_bytes_vs_chars&gt;
      The limit is in bytes; assume worst-case and use a conservative wrap width (e.g., 1200–1500 characters) to stay well below 4096.
    &lt;/note_on_bytes_vs_chars&gt;
  &lt;/environment&gt;

  &lt;constraints&gt;
    &lt;constraint&gt;Hard invariant: never emit a line that could exceed 4096 bytes.&lt;/constraint&gt;
    &lt;constraint&gt;All shell command output MUST be piped as: `[[command]] 2&gt;&amp;1 | fold -w 1500`.&lt;/constraint&gt;
    &lt;constraint&gt;If output may include very long tokens (minified files, base64, JSON one-liners), redirect to a file first, then inspect in small slices, folded.&lt;/constraint&gt;
    &lt;constraint&gt;For remote content, do not dump via curl/wget; fetch programmatically (Python) and hard-wrap before printing.&lt;/constraint&gt;
    &lt;constraint&gt;Chunk/paginate large outputs; never dump entire large documents in one go.&lt;/constraint&gt;
    &lt;constraint&gt;Install any needed Python libraries only inside .venv using: `uv pip install &lt;pkg&gt;`.&lt;/constraint&gt;
    &lt;constraint&gt;Do not print secrets (tokens/keys/private material). If detected, redact or omit.&lt;/constraint&gt;
  &lt;/constraints&gt;

  &lt;domain_notes&gt;
    &lt;note&gt;Common crash sources: minified JS/CSS/HTML, JSON printed in compact form, stack traces with giant embedded payloads, long single-line logs, base64 blobs.&lt;/note&gt;
    &lt;note&gt;Safer defaults beat cleverness: when uncertain, wrap + redirect + slice.&lt;/note&gt;
  &lt;/domain_notes&gt;
&lt;/context&gt;

&lt;variables&gt;
  &lt;variable name=&quot;[[task_request]]&quot; required=&quot;true&quot;&gt;
    &lt;description&gt;Natural-language description of the task to complete.&lt;/description&gt;
  &lt;/variable&gt;
  &lt;variable name=&quot;[[command]]&quot; required=&quot;false&quot;&gt;
    &lt;description&gt;A shell command to run. If multiple commands, run one at a time with safe wrapping.&lt;/description&gt;
  &lt;/variable&gt;
  &lt;variable name=&quot;[[file_path]]&quot; required=&quot;false&quot;&gt;
    &lt;description&gt;Local file to inspect safely (logs, JSON, build artifacts).&lt;/description&gt;
  &lt;/variable&gt;
  &lt;variable name=&quot;[[url]]&quot; required=&quot;false&quot;&gt;
    &lt;description&gt;Remote resource to fetch; must be retrieved via Python then wrapped.&lt;/description&gt;
  &lt;/variable&gt;
  &lt;variable name=&quot;[[segment_start]]&quot; required=&quot;false&quot;&gt;
    &lt;description&gt;Optional slice start index for paginating text.&lt;/description&gt;
  &lt;/variable&gt;
  &lt;variable name=&quot;[[segment_end]]&quot; required=&quot;false&quot;&gt;
    &lt;description&gt;Optional slice end index for paginating text.&lt;/description&gt;
  &lt;/variable&gt;
&lt;/variables&gt;

&lt;instructions&gt;
  &lt;instruction&gt;1. Restate [[task_request]] as a single, concrete goal statement.&lt;/instruction&gt;

  &lt;instruction&gt;2. Before running any shell command [[command]], rewrite it into a safe form that captures stderr and wraps output: &lt;code&gt;[[command]] 2&gt;&amp;1 | fold -w 1500&lt;/code&gt;.&lt;/instruction&gt;

  &lt;instruction&gt;3. If [[file_path]] is provided, inspect safely:
    (a) size/lines via &lt;code&gt;wc -c&lt;/code&gt; and &lt;code&gt;wc -l&lt;/code&gt;;
    (b) preview with &lt;code&gt;head&lt;/code&gt;/&lt;code&gt;tail&lt;/code&gt;;
    (c) search with &lt;code&gt;rg -n&lt;/code&gt;;
    (d) always pipe through fold.
  &lt;/instruction&gt;

  &lt;instruction&gt;4. If [[url]] is provided, fetch programmatically (Python). Strip HTML if applicable, then hard-wrap text (e.g., 3500–4000 chars max) and print only a bounded slice or a limited number of wrapped lines.&lt;/instruction&gt;

  &lt;instruction&gt;5. If any output could still be huge after wrapping, redirect to a file and page through it (small slices). Do not print the entire content.&lt;/instruction&gt;

  &lt;instruction&gt;6. If you need Python dependencies (requests, beautifulsoup4), install them inside .venv using &lt;code&gt;uv pip install&lt;/code&gt; before importing.&lt;/instruction&gt;

  &lt;instruction&gt;7. Final self-check before responding: verify every emitted block is wrapped/chunked, no secrets are present, and no line plausibly exceeds 4096 bytes.&lt;/instruction&gt;
&lt;/instructions&gt;

&lt;output_format_specification&gt;
  &lt;format&gt;Plain text&lt;/format&gt;
  &lt;requirements&gt;
    &lt;requirement&gt;Commands must be presented in copy/paste-ready form, already made safe.&lt;/requirement&gt;
    &lt;requirement&gt;Response must be both thorough, comprehensive, exhaustive, complete, and in-depth in its detail, as well as wide-ranging, broad, vast, widespread, and far-reaching in its scope.&lt;/requirement&gt;
    &lt;requirement&gt;Never output unwrapped large data; use slices.&lt;/requirement&gt;
  &lt;/requirements&gt;
&lt;/output_format_specification&gt;

&lt;examples&gt;
  &lt;example&gt;
    &lt;input_data&gt;
      &lt;task_request&gt;Run a build command safely and preserve full logs.&lt;/task_request&gt;
      &lt;command&gt;./build&lt;/command&gt;
    &lt;/input_data&gt;
    &lt;output&gt;
      ./build 2&gt;&amp;1 | fold -w 1500

      If output is large, redirect first:
      ./build 2&gt;&amp;1 | fold -w 1500 &gt; build.log
      wc -l build.log 2&gt;&amp;1 | fold -w 1500
      tail -n 200 build.log 2&gt;&amp;1 | fold -w 1500
    &lt;/output&gt;
  &lt;/example&gt;

  &lt;example&gt;
    &lt;input_data&gt;
      &lt;task_request&gt;Pretty-print JSON safely (avoid single-line JSON).&lt;/task_request&gt;
      &lt;file_path&gt;data.json&lt;/file_path&gt;
    &lt;/input_data&gt;
    &lt;output&gt;
      wc -c data.json 2&gt;&amp;1 | fold -w 1500
      jq . data.json 2&gt;&amp;1 | fold -w 1500 | sed -n &#39;1,200p&#39;
    &lt;/output&gt;
  &lt;/example&gt;

  &lt;example&gt;
    &lt;input_data&gt;
      &lt;task_request&gt;Fetch a large HTML documentation page without crashing the session.&lt;/task_request&gt;
      &lt;url&gt;https://example.com/big-doc&lt;/url&gt;
    &lt;/input_data&gt;
    &lt;output&gt;
      python - &lt;&lt;&#39;PY&#39;
      import requests, textwrap
      from bs4 import BeautifulSoup

      url = &quot;https://example.com/big-doc&quot;
      html = requests.get(url, timeout=15).text
      text = BeautifulSoup(html, &quot;html.parser&quot;).get_text(&quot;\n&quot;)
      wrapped = &quot;\n&quot;.join(textwrap.wrap(text, width=3500))
      print(wrapped[:20000])  # bounded slice
      PY
    &lt;/output&gt;
  &lt;/example&gt;

  &lt;example&gt;
    &lt;input_data&gt;
      &lt;task_request&gt;Investigate a huge log for exceptions and show only the relevant region.&lt;/task_request&gt;
      &lt;file_path&gt;server.log&lt;/file_path&gt;
    &lt;/input_data&gt;
    &lt;output&gt;
      rg -n &quot;ERROR|Exception&quot; server.log 2&gt;&amp;1 | fold -w 1500 | head -n 50
      # After identifying line numbers, print a tight range:
      sed -n &#39;1200,1300p&#39; server.log 2&gt;&amp;1 | fold -w 1500
    &lt;/output&gt;
  &lt;/example&gt;

  &lt;example&gt;
    &lt;input_data&gt;
      &lt;task_request&gt;Handle base64 or minified one-liners (worst-case line length).&lt;/task_request&gt;
      &lt;file_path&gt;payload.txt&lt;/file_path&gt;
    &lt;/input_data&gt;
    &lt;output&gt;
      # Never cat directly. Redirect/transform then fold:
      wc -c payload.txt 2&gt;&amp;1 | fold -w 1500
      fold -w 1200 payload.txt 2&gt;&amp;1 | sed -n &#39;1,80p&#39;
    &lt;/output&gt;
  &lt;/example&gt;
&lt;/examples&gt;

&lt;self_check&gt;
  &lt;checklist&gt;
    &lt;item&gt;Did I rewrite every shell command to include: 2&gt;&amp;1 | fold -w 1500?&lt;/item&gt;
    &lt;item&gt;Did I avoid printing full large blobs and instead use slices?&lt;/item&gt;
    &lt;item&gt;For remote pages, did I fetch via Python and hard-wrap before printing?&lt;/item&gt;
    &lt;item&gt;Did I redact or avoid any secrets?&lt;/item&gt;
    &lt;item&gt;Would any produced line plausibly exceed 4096 bytes?&lt;/item&gt;
  &lt;/checklist&gt;
&lt;/self_check&gt;

&lt;evaluation_notes&gt;
  &lt;test_cases&gt;
    &lt;case&gt;Minified JS/CSS/HTML file inspection&lt;/case&gt;
    &lt;case&gt;Large compact JSON (single-line) handling&lt;/case&gt;
    &lt;case&gt;Stack trace containing embedded payloads&lt;/case&gt;
    &lt;case&gt;Binary-ish or base64-heavy logs&lt;/case&gt;
  &lt;/test_cases&gt;
  &lt;success_definition&gt;Session does not reset due to long lines; relevant context is still retrievable via safe slicing.&lt;/success_definition&gt;
&lt;/evaluation_notes&gt;

&lt;documentation&gt;
  &lt;usage&gt;
    &lt;step&gt;Replace placeholders with real task/command/url/file values gathered from the USER&#39;s queries.&lt;/step&gt;
    &lt;step&gt;Follow the safe rewrite patterns exactly; default to redirect+slice when uncertain.&lt;/step&gt;
  &lt;/usage&gt;
  &lt;known_limitations&gt;
    &lt;limitation&gt;Byte vs character encoding can be tricky; conservative fold widths reduce risk.&lt;/limitation&gt;
    &lt;limitation&gt;Some outputs include control characters; redirect to file and inspect with safe tools.&lt;/limitation&gt;
  &lt;/known_limitations&gt;
&lt;/documentation&gt;" data-download-link="" data-download-label="Download Markdown">
  <code class="language-markdown">&lt;purpose&gt;
  You are a terminal-safe coding agent. Complete [[task_request]] while guaranteeing that no single line written to stdout/stderr exceeds 4096 bytes (hard limit). Prevent session resets by wrapping, chunking, paging, or redirecting output before any potentially long print.
&lt;/purpose&gt;

&lt;context&gt;
  &lt;environment&gt;
    &lt;terminal_output_limit_bytes&gt;4096&lt;/terminal_output_limit_bytes&gt;
    &lt;failure_mode&gt;Any single output line above the limit crashes the session and resets state.&lt;/failure_mode&gt;
    &lt;note_on_bytes_vs_chars&gt;
      The limit is in bytes; assume worst-case and use a conservative wrap width (e.g., 1200–1500 characters) to stay well below 4096.
    &lt;/note_on_bytes_vs_chars&gt;
  &lt;/environment&gt;

  &lt;constraints&gt;
    &lt;constraint&gt;Hard invariant: never emit a line that could exceed 4096 bytes.&lt;/constraint&gt;
    &lt;constraint&gt;All shell command output MUST be piped as: `[[command]] 2&gt;&amp;1 | fold -w 1500`.&lt;/constraint&gt;
    &lt;constraint&gt;If output may include very long tokens (minified files, base64, JSON one-liners), redirect to a file first, then inspect in small slices, folded.&lt;/constraint&gt;
    &lt;constraint&gt;For remote content, do not dump via curl/wget; fetch programmatically (Python) and hard-wrap before printing.&lt;/constraint&gt;
    &lt;constraint&gt;Chunk/paginate large outputs; never dump entire large documents in one go.&lt;/constraint&gt;
    &lt;constraint&gt;Install any needed Python libraries only inside .venv using: `uv pip install &lt;pkg&gt;`.&lt;/constraint&gt;
    &lt;constraint&gt;Do not print secrets (tokens/keys/private material). If detected, redact or omit.&lt;/constraint&gt;
  &lt;/constraints&gt;

  &lt;domain_notes&gt;
    &lt;note&gt;Common crash sources: minified JS/CSS/HTML, JSON printed in compact form, stack traces with giant embedded payloads, long single-line logs, base64 blobs.&lt;/note&gt;
    &lt;note&gt;Safer defaults beat cleverness: when uncertain, wrap + redirect + slice.&lt;/note&gt;
  &lt;/domain_notes&gt;
&lt;/context&gt;

&lt;variables&gt;
  &lt;variable name=&quot;[[task_request]]&quot; required=&quot;true&quot;&gt;
    &lt;description&gt;Natural-language description of the task to complete.&lt;/description&gt;
  &lt;/variable&gt;
  &lt;variable name=&quot;[[command]]&quot; required=&quot;false&quot;&gt;
    &lt;description&gt;A shell command to run. If multiple commands, run one at a time with safe wrapping.&lt;/description&gt;
  &lt;/variable&gt;
  &lt;variable name=&quot;[[file_path]]&quot; required=&quot;false&quot;&gt;
    &lt;description&gt;Local file to inspect safely (logs, JSON, build artifacts).&lt;/description&gt;
  &lt;/variable&gt;
  &lt;variable name=&quot;[[url]]&quot; required=&quot;false&quot;&gt;
    &lt;description&gt;Remote resource to fetch; must be retrieved via Python then wrapped.&lt;/description&gt;
  &lt;/variable&gt;
  &lt;variable name=&quot;[[segment_start]]&quot; required=&quot;false&quot;&gt;
    &lt;description&gt;Optional slice start index for paginating text.&lt;/description&gt;
  &lt;/variable&gt;
  &lt;variable name=&quot;[[segment_end]]&quot; required=&quot;false&quot;&gt;
    &lt;description&gt;Optional slice end index for paginating text.&lt;/description&gt;
  &lt;/variable&gt;
&lt;/variables&gt;

&lt;instructions&gt;
  &lt;instruction&gt;1. Restate [[task_request]] as a single, concrete goal statement.&lt;/instruction&gt;

  &lt;instruction&gt;2. Before running any shell command [[command]], rewrite it into a safe form that captures stderr and wraps output: &lt;code&gt;[[command]] 2&gt;&amp;1 | fold -w 1500&lt;/code&gt;.&lt;/instruction&gt;

  &lt;instruction&gt;3. If [[file_path]] is provided, inspect safely:
    (a) size/lines via &lt;code&gt;wc -c&lt;/code&gt; and &lt;code&gt;wc -l&lt;/code&gt;;
    (b) preview with &lt;code&gt;head&lt;/code&gt;/&lt;code&gt;tail&lt;/code&gt;;
    (c) search with &lt;code&gt;rg -n&lt;/code&gt;;
    (d) always pipe through fold.
  &lt;/instruction&gt;

  &lt;instruction&gt;4. If [[url]] is provided, fetch programmatically (Python). Strip HTML if applicable, then hard-wrap text (e.g., 3500–4000 chars max) and print only a bounded slice or a limited number of wrapped lines.&lt;/instruction&gt;

  &lt;instruction&gt;5. If any output could still be huge after wrapping, redirect to a file and page through it (small slices). Do not print the entire content.&lt;/instruction&gt;

  &lt;instruction&gt;6. If you need Python dependencies (requests, beautifulsoup4), install them inside .venv using &lt;code&gt;uv pip install&lt;/code&gt; before importing.&lt;/instruction&gt;

  &lt;instruction&gt;7. Final self-check before responding: verify every emitted block is wrapped/chunked, no secrets are present, and no line plausibly exceeds 4096 bytes.&lt;/instruction&gt;
&lt;/instructions&gt;

&lt;output_format_specification&gt;
  &lt;format&gt;Plain text&lt;/format&gt;
  &lt;requirements&gt;
    &lt;requirement&gt;Commands must be presented in copy/paste-ready form, already made safe.&lt;/requirement&gt;
    &lt;requirement&gt;Response must be both thorough, comprehensive, exhaustive, complete, and in-depth in its detail, as well as wide-ranging, broad, vast, widespread, and far-reaching in its scope.&lt;/requirement&gt;
    &lt;requirement&gt;Never output unwrapped large data; use slices.&lt;/requirement&gt;
  &lt;/requirements&gt;
&lt;/output_format_specification&gt;

&lt;examples&gt;
  &lt;example&gt;
    &lt;input_data&gt;
      &lt;task_request&gt;Run a build command safely and preserve full logs.&lt;/task_request&gt;
      &lt;command&gt;./build&lt;/command&gt;
    &lt;/input_data&gt;
    &lt;output&gt;
      ./build 2&gt;&amp;1 | fold -w 1500

      If output is large, redirect first:
      ./build 2&gt;&amp;1 | fold -w 1500 &gt; build.log
      wc -l build.log 2&gt;&amp;1 | fold -w 1500
      tail -n 200 build.log 2&gt;&amp;1 | fold -w 1500
    &lt;/output&gt;
  &lt;/example&gt;

  &lt;example&gt;
    &lt;input_data&gt;
      &lt;task_request&gt;Pretty-print JSON safely (avoid single-line JSON).&lt;/task_request&gt;
      &lt;file_path&gt;data.json&lt;/file_path&gt;
    &lt;/input_data&gt;
    &lt;output&gt;
      wc -c data.json 2&gt;&amp;1 | fold -w 1500
      jq . data.json 2&gt;&amp;1 | fold -w 1500 | sed -n &#39;1,200p&#39;
    &lt;/output&gt;
  &lt;/example&gt;

  &lt;example&gt;
    &lt;input_data&gt;
      &lt;task_request&gt;Fetch a large HTML documentation page without crashing the session.&lt;/task_request&gt;
      &lt;url&gt;https://example.com/big-doc&lt;/url&gt;
    &lt;/input_data&gt;
    &lt;output&gt;
      python - &lt;&lt;&#39;PY&#39;
      import requests, textwrap
      from bs4 import BeautifulSoup

      url = &quot;https://example.com/big-doc&quot;
      html = requests.get(url, timeout=15).text
      text = BeautifulSoup(html, &quot;html.parser&quot;).get_text(&quot;\n&quot;)
      wrapped = &quot;\n&quot;.join(textwrap.wrap(text, width=3500))
      print(wrapped[:20000])  # bounded slice
      PY
    &lt;/output&gt;
  &lt;/example&gt;

  &lt;example&gt;
    &lt;input_data&gt;
      &lt;task_request&gt;Investigate a huge log for exceptions and show only the relevant region.&lt;/task_request&gt;
      &lt;file_path&gt;server.log&lt;/file_path&gt;
    &lt;/input_data&gt;
    &lt;output&gt;
      rg -n &quot;ERROR|Exception&quot; server.log 2&gt;&amp;1 | fold -w 1500 | head -n 50
      # After identifying line numbers, print a tight range:
      sed -n &#39;1200,1300p&#39; server.log 2&gt;&amp;1 | fold -w 1500
    &lt;/output&gt;
  &lt;/example&gt;

  &lt;example&gt;
    &lt;input_data&gt;
      &lt;task_request&gt;Handle base64 or minified one-liners (worst-case line length).&lt;/task_request&gt;
      &lt;file_path&gt;payload.txt&lt;/file_path&gt;
    &lt;/input_data&gt;
    &lt;output&gt;
      # Never cat directly. Redirect/transform then fold:
      wc -c payload.txt 2&gt;&amp;1 | fold -w 1500
      fold -w 1200 payload.txt 2&gt;&amp;1 | sed -n &#39;1,80p&#39;
    &lt;/output&gt;
  &lt;/example&gt;
&lt;/examples&gt;

&lt;self_check&gt;
  &lt;checklist&gt;
    &lt;item&gt;Did I rewrite every shell command to include: 2&gt;&amp;1 | fold -w 1500?&lt;/item&gt;
    &lt;item&gt;Did I avoid printing full large blobs and instead use slices?&lt;/item&gt;
    &lt;item&gt;For remote pages, did I fetch via Python and hard-wrap before printing?&lt;/item&gt;
    &lt;item&gt;Did I redact or avoid any secrets?&lt;/item&gt;
    &lt;item&gt;Would any produced line plausibly exceed 4096 bytes?&lt;/item&gt;
  &lt;/checklist&gt;
&lt;/self_check&gt;

&lt;evaluation_notes&gt;
  &lt;test_cases&gt;
    &lt;case&gt;Minified JS/CSS/HTML file inspection&lt;/case&gt;
    &lt;case&gt;Large compact JSON (single-line) handling&lt;/case&gt;
    &lt;case&gt;Stack trace containing embedded payloads&lt;/case&gt;
    &lt;case&gt;Binary-ish or base64-heavy logs&lt;/case&gt;
  &lt;/test_cases&gt;
  &lt;success_definition&gt;Session does not reset due to long lines; relevant context is still retrievable via safe slicing.&lt;/success_definition&gt;
&lt;/evaluation_notes&gt;

&lt;documentation&gt;
  &lt;usage&gt;
    &lt;step&gt;Replace placeholders with real task/command/url/file values gathered from the USER&#39;s queries.&lt;/step&gt;
    &lt;step&gt;Follow the safe rewrite patterns exactly; default to redirect+slice when uncertain.&lt;/step&gt;
  &lt;/usage&gt;
  &lt;known_limitations&gt;
    &lt;limitation&gt;Byte vs character encoding can be tricky; conservative fold widths reduce risk.&lt;/limitation&gt;
    &lt;limitation&gt;Some outputs include control characters; redirect to file and inspect with safe tools.&lt;/limitation&gt;
  &lt;/known_limitations&gt;
&lt;/documentation&gt;</code>
</section>]]></content><author><name></name></author><category term="AI&gt;prompt" /></entry><entry><title type="html">better call saul</title><link href="https://ib.bsb.br/saul/" rel="alternate" type="text/html" title="better call saul" /><published>2026-01-07T00:00:00+00:00</published><updated>2026-01-07T13:59:22+00:00</updated><id>https://ib.bsb.br/saul</id><content type="html" xml:base="https://ib.bsb.br/saul/"><![CDATA[<section class="code-block-container" role="group" aria-label="Markdown Code Block" data-filename="markdown_code_block.md" data-code="&lt;purpose&gt;
    Você é um assistente especializado em leitura crítica de processos no SEI (Sistema Eletrônico de Informações) e redação de peças jurídico-administrativas.
    Com base no conteúdo fornecido em [[conteudo_processo]], bem como no ordenamento jurídico brasileiro (Constituição Federal de 1988, Emendas Constitucionais, Tratados Internacionais de Direitos Humanos, Leis Complementares, Leis Ordinárias, Leis Delegadas, Medidas Provisórias, Decretos Legislativos, Resoluções, Tratados Internacionais Comuns, Decretos Autônomos, Decretos Regulamentares, Portarias, Instruções Normativas, Convenções e Acordos Coletivos de Trabalho, Súmulas Vinculantes, Jurisprudência, Súmulas Comuns, Doutrina, Costumes, Princípios Gerais do Direito) você deve:
    (1) reconstruir a linha do tempo do Processo SEI nº &lt;!-- placeholder_sei --&gt;;
    (2) classificar o tipo de procedimento (ex.: PAD/sindicância vs. processo administrativo geral vs. rito específico indicado no próprio processo; etc.);
    (3) identificar o estágio atual do fluxo processual com evidências explícitas;
    (4) redigir a peça cabível e suficiente a ser apresentada pela parte denominada &lt;!-- placeholder_parte --&gt; para dar continuidade ao devido processo.
    Sucesso = diagnóstico auditável + peça pronta para protocolo + anexos/checklist, sem invenções.
  &lt;/purpose&gt;

  &lt;context&gt;
    &lt;style_guide&gt;
      &lt;language&gt;pt-BR&lt;/language&gt;
      &lt;format&gt;The response must be both thorough, comprehensive, exhaustive, complete, and in-depth in its detail, as well as wide-ranging, broad, vast, widespread, and far-reaching in its scope.&lt;/format&gt;
    &lt;/style_guide&gt;

    &lt;ethical_guardrails&gt;
      &lt;rule&gt;Não invente fatos, datas, atos, decisões, prazos, autoridades, unidades ou documentos.&lt;/rule&gt;
      &lt;rule&gt;Cite normativos/artigos/incisos específicos se eles estiverem presentes em [[conteudo_processo]], ou no ordenamento jurídico brasileiro (Constituição Federal de 1988, Emendas Constitucionais, Tratados Internacionais de Direitos Humanos, Leis Complementares, Leis Ordinárias, Leis Delegadas, Medidas Provisórias, Decretos Legislativos, Resoluções, Tratados Internacionais Comuns, Decretos Autônomos, Decretos Regulamentares, Portarias, Instruções Normativas, Convenções e Acordos Coletivos de Trabalho, Súmulas Vinculantes, Jurisprudência, Súmulas Comuns, Doutrina, Costumes, Princípios Gerais do Direito).&lt;/rule&gt;
      &lt;rule&gt;Se algo essencial estiver ausente (ex.: última decisão, data de ciência, regra de prazo), declare “não determinável com os dados fornecidos” e liste a lacuna.&lt;/rule&gt;
    &lt;/ethical_guardrails&gt;

    &lt;constraints&gt;
      &lt;constraint&gt;Baseie toda a análise e a redação apenas em [[conteudo_processo]], bem como no ordenamento jurídico brasileiro (Constituição Federal de 1988, Emendas Constitucionais, Tratados Internacionais de Direitos Humanos, Leis Complementares, Leis Ordinárias, Leis Delegadas, Medidas Provisórias, Decretos Legislativos, Resoluções, Tratados Internacionais Comuns, Decretos Autônomos, Decretos Regulamentares, Portarias, Instruções Normativas, Convenções e Acordos Coletivos de Trabalho, Súmulas Vinculantes, Jurisprudência, Súmulas Comuns, Doutrina, Costumes, Princípios Gerais do Direito).&lt;/constraint&gt;
      &lt;constraint&gt;Use evidências curtas e rastreáveis (título da peça + data; se houver, identificador do documento SEI e/ou página/trecho curto; etc.).&lt;/constraint&gt;
      &lt;constraint&gt;O resultado final deve ser protocolável no SEI (texto final coeso, pedidos claros e anexos listados).&lt;/constraint&gt;
    &lt;/constraints&gt;
  &lt;/context&gt;

  &lt;instructions&gt;
    &lt;instruction&gt;1) Leitura: leia integralmente [[conteudo_processo]].&lt;/instruction&gt;

    &lt;instruction&gt;2) Extração estruturada: identifique e liste (com evidência) as peças/atos do processo (ex.: requerimentos, despachos, decisões, notificações/intimações, recursos, encaminhamentos, pareceres, etc.).&lt;/instruction&gt;

    &lt;instruction&gt;3) Linha do tempo: construa uma tabela com colunas: Data | Peça/Ato | Unidade/Autoridade | Efeito processual (abre prazo? decide? diligencia? encaminha?) | Evidência (referência curta).&lt;/instruction&gt;

    &lt;instruction&gt;4) Classificação do procedimento (obrigatória): com base em evidência textual, classifique o procedimento (ex.: (A) PAD/sindicância (sinais: portaria de instauração, comissão, termo de indiciação, instrução, defesa, relatório); (B) processo administrativo geral/recursal (sinais: decisão administrativa, ciência, pedido de reconsideração, recurso, autoridade superior); (C) rito específico (se o processo mencionar norma/rito próprio); etc.). Se não houver evidência suficiente, declare “tipo não identificável” e prossiga com cautela.&lt;/instruction&gt;

    &lt;instruction&gt;5) Diagnóstico do estágio processual: identifique o ato mais recente e determine o estágio atual do fluxo processual, escolhendo entre estados como, por exemplo:
      - aguardando ciência/intimação
      - prazo aberto para manifestação/recurso
      - pedido de reconsideração cabível/pendente
      - recurso interposto aguardando admissibilidade/encaminhamento
      - em juízo de retratação/decisão recursal
      - diligência/complementação pendente
      - decisão recursal proferida aguardando cumprimento
      - etc.
      Se houver mais de uma interpretação plausível, apresente hipóteses com critérios e evidências.&lt;/instruction&gt;

    &lt;instruction&gt;6) Prazos (somente se determinável): se houver data de ciência/intimação e regra de prazo explícita no processo, calcule a data-limite e registre. Caso contrário, escreva “prazo não determinável com os dados fornecidos”.&lt;/instruction&gt;

    &lt;instruction&gt;7) Seleção da peça “cabível e suficiente”: com base no estágio identificado, escolha a peça adequada (ex.: manifestação, juntada/cumprimento de diligência, pedido de reconsideração, recurso administrativo/hierárquico, pedido de prosseguimento, etc.). Explique por que essa é a peça correta para o estágio.&lt;/instruction&gt;

    &lt;instruction&gt;8) Redação da peça final: redija o documento completo para protocolo no SEI, com:
      (a) Endereçamento: use a autoridade/unidade explicitamente indicada como competente no processo; se não existir indicação clara, use forma neutra (“À Autoridade Competente/À Unidade Responsável pelo Processo”).
      (b) Referência: Processo SEI nº &lt;!-- placeholder_sei --&gt;.
      (c) Qualificação: &lt;!-- placeholder_parte --&gt; conforme constar no processo (sem inventar dados).
      (d) Descrição do histórico com marcos relevantes.
      (e) Fundamentação: fatos e, quando aplicável, referências a atos normativos mencionados no conteúdo do próprio processo ou que compõem o ordenamento jurídico brasileiro.
      (f) Pedidos: numerados, objetivos, coerentes com o estágio (ex.: recebimento, conhecimento, encaminhamento, juntada, reabertura de prazo se cabível e fundamentada por evidência do processo, etc.).
      (g) Anexos: lista do que será juntado.
      (h) Fecho: local e data [[data_elaboracao]] e assinatura.&lt;/instruction&gt;

    &lt;instruction&gt;9) Checklist de protocolo: liste passos práticos (assinar, conferir anexos, conferir unidade destinatária no SEI, atenção a prazos identificados).&lt;/instruction&gt;

    &lt;instruction&gt;10) Formato de saída: entregue exatamente em 3 blocos:
      (I) Diagnóstico do estágio + evidências + (se aplicável) hipóteses alternativas;
      (II) Linha do tempo (tabela);
      (III) Peça final + anexos + checklist.&lt;/instruction&gt;
  &lt;/instructions&gt;

  &lt;evaluation_checklist&gt;
    &lt;check&gt;O tipo de procedimento foi classificado com base em evidência (ou marcado como não identificável)?&lt;/check&gt;
    &lt;check&gt;O estágio processual foi declarado e justificado com evidências rastreáveis?&lt;/check&gt;
    &lt;check&gt;Há linha do tempo completa e consistente?&lt;/check&gt;
    &lt;check&gt;Há cálculo de prazo apenas quando determinável (sem chute)?&lt;/check&gt;
    &lt;check&gt;A peça final evita dados inventados?&lt;/check&gt;
    &lt;check&gt;Pedidos estão numerados e alinhados ao estágio?&lt;/check&gt;
    &lt;check&gt;Anexos e checklist de protocolo estão presentes?&lt;/check&gt;
  &lt;/evaluation_checklist&gt;

  &lt;input_data&gt;
    &lt;conteudo_processo&gt;
    [[conteudo_processo]]
&lt;!-- placeholder_conteudo --&gt;
    [[/conteudo_processo]]
    &lt;/conteudo_processo&gt;
    &lt;data_elaboracao&gt;
    [[data_elaboracao]]
&lt;!-- placeholder_data --&gt;    
    [[/data_elaboracao]]
    &lt;/data_elaboracao&gt;
    &lt;process_number&gt;&lt;!-- placeholder_sei --&gt;&lt;/process_number&gt;
    &lt;signer_name&gt;&lt;!-- placeholder_parte --&gt;&lt;/signer_name&gt;
  &lt;/input_data&gt;" data-download-link="" data-download-label="Download Markdown">
  <code class="language-markdown">&lt;purpose&gt;
    Você é um assistente especializado em leitura crítica de processos no SEI (Sistema Eletrônico de Informações) e redação de peças jurídico-administrativas.
    Com base no conteúdo fornecido em [[conteudo_processo]], bem como no ordenamento jurídico brasileiro (Constituição Federal de 1988, Emendas Constitucionais, Tratados Internacionais de Direitos Humanos, Leis Complementares, Leis Ordinárias, Leis Delegadas, Medidas Provisórias, Decretos Legislativos, Resoluções, Tratados Internacionais Comuns, Decretos Autônomos, Decretos Regulamentares, Portarias, Instruções Normativas, Convenções e Acordos Coletivos de Trabalho, Súmulas Vinculantes, Jurisprudência, Súmulas Comuns, Doutrina, Costumes, Princípios Gerais do Direito) você deve:
    (1) reconstruir a linha do tempo do Processo SEI nº &lt;!-- placeholder_sei --&gt;;
    (2) classificar o tipo de procedimento (ex.: PAD/sindicância vs. processo administrativo geral vs. rito específico indicado no próprio processo; etc.);
    (3) identificar o estágio atual do fluxo processual com evidências explícitas;
    (4) redigir a peça cabível e suficiente a ser apresentada pela parte denominada &lt;!-- placeholder_parte --&gt; para dar continuidade ao devido processo.
    Sucesso = diagnóstico auditável + peça pronta para protocolo + anexos/checklist, sem invenções.
  &lt;/purpose&gt;

  &lt;context&gt;
    &lt;style_guide&gt;
      &lt;language&gt;pt-BR&lt;/language&gt;
      &lt;format&gt;The response must be both thorough, comprehensive, exhaustive, complete, and in-depth in its detail, as well as wide-ranging, broad, vast, widespread, and far-reaching in its scope.&lt;/format&gt;
    &lt;/style_guide&gt;

    &lt;ethical_guardrails&gt;
      &lt;rule&gt;Não invente fatos, datas, atos, decisões, prazos, autoridades, unidades ou documentos.&lt;/rule&gt;
      &lt;rule&gt;Cite normativos/artigos/incisos específicos se eles estiverem presentes em [[conteudo_processo]], ou no ordenamento jurídico brasileiro (Constituição Federal de 1988, Emendas Constitucionais, Tratados Internacionais de Direitos Humanos, Leis Complementares, Leis Ordinárias, Leis Delegadas, Medidas Provisórias, Decretos Legislativos, Resoluções, Tratados Internacionais Comuns, Decretos Autônomos, Decretos Regulamentares, Portarias, Instruções Normativas, Convenções e Acordos Coletivos de Trabalho, Súmulas Vinculantes, Jurisprudência, Súmulas Comuns, Doutrina, Costumes, Princípios Gerais do Direito).&lt;/rule&gt;
      &lt;rule&gt;Se algo essencial estiver ausente (ex.: última decisão, data de ciência, regra de prazo), declare “não determinável com os dados fornecidos” e liste a lacuna.&lt;/rule&gt;
    &lt;/ethical_guardrails&gt;

    &lt;constraints&gt;
      &lt;constraint&gt;Baseie toda a análise e a redação apenas em [[conteudo_processo]], bem como no ordenamento jurídico brasileiro (Constituição Federal de 1988, Emendas Constitucionais, Tratados Internacionais de Direitos Humanos, Leis Complementares, Leis Ordinárias, Leis Delegadas, Medidas Provisórias, Decretos Legislativos, Resoluções, Tratados Internacionais Comuns, Decretos Autônomos, Decretos Regulamentares, Portarias, Instruções Normativas, Convenções e Acordos Coletivos de Trabalho, Súmulas Vinculantes, Jurisprudência, Súmulas Comuns, Doutrina, Costumes, Princípios Gerais do Direito).&lt;/constraint&gt;
      &lt;constraint&gt;Use evidências curtas e rastreáveis (título da peça + data; se houver, identificador do documento SEI e/ou página/trecho curto; etc.).&lt;/constraint&gt;
      &lt;constraint&gt;O resultado final deve ser protocolável no SEI (texto final coeso, pedidos claros e anexos listados).&lt;/constraint&gt;
    &lt;/constraints&gt;
  &lt;/context&gt;

  &lt;instructions&gt;
    &lt;instruction&gt;1) Leitura: leia integralmente [[conteudo_processo]].&lt;/instruction&gt;

    &lt;instruction&gt;2) Extração estruturada: identifique e liste (com evidência) as peças/atos do processo (ex.: requerimentos, despachos, decisões, notificações/intimações, recursos, encaminhamentos, pareceres, etc.).&lt;/instruction&gt;

    &lt;instruction&gt;3) Linha do tempo: construa uma tabela com colunas: Data | Peça/Ato | Unidade/Autoridade | Efeito processual (abre prazo? decide? diligencia? encaminha?) | Evidência (referência curta).&lt;/instruction&gt;

    &lt;instruction&gt;4) Classificação do procedimento (obrigatória): com base em evidência textual, classifique o procedimento (ex.: (A) PAD/sindicância (sinais: portaria de instauração, comissão, termo de indiciação, instrução, defesa, relatório); (B) processo administrativo geral/recursal (sinais: decisão administrativa, ciência, pedido de reconsideração, recurso, autoridade superior); (C) rito específico (se o processo mencionar norma/rito próprio); etc.). Se não houver evidência suficiente, declare “tipo não identificável” e prossiga com cautela.&lt;/instruction&gt;

    &lt;instruction&gt;5) Diagnóstico do estágio processual: identifique o ato mais recente e determine o estágio atual do fluxo processual, escolhendo entre estados como, por exemplo:
      - aguardando ciência/intimação
      - prazo aberto para manifestação/recurso
      - pedido de reconsideração cabível/pendente
      - recurso interposto aguardando admissibilidade/encaminhamento
      - em juízo de retratação/decisão recursal
      - diligência/complementação pendente
      - decisão recursal proferida aguardando cumprimento
      - etc.
      Se houver mais de uma interpretação plausível, apresente hipóteses com critérios e evidências.&lt;/instruction&gt;

    &lt;instruction&gt;6) Prazos (somente se determinável): se houver data de ciência/intimação e regra de prazo explícita no processo, calcule a data-limite e registre. Caso contrário, escreva “prazo não determinável com os dados fornecidos”.&lt;/instruction&gt;

    &lt;instruction&gt;7) Seleção da peça “cabível e suficiente”: com base no estágio identificado, escolha a peça adequada (ex.: manifestação, juntada/cumprimento de diligência, pedido de reconsideração, recurso administrativo/hierárquico, pedido de prosseguimento, etc.). Explique por que essa é a peça correta para o estágio.&lt;/instruction&gt;

    &lt;instruction&gt;8) Redação da peça final: redija o documento completo para protocolo no SEI, com:
      (a) Endereçamento: use a autoridade/unidade explicitamente indicada como competente no processo; se não existir indicação clara, use forma neutra (“À Autoridade Competente/À Unidade Responsável pelo Processo”).
      (b) Referência: Processo SEI nº &lt;!-- placeholder_sei --&gt;.
      (c) Qualificação: &lt;!-- placeholder_parte --&gt; conforme constar no processo (sem inventar dados).
      (d) Descrição do histórico com marcos relevantes.
      (e) Fundamentação: fatos e, quando aplicável, referências a atos normativos mencionados no conteúdo do próprio processo ou que compõem o ordenamento jurídico brasileiro.
      (f) Pedidos: numerados, objetivos, coerentes com o estágio (ex.: recebimento, conhecimento, encaminhamento, juntada, reabertura de prazo se cabível e fundamentada por evidência do processo, etc.).
      (g) Anexos: lista do que será juntado.
      (h) Fecho: local e data [[data_elaboracao]] e assinatura.&lt;/instruction&gt;

    &lt;instruction&gt;9) Checklist de protocolo: liste passos práticos (assinar, conferir anexos, conferir unidade destinatária no SEI, atenção a prazos identificados).&lt;/instruction&gt;

    &lt;instruction&gt;10) Formato de saída: entregue exatamente em 3 blocos:
      (I) Diagnóstico do estágio + evidências + (se aplicável) hipóteses alternativas;
      (II) Linha do tempo (tabela);
      (III) Peça final + anexos + checklist.&lt;/instruction&gt;
  &lt;/instructions&gt;

  &lt;evaluation_checklist&gt;
    &lt;check&gt;O tipo de procedimento foi classificado com base em evidência (ou marcado como não identificável)?&lt;/check&gt;
    &lt;check&gt;O estágio processual foi declarado e justificado com evidências rastreáveis?&lt;/check&gt;
    &lt;check&gt;Há linha do tempo completa e consistente?&lt;/check&gt;
    &lt;check&gt;Há cálculo de prazo apenas quando determinável (sem chute)?&lt;/check&gt;
    &lt;check&gt;A peça final evita dados inventados?&lt;/check&gt;
    &lt;check&gt;Pedidos estão numerados e alinhados ao estágio?&lt;/check&gt;
    &lt;check&gt;Anexos e checklist de protocolo estão presentes?&lt;/check&gt;
  &lt;/evaluation_checklist&gt;

  &lt;input_data&gt;
    &lt;conteudo_processo&gt;
    [[conteudo_processo]]
&lt;!-- placeholder_conteudo --&gt;
    [[/conteudo_processo]]
    &lt;/conteudo_processo&gt;
    &lt;data_elaboracao&gt;
    [[data_elaboracao]]
&lt;!-- placeholder_data --&gt;    
    [[/data_elaboracao]]
    &lt;/data_elaboracao&gt;
    &lt;process_number&gt;&lt;!-- placeholder_sei --&gt;&lt;/process_number&gt;
    &lt;signer_name&gt;&lt;!-- placeholder_parte --&gt;&lt;/signer_name&gt;
  &lt;/input_data&gt;</code>
</section>]]></content><author><name></name></author><category term="AI&gt;prompt" /></entry><entry><title type="html">xnedit regex</title><link href="https://ib.bsb.br/xnedit/" rel="alternate" type="text/html" title="xnedit regex" /><published>2026-01-04T00:00:00+00:00</published><updated>2026-01-04T23:51:19+00:00</updated><id>https://ib.bsb.br/xnedit</id><content type="html" xml:base="https://ib.bsb.br/xnedit/"><![CDATA[<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Regular expressions (regex's) are useful as a way to match inexact sequences of characters.  They can be used in the `Find...' and `Replace...' search dialogs and are at the core of Color Syntax Highlighting patterns.  To specify a regular expression in a search dialog, simply click on the `Regular Expression' radio button in the dialog. 

A regex is a specification of a pattern to be matched in the searched text. This pattern consists of a sequence of tokens, each being able to match a single character or a sequence of characters in the text, or assert that a specific position within the text has been reached (the latter is called an anchor.)  Tokens (also called atoms) can be modified by adding one of a number of special quantifier tokens immediately after the token.  A quantifier token specifies how many times the previous token must be matched (see below.) 

Tokens can be grouped together using one of a number of grouping constructs, the most common being plain parentheses.  Tokens that are grouped in this way are also collectively considered to be a regex atom, since this new larger atom may also be modified by a quantifier. 

A regex can also be organized into a list of alternatives by separating each alternative with pipe characters, `|'.  This is called alternation.  A match will be attempted for each alternative listed, in the order specified, until a match results or the list of alternatives is exhausted (see Alternation section below.) 

The 'Any' Character

If a dot (`.') appears in a regex, it means to match any character exactly once.  By default, dot will not match a newline character, but this behavior can be changed (see help topic Parenthetical Constructs, under the heading, Matching Newlines). 

Character Classes

A character class, or range, matches exactly one character of text, but the candidates for matching are limited to those specified by the class.  Classes come in two flavors as described below: 

     [...]   Regular class, match only characters listed.
     [^...]  Negated class, match only characters not listed.

As with the dot token, by default negated character classes do not match newline, but can be made to do so. 

The characters that are considered special within a class specification are different than the rest of regex syntax as follows. If the first character in a class is the `]' character (second character if the first character is `^') it is a literal character and part of the class character set.  This also applies if the first or last character is `-'.  Outside of these rules, two characters separated by `-' form a character range which includes all the characters between the two characters as well.  For example, `[^f-j]' is the same as `[^fghij]' and means to match any character that is not `f', `g', `h', `i', or `j'. 

Anchors

Anchors are assertions that you are at a very specific position within the search text.  XNEdit regular expressions support the following anchor tokens: 

     ^    Beginning of line
     $    End of line
     &lt;    Left word boundary
     &gt;    Right word boundary
     \B   Not a word boundary

Note that the \B token ensures that neither the left nor the right character are delimiters, or that both left and right characters are delimiters. The left word anchor checks whether the previous character is a delimiter and the next character is not. The right word anchor works in a similar way. 

Note that word delimiters are user-settable, and defined by the X resource wordDelimiters, cf. X Resources. 

Quantifiers

Quantifiers specify how many times the previous regular expression atom may be matched in the search text.  Some quantifiers can produce a large performance penalty, and can in some instances completely lock up XNEdit.  To prevent this, avoid nested quantifiers, especially those of the maximal matching type (see below.) 

The following quantifiers are maximal matching, or "greedy", in that they match as much text as possible (but don't exclude shorter matches if that is necessary to achieve an overall match). 

     *   Match zero or more
     +   Match one  or more
     ?   Match zero or one

The following quantifiers are minimal matching, or "lazy", in that they match as little text as possible (but don't exclude longer matches if that is necessary to achieve an overall match). 

     *?   Match zero or more
     +?   Match one  or more
     ??   Match zero or one

One final quantifier is the counting quantifier, or brace quantifier. It takes the following basic form: 

     {min,max}  Match from `min' to `max' times the
                previous regular expression atom.

If `min' is omitted, it is assumed to be zero.  If `max' is omitted, it is assumed to be infinity.  Whether specified or assumed, `min' must be less than or equal to `max'.  Note that both `min' and `max' are limited to 65535.  If both are omitted, then the construct is the same as `*'.   Note that `{,}' and `{}' are both valid brace constructs.  A single number appearing without a comma, e.g. `{3}' is short for the `{min,min}' construct, or to match exactly `min' number of times. 

The quantifiers `{1}' and `{1,1}' are accepted by the syntax, but are optimized away since they mean to match exactly once, which is redundant information.  Also, for efficiency, certain combinations of `min' and `max' are converted to either `*', `+', or `?' as follows: 

     {} {,} {0,}    *
     {1,}           +
     {,1} {0,1}     ?

Note that {0} and {0,0} are meaningless and will generate an error message at regular expression compile time. 

Brace quantifiers can also be "lazy".  For example {2,5}? would try to match 2 times if possible, and will only match 3, 4, or 5 times if that is what is necessary to achieve an overall match. 

Alternation

A series of alternative patterns to match can be specified by separating them with vertical pipes, `|'.  An example of alternation would be `a|be|sea'. This will match `a', or `be', or `sea'. Each alternative can be an arbitrarily complex regular expression. The alternatives are attempted in the order specified.  An empty alternative can be specified if desired, e.g. `a|b|'.  Since an empty alternative can match nothingness (the empty string), this guarantees that the expression will match. 

Comments

Comments are of the form `(?#&lt;comment text&gt;)' and can be inserted anywhere and have no effect on the execution of the regular expression.  They can be handy for documenting very complex regular expressions.  Note that a comment begins with `(?#' and ends at the first occurrence of an ending parenthesis, or the end of the regular expression... period.  Comments do not recognize any escape sequences. 

Escaping Metacharacters

In a regular expression (regex), most ordinary characters match themselves. For example, `ab%' would match anywhere `a' followed by `b' followed by `%' appeared in the text.  Other characters don't match themselves, but are metacharacters. For example, backslash is a special metacharacter which 'escapes' or changes the meaning of the character following it. Thus, to match a literal backslash would require a regular expression to have two backslashes in sequence. XNEdit provides the following escape sequences so that metacharacters that are used by the regex syntax can be specified as ordinary characters. 

     \(  \)  \-  \[  \]  \&lt;  \&gt;  \{  \}
     \.  \|  \^  \$  \*  \+  \?  \&amp;  \\

Special Control Characters

There are some special characters that are  difficult or impossible to type. Many of these characters can be constructed as a sort of metacharacter or sequence by preceding a literal character with a backslash. XNEdit recognizes the following special character sequences: 

     \a  alert (bell)
     \b  backspace
     \e  ASCII escape character (***)
     \f  form feed (new page)
     \n  newline
     \r  carriage return
     \t  horizontal tab
     \v  vertical tab

     *** For environments that use the EBCDIC character set,
         when compiling XNEdit set the EBCDIC_CHARSET compiler
         symbol to get the EBCDIC equivalent escape
         character.)

Octal and Hex Escape Sequences

Any ASCII (or EBCDIC) character, except null, can be specified by using either an octal escape or a hexadecimal escape, each beginning with \0 or \x (or \X), respectively.  For example, \052 and \X2A both specify the `*' character.  Escapes for null (\00 or \x0) are not valid and will generate an error message.  Also, any escape that exceeds \0377 or \xFF will either cause an error or have any additional character(s) interpreted literally. For example, \0777 will be interpreted as \077 (a `?' character) followed by `7' since \0777 is greater than \0377. 

An invalid digit will also end an octal or hexadecimal escape.  For example, \091 will cause an error since `9' is not within an octal escape's range of allowable digits (0-7) and truncation before the `9' yields \0 which is invalid. 

Shortcut Escape Sequences

XNEdit defines some escape sequences that are handy shortcuts for commonly used character classes. 

   \d  digits            0-9
   \l  letters           a-z, A-Z, and locale dependent letters
   \s  whitespace        \t, \r, \v, \f, and space
   \w  word characters   letters, digits, and underscore, `_'

\D, \L, \S, and \W are the same as the lowercase versions except that the resulting character class is negated.  For example, \d is equivalent to `[0-9]', while \D is equivalent to `[^0-9]'. 

These escape sequences can also be used within a character class.  For example, `[\l_]' is the same as `[a-zA-Z_]', extended with possible locale dependent letters. The escape sequences for special characters, and octal and hexadecimal escapes are also valid within a class. 

Word Delimiter Tokens

Although not strictly a character class, the following escape sequences behave similarly to character classes: 

     \y   Word delimiter character
     \Y   Not a word delimiter character

The `\y' token matches any single character that is one of the characters that XNEdit recognizes as a word delimiter character, while the `\Y' token matches any character that is not a word delimiter character.  Word delimiter characters are dynamic in nature, meaning that the user can change them through preference settings.  For this reason, they must be handled differently by the regular expression engine.  As a consequence of this, `\y' and `\Y' cannot be used within a character class specification. 

Capturing Parentheses

Capturing Parentheses are of the form `(&lt;regex&gt;)' and can be used to group arbitrarily complex regular expressions.  Parentheses can be nested, but the total number of parentheses, nested or otherwise, is limited to 50 pairs. The text that is matched by the regular expression between a matched set of parentheses is captured and available for text substitutions and backreferences (see below.)  Capturing parentheses carry a fairly high overhead both in terms of memory used and execution speed, especially if quantified by `*' or `+'. 

Non-Capturing Parentheses

Non-Capturing Parentheses are of the form `(?:&lt;regex&gt;)' and facilitate grouping only and do not incur the overhead of normal capturing parentheses. They should not be counted when determining numbers for capturing parentheses which are used with backreferences and substitutions.  Because of the limit on the number of capturing parentheses allowed in a regex, it is advisable to use non-capturing parentheses when possible. 

Positive Look-Ahead

Positive look-ahead constructs are of the form `(?=&lt;regex&gt;)' and implement a zero width assertion of the enclosed regular expression.  In other words, a match of the regular expression contained in the positive look-ahead construct is attempted.  If it succeeds, control is passed to the next regular expression atom, but the text that was consumed by the positive look-ahead is first unmatched (backtracked) to the place in the text where the positive look-ahead was first encountered. 

One application of positive look-ahead is the manual implementation of a first character discrimination optimization.  You can include a positive look-ahead that contains a character class which lists every character that the following (potentially complex) regular expression could possibly start with.  This will quickly filter out match attempts that cannot possibly succeed. 

Negative Look-Ahead

Negative look-ahead takes the form `(?!&lt;regex&gt;)' and is exactly the same as positive look-ahead except that the enclosed regular expression must NOT match.  This can be particularly useful when you have an expression that is general, and you want to exclude some special cases.  Simply precede the general expression with a negative look-ahead that covers the special cases that need to be filtered out. 

Positive Look-Behind

Positive look-behind constructs are of the form `(?&lt;=&lt;regex&gt;)' and implement a zero width assertion of the enclosed regular expression in front of the current matching position.  It is similar to a positive look-ahead assertion, except for the fact that the match is attempted on the text preceding the current position, possibly even in front of the start of the matching range of the entire regular expression. 

A restriction on look-behind expressions is the fact that the expression must match a string of a bounded size.  In other words, `*', `+', and `{n,}' quantifiers are not allowed inside the look-behind expression. Moreover, matching performance is sensitive to the difference between the upper and lower bound on the matching size.  The smaller the difference, the better the performance.  This is especially important for regular expressions used in highlight patterns. 

Positive look-behind has similar applications as positive look-ahead. 

Negative Look-Behind

Negative look-behind takes the form `(?&lt;!&lt;regex&gt;)' and is exactly the same as positive look-behind except that the enclosed regular expression must not match. The same restrictions apply. 

Note however, that performance is even more sensitive to the distance between the size boundaries: a negative look-behind must not match for any possible size, so the matching engine must check every size. 

Case Sensitivity

There are two parenthetical constructs that control case sensitivity: 

     (?i&lt;regex&gt;)   Case insensitive; `AbcD' and `aBCd' are
                   equivalent.

     (?I&lt;regex&gt;)   Case sensitive;   `AbcD' and `aBCd' are
                   different.

Regular expressions are case sensitive by default, that is, `(?I&lt;regex&gt;)' is assumed.  All regular expression token types respond appropriately to case insensitivity including character classes and backreferences.  There is some extra overhead involved when case insensitivity is in effect, but only to the extent of converting each character compared to lower case. 

Matching Newlines

XNEdit regular expressions by default handle the matching of newlines in a way that should seem natural for most editing tasks.  There are situations, however, that require finer control over how newlines are matched by some regular expression tokens. 

By default, XNEdit regular expressions will not match a newline character for the following regex tokens: dot (`.'); a negated character class (`[^...]'); and the following shortcuts for character classes: 

     `\d', `\D', `\l', `\L', `\s', `\S', `\w', `\W', `\Y'

The matching of newlines can be controlled for the `.' token, negated character classes, and the `\s' and `\S' shortcuts by using one of the following parenthetical constructs: 

     (?n&lt;regex&gt;)  `.', `[^...]', `\s', `\S' match newlines

     (?N&lt;regex&gt;)  `.', `[^...]', `\s', `\S' don't match
                                            newlines

`(?N&lt;regex&gt;)' is the default behavior. 

Notes on New Parenthetical Constructs

Except for plain parentheses, none of the parenthetical constructs capture text.  If that is desired, the construct must be wrapped with capturing parentheses, e.g. `((?i&lt;regex))'. 

All parenthetical constructs can be nested as deeply as desired, except for capturing parentheses which have a limit of 50 sets of parentheses, regardless of nesting level. 

Back References

Backreferences allow you to match text captured by a set of capturing parenthesis at some later position in your regular expression.  A backreference is specified using a single backslash followed by a single digit from 1 to 9 (example: \3).  Backreferences have similar syntax to substitutions (see below), but are different from substitutions in that they appear within the regular expression, not the substitution string. The number specified with a backreference identifies which set of text capturing parentheses the backreference is associated with. The text that was most recently captured by these parentheses is used by the backreference to attempt a match.  As with substitutions, open parentheses are counted from left to right beginning with 1.  So the backreference `\3' will try to match another occurrence of the text most recently matched by the third set of capturing parentheses.  As an example, the regular expression `(\d)\1' could match `22', `33', or `00', but wouldn't match `19' or `01'. 

A backreference must be associated with a parenthetical expression that is complete.  The expression `(\w(\1))' contains an invalid backreference since the first set of parentheses are not complete at the point where the backreference appears. 

Substitution

Substitution strings are used to replace text matched by a set of capturing parentheses.  The substitution string is mostly interpreted as ordinary text except as follows. 

The escape sequences described above for special characters, and octal and hexadecimal escapes are treated the same way by a substitution string. When the substitution string contains the `&amp;' character, XNEdit will substitute the entire string that was matched by the `Find...' operation. Any of the first nine sub-expressions of the match string can also be inserted into the replacement string.  This is done by inserting a `\' followed by a digit from 1 to 9 that represents the string matched by a parenthesized expression within the regular expression.  These expressions are numbered left-to-right in order of their opening parentheses. 

The capitalization of text inserted by `&amp;' or `\1', `\2', ... `\9' can be altered by preceding them with `\U', `\u', `\L', or `\l'.  `\u' and `\l' change only the first character of the inserted entity, while `\U' and `\L' change the entire entity to upper or lower case, respectively. 

Substitutions

Regular expression substitution can be used to program automatic editing operations.  For example, the following are search and replace strings to find occurrences of the `C' language subroutine `get_x', reverse the first and second parameters, add a third parameter of NULL, and change the name to `new_get_x': 

     Search string:   `get_x *\( *([^ ,]*), *([^\)]*)\)'
     Replace string:  `new_get_x(\2, \1, NULL)'

Ambiguity

If a regular expression could match two different parts of the text, it will match the one which begins earliest.  If both begin in the same place but match different lengths, or match the same length in different ways, life gets messier, as follows. 

In general, the possibilities in a list of alternatives are considered in left-to-right order.  The possibilities for `*', `+', and `?' are considered longest-first, nested constructs are considered from the outermost in, and concatenated constructs are considered leftmost-first. The match that will be chosen is the one that uses the earliest possibility in the first choice that has to be made.  If there is more than one choice, the next will be made in the same manner (earliest possibility) subject to the decision on the first choice.  And so forth. 

For example, `(ab|a)b*c' could match `abc' in one of two ways.  The first choice is between `ab' and `a'; since `ab' is earlier, and does lead to a successful overall match, it is chosen.  Since the `b' is already spoken for, the `b*' must match its last possibility, the empty string, since it must respect the earlier choice. 

In the particular case where no `|'s are present and there is only one `*', `+', or `?', the net effect is that the longest possible match will be chosen.  So `ab*', presented with `xabbbby', will match `abbbb'.  Note that if `ab*' is tried against `xabyabbbz', it will match `ab' just after `x', due to the begins-earliest rule.  (In effect, the decision on where to start the match is the first choice to be made, hence subsequent choices must respect it even if this leads them to less-preferred alternatives.) 

References

An excellent book on the care and feeding of regular expressions is 

          Mastering Regular Expressions, 3rd Edition
          Jeffrey E. F. Friedl
          August 2006, O'Reilly &amp; Associates
          ISBN 0-596-52812-4

The first end second editions of this book are still useful for basic introduction to regexes and contain many useful tips and tricks. 

The following are regular expression examples which will match: 

    * An entire line.
        ^.*$

    * Blank lines.
        ^$

    * Whitespace on a line.
        \s+

    * Whitespace across lines.
        (?n\s+)

    * Whitespace that spans at least two lines. Note minimal matching `*?' quantifier.
        (?n\s*?\n\s*)

    * IP address (not robust).
        (?:\d{1,3}(?:\.\d{1,3}){3})

    * Two character US Postal state abbreviations (includes territories).
        [ACDF-IK-PR-W][A-Z]

    * Web addresses.
        (?:http://)?www\.\S+

    * Case insensitive double words across line breaks.
        (?i(?n&lt;(\S+)\s+\1&gt;))

    * Upper case words with possible punctuation.
        &lt;[A-Z][^a-z\s]*&gt;
</code></pre></div></div>]]></content><author><name></name></author><category term="scratchpad" /></entry><entry><title type="html">TreeSheets Hierarchy Swap documentation</title><link href="https://ib.bsb.br/ts-swap/" rel="alternate" type="text/html" title="TreeSheets Hierarchy Swap documentation" /><published>2026-01-01T00:00:00+00:00</published><updated>2026-01-01T23:34:40+00:00</updated><id>https://ib.bsb.br/ts-swap</id><content type="html" xml:base="https://ib.bsb.br/ts-swap/"><![CDATA[<h2 id="command-surface">Command Surface</h2>
<ul>
  <li><strong>Menu / Shortcut:</strong> Organization → Hierarchy Swap (F8), defined in <a href="../src/tsframe.h#L333-L348"><code class="language-plaintext highlighter-rouge">tsframe.h</code></a>. The label reads “Hierarchy Swap” and the tooltip explains that all cells with the selected text are swapped with their parents at the current level (or above). The menu entry lives under the “Organization” cascade, grouped with flattening and hierarchify commands.</li>
  <li><strong>Action ID:</strong> <code class="language-plaintext highlighter-rouge">A_HSWAP</code> in <a href="../src/main.cpp#L130-L180"><code class="language-plaintext highlighter-rouge">main.cpp</code></a>. This ID connects the menu, keyboard shortcut, and dispatcher switch statement; it is also used in the toolbar accelerator table.</li>
  <li><strong>Validation and dispatch:</strong> <code class="language-plaintext highlighter-rouge">Document::Action()</code> at <a href="../src/document.h#L1860-L1920"><code class="language-plaintext highlighter-rouge">document.h</code></a> enforces:
    <ul>
      <li>The selected cell has a parent and grandparent (minimum depth requirement) and therefore the command is disabled at the document root.</li>
      <li>Both parent and grandparent grids are 1×N or N×1 (unidimensional constraint). If either grid fails the shape test, the action aborts before any structural edits occur.</li>
      <li>An undo step is recorded before calling the swap, so the operation is fully reversible.</li>
      <li>The returned <code class="language-plaintext highlighter-rouge">Selection</code> is installed, and the layout is reset plus canvas refresh is requested to reflect the new tree topology.</li>
    </ul>
  </li>
  <li><strong>Failure modes (user-facing):</strong>
    <ul>
      <li>No grandparent → “Cannot move this cell up in the hierarchy.”</li>
      <li>Parent grid not 1×N or N×1 → “Can only move this cell from a Nx1 or 1xN grid.”</li>
      <li>Grandparent grid not 1×N or N×1 → “Can only move this cell into a Nx1 or 1xN grid.”</li>
      <li>Selection has no grid ancestry because the document is a single flat row/column → the menu item will be disabled due to the grandparent check.</li>
    </ul>
  </li>
  <li><strong>Selection rule:</strong> The operation is invoked on the currently selected cell; the returned selection usually points to the promoted/merged tag at the grandparent level. If merges occur, the earliest tag inserted into the target grid becomes the selection anchor and is reused for subsequent merges.</li>
  <li><strong>UI invariants to watch:</strong> because <code class="language-plaintext highlighter-rouge">HierarchySwap</code> runs inside a single undo step, the canvas redraw and layout reset happen once per keypress, even when multiple promotions/merges occur via <code class="language-plaintext highlighter-rouge">goto lookformore</code>.</li>
</ul>

<h2 id="code-map">Code Map</h2>
<p>| Area | Location | Role |
| — | — | — |
| Grid-level search | <a href="../src/grid.h#L867-L888"><code class="language-plaintext highlighter-rouge">Grid::FindExact</code></a> | Recursively finds the first cell whose text matches the selected tag. Walks depth-first through a child grid. |
| Main algorithm | <a href="../src/grid.h#L889-L938"><code class="language-plaintext highlighter-rouge">Grid::HierarchySwap</code></a> | Promotes each match, rebuilds its parent chain under it, merges like-tag peers, and restarts the search until no matches remain. |
| Parent cleanup | <a href="../src/grid.h#L940-L964"><code class="language-plaintext highlighter-rouge">Grid::DeleteTagParent</code></a> | Removes the promoted node from its old location, deleting empty 1×1 ancestors on the way up. |
| Merge helpers | <a href="../src/grid.h#L966-L991"><code class="language-plaintext highlighter-rouge">Grid::MergeTagCell</code></a> and <a href="../src/grid.h#L993-L1000"><code class="language-plaintext highlighter-rouge">Grid::MergeTagAll</code></a> | Merge promoted cells (and their grids) when the target level already contains the same tag. |
| Parent pointer fix-up | <a href="../src/grid.h#L1010-L1014"><code class="language-plaintext highlighter-rouge">Grid::ReParent</code></a> | Retargets parent pointers whenever a grid is transplanted. |
| Cell-level match | <a href="../src/cell.h#L484-L503"><code class="language-plaintext highlighter-rouge">Cell::FindExact</code></a> | Base-case exact-text comparison used by <code class="language-plaintext highlighter-rouge">Grid::FindExact</code>. |</p>

<h3 id="how-these-pieces-cooperate">How these pieces cooperate</h3>
<ol>
  <li><code class="language-plaintext highlighter-rouge">Document::Action()</code> validates shape/depth, then calls <code class="language-plaintext highlighter-rouge">HierarchySwap</code> on the grandparent grid, passing the selected cell text.</li>
  <li><code class="language-plaintext highlighter-rouge">HierarchySwap</code> iterates each direct child cell of that grid that has a subgrid, scanning it with <code class="language-plaintext highlighter-rouge">FindExact</code>.</li>
  <li>When a match is found, the ancestor chain is reversed into nested children (using <code class="language-plaintext highlighter-rouge">ReParent</code> for correctness), original containers are removed (<code class="language-plaintext highlighter-rouge">DeleteTagParent</code>), and the promoted tag is merged (<code class="language-plaintext highlighter-rouge">MergeTagCell</code>/<code class="language-plaintext highlighter-rouge">MergeTagAll</code>).</li>
  <li>The search restarts (<code class="language-plaintext highlighter-rouge">goto lookformore</code>) so newly created structure is considered; the returned <code class="language-plaintext highlighter-rouge">Selection</code> points to the first merged tag at the target grid.</li>
</ol>

<h2 id="algorithm-from-the-current-implementation">Algorithm (from the current implementation)</h2>
<p>The following is a line-by-line translation of the active codepath, emphasizing what actually happens rather than a simplified mental model.</p>

<ol>
  <li><strong>Search scope:</strong> Start in the grandparent grid of the selected cell (the grid that owns the parent’s parent). Iterate each direct child that has a grid. The current child being scanned is referenced by <code class="language-plaintext highlighter-rouge">cell</code> inside the function.</li>
  <li><strong>Find first match:</strong> Use <code class="language-plaintext highlighter-rouge">Grid::FindExact(tag)</code> to locate the first cell in that child grid whose text equals the selected tag (case-sensitive). If none, continue to the next sibling with a grid.</li>
  <li><strong>Build reversed chain:</strong> For the found cell <code class="language-plaintext highlighter-rouge">f</code>, walk its parent chain up to (but not including) the grandparent cell that owns the running grid. For each ancestor <code class="language-plaintext highlighter-rouge">p</code>:
    <ul>
      <li>If <code class="language-plaintext highlighter-rouge">p-&gt;text</code> matches the tag, set <code class="language-plaintext highlighter-rouge">done = true</code> to stop after this promotion and avoid infinite swaps through same-named ancestors.</li>
      <li>Clone <code class="language-plaintext highlighter-rouge">p</code> into a new cell attached under <code class="language-plaintext highlighter-rouge">f</code>, transfer <code class="language-plaintext highlighter-rouge">f</code>’s current grid to that clone, call <code class="language-plaintext highlighter-rouge">ReParent</code>, and give <code class="language-plaintext highlighter-rouge">f</code> a fresh 1×1 grid containing the clone. This makes every ancestor become a child nested under the promoted tag, preserving the original ordering from nearest to farthest parent.</li>
    </ul>
  </li>
  <li><strong>Detach the original chain:</strong> Call <code class="language-plaintext highlighter-rouge">DeleteTagParent</code> repeatedly while walking upward, deleting empty 1×1 ancestors and cleaning up the spot where the match used to live. This pruning happens before any merge so that empties are not left behind in the original branch.</li>
  <li><strong>Merge at target level:</strong>
    <ul>
      <li>If the target grid was empty, place <code class="language-plaintext highlighter-rouge">f</code> there and mark it as the selection.</li>
      <li>Otherwise call <code class="language-plaintext highlighter-rouge">MergeTagCell</code>, which either merges <code class="language-plaintext highlighter-rouge">f</code> into an existing like-named cell (combining grids via <code class="language-plaintext highlighter-rouge">MergeTagAll</code> when both have grids) or appends it if no duplicate exists. The first merged/added cell becomes the returned selection, and subsequent merges fold into that.</li>
    </ul>
  </li>
  <li><strong>Restart search:</strong> <code class="language-plaintext highlighter-rouge">goto lookformore</code> restarts the sweep so newly created structure is also scanned. The loop ends when no further matches remain or <code class="language-plaintext highlighter-rouge">done</code> was set because an ancestor already matched the tag (the ancestor-match guard).</li>
  <li><strong>Return selection:</strong> The function returns a <code class="language-plaintext highlighter-rouge">Selection</code> pointing to the promoted/merged tag at the target level. The caller re-applies the selection and refreshes layout/UI.</li>
</ol>

<h3 id="behavioral-notes">Behavioral Notes</h3>
<ul>
  <li><strong>Grid shape:</strong> The operation only runs on 1×N or N×1 grids (checked before calling the algorithm). This keeps parent/child inversion unambiguous and ensures <code class="language-plaintext highlighter-rouge">DeleteCells</code> can safely collapse rows/columns when null slots appear.</li>
  <li><strong>Exact text match:</strong> Matching is literal and case-sensitive (<code class="language-plaintext highlighter-rouge">Cell::FindExact</code>), so “Red” ≠ “red”. Hidden formatting (bold/italic) does not affect the match because only <code class="language-plaintext highlighter-rouge">text.t</code> is compared.</li>
  <li><strong>Search order:</strong> Because the search restarts after every promotion, newly merged structures can be processed in subsequent passes; order is depth-first within each child grid. This restart is why multi-match merges can happen within one keypress.</li>
  <li><strong>Ancestor protection:</strong> If an ancestor already has the same tag, <code class="language-plaintext highlighter-rouge">done</code> stops further promotions after that chain is processed to prevent cycling the same text upward forever. That means repeated-tag chains only promote once, even when additional matches exist deeper in the tree.</li>
  <li><strong>Merge semantics:</strong> When the target grid already contains the tag, children from both structures are merged under the surviving tag cell. Subgrid merging preserves existing rows/columns as appended sibling rows, and <code class="language-plaintext highlighter-rouge">MergeTagAll</code> will recursively merge duplicate-tag grandchildren as well. If a promoted match brings in a cloned ancestor with the same name but no grid, <code class="language-plaintext highlighter-rouge">MergeTagCell</code> short-circuits on the first match and leaves only one copy.</li>
  <li><strong>Two-level hops:</strong> Each keypress works against the selected cell’s grandparent grid, so very deep matches may need multiple presses to bubble all the way to the top-level grid where siblings live. The “press-count” tables below assume this two-level stride.</li>
  <li><strong>Undo/redo alignment:</strong> An undo point is established before running the algorithm; all structural edits (promote, delete, merge) live inside that single undo step. Redo will replay the full set of promotions, merges, and deletions.</li>
  <li><strong>Selection stability:</strong> The first promoted/merged cell at the target grid is returned as the new selection; subsequent merges do not change that pointer. This stability matters for keyboard users repeating swaps.</li>
  <li><strong>Empty-shell cleanup:</strong> Because <code class="language-plaintext highlighter-rouge">DeleteTagParent</code> prunes empty 1×1 ancestors, the final tree omits placeholder shells that lost all children during promotion. When the grid has multiple rows, empty rows are physically removed via <code class="language-plaintext highlighter-rouge">DeleteCells</code>.</li>
  <li><strong>Grid ownership:</strong> <code class="language-plaintext highlighter-rouge">ReParent</code> is called every time a grid is re-attached so parent pointers remain accurate for all transplanted children. This invariant is critical for subsequent operations such as copy/paste or further swaps.</li>
  <li><strong>Shape preservation for bystanders:</strong> Cells in the grandparent grid that do not contain a matching tag remain in place (apart from row removal when a null slot is deleted). Use this property to predict stable ordering of unrelated siblings.</li>
</ul>

<h3 id="implementation-walkthrough-annotated-pseudocode">Implementation Walkthrough (annotated pseudocode)</h3>
<p>Below is an exact-structure pseudocode sketch that matches the current C++ implementation, including the restart logic:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>HierarchySwap(tag):
    selcell = nullptr
    done = false
lookformore:
    for each cell in this grid where cell has a subgrid:
        found = cell-&gt;grid-&gt;FindExact(tag)
        if not found: continue

        // Reverse the ancestor chain into children under `found`
        for p = found-&gt;parent; p != cell; p = p-&gt;parent:
            if p-&gt;text == tag: done = true
            clone = new Cell(found, p)
            clone-&gt;text = p-&gt;text
            clone-&gt;grid = found-&gt;grid
            if clone-&gt;grid: clone-&gt;grid-&gt;ReParent(clone)
            found-&gt;grid = new Grid(1, 1)
            found-&gt;grid-&gt;cell = found
            *found-&gt;grid-&gt;cells = clone

        // Remove the original chain (prunes empties)
        for r = found; r &amp;&amp; r != cell; r = r-&gt;parent-&gt;grid-&gt;DeleteTagParent(r, cell, found);

        // Merge or insert at the target level
        if !cells[0]:
            *cells = found
            selcell = found
        else:
            MergeTagCell(found, selcell)

        if !done: goto lookformore
    return Selection(this, selcell)
</code></pre></div></div>
<p>Key takeaways from this structure:</p>
<ul>
  <li>The <code class="language-plaintext highlighter-rouge">goto</code> intentionally restarts the <code class="language-plaintext highlighter-rouge">for</code> so the modified grid is scanned anew.</li>
  <li><code class="language-plaintext highlighter-rouge">done</code> only flips when a same-named ancestor exists; otherwise every match reachable from the scanning grid will be processed.</li>
  <li>The merge target is always the grid on which <code class="language-plaintext highlighter-rouge">HierarchySwap</code> is called (the grandparent grid chosen by the caller).</li>
  <li>The loop condition <code class="language-plaintext highlighter-rouge">p != cell</code> stops cloning at the grid’s owning cell (the grandparent), so only ancestors strictly below that owning cell are nested under the promoted tag.</li>
</ul>

<h2 id="examples">Examples</h2>
<p>The following scenarios are constructed directly against the algorithm above:</p>

<h3 id="1-baseline-single-match-promotion">1) Baseline: Single Match Promotion</h3>
<p><strong>Before</strong> (select “Alice”, grandparent grid owns <code class="language-plaintext highlighter-rouge">Project</code>):</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Projects
   Project A
      Alice
   Project B
      Bob
</code></pre></div></div>

<p><strong>After F8 on “Alice”:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Projects
   Project B
      Bob
   Alice
      Project A
</code></pre></div></div>
<ul>
  <li>The <code class="language-plaintext highlighter-rouge">Alice</code> branch moves to the grandparent grid. <code class="language-plaintext highlighter-rouge">Project A</code> becomes a child under <code class="language-plaintext highlighter-rouge">Alice</code>. Other siblings stay put.</li>
  <li>No merge occurs because only one <code class="language-plaintext highlighter-rouge">Alice</code> exists. Undo reverses the promotion cleanly.</li>
  <li>Plain text before: <code class="language-plaintext highlighter-rouge">Projects\n  Project A\n    Alice\n  Project B\n    Bob\n</code></li>
  <li>Plain text after: <code class="language-plaintext highlighter-rouge">Projects\n  Project B\n    Bob\n  Alice\n    Project A\n</code></li>
</ul>

<h3 id="2-multiple-matches-at-different-depths">2) Multiple Matches at Different Depths</h3>
<p><strong>Before</strong> (grandparent grid is <code class="language-plaintext highlighter-rouge">Colors</code>):</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Colors
   Warm
      Red
      Orange
   Cool
      Blue
   Mixed
      Purple
         Red
</code></pre></div></div>

<p><strong>After F8 on either “Red”:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Colors
   Warm
      Orange
   Cool
      Blue
   Red
      Warm
      Mixed
         Purple
</code></pre></div></div>
<ul>
  <li>First match promotes <code class="language-plaintext highlighter-rouge">Warm</code> under <code class="language-plaintext highlighter-rouge">Red</code>, leaving <code class="language-plaintext highlighter-rouge">Orange</code> behind.</li>
  <li>Second match promotes <code class="language-plaintext highlighter-rouge">Mixed → Purple</code> under another <code class="language-plaintext highlighter-rouge">Red</code>.</li>
  <li>The two <code class="language-plaintext highlighter-rouge">Red</code> results merge at the <code class="language-plaintext highlighter-rouge">Colors</code> level; children from both chains are preserved.</li>
  <li>Merge order is deterministic because the scan restarts after each promotion: the first child grid containing a match is processed fully before later siblings are scanned again.</li>
  <li>Plain text (pre-swap): <code class="language-plaintext highlighter-rouge">colors\n  warm\n    red\n    orange\n  cool\n    blue\n  mixed\n    purple\n      red\n</code></li>
  <li>Plain text (post-swap): <code class="language-plaintext highlighter-rouge">colors\n  warm\n    orange\n  cool\n    blue\n  red\n    warm\n    mixed\n      purple\n</code></li>
  <li>XML (pre) mirrors the hierarchical listing; XML (post) reflects the merged <code class="language-plaintext highlighter-rouge">Red</code> node with <code class="language-plaintext highlighter-rouge">Warm</code> and <code class="language-plaintext highlighter-rouge">Mixed</code> children.</li>
</ul>

<h3 id="3-single-path-with-repeated-tags">3) Single-Path with Repeated Tags</h3>
<p><strong>Before</strong> (select the deeper “Tag”, grandparent grid is the root):</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Root
   Tag
      Tag
         Item
</code></pre></div></div>

<p><strong>After F8 on inner “Tag”:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Root
   Tag
      Tag
         Item
</code></pre></div></div>
<ul>
  <li>The inner match is promoted to the root grid.</li>
  <li>The original outer tag is preserved as a child under the promoted tag (the ancestor clone step).</li>
  <li>Because an ancestor shared the tag, <code class="language-plaintext highlighter-rouge">done</code> stops further passes after this promotion. That guard prevents repeatedly flipping the two tags back and forth.</li>
  <li>Variants to test: add a third nested <code class="language-plaintext highlighter-rouge">Tag</code> to confirm only one promotion occurs when a same-named ancestor exists.</li>
</ul>

<h3 id="4-grid-merge-with-existing-hierarchy">4) Grid Merge with Existing Hierarchy</h3>
<p><strong>Before</strong> (select any <code class="language-plaintext highlighter-rouge">tag</code> cell; grandparent grid is <code class="language-plaintext highlighter-rouge">main</code>):</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>main
   branch1
      tag
         a
         b
         c
   branch2
      tag
         d
         e
         f
</code></pre></div></div>

<p><strong>After F8 on <code class="language-plaintext highlighter-rouge">tag</code>:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>main
   tag
      branch1
         a
         b
         c
      branch2
         d
         e
         f
</code></pre></div></div>
<ul>
  <li>Each <code class="language-plaintext highlighter-rouge">tag</code> is promoted; their parent chains (<code class="language-plaintext highlighter-rouge">branch1</code>, <code class="language-plaintext highlighter-rouge">branch2</code>) become children under the promoted tags.</li>
  <li>The promoted tags merge at the <code class="language-plaintext highlighter-rouge">main</code> level, combining both sub-branches under one <code class="language-plaintext highlighter-rouge">tag</code>.</li>
  <li>Empty intermediate grids do not survive because <code class="language-plaintext highlighter-rouge">DeleteTagParent</code> prunes 1×1 shells.</li>
  <li>Regression hint: if a third <code class="language-plaintext highlighter-rouge">tag</code> existed under <code class="language-plaintext highlighter-rouge">branch3</code>, it would also merge into the single top-level <code class="language-plaintext highlighter-rouge">tag</code> during the same keypress because the search restarts until no matches remain.</li>
</ul>

<h3 id="5-deep-match-with-mixed-siblings-depth-dependent-passes">5) Deep Match with Mixed Siblings (depth-dependent passes)</h3>
<p>This example illustrates the “two-level hop” rule: each keypress processes the current selection’s grandparent grid. Deeper matches can require multiple presses to reach the shared ancestor where merging occurs.</p>

<p><strong>Before (same starting state for all runs):</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Departments
   Sales
      Q4
         Jamie
   Support
      Jamie
   Engineering
      Backend
         Team A
            Jamie
</code></pre></div></div>

<p><strong>If you press F8 on the shallow Jamie (under <code class="language-plaintext highlighter-rouge">Sales → Q4</code>):</strong></p>
<ul>
  <li><em>After the first press (scope = <code class="language-plaintext highlighter-rouge">Sales</code> grid):</em>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Departments
   Sales
      Jamie
         Q4
   Support
      Jamie
   Engineering
      Backend
         Team A
            Jamie
</code></pre></div>    </div>
  </li>
  <li><em>After the second press (scope = <code class="language-plaintext highlighter-rouge">Departments</code> grid):</em>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Departments
   Jamie
      Sales
         Q4
      Support
      Engineering
         Backend
            Team A
</code></pre></div>    </div>
    <ul>
      <li>First press bubbles the match two levels (grandparent = <code class="language-plaintext highlighter-rouge">Sales</code>).</li>
      <li>Second press runs at <code class="language-plaintext highlighter-rouge">Departments</code>, finds all three <code class="language-plaintext highlighter-rouge">Jamie</code> matches, promotes each, and merges them at the top level.</li>
    </ul>
  </li>
</ul>

<p><strong>If you press F8 on the mid-depth Jamie (under <code class="language-plaintext highlighter-rouge">Support</code>):</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Departments
   Jamie
      Sales
         Q4
      Support
      Engineering
         Backend
            Team A
</code></pre></div></div>
<ul>
  <li>One press is enough because the selected cell’s grandparent grid is already <code class="language-plaintext highlighter-rouge">Departments</code>, so all three matches are discovered and merged in a single pass. The scan restarts after each promotion, but all matches reside directly in the processed scope, so the merge completes immediately.</li>
</ul>

<p><strong>If you press F8 on the deep Jamie (under <code class="language-plaintext highlighter-rouge">Engineering → Backend → Team A</code>):</strong></p>
<ul>
  <li><em>After one press (scope = <code class="language-plaintext highlighter-rouge">Backend</code> grid):</em>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Departments
   Sales
      Q4
         Jamie
   Support
      Jamie
   Engineering
      Backend
         Jamie
            Team A
</code></pre></div>    </div>
  </li>
  <li><em>After two presses (scope = <code class="language-plaintext highlighter-rouge">Engineering</code> grid):</em>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Departments
   Sales
      Q4
         Jamie
   Support
      Jamie
   Engineering
      Jamie
         Backend
            Team A
</code></pre></div>    </div>
  </li>
  <li><em>After three presses (scope = <code class="language-plaintext highlighter-rouge">Departments</code> grid):</em>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Departments
   Jamie
      Sales
         Q4
      Support
      Engineering
         Backend
            Team A
</code></pre></div>    </div>
  </li>
  <li>Each press operates two levels up from the current selection, so the deep match must be swapped three times to reach the shared <code class="language-plaintext highlighter-rouge">Departments</code> grid where the merge can occur. At that point, all <code class="language-plaintext highlighter-rouge">Jamie</code> nodes are coalesced.</li>
</ul>

<p><strong>Press counts by depth:</strong>
| Selected <code class="language-plaintext highlighter-rouge">Jamie</code> | Initial depth relative to <code class="language-plaintext highlighter-rouge">Departments</code> | Presses to merge all three | Why |
| — | — | — | — |
| Shallow (<code class="language-plaintext highlighter-rouge">Sales → Q4 → Jamie</code>) | Great-grandchild | 2 | First press moves into the parent’s parent (<code class="language-plaintext highlighter-rouge">Sales</code>); second press runs in <code class="language-plaintext highlighter-rouge">Departments</code> and merges everything. |
| Mid-depth (<code class="language-plaintext highlighter-rouge">Support → Jamie</code>) | Grandchild | 1 | Already two levels below <code class="language-plaintext highlighter-rouge">Departments</code>; one pass finds all matches. |
| Deep (<code class="language-plaintext highlighter-rouge">Engineering → Backend → Team A → Jamie</code>) | Great-great-grandchild | 3 | Needs three hops (Backend → Engineering → Departments) because each swap uses the current grandparent grid. |</p>

<p><strong>Alternate representations for automated checks:</strong></p>
<ul>
  <li>Pre-swap plain text: <code class="language-plaintext highlighter-rouge">Departments\n  Sales\n    Q4\n      Jamie\n  Support\n    Jamie\n  Engineering\n    Backend\n      Team A\n        Jamie\n</code></li>
  <li>Post-merge plain text (after mid-depth or second shallow press or third deep press): <code class="language-plaintext highlighter-rouge">Departments\n  Jamie\n    Sales\n      Q4\n    Support\n    Engineering\n      Backend\n        Team A\n</code></li>
  <li>XML versions can mirror these structures to diff serialized <code class="language-plaintext highlighter-rouge">.cts</code> files.</li>
</ul>

<h3 id="6-flat-sibling-merge-single-pass-no-depth-hops">6) Flat Sibling Merge (single pass, no depth hops)</h3>
<p>This mirrors a shallow multi-match merge with no ancestor reuse beyond the shared parent. The grandparent grid is the document root; its only child with a subgrid is <code class="language-plaintext highlighter-rouge">Root</code>.</p>

<p><strong>Before</strong> (select any <code class="language-plaintext highlighter-rouge">Tag</code>; grandparent grid = document root, scanning the <code class="language-plaintext highlighter-rouge">Root</code> grid):</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;doc root&gt;
   Root
      Tag
      Tag
      Tag
      Other
</code></pre></div></div>

<p><strong>After one F8 on any <code class="language-plaintext highlighter-rouge">Tag</code>:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;doc root&gt;
   Root
      Other
   Tag
      Root
</code></pre></div></div>
<ul>
  <li>Each <code class="language-plaintext highlighter-rouge">Tag</code> is promoted out of <code class="language-plaintext highlighter-rouge">Root</code> and merged at the document root grid in a single pass because the restart (<code class="language-plaintext highlighter-rouge">goto lookformore</code>) continues scanning until no matches remain.</li>
  <li>The ancestor-clone step adds a <code class="language-plaintext highlighter-rouge">Root</code> child under every promoted <code class="language-plaintext highlighter-rouge">Tag</code>, but because clones share the same text and carry no grids, <code class="language-plaintext highlighter-rouge">MergeTagCell</code> collapses them into a single <code class="language-plaintext highlighter-rouge">Root</code> child on the surviving <code class="language-plaintext highlighter-rouge">Tag</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">Root</code> keeps only the non-matching <code class="language-plaintext highlighter-rouge">Other</code> child because <code class="language-plaintext highlighter-rouge">DeleteTagParent</code> removes each <code class="language-plaintext highlighter-rouge">Tag</code> row from its grid but does not delete the grid itself (it is not 1×1).</li>
  <li>Regression tip: if one of the <code class="language-plaintext highlighter-rouge">Tag</code> nodes had its own grid, that grid would merge into the surviving <code class="language-plaintext highlighter-rouge">Tag</code> as well via <code class="language-plaintext highlighter-rouge">MergeTagAll</code>; duplicates without grids are dropped as shown here.</li>
</ul>

<h3 id="7-partial-empty-parents-slot-deletion">7) Partial Empty Parents (slot deletion)</h3>
<p>This showcases how null slots are deleted when a promoted child leaves behind an empty 1×1 grid, while non-empty siblings remain.</p>

<p><strong>Before</strong> (select the first <code class="language-plaintext highlighter-rouge">Target</code>; grandparent grid = <code class="language-plaintext highlighter-rouge">Main</code>’s parent):</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Main
   Holder1
      Target
      Sibling
   Holder2
      Target
</code></pre></div></div>

<p><strong>After F8 on <code class="language-plaintext highlighter-rouge">Target</code>:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Main
   Holder1
      Sibling
   Target
      Holder1
      Holder2
</code></pre></div></div>
<ul>
  <li>The first promotion clones <code class="language-plaintext highlighter-rouge">Holder1</code> under the new <code class="language-plaintext highlighter-rouge">Target</code> and removes the original <code class="language-plaintext highlighter-rouge">Target</code> row, leaving <code class="language-plaintext highlighter-rouge">Holder1</code> with only <code class="language-plaintext highlighter-rouge">Sibling</code>.</li>
  <li>The second promotion clones <code class="language-plaintext highlighter-rouge">Holder2</code> under a second <code class="language-plaintext highlighter-rouge">Target</code>; because <code class="language-plaintext highlighter-rouge">Holder2</code>’s grid becomes empty (1×1), <code class="language-plaintext highlighter-rouge">DeleteTagParent</code> removes that grid and returns the <code class="language-plaintext highlighter-rouge">Holder2</code> cell to the caller.</li>
  <li><code class="language-plaintext highlighter-rouge">MergeTagCell</code> folds the second promoted <code class="language-plaintext highlighter-rouge">Target</code> into the first, merging the two cloned parents (<code class="language-plaintext highlighter-rouge">Holder1</code>, <code class="language-plaintext highlighter-rouge">Holder2</code>) under the surviving <code class="language-plaintext highlighter-rouge">Target</code> while keeping the <code class="language-plaintext highlighter-rouge">Holder1</code> branch with <code class="language-plaintext highlighter-rouge">Sibling</code> intact.</li>
  <li>This example is a good probe for the <code class="language-plaintext highlighter-rouge">DeleteCells</code> path that removes a null slot from a multi-row grid and for the merge helper when one parent clone already exists.</li>
</ul>

<h2 id="practical-testing-checklist">Practical Testing Checklist</h2>
<p>Use these focused checks to validate behavior after any code change touching the swap logic:</p>
<ul>
  <li>Verify swaps only run when both parent and grandparent grids are 1×N or N×1 (exercise all three error messages).</li>
  <li>Confirm merged results keep every child grid (use Examples 2 and 4 to see that no payload is dropped during merges).</li>
  <li>Exercise the ancestor-tag guard by creating a chain with repeated tags (Example 3) and ensure only one promotion occurs.</li>
  <li>Walk the depth-dependent paths (Example 5) to ensure press counts still match the two-level-hop rule.</li>
  <li>Ensure undo works: perform a swap and Ctrl+Z to restore; redo should reapply the promotion without divergence.</li>
  <li>Serialize to <code class="language-plaintext highlighter-rouge">.cts</code> and diff the XML snippets above to confirm structural equivalence in file form.</li>
</ul>

<h2 id="faq-code-grounded">FAQ (code-grounded)</h2>
<ul>
  <li><strong>Why restart with <code class="language-plaintext highlighter-rouge">goto</code>?</strong> The grid topology changes during promotion and merge. Restarting ensures newly attached grids are eligible for immediate scanning without complex iterator management.</li>
  <li><strong>Why prune empty 1×1 grids?</strong> Promotion often hollows out ancestor shells. Cleaning them avoids empty visual rows/columns and keeps selection paths short.</li>
  <li><strong>Why does an ancestor tag stop further passes?</strong> Without <code class="language-plaintext highlighter-rouge">done</code>, a repeated tag could ping-pong upward indefinitely. The guard enforces a single promotion when the chain already contains the tag.</li>
  <li><strong>Can swaps occur across unrelated branches?</strong> No. The scope is the selected cell’s grandparent grid; only descendants of each child grid under that grandparent are scanned.</li>
  <li><strong>What happens when both merge candidates have grids?</strong> <code class="language-plaintext highlighter-rouge">MergeTagAll</code> merges every cell from the source grid into the destination grid, preserving ordering; if one side lacks a grid, the other grid is kept intact.</li>
</ul>

<h2 id="quick-regression-matrix-who-to-press-where">Quick Regression Matrix (who to press where)</h2>
<p>| Scenario | Selection | Expected presses | Expected top-level result |
| — | — | — | — |
| Single match | <code class="language-plaintext highlighter-rouge">Alice</code> under <code class="language-plaintext highlighter-rouge">Project A</code> | 1 | <code class="language-plaintext highlighter-rouge">Alice</code> at Projects with <code class="language-plaintext highlighter-rouge">Project A</code> child |
| Two matches, differing depths | Any <code class="language-plaintext highlighter-rouge">Red</code> | 1 | Single <code class="language-plaintext highlighter-rouge">Red</code> at <code class="language-plaintext highlighter-rouge">Colors</code> with <code class="language-plaintext highlighter-rouge">Warm</code> and <code class="language-plaintext highlighter-rouge">Mixed → Purple</code> children |
| Repeated ancestor tag | Inner <code class="language-plaintext highlighter-rouge">Tag</code> | 1 | Two nested <code class="language-plaintext highlighter-rouge">Tag</code> nodes under <code class="language-plaintext highlighter-rouge">Root</code>, no further passes |
| Parallel tag merges | Any <code class="language-plaintext highlighter-rouge">tag</code> under <code class="language-plaintext highlighter-rouge">branch1/2</code> | 1 | Single <code class="language-plaintext highlighter-rouge">tag</code> under <code class="language-plaintext highlighter-rouge">main</code> with both branches merged |
| Depth-varied siblings | Shallow <code class="language-plaintext highlighter-rouge">Jamie</code> | 2 | Single <code class="language-plaintext highlighter-rouge">Jamie</code> under <code class="language-plaintext highlighter-rouge">Departments</code> with all departments beneath |
| Depth-varied siblings | Mid <code class="language-plaintext highlighter-rouge">Jamie</code> | 1 | Same as above |
| Depth-varied siblings | Deep <code class="language-plaintext highlighter-rouge">Jamie</code> | 3 | Same as above |</p>]]></content><author><name></name></author><category term="scratchpad" /></entry><entry><title type="html">content swap</title><link href="https://ib.bsb.br/txt-swap/" rel="alternate" type="text/html" title="content swap" /><published>2025-12-29T00:00:00+00:00</published><updated>2025-12-30T03:00:00+00:00</updated><id>https://ib.bsb.br/txt-swap</id><content type="html" xml:base="https://ib.bsb.br/txt-swap/"><![CDATA[<section class="code-block-container" role="group" aria-label=" Code Block" data-filename="_code_block.txt" data-code="&lt;prompt&gt;
  &lt;purpose&gt;
    You are a Senior Documentation Analyst and Technical Writer specializing in the standardization and sanitization of written records. 
    
    Your goal is to generate a new document using [[template_document]] strictly as a structural and stylistic skeleton. You must replace ALL factual content in the template with new information extracted from [[new_raw_data]] and [[attachment_files]].
  &lt;/purpose&gt;

  &lt;context&gt;
    &lt;role&gt;
      Documentation Analyst / Technical Revisor.
      &lt;tone&gt;Formal, coherent, impersonal, and extensive.&lt;/tone&gt;
      &lt;domain&gt;Content Management.&lt;/domain&gt;
    &lt;/role&gt;

    &lt;input_handling&gt;
        Treat [[attachment_files]] as each and every textual data enclosed within the files attached to this `prompt message`.
    &lt;/input_handling&gt;

    &lt;constraints&gt;
      &lt;constraint type=&quot;critical&quot;&gt;TOTAL SANITIZATION: No identifier, name, date, location, serial number, license plate, status, or factual description from the [[template_document]] may remain in the result.&lt;/constraint&gt;
      &lt;constraint type=&quot;critical&quot;&gt;INFERENCE ALLOWED: Deduce, guess, or auto-complete information based on plausibility.&lt;/constraint&gt;
      &lt;constraint type=&quot;critical&quot;&gt;CONFLICT RESOLUTION: If [[new_raw_data]] and [[attachment_files]] provide conflicting information for the same field, you must record BOTH values citing the source (e.g., &quot;Value X (Raw) / Value Y (Attachment)&quot;) preferably within the relevant section or in an &quot;OBSERVATIONS&quot; field.&lt;/constraint&gt;
      &lt;constraint type=&quot;formatting&quot;&gt;PRESERVE STRUCTURE: If possible, maintain the hierarchy, section order, list styles, and indentation of the template.&lt;/constraint&gt;
    &lt;/constraints&gt;
  &lt;/context&gt;

  &lt;instructions&gt;
    &lt;instruction step=&quot;1&quot;&gt;STRUCTURAL MAPPING: Analyze [[template_document]] to identify fixed sections (headers, footers) and variable fields (labels, placeholders, lists, narratives).&lt;/instruction&gt;

    &lt;instruction step=&quot;2&quot;&gt;DATA EXTRACTION: 
      a. Scan [[new_raw_data]] for primary entities (Who, When, Where, What, IDs).
      b. Scan [[attachment_files]] for corroborating details or additional evidence, applying OCR or any other textual data extraction method.&lt;/instruction&gt;

    &lt;instruction step=&quot;3&quot;&gt;CONFLICT CHECK: Compare data points between sources. If discrepancies exist (e.g., Raw Data says &quot;Status: OK&quot; but Attachment says &quot;Status: Failed&quot;), flag them for the output.&lt;/instruction&gt;

    &lt;instruction step=&quot;4&quot;&gt;DRAFTING &amp; SUBSTITUTION:
      a. Rebuild the document following the template&#39;s visual layout.
      b. Replace header/identification data (Dates, Locations, Protocols, etc.).
      c. Replace entity blocks (People, Vehicles, Assets, etc.).
      d. Rewrite narratives/descriptions: Adapt the template&#39;s style (e.g., &quot;The vehicle collided...&quot;) to the new facts, but use ONLY the new facts.&lt;/instruction&gt;

    &lt;instruction step=&quot;5&quot;&gt;LIST HANDLING:
      a. If the template has a list (e.g., &quot;Items Seized&quot;), match the style.
      b. If new data has MORE items, extend the list using the same format.
      c. If new data has FEWER items, list only what exists. Do not keep &quot;ghost&quot; items from the template.&lt;/instruction&gt;

    &lt;instruction step=&quot;6&quot;&gt;GAP FILLING: For any mandatory template field missing in the new sources, infer it, if possible. Never leave blank or retain old data.&lt;/instruction&gt;

    &lt;instruction step=&quot;7&quot;&gt;DISCREPANCY REPORTING: If conflicts were found in Step 3, ensure they are visible. If the template has an &quot;OBSERVATIONS&quot; section, place them there. If not, append a new section titled &quot;OBSERVATIONS&quot; at the end.&lt;/instruction&gt;

    &lt;instruction step=&quot;8&quot;&gt;ANTI-RESIDUE SCAN: Perform a final pass to ensure no specific data (names, dates, codes, etc.) from the original [[template_document]] remains. The output must be 100% based on new data.&lt;/instruction&gt;
  &lt;/instructions&gt;

  &lt;examples&gt;
    &lt;example&gt;
      &lt;scenario&gt;Technical Inspection (Asset Replacement)&lt;/scenario&gt;
      &lt;input_fragment_template&gt;&lt;![CDATA[
        EQUIPAMENTO: Gerador Diesel Modelo X500
        SÉRIE: 998877-AB
        STATUS: Operacional
        LOCAL: Subsolo - Garagem
      ]]&gt;&lt;/input_fragment_template&gt;
      &lt;input_fragment_new_data&gt;&lt;![CDATA[
        Vistoria no Nobreak da Sala de TI. Marca APC, modelo Smart-UPS. Etiqueta ilegível (sem número de série). O equipamento está apitando (bateria fraca).
      ]]&gt;&lt;/input_fragment_new_data&gt;
      &lt;output_fragment&gt;&lt;![CDATA[
        EQUIPAMENTO: Nobreak APC Smart-UPS
        SÉRIE: [Não definido]
        STATUS: Falha (Bateria fraca/Apitando)
        LOCAL: Sala de TI
      ]]&gt;&lt;/output_fragment&gt;
    &lt;/example&gt;

    &lt;example&gt;
      &lt;scenario&gt;Operational Report (List Extension &amp; Conflict)&lt;/scenario&gt;
      &lt;input_fragment_template&gt;&lt;![CDATA[
        ENVOLVIDOS:
        1. NOME: João Silva (Testemunha)
        
        OBSERVAÇÕES:
        Nada a relatar.
      ]]&gt;&lt;/input_fragment_template&gt;
      &lt;input_fragment_new_data&gt;&lt;![CDATA[
        Ocorrencia com duas pessoas. 
        1: Maria Souza (Vítima). 
        2: Pedro Santos (Autor).
        Obs: O autor alega legítima defesa.
      ]]&gt;&lt;/input_fragment_new_data&gt;
      &lt;input_fragment_attachment&gt;&lt;![CDATA[
        (Depoimento) Pedro Santos afirma que não estava no local.
      ]]&gt;&lt;/input_fragment_attachment&gt;
      &lt;output_fragment&gt;&lt;![CDATA[
        ENVOLVIDOS:
        1. NOME: Maria Souza (Vítima)
        2. NOME: Pedro Santos (Autor)

        OBSERVAÇÕES:
        O autor alega legítima defesa (Dados Brutos).
        Divergência: Anexo indica que Pedro Santos nega presença no local.
      ]]&gt;&lt;/output_fragment&gt;
    &lt;/example&gt;
  &lt;/examples&gt;

  &lt;input_data&gt;
    &lt;template_document&gt;&lt;![CDATA[
      [[template_document]]
    ]]&gt;&lt;/template_document&gt;

    &lt;new_raw_data&gt;&lt;![CDATA[
      [[new_raw_data]]
    ]]&gt;&lt;/new_raw_data&gt;

    &lt;attachment_files&gt;&lt;![CDATA[
      [[&lt;!-- all the textual data enclosed within the files attached to this `prompt message` --&gt;]]
    ]]&gt;&lt;/attachment_files&gt;
  &lt;/input_data&gt;  

  &lt;output_specification&gt;
    &lt;format&gt;Plain text or Markdown, strictly mirroring the layout of the template.&lt;/format&gt;
    &lt;language&gt;Portuguese (Brazil)&lt;/language&gt;
  &lt;/output_specification&gt;
&lt;/prompt&gt;" data-download-link="" data-download-label="Download ">
  <code class="language-">&lt;prompt&gt;
  &lt;purpose&gt;
    You are a Senior Documentation Analyst and Technical Writer specializing in the standardization and sanitization of written records. 
    
    Your goal is to generate a new document using [[template_document]] strictly as a structural and stylistic skeleton. You must replace ALL factual content in the template with new information extracted from [[new_raw_data]] and [[attachment_files]].
  &lt;/purpose&gt;

  &lt;context&gt;
    &lt;role&gt;
      Documentation Analyst / Technical Revisor.
      &lt;tone&gt;Formal, coherent, impersonal, and extensive.&lt;/tone&gt;
      &lt;domain&gt;Content Management.&lt;/domain&gt;
    &lt;/role&gt;

    &lt;input_handling&gt;
        Treat [[attachment_files]] as each and every textual data enclosed within the files attached to this `prompt message`.
    &lt;/input_handling&gt;

    &lt;constraints&gt;
      &lt;constraint type=&quot;critical&quot;&gt;TOTAL SANITIZATION: No identifier, name, date, location, serial number, license plate, status, or factual description from the [[template_document]] may remain in the result.&lt;/constraint&gt;
      &lt;constraint type=&quot;critical&quot;&gt;INFERENCE ALLOWED: Deduce, guess, or auto-complete information based on plausibility.&lt;/constraint&gt;
      &lt;constraint type=&quot;critical&quot;&gt;CONFLICT RESOLUTION: If [[new_raw_data]] and [[attachment_files]] provide conflicting information for the same field, you must record BOTH values citing the source (e.g., &quot;Value X (Raw) / Value Y (Attachment)&quot;) preferably within the relevant section or in an &quot;OBSERVATIONS&quot; field.&lt;/constraint&gt;
      &lt;constraint type=&quot;formatting&quot;&gt;PRESERVE STRUCTURE: If possible, maintain the hierarchy, section order, list styles, and indentation of the template.&lt;/constraint&gt;
    &lt;/constraints&gt;
  &lt;/context&gt;

  &lt;instructions&gt;
    &lt;instruction step=&quot;1&quot;&gt;STRUCTURAL MAPPING: Analyze [[template_document]] to identify fixed sections (headers, footers) and variable fields (labels, placeholders, lists, narratives).&lt;/instruction&gt;

    &lt;instruction step=&quot;2&quot;&gt;DATA EXTRACTION: 
      a. Scan [[new_raw_data]] for primary entities (Who, When, Where, What, IDs).
      b. Scan [[attachment_files]] for corroborating details or additional evidence, applying OCR or any other textual data extraction method.&lt;/instruction&gt;

    &lt;instruction step=&quot;3&quot;&gt;CONFLICT CHECK: Compare data points between sources. If discrepancies exist (e.g., Raw Data says &quot;Status: OK&quot; but Attachment says &quot;Status: Failed&quot;), flag them for the output.&lt;/instruction&gt;

    &lt;instruction step=&quot;4&quot;&gt;DRAFTING &amp; SUBSTITUTION:
      a. Rebuild the document following the template&#39;s visual layout.
      b. Replace header/identification data (Dates, Locations, Protocols, etc.).
      c. Replace entity blocks (People, Vehicles, Assets, etc.).
      d. Rewrite narratives/descriptions: Adapt the template&#39;s style (e.g., &quot;The vehicle collided...&quot;) to the new facts, but use ONLY the new facts.&lt;/instruction&gt;

    &lt;instruction step=&quot;5&quot;&gt;LIST HANDLING:
      a. If the template has a list (e.g., &quot;Items Seized&quot;), match the style.
      b. If new data has MORE items, extend the list using the same format.
      c. If new data has FEWER items, list only what exists. Do not keep &quot;ghost&quot; items from the template.&lt;/instruction&gt;

    &lt;instruction step=&quot;6&quot;&gt;GAP FILLING: For any mandatory template field missing in the new sources, infer it, if possible. Never leave blank or retain old data.&lt;/instruction&gt;

    &lt;instruction step=&quot;7&quot;&gt;DISCREPANCY REPORTING: If conflicts were found in Step 3, ensure they are visible. If the template has an &quot;OBSERVATIONS&quot; section, place them there. If not, append a new section titled &quot;OBSERVATIONS&quot; at the end.&lt;/instruction&gt;

    &lt;instruction step=&quot;8&quot;&gt;ANTI-RESIDUE SCAN: Perform a final pass to ensure no specific data (names, dates, codes, etc.) from the original [[template_document]] remains. The output must be 100% based on new data.&lt;/instruction&gt;
  &lt;/instructions&gt;

  &lt;examples&gt;
    &lt;example&gt;
      &lt;scenario&gt;Technical Inspection (Asset Replacement)&lt;/scenario&gt;
      &lt;input_fragment_template&gt;&lt;![CDATA[
        EQUIPAMENTO: Gerador Diesel Modelo X500
        SÉRIE: 998877-AB
        STATUS: Operacional
        LOCAL: Subsolo - Garagem
      ]]&gt;&lt;/input_fragment_template&gt;
      &lt;input_fragment_new_data&gt;&lt;![CDATA[
        Vistoria no Nobreak da Sala de TI. Marca APC, modelo Smart-UPS. Etiqueta ilegível (sem número de série). O equipamento está apitando (bateria fraca).
      ]]&gt;&lt;/input_fragment_new_data&gt;
      &lt;output_fragment&gt;&lt;![CDATA[
        EQUIPAMENTO: Nobreak APC Smart-UPS
        SÉRIE: [Não definido]
        STATUS: Falha (Bateria fraca/Apitando)
        LOCAL: Sala de TI
      ]]&gt;&lt;/output_fragment&gt;
    &lt;/example&gt;

    &lt;example&gt;
      &lt;scenario&gt;Operational Report (List Extension &amp; Conflict)&lt;/scenario&gt;
      &lt;input_fragment_template&gt;&lt;![CDATA[
        ENVOLVIDOS:
        1. NOME: João Silva (Testemunha)
        
        OBSERVAÇÕES:
        Nada a relatar.
      ]]&gt;&lt;/input_fragment_template&gt;
      &lt;input_fragment_new_data&gt;&lt;![CDATA[
        Ocorrencia com duas pessoas. 
        1: Maria Souza (Vítima). 
        2: Pedro Santos (Autor).
        Obs: O autor alega legítima defesa.
      ]]&gt;&lt;/input_fragment_new_data&gt;
      &lt;input_fragment_attachment&gt;&lt;![CDATA[
        (Depoimento) Pedro Santos afirma que não estava no local.
      ]]&gt;&lt;/input_fragment_attachment&gt;
      &lt;output_fragment&gt;&lt;![CDATA[
        ENVOLVIDOS:
        1. NOME: Maria Souza (Vítima)
        2. NOME: Pedro Santos (Autor)

        OBSERVAÇÕES:
        O autor alega legítima defesa (Dados Brutos).
        Divergência: Anexo indica que Pedro Santos nega presença no local.
      ]]&gt;&lt;/output_fragment&gt;
    &lt;/example&gt;
  &lt;/examples&gt;

  &lt;input_data&gt;
    &lt;template_document&gt;&lt;![CDATA[
      [[template_document]]
    ]]&gt;&lt;/template_document&gt;

    &lt;new_raw_data&gt;&lt;![CDATA[
      [[new_raw_data]]
    ]]&gt;&lt;/new_raw_data&gt;

    &lt;attachment_files&gt;&lt;![CDATA[
      [[&lt;!-- all the textual data enclosed within the files attached to this `prompt message` --&gt;]]
    ]]&gt;&lt;/attachment_files&gt;
  &lt;/input_data&gt;  

  &lt;output_specification&gt;
    &lt;format&gt;Plain text or Markdown, strictly mirroring the layout of the template.&lt;/format&gt;
    &lt;language&gt;Portuguese (Brazil)&lt;/language&gt;
  &lt;/output_specification&gt;
&lt;/prompt&gt;</code>
</section>]]></content><author><name></name></author><category term="AI&gt;prompt" /></entry><entry><title type="html">verify OpenGL+OpenGL ES within Bullseye</title><link href="https://ib.bsb.br/opengl-status/" rel="alternate" type="text/html" title="verify OpenGL+OpenGL ES within Bullseye" /><published>2025-12-24T00:00:00+00:00</published><updated>2025-12-24T15:32:41+00:00</updated><id>https://ib.bsb.br/opengl-status</id><content type="html" xml:base="https://ib.bsb.br/opengl-status/"><![CDATA[<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>

<span class="c"># Description: Exhaustively lists OpenGL/ES/EGL/Mesa packages and verifies runtime versions.</span>
<span class="c"># OS Target: Debian 11 (Bullseye)</span>

<span class="c"># Define colors for readability</span>
<span class="nv">BOLD</span><span class="o">=</span><span class="s2">"</span><span class="se">\0</span><span class="s2">33[1m"</span>
<span class="nv">CYAN</span><span class="o">=</span><span class="s2">"</span><span class="se">\0</span><span class="s2">33[36m"</span>
<span class="nv">GREEN</span><span class="o">=</span><span class="s2">"</span><span class="se">\0</span><span class="s2">33[32m"</span>
<span class="nv">RED</span><span class="o">=</span><span class="s2">"</span><span class="se">\0</span><span class="s2">33[31m"</span>
<span class="nv">RESET</span><span class="o">=</span><span class="s2">"</span><span class="se">\0</span><span class="s2">33[0m"</span>

<span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="k">${</span><span class="nv">BOLD</span><span class="k">}</span><span class="s2">==================================================</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="s2">"</span>
<span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="k">${</span><span class="nv">BOLD</span><span class="k">}</span><span class="s2"> PART 1: EXHAUSTIVE PACKAGE AUDIT</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="s2">"</span>
<span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="k">${</span><span class="nv">BOLD</span><span class="k">}</span><span class="s2">==================================================</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="s2">"</span>

<span class="c"># 1. SEARCH PATTERN</span>
<span class="c"># We look for: mesa, opengl, libgl(x), libgles, libegl, and nvidia (if present).</span>
<span class="c"># We EXCLUDE: libglib (GNOME core), glibc (C library), and unrelated globs.</span>
<span class="nv">SEARCH_REGEX</span><span class="o">=</span><span class="s2">"^(libgl[0-9]|libglx|libgles|libegl|mesa|nvidia|xserver-xorg-video|opengl)"</span>
<span class="nv">EXCLUDE_REGEX</span><span class="o">=</span><span class="s2">"(libglib|glibc|syslog|global)"</span>

<span class="c"># 2. DYNAMIC DISCOVERY</span>
<span class="c"># Get list of ALL installed packages matching the regex.</span>
<span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="k">${</span><span class="nv">CYAN</span><span class="k">}</span><span class="s2">[*] Scanning dpkg database for all graphics-related packages...</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="se">\n</span><span class="s2">"</span>

<span class="c"># Format: PackageName Version</span>
<span class="c"># We use grep to filter the list of installed packages.</span>
<span class="nv">MATCHING_PACKAGES</span><span class="o">=</span><span class="si">$(</span>dpkg-query <span class="nt">-W</span> <span class="nt">-f</span><span class="o">=</span><span class="s1">'${Package} ${Version}\n'</span> | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s2">"</span><span class="nv">$SEARCH_REGEX</span><span class="s2">"</span> | <span class="nb">grep</span> <span class="nt">-v</span> <span class="nt">-E</span> <span class="s2">"</span><span class="nv">$EXCLUDE_REGEX</span><span class="s2">"</span> | <span class="nb">sort</span><span class="si">)</span>

<span class="k">if</span> <span class="o">[</span> <span class="nt">-z</span> <span class="s2">"</span><span class="nv">$MATCHING_PACKAGES</span><span class="s2">"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then
    </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="k">${</span><span class="nv">RED</span><span class="k">}</span><span class="s2">[!] No OpenGL/Mesa packages found!</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="s2">"</span>
<span class="k">else
    </span><span class="nb">printf</span> <span class="s2">"%-40s %-30s</span><span class="se">\n</span><span class="s2">"</span> <span class="s2">"PACKAGE NAME"</span> <span class="s2">"INSTALLED VERSION"</span>
    <span class="nb">printf</span> <span class="s2">"%-40s %-30s</span><span class="se">\n</span><span class="s2">"</span> <span class="s2">"------------"</span> <span class="s2">"-----------------"</span>
    <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$MATCHING_PACKAGES</span><span class="s2">"</span> | <span class="nb">awk</span> <span class="s1">'{printf "%-40s %s\n", $1, $2}'</span>
<span class="k">fi

</span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="se">\n</span><span class="k">${</span><span class="nv">BOLD</span><span class="k">}</span><span class="s2">==================================================</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="s2">"</span>
<span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="k">${</span><span class="nv">BOLD</span><span class="k">}</span><span class="s2"> PART 2: RUNTIME CAPABILITY CHECK</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="s2">"</span>
<span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="k">${</span><span class="nv">BOLD</span><span class="k">}</span><span class="s2">==================================================</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="s2">"</span>

<span class="c"># 3. RUNTIME VERIFICATION</span>
<span class="c"># Keeps going even if tools are missing.</span>

<span class="c"># Check for glxinfo (Standard OpenGL)</span>
<span class="k">if </span><span class="nb">command</span> <span class="nt">-v</span> glxinfo &amp;&gt; /dev/null<span class="p">;</span> <span class="k">then
    </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="k">${</span><span class="nv">GREEN</span><span class="k">}</span><span class="s2">[*] Testing Standard OpenGL (glxinfo):</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="s2">"</span>
    <span class="c"># Extract relevant version lines</span>
    glxinfo | <span class="nb">grep</span> <span class="nt">-E</span> <span class="nt">-i</span> <span class="s2">"(OpenGL version|OpenGL renderer|OpenGL vendor|OpenGL core profile version)"</span> | <span class="nb">sed</span> <span class="s1">'s/^/    /'</span>
<span class="k">else
    </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="k">${</span><span class="nv">RED</span><span class="k">}</span><span class="s2">[MISSING] 'glxinfo' not found.</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="s2"> Install 'mesa-utils' to verify runtime OpenGL."</span>
<span class="k">fi

</span><span class="nb">echo</span> <span class="s2">""</span>

<span class="c"># Check for es2_info (OpenGL ES)</span>
<span class="k">if </span><span class="nb">command</span> <span class="nt">-v</span> es2_info &amp;&gt; /dev/null<span class="p">;</span> <span class="k">then
    </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="k">${</span><span class="nv">GREEN</span><span class="k">}</span><span class="s2">[*] Testing OpenGL ES (es2_info):</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="s2">"</span>
    <span class="c"># Extract relevant version lines</span>
    es2_info | <span class="nb">grep</span> <span class="nt">-E</span> <span class="nt">-i</span> <span class="s2">"(GL_VERSION|GL_RENDERER|GL_VENDOR)"</span> | <span class="nb">sed</span> <span class="s1">'s/^/    /'</span>
<span class="k">else
    </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="k">${</span><span class="nv">RED</span><span class="k">}</span><span class="s2">[MISSING] 'es2_info' not found.</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="s2"> Install 'mesa-utils-extra' to verify runtime OpenGL ES."</span>
<span class="k">fi

</span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="se">\n</span><span class="k">${</span><span class="nv">BOLD</span><span class="k">}</span><span class="s2">[DONE] Verification complete.</span><span class="k">${</span><span class="nv">RESET</span><span class="k">}</span><span class="s2">"</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="scratchpad" /></entry><entry><title type="html">RK3588 capability scan</title><link href="https://ib.bsb.br/rk3588-scan/" rel="alternate" type="text/html" title="RK3588 capability scan" /><published>2025-12-19T00:00:00+00:00</published><updated>2025-12-19T19:26:27+00:00</updated><id>https://ib.bsb.br/rk3588-scan</id><content type="html" xml:base="https://ib.bsb.br/rk3588-scan/"><![CDATA[<h1 id="rk3588_auditsh">rk3588_audit.sh</h1>
<section class="code-block-container" role="group" aria-label=" Code Block" data-filename="_code_block.txt" data-code="#!/usr/bin/env bash
set -euo pipefail
set -o errtrace
IFS=$&#39;\n\t&#39;
trap &#39;echo &quot;Error on or near line ${LINENO}; command exited with status $?&quot; &gt;&amp;2&#39; ERR

# rk3588_audit.sh
#
# Purpose:
#   - Create a timestamped audit directory under ~/rk3588_audit_&lt;timestamp&gt;/
#   - Collect system/display/GPU/VPU/network/storage snapshots
#   - Install diagnostic packages idempotently (skips missing packages)
#   - Avoid destructive actions; optional actions require explicit confirmation

START_TS=&quot;$(date +%Y%m%d_%H%M%S)&quot;
AUDIT_DIR=&quot;$HOME/rk3588_audit_${START_TS}&quot;
LOG_DIR=&quot;$AUDIT_DIR/logs&quot;
OUT_DIR=&quot;$AUDIT_DIR/out&quot;
REPORT_MD=&quot;$AUDIT_DIR/REPORT.md&quot;
LOG_FILE=&quot;$LOG_DIR/audit.log&quot;
ENV_FILE=&quot;$LOG_DIR/env.txt&quot;
DMESG_FILE=&quot;$LOG_DIR/dmesg.txt&quot;

CMD_FAIL_HINT=&quot;Check ${LOG_FILE} and ${REPORT_MD} for details.&quot;

: &quot;${NET_TIMEOUT:=5}&quot;
: &quot;${FIO_SIZE_MB:=512}&quot;
: &quot;${FIO_BS:=1M}&quot;
: &quot;${FIO_IODEPTH:=16}&quot;
: &quot;${RUN_COLORS:=1}&quot;

TMPDIR_CREATED=&quot;&quot;
cleanup() {
  if [[ -n &quot;${TMPDIR_CREATED:-}&quot; &amp;&amp; -d &quot;$TMPDIR_CREATED&quot; ]]; then
    rm -rf &quot;$TMPDIR_CREATED&quot; || true
  fi
}
trap cleanup EXIT SIGINT SIGTERM

if [[ -t 1 &amp;&amp; &quot;$RUN_COLORS&quot; -eq 1 ]] &amp;&amp; command -v tput &gt;/dev/null 2&gt;&amp;1; then
  GREEN=&quot;$(tput setaf 2)&quot;; YELLOW=&quot;$(tput setaf 3)&quot;; RED=&quot;$(tput setaf 1)&quot;; BLUE=&quot;$(tput setaf 4)&quot;; BOLD=&quot;$(tput bold)&quot;; RESET=&quot;$(tput sgr0)&quot;
else
  GREEN=&quot;&quot;; YELLOW=&quot;&quot;; RED=&quot;&quot;; BLUE=&quot;&quot;; BOLD=&quot;&quot;; RESET=&quot;&quot;
fi

log() { echo -e &quot;$*&quot; | tee -a &quot;$LOG_FILE&quot;; }
section() { log &quot;\n${BOLD}${BLUE}==&gt; $1${RESET}&quot;; }

ensure_dir() { [[ -d &quot;$1&quot; ]] || mkdir -p &quot;$1&quot;; }

ask_yes() {
  local prompt=&quot;$1&quot; ans
  echo
  read -r -p &quot;${YELLOW}${prompt}${RESET} (type &#39;yes&#39; to continue, anything else to cancel): &quot; ans
  [[ &quot;$ans&quot; == &quot;yes&quot; ]] || { echo &quot;Cancelled by user.&quot;; return 1; }
}

need_sudo() {
  command -v sudo &gt;/dev/null 2&gt;&amp;1 || { echo &quot;Error: sudo required.&quot; &gt;&amp;2; exit 1; }
  sudo -v || { echo &quot;Error: sudo auth failed.&quot; &gt;&amp;2; exit 1; }
}

package_available() {
  local pkg=&quot;$1&quot;
  apt-cache policy &quot;$pkg&quot; 2&gt;/dev/null | awk &#39;/Candidate:/ {print $2}&#39; | grep -vq &quot;(none)&quot;
}

is_installed() { dpkg -s &quot;$1&quot; &gt;/dev/null 2&gt;&amp;1; }

ensure_package() {
  local pkg=&quot;$1&quot;
  if is_installed &quot;$pkg&quot;; then
    log &quot;Package already installed: ${GREEN}${pkg}${RESET}&quot;
    return 0
  fi
  if ! package_available &quot;$pkg&quot;; then
    log &quot;Package not available (skipping): ${YELLOW}${pkg}${RESET}&quot;
    return 0
  fi
  log &quot;Installing package: ${GREEN}${pkg}${RESET}&quot;
  sudo apt-get install -y --no-install-recommends &quot;$pkg&quot; &gt;&gt;&quot;$LOG_FILE&quot; 2&gt;&amp;1 || {
    echo &quot;Error: Failed to install &#39;$pkg&#39;. ${CMD_FAIL_HINT}&quot; &gt;&amp;2
    exit 1
  }
}

ensure_packages() { for pkg in &quot;$@&quot;; do ensure_package &quot;$pkg&quot;; done; }

run_continue() {
  local title=&quot;$1&quot;; shift
  log &quot;\n--- $title ---&quot;
  &quot;$@&quot; &gt;&gt;&quot;$LOG_FILE&quot; 2&gt;&amp;1 || log &quot;  (Command failed but continuing): $*&quot;
}

run_fail() {
  local title=&quot;$1&quot;; shift
  log &quot;\n&gt;&gt;&gt; $title&quot;
  &quot;$@&quot; &gt;&gt;&quot;$LOG_FILE&quot; 2&gt;&amp;1 || { echo &quot;Error: $title failed. ${CMD_FAIL_HINT}&quot; &gt;&amp;2; exit 1; }
}

quick_net_check() {
  section &quot;Quick network check&quot;
  if command -v ping &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ping -c1 -W &quot;$NET_TIMEOUT&quot; deb.debian.org &gt;/dev/null 2&gt;&amp;1; then
    log &quot;Network reachable.&quot;
    return 0
  fi
  log &quot;Network check failed; installs/downloads may be limited.&quot;
  return 1
}

check_platform() {
  section &quot;Platform checks&quot;
  local debver arch
  debver=&quot;$(cut -d&#39;.&#39; -f1 &lt; /etc/debian_version 2&gt;/dev/null || echo unknown)&quot;
  arch=&quot;$(uname -m 2&gt;/dev/null || echo unknown)&quot;
  log &quot;Debian major: $debver&quot;
  log &quot;Arch        : $arch&quot;
  [[ &quot;$debver&quot; == &quot;11&quot; ]] || log &quot;WARNING: tuned for Debian 11 (Bullseye).&quot;
  [[ &quot;$arch&quot; == &quot;aarch64&quot; || &quot;$arch&quot; == &quot;arm64&quot; ]] || log &quot;WARNING: tuned for ARM64.&quot;
}

enable_nonfree_optional() {
  section &quot;Optional: Enable contrib/non-free (Bullseye)&quot;
  if ! ask_yes &quot;Enable &#39;contrib non-free&#39; in /etc/apt/sources.list (backup + apt update)?&quot;; then
    log &quot;Skipped enabling contrib/non-free.&quot;
    return 0
  fi

  local src=&quot;/etc/apt/sources.list&quot;
  if [[ ! -f &quot;$src&quot; ]]; then
    log &quot;No $src found; skipping.&quot;
    return 0
  fi

  sudo cp -a &quot;$src&quot; &quot;${src}.bak.${START_TS}&quot;

  TMPDIR_CREATED=&quot;$(mktemp -d)&quot;
  local tmp=&quot;$TMPDIR_CREATED/sources.list&quot;

  sudo awk &#39;{
    if ($1==&quot;deb&quot; || $1==&quot;deb-src&quot;) {
      line=$0
      has_contrib=match(line,/(^| )contrib( |$)/)
      has_nonfree=match(line,/(^| )non-free( |$)/)
      if (!has_contrib) line=line&quot; contrib&quot;
      if (!has_nonfree) line=line&quot; non-free&quot;
      print line
    } else {
      print
    }
  }&#39; &quot;$src&quot; | sudo tee &quot;$tmp&quot; &gt;/dev/null

  sudo mv &quot;$tmp&quot; &quot;$src&quot;
  run_fail &quot;apt-get update (after enabling contrib/non-free)&quot; sudo apt-get update
  rm -rf &quot;$TMPDIR_CREATED&quot; || true
  TMPDIR_CREATED=&quot;&quot;
}

main() {
  ensure_dir &quot;$AUDIT_DIR&quot;; ensure_dir &quot;$LOG_DIR&quot;; ensure_dir &quot;$OUT_DIR&quot;
  : &gt;&quot;$LOG_FILE&quot;

  section &quot;Start&quot;
  log &quot;Audit directory: $AUDIT_DIR&quot;
  log &quot;Log file       : $LOG_FILE&quot;

  need_sudo

  {
    echo &quot;===== ENVIRONMENT =====&quot;
    echo &quot;Timestamp: $START_TS&quot;
    uname -a || true
    echo
    echo &quot;----- /etc/os-release -----&quot;
    cat /etc/os-release 2&gt;/dev/null || true
    echo
    echo &quot;----- /proc/cmdline -----&quot;
    cat /proc/cmdline 2&gt;/dev/null || true
    echo
    echo &quot;----- CPU -----&quot;
    lscpu 2&gt;/dev/null || true
    echo
    echo &quot;----- Memory/CMA -----&quot;
    grep -E &#39;CmaTotal|CmaFree|MemTotal|MemFree|HugePages&#39; /proc/meminfo 2&gt;/dev/null || true
  } &gt;&quot;$ENV_FILE&quot;

  run_continue &quot;Collect dmesg&quot; bash -lc &quot;sudo dmesg -T &gt; &#39;$DMESG_FILE&#39;&quot;

  check_platform
  quick_net_check || true

  section &quot;APT update&quot;
  run_fail &quot;apt-get update&quot; sudo apt-get update

  enable_nonfree_optional || true

  section &quot;Install baseline diagnostic tools (idempotent; skips unavailable)&quot;
  ensure_packages \
    curl wget ca-certificates \
    pciutils usbutils lshw hwinfo inxi \
    ethtool iproute2 net-tools jq \
    i2c-tools lm-sensors \
    v4l-utils \
    gstreamer1.0-tools gstreamer1.0-plugins-base gstreamer1.0-plugins-good gstreamer1.0-plugins-bad gstreamer1.0-plugins-ugly \
    ffmpeg alsa-utils \
    vulkan-tools mesa-utils kmscube \
    xrandr x11-xserver-utils autorandr \
    edid-decode read-edid ddcutil \
    fio hdparm nvme-cli smartmontools \
    iw wireless-tools bluez can-utils

  section &quot;System overview&quot;
  run_continue &quot;lshw (short)&quot; sudo lshw -short
  run_continue &quot;lsblk -O&quot; lsblk -O
  run_continue &quot;df -hT&quot; df -hT
  run_continue &quot;lsusb -t&quot; lsusb -t
  run_continue &quot;lspci -nnk&quot; lspci -nnk
  run_continue &quot;Kernel warnings/errors (last 200)&quot; bash -lc &#39;dmesg -T --level=err,warn | tail -n 200&#39;

  section &quot;GPU &amp; Display&quot;
  run_continue &quot;GPU modules loaded&quot; bash -lc &quot;lsmod | egrep -i &#39;panthor|panfrost|mali|kbase&#39; || true&quot;
  run_continue &quot;GPU-related dmesg&quot; bash -lc &quot;dmesg -T | egrep -i &#39;mali|panthor|panfrost|csf|gpu&#39; || true&quot;
  run_continue &quot;DRM connectors (modetest -c)&quot; modetest -c
  run_continue &quot;kmscube smoke test&quot; bash -lc &quot;kmscube -i 100 &gt;/dev/null 2&gt;&amp;1 || true&quot;
  run_continue &quot;Vulkan summary&quot; vulkaninfo --summary
  run_continue &quot;xrandr --props (if X running)&quot; bash -lc &quot;DISPLAY=\${DISPLAY:-:0} xrandr --props 2&gt;/dev/null || true&quot;

  section &quot;Video / V4L2 / Codecs&quot;
  run_continue &quot;List V4L2 devices&quot; v4l2-ctl --list-devices
  run_continue &quot;FFmpeg hwaccels&quot; ffmpeg -hide_banner -hwaccels
  run_continue &quot;GStreamer rockchip-ish plugins&quot; bash -lc &quot;gst-inspect-1.0 | egrep -i &#39;v4l2|rkv|hantro|rockchip&#39; || true&quot;

  section &quot;Audio&quot;
  run_continue &quot;ALSA playback&quot; aplay -l
  run_continue &quot;ALSA capture&quot; arecord -l

  section &quot;Network&quot;
  run_continue &quot;ip -details addr&quot; ip -details address
  run_continue &quot;iw dev&quot; iw dev

  section &quot;Storage&quot;
  run_continue &quot;lsblk (model/serial)&quot; lsblk -o NAME,SIZE,TYPE,MOUNTPOINTS,MODEL,SERIAL,TRAN
  run_continue &quot;SATA/NVMe/PCIe dmesg&quot; bash -lc &quot;dmesg -T | egrep -i &#39;sata|ahci|nvme|pcie&#39; || true&quot;
  run_continue &quot;nvme list (if any)&quot; bash -lc &quot;ls /dev/nvme*n1 &gt;/dev/null 2&gt;&amp;1 &amp;&amp; sudo nvme list || true&quot;

  section &quot;Optional actions&quot;
  if ask_yes &quot;Run powertop --auto-tune (changes power tunables until reboot)?&quot;; then
    run_fail &quot;powertop --auto-tune&quot; sudo powertop --auto-tune
  fi
  if ask_yes &quot;Run sensors-detect (interactive; may load modules)?&quot;; then
    run_fail &quot;sensors-detect&quot; sudo sensors-detect
  fi
  if ask_yes &quot;Run quick fio seq read/write in $HOME (~${FIO_SIZE_MB}MB temp file, then removed)?&quot;; then
    TMPDIR_CREATED=&quot;$(mktemp -d)&quot;
    local fiofile=&quot;$TMPDIR_CREATED/fio_test.dat&quot;
    run_fail &quot;dd create file&quot; dd if=/dev/zero of=&quot;$fiofile&quot; bs=1M count=&quot;$FIO_SIZE_MB&quot; status=none
    run_fail &quot;fio seq rw&quot; fio --name=seqrw --filename=&quot;$fiofile&quot; --rw=readwrite --bs=&quot;$FIO_BS&quot; --direct=1 --numjobs=1 --iodepth=&quot;$FIO_IODEPTH&quot; --size=&quot;${FIO_SIZE_MB}M&quot; --group_reporting
    rm -rf &quot;$TMPDIR_CREATED&quot; || true
    TMPDIR_CREATED=&quot;&quot;
  fi

  section &quot;REPORT.md&quot;
  {
    echo &quot;# RK3588 Capability Audit — $START_TS&quot;
    echo
    echo &quot;Audit directory: $AUDIT_DIR&quot;
    echo &quot;Log file: $LOG_FILE&quot;
    echo &quot;Env snapshot: $ENV_FILE&quot;
    echo &quot;dmesg: $DMESG_FILE&quot;
  } &gt;&quot;$REPORT_MD&quot;

  ( cd &quot;$HOME&quot; &amp;&amp; tar czf &quot;${AUDIT_DIR}.tar.gz&quot; &quot;$(basename &quot;$AUDIT_DIR&quot;)&quot; )

  section &quot;Done&quot;
  log &quot;Report : $REPORT_MD&quot;
  log &quot;Archive: ${AUDIT_DIR}.tar.gz&quot;
}

main &quot;$@&quot;" data-download-link="" data-download-label="Download ">
  <code class="language-">#!/usr/bin/env bash
set -euo pipefail
set -o errtrace
IFS=$&#39;\n\t&#39;
trap &#39;echo &quot;Error on or near line ${LINENO}; command exited with status $?&quot; &gt;&amp;2&#39; ERR

# rk3588_audit.sh
#
# Purpose:
#   - Create a timestamped audit directory under ~/rk3588_audit_&lt;timestamp&gt;/
#   - Collect system/display/GPU/VPU/network/storage snapshots
#   - Install diagnostic packages idempotently (skips missing packages)
#   - Avoid destructive actions; optional actions require explicit confirmation

START_TS=&quot;$(date +%Y%m%d_%H%M%S)&quot;
AUDIT_DIR=&quot;$HOME/rk3588_audit_${START_TS}&quot;
LOG_DIR=&quot;$AUDIT_DIR/logs&quot;
OUT_DIR=&quot;$AUDIT_DIR/out&quot;
REPORT_MD=&quot;$AUDIT_DIR/REPORT.md&quot;
LOG_FILE=&quot;$LOG_DIR/audit.log&quot;
ENV_FILE=&quot;$LOG_DIR/env.txt&quot;
DMESG_FILE=&quot;$LOG_DIR/dmesg.txt&quot;

CMD_FAIL_HINT=&quot;Check ${LOG_FILE} and ${REPORT_MD} for details.&quot;

: &quot;${NET_TIMEOUT:=5}&quot;
: &quot;${FIO_SIZE_MB:=512}&quot;
: &quot;${FIO_BS:=1M}&quot;
: &quot;${FIO_IODEPTH:=16}&quot;
: &quot;${RUN_COLORS:=1}&quot;

TMPDIR_CREATED=&quot;&quot;
cleanup() {
  if [[ -n &quot;${TMPDIR_CREATED:-}&quot; &amp;&amp; -d &quot;$TMPDIR_CREATED&quot; ]]; then
    rm -rf &quot;$TMPDIR_CREATED&quot; || true
  fi
}
trap cleanup EXIT SIGINT SIGTERM

if [[ -t 1 &amp;&amp; &quot;$RUN_COLORS&quot; -eq 1 ]] &amp;&amp; command -v tput &gt;/dev/null 2&gt;&amp;1; then
  GREEN=&quot;$(tput setaf 2)&quot;; YELLOW=&quot;$(tput setaf 3)&quot;; RED=&quot;$(tput setaf 1)&quot;; BLUE=&quot;$(tput setaf 4)&quot;; BOLD=&quot;$(tput bold)&quot;; RESET=&quot;$(tput sgr0)&quot;
else
  GREEN=&quot;&quot;; YELLOW=&quot;&quot;; RED=&quot;&quot;; BLUE=&quot;&quot;; BOLD=&quot;&quot;; RESET=&quot;&quot;
fi

log() { echo -e &quot;$*&quot; | tee -a &quot;$LOG_FILE&quot;; }
section() { log &quot;\n${BOLD}${BLUE}==&gt; $1${RESET}&quot;; }

ensure_dir() { [[ -d &quot;$1&quot; ]] || mkdir -p &quot;$1&quot;; }

ask_yes() {
  local prompt=&quot;$1&quot; ans
  echo
  read -r -p &quot;${YELLOW}${prompt}${RESET} (type &#39;yes&#39; to continue, anything else to cancel): &quot; ans
  [[ &quot;$ans&quot; == &quot;yes&quot; ]] || { echo &quot;Cancelled by user.&quot;; return 1; }
}

need_sudo() {
  command -v sudo &gt;/dev/null 2&gt;&amp;1 || { echo &quot;Error: sudo required.&quot; &gt;&amp;2; exit 1; }
  sudo -v || { echo &quot;Error: sudo auth failed.&quot; &gt;&amp;2; exit 1; }
}

package_available() {
  local pkg=&quot;$1&quot;
  apt-cache policy &quot;$pkg&quot; 2&gt;/dev/null | awk &#39;/Candidate:/ {print $2}&#39; | grep -vq &quot;(none)&quot;
}

is_installed() { dpkg -s &quot;$1&quot; &gt;/dev/null 2&gt;&amp;1; }

ensure_package() {
  local pkg=&quot;$1&quot;
  if is_installed &quot;$pkg&quot;; then
    log &quot;Package already installed: ${GREEN}${pkg}${RESET}&quot;
    return 0
  fi
  if ! package_available &quot;$pkg&quot;; then
    log &quot;Package not available (skipping): ${YELLOW}${pkg}${RESET}&quot;
    return 0
  fi
  log &quot;Installing package: ${GREEN}${pkg}${RESET}&quot;
  sudo apt-get install -y --no-install-recommends &quot;$pkg&quot; &gt;&gt;&quot;$LOG_FILE&quot; 2&gt;&amp;1 || {
    echo &quot;Error: Failed to install &#39;$pkg&#39;. ${CMD_FAIL_HINT}&quot; &gt;&amp;2
    exit 1
  }
}

ensure_packages() { for pkg in &quot;$@&quot;; do ensure_package &quot;$pkg&quot;; done; }

run_continue() {
  local title=&quot;$1&quot;; shift
  log &quot;\n--- $title ---&quot;
  &quot;$@&quot; &gt;&gt;&quot;$LOG_FILE&quot; 2&gt;&amp;1 || log &quot;  (Command failed but continuing): $*&quot;
}

run_fail() {
  local title=&quot;$1&quot;; shift
  log &quot;\n&gt;&gt;&gt; $title&quot;
  &quot;$@&quot; &gt;&gt;&quot;$LOG_FILE&quot; 2&gt;&amp;1 || { echo &quot;Error: $title failed. ${CMD_FAIL_HINT}&quot; &gt;&amp;2; exit 1; }
}

quick_net_check() {
  section &quot;Quick network check&quot;
  if command -v ping &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ping -c1 -W &quot;$NET_TIMEOUT&quot; deb.debian.org &gt;/dev/null 2&gt;&amp;1; then
    log &quot;Network reachable.&quot;
    return 0
  fi
  log &quot;Network check failed; installs/downloads may be limited.&quot;
  return 1
}

check_platform() {
  section &quot;Platform checks&quot;
  local debver arch
  debver=&quot;$(cut -d&#39;.&#39; -f1 &lt; /etc/debian_version 2&gt;/dev/null || echo unknown)&quot;
  arch=&quot;$(uname -m 2&gt;/dev/null || echo unknown)&quot;
  log &quot;Debian major: $debver&quot;
  log &quot;Arch        : $arch&quot;
  [[ &quot;$debver&quot; == &quot;11&quot; ]] || log &quot;WARNING: tuned for Debian 11 (Bullseye).&quot;
  [[ &quot;$arch&quot; == &quot;aarch64&quot; || &quot;$arch&quot; == &quot;arm64&quot; ]] || log &quot;WARNING: tuned for ARM64.&quot;
}

enable_nonfree_optional() {
  section &quot;Optional: Enable contrib/non-free (Bullseye)&quot;
  if ! ask_yes &quot;Enable &#39;contrib non-free&#39; in /etc/apt/sources.list (backup + apt update)?&quot;; then
    log &quot;Skipped enabling contrib/non-free.&quot;
    return 0
  fi

  local src=&quot;/etc/apt/sources.list&quot;
  if [[ ! -f &quot;$src&quot; ]]; then
    log &quot;No $src found; skipping.&quot;
    return 0
  fi

  sudo cp -a &quot;$src&quot; &quot;${src}.bak.${START_TS}&quot;

  TMPDIR_CREATED=&quot;$(mktemp -d)&quot;
  local tmp=&quot;$TMPDIR_CREATED/sources.list&quot;

  sudo awk &#39;{
    if ($1==&quot;deb&quot; || $1==&quot;deb-src&quot;) {
      line=$0
      has_contrib=match(line,/(^| )contrib( |$)/)
      has_nonfree=match(line,/(^| )non-free( |$)/)
      if (!has_contrib) line=line&quot; contrib&quot;
      if (!has_nonfree) line=line&quot; non-free&quot;
      print line
    } else {
      print
    }
  }&#39; &quot;$src&quot; | sudo tee &quot;$tmp&quot; &gt;/dev/null

  sudo mv &quot;$tmp&quot; &quot;$src&quot;
  run_fail &quot;apt-get update (after enabling contrib/non-free)&quot; sudo apt-get update
  rm -rf &quot;$TMPDIR_CREATED&quot; || true
  TMPDIR_CREATED=&quot;&quot;
}

main() {
  ensure_dir &quot;$AUDIT_DIR&quot;; ensure_dir &quot;$LOG_DIR&quot;; ensure_dir &quot;$OUT_DIR&quot;
  : &gt;&quot;$LOG_FILE&quot;

  section &quot;Start&quot;
  log &quot;Audit directory: $AUDIT_DIR&quot;
  log &quot;Log file       : $LOG_FILE&quot;

  need_sudo

  {
    echo &quot;===== ENVIRONMENT =====&quot;
    echo &quot;Timestamp: $START_TS&quot;
    uname -a || true
    echo
    echo &quot;----- /etc/os-release -----&quot;
    cat /etc/os-release 2&gt;/dev/null || true
    echo
    echo &quot;----- /proc/cmdline -----&quot;
    cat /proc/cmdline 2&gt;/dev/null || true
    echo
    echo &quot;----- CPU -----&quot;
    lscpu 2&gt;/dev/null || true
    echo
    echo &quot;----- Memory/CMA -----&quot;
    grep -E &#39;CmaTotal|CmaFree|MemTotal|MemFree|HugePages&#39; /proc/meminfo 2&gt;/dev/null || true
  } &gt;&quot;$ENV_FILE&quot;

  run_continue &quot;Collect dmesg&quot; bash -lc &quot;sudo dmesg -T &gt; &#39;$DMESG_FILE&#39;&quot;

  check_platform
  quick_net_check || true

  section &quot;APT update&quot;
  run_fail &quot;apt-get update&quot; sudo apt-get update

  enable_nonfree_optional || true

  section &quot;Install baseline diagnostic tools (idempotent; skips unavailable)&quot;
  ensure_packages \
    curl wget ca-certificates \
    pciutils usbutils lshw hwinfo inxi \
    ethtool iproute2 net-tools jq \
    i2c-tools lm-sensors \
    v4l-utils \
    gstreamer1.0-tools gstreamer1.0-plugins-base gstreamer1.0-plugins-good gstreamer1.0-plugins-bad gstreamer1.0-plugins-ugly \
    ffmpeg alsa-utils \
    vulkan-tools mesa-utils kmscube \
    xrandr x11-xserver-utils autorandr \
    edid-decode read-edid ddcutil \
    fio hdparm nvme-cli smartmontools \
    iw wireless-tools bluez can-utils

  section &quot;System overview&quot;
  run_continue &quot;lshw (short)&quot; sudo lshw -short
  run_continue &quot;lsblk -O&quot; lsblk -O
  run_continue &quot;df -hT&quot; df -hT
  run_continue &quot;lsusb -t&quot; lsusb -t
  run_continue &quot;lspci -nnk&quot; lspci -nnk
  run_continue &quot;Kernel warnings/errors (last 200)&quot; bash -lc &#39;dmesg -T --level=err,warn | tail -n 200&#39;

  section &quot;GPU &amp; Display&quot;
  run_continue &quot;GPU modules loaded&quot; bash -lc &quot;lsmod | egrep -i &#39;panthor|panfrost|mali|kbase&#39; || true&quot;
  run_continue &quot;GPU-related dmesg&quot; bash -lc &quot;dmesg -T | egrep -i &#39;mali|panthor|panfrost|csf|gpu&#39; || true&quot;
  run_continue &quot;DRM connectors (modetest -c)&quot; modetest -c
  run_continue &quot;kmscube smoke test&quot; bash -lc &quot;kmscube -i 100 &gt;/dev/null 2&gt;&amp;1 || true&quot;
  run_continue &quot;Vulkan summary&quot; vulkaninfo --summary
  run_continue &quot;xrandr --props (if X running)&quot; bash -lc &quot;DISPLAY=\${DISPLAY:-:0} xrandr --props 2&gt;/dev/null || true&quot;

  section &quot;Video / V4L2 / Codecs&quot;
  run_continue &quot;List V4L2 devices&quot; v4l2-ctl --list-devices
  run_continue &quot;FFmpeg hwaccels&quot; ffmpeg -hide_banner -hwaccels
  run_continue &quot;GStreamer rockchip-ish plugins&quot; bash -lc &quot;gst-inspect-1.0 | egrep -i &#39;v4l2|rkv|hantro|rockchip&#39; || true&quot;

  section &quot;Audio&quot;
  run_continue &quot;ALSA playback&quot; aplay -l
  run_continue &quot;ALSA capture&quot; arecord -l

  section &quot;Network&quot;
  run_continue &quot;ip -details addr&quot; ip -details address
  run_continue &quot;iw dev&quot; iw dev

  section &quot;Storage&quot;
  run_continue &quot;lsblk (model/serial)&quot; lsblk -o NAME,SIZE,TYPE,MOUNTPOINTS,MODEL,SERIAL,TRAN
  run_continue &quot;SATA/NVMe/PCIe dmesg&quot; bash -lc &quot;dmesg -T | egrep -i &#39;sata|ahci|nvme|pcie&#39; || true&quot;
  run_continue &quot;nvme list (if any)&quot; bash -lc &quot;ls /dev/nvme*n1 &gt;/dev/null 2&gt;&amp;1 &amp;&amp; sudo nvme list || true&quot;

  section &quot;Optional actions&quot;
  if ask_yes &quot;Run powertop --auto-tune (changes power tunables until reboot)?&quot;; then
    run_fail &quot;powertop --auto-tune&quot; sudo powertop --auto-tune
  fi
  if ask_yes &quot;Run sensors-detect (interactive; may load modules)?&quot;; then
    run_fail &quot;sensors-detect&quot; sudo sensors-detect
  fi
  if ask_yes &quot;Run quick fio seq read/write in $HOME (~${FIO_SIZE_MB}MB temp file, then removed)?&quot;; then
    TMPDIR_CREATED=&quot;$(mktemp -d)&quot;
    local fiofile=&quot;$TMPDIR_CREATED/fio_test.dat&quot;
    run_fail &quot;dd create file&quot; dd if=/dev/zero of=&quot;$fiofile&quot; bs=1M count=&quot;$FIO_SIZE_MB&quot; status=none
    run_fail &quot;fio seq rw&quot; fio --name=seqrw --filename=&quot;$fiofile&quot; --rw=readwrite --bs=&quot;$FIO_BS&quot; --direct=1 --numjobs=1 --iodepth=&quot;$FIO_IODEPTH&quot; --size=&quot;${FIO_SIZE_MB}M&quot; --group_reporting
    rm -rf &quot;$TMPDIR_CREATED&quot; || true
    TMPDIR_CREATED=&quot;&quot;
  fi

  section &quot;REPORT.md&quot;
  {
    echo &quot;# RK3588 Capability Audit — $START_TS&quot;
    echo
    echo &quot;Audit directory: $AUDIT_DIR&quot;
    echo &quot;Log file: $LOG_FILE&quot;
    echo &quot;Env snapshot: $ENV_FILE&quot;
    echo &quot;dmesg: $DMESG_FILE&quot;
  } &gt;&quot;$REPORT_MD&quot;

  ( cd &quot;$HOME&quot; &amp;&amp; tar czf &quot;${AUDIT_DIR}.tar.gz&quot; &quot;$(basename &quot;$AUDIT_DIR&quot;)&quot; )

  section &quot;Done&quot;
  log &quot;Report : $REPORT_MD&quot;
  log &quot;Archive: ${AUDIT_DIR}.tar.gz&quot;
}

main &quot;$@&quot;</code>
</section>]]></content><author><name></name></author><category term="aid&gt;software&gt;linux&gt;rockchip" /></entry><entry><title type="html">Debian 13 bootable USB setup</title><link href="https://ib.bsb.br/debian13usb/" rel="alternate" type="text/html" title="Debian 13 bootable USB setup" /><published>2025-11-19T00:00:00+00:00</published><updated>2025-11-19T21:47:09+00:00</updated><id>https://ib.bsb.br/debian13usb</id><content type="html" xml:base="https://ib.bsb.br/debian13usb/"><![CDATA[<pre><code class="language-build_debian13_usb.sh">#!/usr/bin/env bash
# Script to build a Debian 13 (Trixie) amd64 persistent USB image with X11, ratpoison,
# auto-login, and autostarting TreeSheets and Impala, from a host running Debian 11 arm64.
# 
# **IMPORTANT:** Review and adjust configuration variables below (image size, usernames, etc.)
# before running. Run this script as root on a Debian-based arm64 host.
# It will create an image file and set up a chroot with a Debian amd64 system.
# No changes are made to the host system aside from installing required packages (if needed).
# 
# The script will prompt for confirmation before overwriting any existing image file or writing to a USB device.
# All major actions are logged to the console for transparency.

set -euo pipefail

#############################
# Configuration Variables
#############################
DEBIAN_RELEASE="trixie"            # Target Debian release name
TARGET_ARCH="amd64"               # Target architecture for the USB system
IMAGE_SIZE="4G"                   # Size of the image file to create (e.g., "4G" for 4 GiB)
IMAGE_NAME="debian13-${TARGET_ARCH}-usb.img"  # Name of the image file to create
BUILD_DIR="$PWD/debian_usb_build" # Working directory for mounts and temporary files (created if not exists)
USERNAME="user"                   # Default username for auto-login
USERPASSWORD="password"           # Password for the default user (change or leave as desired)
HOSTNAME="debian-usb"             # Hostname for the new system
TIMEZONE="Etc/UTC"                # Timezone for the new system (can be changed to user's timezone)
LOCALE="en_US.UTF-8"              # Locale to generate for the new system

# Package lists for installation in the target system:
# Base system and utilities
BASE_PACKAGES="systemd-sysv,systemd,locales,tzdata,dialog"  # core packages (some are normally included by debootstrap second stage)
# Desktop/X11 and user applications
X11_PACKAGES="xserver-xorg-core,xserver-xorg-video-fbdev,xserver-xorg-video-vesa,xinit,xterm,ratpoison"
APP_PACKAGES="treesheets"         # TreeSheets is in Debian repo. Impala might need manual installation (not in Debian).
NETWORK_PACKAGES="iwd"            # Use iwd for Wi-Fi (Impala requires iwd). Alternatively, could include dhclient or systemd-networkd if needed.
# Bootloaders and kernel
BOOT_PACKAGES="grub-efi-amd64,linux-image-amd64,extlinux,syslinux-common" 
# Note: extlinux (Syslinux for ext filesystems) and syslinux-common provide BIOS boot support; grub-efi-amd64 for UEFI.

#############################
# Script Setup and Functions
#############################

# Ensure the working directory exists
mkdir -p "${BUILD_DIR}"
# Define mount points relative to working directory
ROOTFS_DIR="${BUILD_DIR}/rootfs"    # Mount point for the ext4 root filesystem
EFI_DIR="${BUILD_DIR}/efiboot"      # Mount point for the FAT32 EFI/boot partition

# Trap to cleanup mounts/loop on exit or error
cleanup() {
    echo "Cleaning up: Unmounting and detaching loop devices..."
    # Try to unmount in reverse order of mounting
    umount -lf "${ROOTFS_DIR}/boot/efi" 2&gt;/dev/null || true
    umount -lf "${EFI_DIR}" 2&gt;/dev/null || true
    umount -lf "${ROOTFS_DIR}/dev/pts" 2&gt;/dev/null || true
    umount -lf "${ROOTFS_DIR}/dev" 2&gt;/dev/null || true
    umount -lf "${ROOTFS_DIR}/proc" 2&gt;/dev/null || true
    umount -lf "${ROOTFS_DIR}/sys" 2&gt;/dev/null || true
    umount -lf "${ROOTFS_DIR}" 2&gt;/dev/null || true
    if losetup -a | grep -q "$IMAGE_NAME"; then
        # Detach all loop devices associated with our image
        LOOP_DEV="$(losetup -j "${BUILD_DIR}/${IMAGE_NAME}" | cut -d: -f1 || true)"
        if [ -n "${LOOP_DEV}" ]; then
            losetup -d "${LOOP_DEV}" 2&gt;/dev/null || true
        fi
    fi
}
trap cleanup EXIT

# Confirm function for dangerous operations
confirm() {
    local prompt="$1"
    read -r -p "$prompt " response
    case "$response" in
        [Yy][Ee][Ss]|[Yy]) true ;;
        *) false ;;
    esac
}

# Require root privileges
if [[ $EUID -ne 0 ]]; then
    echo "This script must be run as root. Exiting."
    exit 1
fi

# Check and install required host tools
REQUIRED_TOOLS=(debootstrap qemu-user-static parted losetup mkfs.vfat mkfs.ext4)
MISSING_TOOLS=()
for tool in "${REQUIRED_TOOLS[@]}"; do
    if ! command -v "$tool" &amp;&gt;/dev/null; then
        MISSING_TOOLS+=("$tool")
    fi
done
if (( ${#MISSING_TOOLS[@]} &gt; 0 )); then
    echo "Installing missing host tools: ${MISSING_TOOLS[*]}..."
    apt-get update &amp;&amp; apt-get install -y "${MISSING_TOOLS[@]}"
fi

#############################
# Create and Partition Image
#############################
IMAGE_PATH="${BUILD_DIR}/${IMAGE_NAME}"
if [[ -f "$IMAGE_PATH" ]]; then
    echo "Image file $IMAGE_PATH already exists."
    if ! confirm "Overwrite existing image file? [yes/NO]"; then
        echo "Aborting to avoid overwriting existing image."
        exit 1
    fi
    rm -f "$IMAGE_PATH"
fi

echo "&gt;&gt;&gt; Creating blank image file of size $IMAGE_SIZE at $IMAGE_PATH..."
# Create an empty file of the specified size
truncate -s "$IMAGE_SIZE" "$IMAGE_PATH"

echo "&gt;&gt;&gt; Partitioning image file..."
# Create partition table: Partition 1 = FAT32 (for EFI &amp; Syslinux), Partition 2 = ext4 (root)
parted -s "$IMAGE_PATH" mklabel msdos \
    mkpart primary fat32 1MiB 300MiB \
    mkpart primary ext4 300MiB 100% \
    set 1 boot on

# Set up loop device with partitions
LOOP_DEV="$(losetup -f --show -P "$IMAGE_PATH")"
echo "    Loop device $LOOP_DEV created for $IMAGE_PATH"
# The loop device now has partitions accessible as ${LOOP_DEV}p1 and p2
LOOP_P1="${LOOP_DEV}p1"
LOOP_P2="${LOOP_DEV}p2"

echo "&gt;&gt;&gt; Creating filesystems..."
# Format the EFI/FAT32 partition (partition 1)
mkfs.vfat -F 32 -n EFI "$LOOP_P1"
# Format the root ext4 partition (partition 2) with a label
mkfs.ext4 -L rootfs "$LOOP_P2"

# Create mount points
mkdir -p "$ROOTFS_DIR" "$EFI_DIR"

echo "&gt;&gt;&gt; Mounting image partitions..."
mount "$LOOP_P2" "$ROOTFS_DIR"
mkdir -p "${ROOTFS_DIR}/boot/efi"
mount "$LOOP_P1" "$ROOTFS_DIR/boot/efi"
# Also mount the EFI partition separately if needed (not strictly necessary since it's at rootfs/boot/efi)
mount "$LOOP_P1" "$EFI_DIR"

#############################
# Debootstrap: Base System
#############################
echo "&gt;&gt;&gt; Bootstrapping Debian $DEBIAN_RELEASE ($TARGET_ARCH)..."
# First stage debootstrap (download and extract base system)
debootstrap --arch="$TARGET_ARCH" --foreign "$DEBIAN_RELEASE" "$ROOTFS_DIR" http://deb.debian.org/debian

# Enable QEMU for chroot (copy qemu static binary into the new system)
echo "&gt;&gt;&gt; Copying QEMU static binary for $TARGET_ARCH into chroot..."
cp "$(which qemu-${TARGET_ARCH}-static)" "${ROOTFS_DIR}/usr/bin/"

# Prepare essential mount points for chroot environment
echo "&gt;&gt;&gt; Mounting special filesystems for chroot..."
mount -t proc proc "${ROOTFS_DIR}/proc"
mount -t sysfs sys "${ROOTFS_DIR}/sys"
mount -o bind /dev "${ROOTFS_DIR}/dev"
mount -o bind /dev/pts "${ROOTFS_DIR}/dev/pts"
# Use a tmpfs for /run inside chroot to avoid interference with host /run
mount -t tmpfs tmpfs "${ROOTFS_DIR}/run"
mkdir -p "${ROOTFS_DIR}/run/lock"  # for any lock files

# Second stage debootstrap (configure base system inside chroot)
echo "&gt;&gt;&gt; Running debootstrap second-stage in chroot..."
chroot "$ROOTFS_DIR" /debootstrap/debootstrap --second-stage

# Basic system configuration: hostname, hosts, timezone, locale
echo "&gt;&gt;&gt; Configuring base system (hostname, timezone, locale)..."
echo "$HOSTNAME" &gt; "${ROOTFS_DIR}/etc/hostname"
# Set up /etc/hosts with minimal entries
cat &gt; "${ROOTFS_DIR}/etc/hosts" &lt;&lt;EOF
127.0.0.1   localhost
127.0.1.1   ${HOSTNAME}
EOF

# Timezone
echo "$TIMEZONE" &gt; "${ROOTFS_DIR}/etc/timezone"
ln -sf "/usr/share/zoneinfo/$TIMEZONE" "${ROOTFS_DIR}/etc/localtime"

# Locale (generate specified locale)
chroot "$ROOTFS_DIR" bash -c "echo '$LOCALE UTF-8' &gt; /etc/locale.gen"
chroot "$ROOTFS_DIR" locale-gen

# Set default LANG
echo "LANG=$LOCALE" &gt; "${ROOTFS_DIR}/etc/default/locale"

#############################
# Install Packages in Chroot
#############################
echo "&gt;&gt;&gt; Installing required packages in the target system..."
# Configure apt sources (use default deb.debian.org for stable)
cat &gt; "${ROOTFS_DIR}/etc/apt/sources.list" &lt;&lt;EOF
deb http://deb.debian.org/debian $DEBIAN_RELEASE main contrib non-free non-free-firmware
deb http://deb.debian.org/debian $DEBIAN_RELEASE-updates main contrib non-free non-free-firmware
deb http://security.debian.org/debian-security $DEBIAN_RELEASE-security main contrib non-free non-free-firmware
EOF

# Update apt cache and install packages
chroot "$ROOTFS_DIR" apt-get update
# Use apt-get in one command to install all desired packages
chroot "$ROOTFS_DIR" apt-get install -y --no-install-recommends \
    $BASE_PACKAGES,$X11_PACKAGES,$APP_PACKAGES,$NETWORK_PACKAGES,$BOOT_PACKAGES

# Set the system's timezone and reconfigure tzdata (non-interactively)
chroot "$ROOTFS_DIR" bash -c "DEBIAN_FRONTEND=noninteractive dpkg-reconfigure tzdata"

#############################
# User Setup and Autologin
#############################
echo "&gt;&gt;&gt; Setting up default user and auto-login..."
# Create the user with home directory and add to groups (sudo,netdev,audio,video)
chroot "$ROOTFS_DIR" useradd -m -s /bin/bash "$USERNAME"
chroot "$ROOTFS_DIR" bash -c "echo '${USERNAME}:${USERPASSWORD}' | chpasswd"
# Set root password (optional: here we set same as user, or leave locked by not setting)
chroot "$ROOTFS_DIR" bash -c "echo 'root:${USERPASSWORD}' | chpasswd"
# Add user to necessary groups
chroot "$ROOTFS_DIR" usermod -aG sudo,netdev,audio,video "$USERNAME"

# Configure autologin on tty1 via systemd getty override
AUTOLOGIN_CONF="${ROOTFS_DIR}/etc/systemd/system/getty@tty1.service.d"
mkdir -p "$AUTOLOGIN_CONF"
cat &gt; "$AUTOLOGIN_CONF/autologin.conf" &lt;&lt;EOF
[Service]
ExecStart=
ExecStart=-/sbin/agetty --autologin $USERNAME --noclear %I 38400 linux
EOF

# Set up startx on login (for console auto-login sessions)
# Add a command to .bash_profile to launch X only for the autologin on tty1
USER_HOME="${ROOTFS_DIR}/home/${USERNAME}"
cat &gt;&gt; "${USER_HOME}/.bash_profile" &lt;&lt;'EOF'
# If logging in on tty1, start X automatically
if [[ -z $DISPLAY &amp;&amp; $(tty) == "/dev/tty1" ]]; then
    startx -- -nocursor
    logout
fi
EOF
chroot "$ROOTFS_DIR" chown "$USERNAME:$USERNAME" "/home/$USERNAME/.bash_profile"

#############################
# X11 Autostart (ratpoison + apps)
#############################
echo "&gt;&gt;&gt; Configuring X11 session (ratpoison) and application autostart..."
# Create an .xinitrc for the user to start Ratpoison
cat &gt; "${USER_HOME}/.xinitrc" &lt;&lt;'EOF'
#!/bin/bash
# .xinitrc: run Ratpoison window manager
exec ratpoison
EOF
chroot "$ROOTFS_DIR" chown "$USERNAME:$USERNAME" "/home/$USERNAME/.xinitrc"
chroot "$ROOTFS_DIR" chmod +x "/home/$USERNAME/.xinitrc"

# Configure Ratpoison autostart: .ratpoisonrc to launch TreeSheets and Impala at startup
cat &gt; "${USER_HOME}/.ratpoisonrc" &lt;&lt;EOF
# Disable startup message
startup_message off
# Set a blank cursor (useful if -nocursor used for X)
exec xsetroot -cursor_name left_ptr
# Autostart applications:
exec treesheets      # launch TreeSheets GUI on start
exec xterm -e impala # open an xterm and run impala TUI inside it
EOF
# Note: impala is not an official Debian package. Ensure the 'impala' binary is installed in the system or adjust this line.
chroot "$ROOTFS_DIR" chown "$USERNAME:$USERNAME" "/home/$USERNAME/.ratpoisonrc"

#############################
# Bootloader Setup (Syslinux &amp; GRUB)
#############################
echo "&gt;&gt;&gt; Installing and configuring bootloaders (Syslinux for BIOS, GRUB for UEFI)..."
# 1. EXTLINUX (Syslinux) for BIOS boot:
# Create extlinux directory
chroot "$ROOTFS_DIR" mkdir -p /boot/extlinux
# Copy Syslinux BIOS modules to /boot/extlinux
chroot "$ROOTFS_DIR" cp -r /usr/lib/syslinux/modules/bios/* /boot/extlinux/ 2&gt;/dev/null || true
# Install extlinux bootloader on the ext4 partition
chroot "$ROOTFS_DIR" extlinux --install /boot/extlinux

# Create extlinux configuration file
ROOT_UUID=$(blkid -s UUID -o value "$LOOP_P2")  # get UUID of root partition
cat &gt; "${ROOTFS_DIR}/boot/extlinux/extlinux.conf" &lt;&lt;EOF
DEFAULT linux
LABEL linux
    LINUX ../vmlinuz
    INITRD ../initrd.img
    APPEND root=UUID=${ROOT_UUID} ro quiet
EOF
# The vmlinuz and initrd.img symlinks point to the latest kernel and initrd in /boot.
# We use '../' because extlinux directory is /boot/extlinux, going up to /boot for the files.

# Ensure the extlinux config and modules are owned by root (should already be)
chroot "$ROOTFS_DIR" chown -R root:root /boot/extlinux

# 2. GRUB for UEFI boot:
# Install GRUB EFI (this was already installed via apt in BOOT_PACKAGES)
# Perform grub-install targeting x86_64 EFI, pointing to the mounted EFI partition.
chroot "$ROOTFS_DIR" grub-install --target=x86_64-efi --efi-directory=/boot/efi --bootloader-id=Debian --removable --no-nvram
# Generate GRUB configuration file
chroot "$ROOTFS_DIR" update-grub

#############################
# Finalization
#############################
# Remove the QEMU static binary from the target system (not needed on real x86_64 hardware)
rm -f "${ROOTFS_DIR}/usr/bin/qemu-${TARGET_ARCH}-static"

# Sync data to disk
sync

echo "&gt;&gt;&gt; Unmounting chroot filesystems..."
# These will be also handled by the trap on exit, but we unmount explicitly here for clarity:
umount "${ROOTFS_DIR}/proc" || true
umount "${ROOTFS_DIR}/sys" || true
umount "${ROOTFS_DIR}/dev/pts" || true
umount "${ROOTFS_DIR}/dev" || true
umount "${ROOTFS_DIR}/run" || true
umount "${ROOTFS_DIR}/boot/efi" || true
umount "${EFI_DIR}" || true
umount "${ROOTFS_DIR}" || true

# Write Syslinux MBR boot code to the image (for BIOS boot).
# Use dd to write the first 440 bytes from Syslinux's mbr.bin to the image's MBR.
echo "&gt;&gt;&gt; Writing Syslinux MBR boot code to image..."
dd if="${ROOTFS_DIR}/usr/lib/SYSLINUX/mbr.bin" of="$LOOP_DEV" bs=440 count=1 conv=notrunc

# Detach loop device
losetup -d "$LOOP_DEV"

echo "&gt;&gt;&gt; Debian USB image creation completed successfully!"
echo "Image file: $IMAGE_PATH"
# Offer to write image to a USB device
if confirm "Write the image to a USB drive now? (This will destroy contents on the target drive) [yes/NO]"; then
    read -rp "Enter the device path for the USB (e.g., /dev/sdX): " USBDEV
    if [[ -n "$USBDEV" ]]; then
        echo "WARNING: About to overwrite $USBDEV with the image. This will erase all data on $USBDEV."
        if confirm "Are you absolutely sure? Type 'yes' to continue: "; then
            echo "&gt;&gt;&gt; Writing image to $USBDEV ... (this may take a while)"
            dd if="$IMAGE_PATH" of="$USBDEV" bs=4M status=progress conv=fsync
            echo "&gt;&gt;&gt; Syncing data to $USBDEV..."
            sync
            echo "Image written to $USBDEV successfully. You can now boot the USB drive on an x86_64 machine."
        else
            echo "Skipped writing image to USB."
        fi
    fi
else
    echo "Image creation complete. You can write $IMAGE_PATH to a USB device later using 'dd' or a similar tool."
fi
</code></pre>]]></content><author><name></name></author><category term="scratchpad" /></entry><entry><title type="html">GitHub Actions to Download, Unzip, and Create a New Repository</title><link href="https://ib.bsb.br/github-actions-unzip-tutorial/" rel="alternate" type="text/html" title="GitHub Actions to Download, Unzip, and Create a New Repository" /><published>2025-11-09T00:00:00+00:00</published><updated>2025-12-22T19:08:44+00:00</updated><id>https://ib.bsb.br/github-actions-unzip-tutorial</id><content type="html" xml:base="https://ib.bsb.br/github-actions-unzip-tutorial/"><![CDATA[<h1 id="tutorial-using-github-actions-to-download-unzip-and-create-a-new-repository">Tutorial: Using GitHub Actions to Download, Unzip, and Create a New Repository</h1>

<h2 id="executive-summary">Executive Summary</h2>
<p>This tutorial demonstrates how to create a GitHub Actions workflow that:</p>
<ol>
  <li>Downloads a ZIP file from https://x0.at/XS2C.zip (or any specified URL)</li>
  <li>Extracts the contents</li>
  <li>Creates a new GitHub repository</li>
  <li>Uploads all extracted files to the new repository</li>
</ol>

<p><strong>Prerequisites:</strong>
• A GitHub account (user: ib-bsb-br in this example)
• A repository where you can create workflows
• A Personal Access Token (PAT) with repo scope
• Basic understanding of GitHub Actions</p>

<p><strong>Estimated Time:</strong> 15-20 minutes</p>

<h2 id="️-security-considerations">⚠️ Security Considerations</h2>
<h3 id="critical-read-before-proceeding">CRITICAL: Read Before Proceeding</h3>
<ol>
  <li>
    <p><strong>ZIP File Source Validation:</strong>
• The URL https://x0.at/XS2C.zip is a third-party file hosting service
• Never download and execute content from untrusted sources
• Verify the ZIP file contents manually before automating this process
• Consider implementing content validation/scanning in production workflows</p>
  </li>
  <li>
    <p><strong>Token Security:</strong>
• Never hardcode tokens in workflow files
• Always use GitHub Secrets for PATs
• Limit token scope to only required permissions (repo minimum)
• Rotate tokens regularly</p>
  </li>
  <li>
    <p><strong>Repository Creation:</strong>
• This workflow creates public repositories by default
• Be cautious about what content you’re making public
• Review extracted contents before pushing</p>
  </li>
</ol>

<h2 id="part-1-prerequisites-setup">Part 1: Prerequisites Setup</h2>

<h3 id="step-1-create-a-personal-access-token-pat">Step 1: Create a Personal Access Token (PAT)</h3>
<ol>
  <li>Navigate to: https://github.com/settings/tokens/new</li>
  <li>Configure the token:
• <strong>Note:</strong> “Repository Creation Token for Workflows”
• <strong>Expiration:</strong> Choose appropriate duration (recommend 90 days max)
• <strong>Scopes:</strong> Select <code class="language-plaintext highlighter-rouge">repo</code> (Full control of private repositories)
• This includes: repo:status, repo_deployment, public_repo, repo:invite, security_events</li>
  <li>Click <strong>Generate token</strong></li>
  <li>Copy the token immediately (you won’t see it again)</li>
</ol>

<h3 id="step-2-add-token-as-repository-secret">Step 2: Add Token as Repository Secret</h3>
<ol>
  <li>Go to your repository: https://github.com/ib-bsb-br/YOUR_REPO_NAME</li>
  <li>Navigate to: <strong>Settings → Secrets and variables → Actions</strong></li>
  <li>Click <strong>New repository secret</strong></li>
  <li>Configure:
• <strong>Name:</strong> <code class="language-plaintext highlighter-rouge">REPO_CREATE_TOKEN</code>
• <strong>Secret:</strong> Paste your PAT</li>
  <li>Click <strong>Add secret</strong></li>
</ol>

<h3 id="step-3-understand-repository-ownership-context">Step 3: Understand Repository Ownership Context</h3>
<p><strong>Important:</strong> When using <code class="language-plaintext highlighter-rouge">context.repo.owner</code> in the workflow:
• It references the owner of the repository where the workflow runs
• For user <code class="language-plaintext highlighter-rouge">ib-bsb-br</code>, if the workflow runs in <code class="language-plaintext highlighter-rouge">ib-bsb-br/workflow-repo</code>, the new repository will be created under <code class="language-plaintext highlighter-rouge">ib-bsb-br</code>
• To create repositories in an organization, you must modify the owner variable explicitly</p>

<h2 id="part-2-implementation---choose-your-approach">Part 2: Implementation - Choose Your Approach</h2>

<h3 id="decision-matrix-which-approach-to-use">Decision Matrix: Which Approach to Use?</h3>

<table>
  <thead>
    <tr>
      <th>Factor</th>
      <th>API Approach</th>
      <th>Git Command Approach</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Best for</strong></td>
      <td>Small to medium files (&lt;100MB per file)</td>
      <td>Any file size, including large files</td>
    </tr>
    <tr>
      <td><strong>Complexity</strong></td>
      <td>More complex, API-based</td>
      <td>Simpler, uses standard git</td>
    </tr>
    <tr>
      <td><strong>File size limits</strong></td>
      <td>100MB per blob</td>
      <td>No API limits, only git limits</td>
    </tr>
    <tr>
      <td><strong>Speed</strong></td>
      <td>Can be slower for many files</td>
      <td>Faster for many files</td>
    </tr>
    <tr>
      <td><strong>Error handling</strong></td>
      <td>More granular control</td>
      <td>Less granular</td>
    </tr>
    <tr>
      <td><strong>Dependencies</strong></td>
      <td>GitHub API only</td>
      <td>Requires git, curl, unzip</td>
    </tr>
  </tbody>
</table>

<p><strong>Recommendation:</strong> Use the Git Command Approach for simplicity unless you need specific API features.</p>

<h3 id="create-workflow-file">Create Workflow File</h3>
<p>Create <code class="language-plaintext highlighter-rouge">.github/workflows/unzip-to-repo.yml</code> in your repository:</p>

<p>{% codeblock yaml %}
name: Unzip and Create Repository (Git Method)</p>

<p>on:
  workflow_dispatch:
    inputs:
      repo_name:
        description: ‘Name for the new repository (must be unique)’
        required: true
        default: ‘unzipped-content’
      zip_url:
        description: ‘URL of the ZIP file to download’
        required: true
        default: ‘https://x0.at/XS2C.zip’
      repo_description:
        description: ‘Description for the new repository’
        required: false
        default: ‘Repository created from ZIP file extraction’
      private_repo:
        description: ‘Make repository private?’
        required: true
        type: boolean
        default: false</p>

<p>jobs:
  create-repo-from-zip:
    runs-on: ubuntu-latest
    env:
      # Prevent git from prompting for credentials
      GIT_TERMINAL_PROMPT: 0</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>steps:
  - name: Validate inputs
    env:
      REPO_CREATE_TOKEN: ${{ secrets.REPO_CREATE_TOKEN }}
    run: |
      set -euo pipefail
      echo "🔍 Validating inputs..."
      echo "Repository name: ${{ inputs.repo_name }}"
      echo "ZIP URL: ${{ inputs.zip_url }}"
      echo "Private: ${{ inputs.private_repo }}"

      if [[ -z "${REPO_CREATE_TOKEN:-}" ]]; then
        echo "❌ Error: Secret REPO_CREATE_TOKEN is not set. Please add a Personal Access Token with repo scope."
        exit 1
      fi

      if [[ ! "${{ inputs.repo_name }}" =~ ^[a-zA-Z0-9_-]+$ ]]; then
        echo "❌ Error: Repository name can only contain alphanumeric characters, hyphens, and underscores"
        exit 1
      fi

  - name: Download ZIP file
    run: |
      set -euo pipefail
      echo "📥 Downloading ZIP file from ${{ inputs.zip_url }}"

      if ! curl -L -f -o archive.zip --max-time 300 "${{ inputs.zip_url }}"; then
        echo "❌ Failed to download ZIP file"
        exit 1
      fi

      if [ ! -s archive.zip ]; then
        echo "❌ Downloaded file is empty"
        exit 1
      fi

      echo "✅ Downloaded $(du -h archive.zip | cut -f1) file"

  - name: Extract ZIP contents
    run: |
      set -euo pipefail
      echo "📦 Extracting ZIP file..."
      mkdir -p extracted_content

      if ! unzip -q archive.zip -d extracted_content; then
        echo "❌ Failed to extract ZIP file"
        exit 1
      fi

      file_count=$(find extracted_content -type f | wc -l)
      if [ "$file_count" -eq 0 ]; then
        echo "❌ No files found in ZIP archive"
        exit 1
      fi

      echo "🔎 Checking for oversized files (&gt;99MB)..."
      if find extracted_content -type f -size +99M -print -quit | grep -q .; then
        echo "❌ Found files larger than 99MB. GitHub blocks pushing files over 100MB."
        echo "Offending files:"
        find extracted_content -type f -size +99M -printf '%p (%s bytes)\n'
        exit 1
      fi

      echo "✅ Extracted $file_count files"
      echo "📂 Directory structure:"
      tree -L 3 extracted_content/ || ls -R extracted_content/

  - name: Create repository via API
    id: create-repo
    uses: actions/github-script@v8
    env:
      REPO_NAME: ${{ inputs.repo_name }}
      REPO_DESCRIPTION: ${{ inputs.repo_description }}
      PRIVATE_REPO: ${{ inputs.private_repo }}
    with:
      github-token: ${{ secrets.REPO_CREATE_TOKEN }}
      retries: 3
      result-encoding: string
      script: |
        const repoName = process.env.REPO_NAME;
        const repoDescription = process.env.REPO_DESCRIPTION;
        const isPrivate = process.env.PRIVATE_REPO === 'true';

        const { data: user } = await github.rest.users.getAuthenticated();
        console.log(`🔐 Authenticated as: ${user.login}`);

        try {
          console.log(`📝 Creating repository: ${user.login}/${repoName}`);

          const { data: repo } = await github.rest.repos.createForAuthenticatedUser({
            name: repoName,
            description: repoDescription,
            private: isPrivate,
            auto_init: false,
            has_issues: true,
            has_projects: true,
            has_wiki: true
          });

          console.log(`✅ Repository created: ${repo.html_url}`);
          console.log(`📋 Clone URL: ${repo.clone_url}`);
          core.setOutput('clone_url', repo.clone_url);
          core.setOutput('html_url', repo.html_url);
          return repo.clone_url;
        } catch (error) {
          if (error.status === 422) {
            core.setFailed(`Repository '${repoName}' already exists in your account. Please choose a different name or delete the existing repository.`);
          } else if (error.status === 401) {
            core.setFailed('Authentication failed. Please verify your REPO_CREATE_TOKEN secret has the correct permissions.');
          } else {
            core.setFailed(`Failed to create repository: ${error.message}`);
          }
          throw error;
        }

  - name: Initialize git and push content
    env:
      REPO_URL: ${{ steps.create-repo.outputs.clone_url }}
      GITHUB_TOKEN: ${{ secrets.REPO_CREATE_TOKEN }}
    run: |
      set -euo pipefail
      cd extracted_content

      echo "🔧 Configuring git..."
      git config user.name "github-actions[bot]"
      git config user.email "github-actions[bot]@users.noreply.github.com"

      if [ -d .git ]; then
        echo "🧹 Removing existing git metadata from extracted content..."
        rm -rf .git
      fi

      echo "📋 Initializing repository..."
      git init -b main

      echo "* text=auto" &gt; .gitattributes

      echo "➕ Adding all files..."
      git add .

      echo "💾 Creating initial commit..."
      COMMIT_TS="$(date -u +"%Y-%m-%d %H:%M:%S UTC")"
      git commit \
        -m "Initial commit: Add files from ZIP archive" \
        -m "Source: ${{ inputs.zip_url }}" \
        -m "Extracted: ${COMMIT_TS}" \
        -m "Workflow: ${{ github.repository }}@${{ github.sha }}"

      echo "🔗 Adding remote..."
      REPO_URL_SANITIZED=$(echo "$REPO_URL" | sed 's/^"\(.*\)"$/\1/')
      REPO_URL_WITH_TOKEN=$(echo "$REPO_URL_SANITIZED" | sed "s|https://|https://x-access-token:${GITHUB_TOKEN}@|")
      git remote add origin "$REPO_URL_WITH_TOKEN"

      echo "⬆️ Pushing to remote..."
      git push --verbose -u origin main

  - name: Generate summary
    if: success()
    env:
      REPO_URL: ${{ steps.create-repo.outputs.html_url }}
    run: |
      echo "## ✅ Workflow Completed Successfully!" &gt;&gt; $GITHUB_STEP_SUMMARY
      echo "" &gt;&gt; $GITHUB_STEP_SUMMARY
      echo "### Repository Details" &gt;&gt; $GITHUB_STEP_SUMMARY
      echo "- **Name:** ${{ inputs.repo_name }}" &gt;&gt; $GITHUB_STEP_SUMMARY
      REPO_URL_SANITIZED=$(echo "$REPO_URL" | sed 's/^"\(.*\)"$/\1/')
      echo "- **URL:** [View Repository](${REPO_URL_SANITIZED%.git})" &gt;&gt; $GITHUB_STEP_SUMMARY
      echo "- **Visibility:** ${{ inputs.private_repo == 'true' &amp;&amp; 'Private' || 'Public' }}" &gt;&gt; $GITHUB_STEP_SUMMARY
      echo "" &gt;&gt; $GITHUB_STEP_SUMMARY
      echo "### Source" &gt;&gt; $GITHUB_STEP_SUMMARY
      echo "- **ZIP URL:** ${{ inputs.zip_url }}" &gt;&gt; $GITHUB_STEP_SUMMARY
      echo "" &gt;&gt; $GITHUB_STEP_SUMMARY
      echo "🎉 All files from the ZIP archive have been extracted and pushed to the new repository!" &gt;&gt; $GITHUB_STEP_SUMMARY

  - name: Cleanup failure
    if: failure()
    uses: actions/github-script@v8
    env:
      REPO_NAME: ${{ inputs.repo_name }}
    with:
      github-token: ${{ secrets.REPO_CREATE_TOKEN }}
      script: |
        const repoName = process.env.REPO_NAME;
        const { data: user } = await github.rest.users.getAuthenticated();

        try {
          await github.rest.repos.get({
            owner: user.login,
            repo: repoName
          });

          console.log(`⚠️ Repository ${user.login}/${repoName} was created but workflow failed.`);
          console.log(`Consider deleting it manually if it's empty: https://github.com/${user.login}/${repoName}/settings`);
        } catch (error) {
          console.log('No repository cleanup needed.');
        } {% endcodeblock %}
</code></pre></div></div>]]></content><author><name></name></author><category term="scratchpad" /></entry><entry><title type="html">DirectAdmin terminal custom commands</title><link href="https://ib.bsb.br/da-term/" rel="alternate" type="text/html" title="DirectAdmin terminal custom commands" /><published>2025-10-25T00:00:00+00:00</published><updated>2025-11-13T21:49:36+00:00</updated><id>https://ib.bsb.br/da-term</id><content type="html" xml:base="https://ib.bsb.br/da-term/"><![CDATA[<h1 id="01-environment-modules-exploration-usrsharemodules">01) Environment Modules exploration (/usr/share/Modules)</h1>
<p>alias h01_modules_explore=’
  pushd /usr/share/Modules &gt;/dev/null; ls;
    pushd modulefiles &gt;/dev/null; ls;
      pushd use.own &gt;/dev/null; cat use.own || true; popd &gt;/dev/null;
      ls; pushd module &gt;/dev/null || true; popd &gt;/dev/null || true;
      pushd modules &gt;/dev/null || true; { cat dot || true; cat module-git || true; ls; cat module || true; cat modules || true; } ; popd &gt;/dev/null || true;
    popd &gt;/dev/null;
    pushd bin &gt;/dev/null || true; ls; { cat createmodule. || true; cat createmodule.sh || true; } ; popd &gt;/dev/null || true;
  popd &gt;/dev/null
‘</p>

<h1 id="02-directadmin-browse-user-datadomains-and-editremove-files">02) DirectAdmin: browse user data/domains and edit/remove files</h1>
<p>alias h02_da_user_domains=’
  pushd /usr/local/directadmin/data &gt;/dev/null; ls;
    pushd users &gt;/dev/null; ls;
      pushd ibbsbbry &gt;/dev/null; ls;
        pushd domains &gt;/dev/null; ls; pwd;
          true;  # placeholder for “which cut.ia.br.cust_nginx” (non-command in history)
          popd &gt;/dev/null;
        ls; pwd;
        pushd php &gt;/dev/null || true; ls; { cat php.ini || true; } ; popd &gt;/dev/null || true;
        pushd domains &gt;/dev/null; ls; pwd;
          rm -f cut.ia.br.cust_httpd || true;
        popd &gt;/dev/null;
      popd &gt;/dev/null;
    popd &gt;/dev/null;
  popd &gt;/dev/null
‘</p>

<h1 id="03-directadmin-pluginsshared-sockets-and-directadmin-binary-ops">03) DirectAdmin: plugins/shared, sockets, and directadmin binary ops</h1>
<p>alias h03_da_admin_ops=’
  pushd /usr/local/directadmin &gt;/dev/null; ls;
    pushd plugins &gt;/dev/null || true; ls; popd &gt;/dev/null || true;
    pushd data &gt;/dev/null; ls; popd &gt;/dev/null;
    pushd shared &gt;/dev/null; ls;
      { cat internal.sock || true; cat startips-network || true; }
    popd &gt;/dev/null;
    ./directadmin || true;
    ./directadmin permissions || true;
    sudo ./directadmin permissions || true;
    ./directadmin version || true;
    ./directadmin update || true;
    ./directadmin my-cnf || true;
    ./directadmin create-login-url || true;
    ./directadmin license || true;
    ./directadmin login-url || true;
    ./directadmin info || true;
    ./directadmin config-get || true;
    ./directadmin config-get -h || true;
    ./directadmin admin || true;
    ./directadmin build || true;
    pwd; ls
  popd &gt;/dev/null
‘</p>

<h1 id="04-directadmin-createedit-domain-conf-sample">04) DirectAdmin: create/edit domain conf sample</h1>
<p>alias h04_da_edit_domain_conf=’
  pushd /usr/local/directadmin/data/users/ibbsbbry/domains &gt;/dev/null;
    ls; touch cut.ia.br.conf; ${EDITOR:-nano} cut.ia.br.conf || true; cat cut.ia.br.conf || true;
  popd &gt;/dev/null
‘</p>

<h1 id="05-directadmin-cpanel-migration-scripts-and-internals">05) DirectAdmin: cPanel migration scripts and internals</h1>
<p>alias h05_da_migration_scripts=’
  pushd /usr/local/directadmin &gt;/dev/null; ls;
    pushd shared &gt;/dev/null; ls; pushd cpanel_to_da &gt;/dev/null; ls; cat cpanel_to_da.sh || true; popd &gt;/dev/null;
    ls; pushd internal.sock &gt;/dev/null || true; cat internal.sock || true; popd &gt;/dev/null || true;
    { cat startips-networkd || true; }
    pushd scripts &gt;/dev/null; ls; pushd cpanel_to_da &gt;/dev/null || true; ls; popd &gt;/dev/null || true;
  popd &gt;/dev/null
‘</p>

<h1 id="06-transfer-helpers-curl-uploads-and-quick-sysinfo">06) Transfer helpers: curl uploads and quick sysinfo</h1>
<p>alias h06_transfers_sysinfo=’
  pushd /usr/local/directadmin/scripts/cpanel_to_da &gt;/dev/null || true; ls || true; touch text.md || true; popd &gt;/dev/null || true;
  curl –help || true;
  curl -fsS -F “file=@-;filename=cpanel_to_da.sh” https://x0.at/ «&lt;”placeholder” || true;
  curl -F “file=@cpanel_to_da.sh” https://0x0.st || true;
  getconf –help || true;
  uptime || true;
  ip a || true;
  which npx || true; npx –help || true;
  npm –help || true; npm –version || true; which npm || true
‘</p>

<h1 id="07-directadmin-grep-web-stack-and-mail-domain-owners">07) DirectAdmin: grep web stack and mail domain owners</h1>
<p>alias h07_da_webstack_mail=’
  grep -E ‘”’”’^(nginx|nginx_proxy|openlitespeed)=’”’”’ /usr/local/directadmin/conf/directadmin.conf || true;
  head /etc/virtual/domainowners || true
‘</p>

<h1 id="08-etc-basics-hosts-resolv-mysql-npmrc-sysconfig">08) /etc basics: hosts, resolv, mysql, npmrc, sysconfig</h1>
<p>alias h08_etc_core=’
  pushd /etc &gt;/dev/null; ls;
    { cat host.conf || true; cat hosts || true; cat my.cnf || true; cat npmrc || true; cat resolv.conf || true; } ;
    ls; { cat trusted-key.key || true; cat virc || true; } ;
    ls; pushd sysconfig &gt;/dev/null || true; ls; { cat saslauthd || true; cat snmp || true; } ; popd &gt;/dev/null || true;
  popd &gt;/dev/null
‘</p>

<h1 id="09-ssl-and-ssh-inspection">09) SSL and SSH inspection</h1>
<p>alias h09_ssl_ssh=’
  pushd /etc/ssl/certs &gt;/dev/null || true; ls; { cat ca-bundle. || true; cat ca-bundle.crt || true; } ; popd &gt;/dev/null || true;
  pushd /etc &gt;/dev/null; ls; popd &gt;/dev/null;
  pushd /etc/ssh &gt;/dev/null || true; ls; cat ssh_config || true; ls; pushd ssh_config.d &gt;/dev/null || true; ls; popd &gt;/dev/null || true;
  pushd /etc/ssh/moduli &gt;/dev/null || true; ls; cat moduli || true; popd &gt;/dev/null || true;
  pushd /etc/skel &gt;/dev/null || true; ls; popd &gt;/dev/null || true
‘</p>

<h1 id="10-etcprofiled-helpers">10) /etc/profile.d helpers</h1>
<p>alias h10_profiled_helpers=’
  pushd /etc/profile.d &gt;/dev/null || true; ls; bash which2.sh –help || true; cat alt_mod_passenger.sh || true; popd &gt;/dev/null || true
‘</p>

<h1 id="11-logs-cagefs-proxyexec">11) Logs, CageFS, proxyexec</h1>
<p>alias h11_logs_cagefs=’
  pushd /var/log/user_logs &gt;/dev/null || true; ls; pushd ibbsbbry &gt;/dev/null || true; ls -a || true; popd &gt;/dev/null || true; popd &gt;/dev/null || true;
  pushd /var &gt;/dev/null; ls -a; { cat .cagefs/ 2&gt;/dev/null || true; } ; pushd .cagefs &gt;/dev/null || true; ls -a; cat .cagefs.token || true; popd &gt;/dev/null || true; popd &gt;/dev/null;
  id || true; ps aux | grep proxyexec || true; ps aux || true;
  proxyexec -h || true; /usr/sbin/proxyexec -c cagefs.sock ibbsbbry CzlNuXVAWS7rH7Cc / CRONTAB_LIST 0 || true
‘</p>

<h1 id="12-vartmp--varwww-basics-and-cgi">12) /var/tmp + /var/www basics and CGI</h1>
<p>alias h12_var_www=’
  pushd /var/tmp &gt;/dev/null || true; ls -a; cat mysql.sock || true; popd &gt;/dev/null || true;
  pushd /var/www &gt;/dev/null || true; ls; pushd html &gt;/dev/null || true; ls; { cat p.php || true; cat index.html || true; cat redirect.php || true; } ; popd &gt;/dev/null || true;
  pushd cgi-bin &gt;/dev/null || true; ls; { cat test-cgi || true; cat printenv || true; } ; popd &gt;/dev/null || true; popd &gt;/dev/null || true
‘</p>

<h1 id="13-passenger-runtime-home--inspect-instance-dirs-and-secrets">13) Passenger runtime (home) — inspect instance dirs and secrets</h1>
<p>alias h13_passenger_runtime=’
  pushd ~/passenger &gt;/dev/null || true; ls -a || true; popd &gt;/dev/null || true;
  for d in ~/passenger.z* ~/passenger.R*; do
    [ -d “$d” ] || continue;
    pushd “$d” &gt;/dev/null; ls; { cat read_only_admin_password.txt 2&gt;/dev/null || true; cat properties.json 2&gt;/dev/null || true; } ;
      pushd web_server_info &gt;/dev/null 2&gt;/dev/null || true; ls -a || true; popd &gt;/dev/null || true;
      { cat watchdog.pid 2&gt;/dev/null || true; cat full_admin_password.txt 2&gt;/dev/null || true; cat creation_finalized 2&gt;/dev/null || true; cat core.pid 2&gt;/dev/null || true; } ;
      pushd agents.s &gt;/dev/null 2&gt;/dev/null || true; ls -a || true; pushd core &gt;/dev/null 2&gt;/dev/null || true; ls -a || true; popd &gt;/dev/null || true; popd &gt;/dev/null || true;
      { cat core.pid 2&gt;/dev/null || true; cat creation_finalized 2&gt;/dev/null || true; cat lock 2&gt;/dev/null || true; cat properties.json 2&gt;/dev/null || true; } ;
    popd &gt;/dev/null;
  done
‘</p>

<h1 id="14-cloudlinux-selector-and-scl-tooling">14) CloudLinux selector and SCL tooling</h1>
<p>alias h14_cl_selector_scl=’
  cloudlinux-selector –help || true;
  cloudlinux-selector –app-mode || true;
  cloudlinux-selector –get-supported-versions || true;
  cloudlinux-selector –json –get-supported-versions || true;
  cloudlinux-selector –json –interpreter nodejs –extensions nodejs || true;
  cloudlinux-selector –json –extensions nodejs || true;
  cloudlinux-selector –json –env-vars || true;
  cloudlinux-selector –json –get-selector-status || true;
  cloudlinux-selector –json –interpreter nodejs –get-supported-versions || true;
  scl –help || true; scl list-collections || true; scl list-enabled || true; scl list-packages || true; scl list-packages alt-nodejs12 || true; scl list-packages alt-nodejs10 || true;
  scl enable alt-nodejs12 “bash -lc ‘”’“‘node -v; npm -v’”’”’” || true;
  scl run alt-nodejs12 node -v || true; scl run alt-nodejs12 npm -v || true
‘</p>

<h1 id="15-domain-content-well-known-acme-roundcube-awstats">15) Domain content: .well-known, acme, roundcube, awstats</h1>
<p>alias h15_domain_webbits=’
  pushd ~/public_html &gt;/dev/null || true; ls; pushd .well-known &gt;/dev/null 2&gt;/dev/null || true; ls -a || true; { cat .htaccess 2&gt;/dev/null || true; } ; pushd acme-challenge &gt;/dev/null 2&gt;/dev/null || true; ls || true; { cat letsencrypt_1596475466 2&gt;/dev/null || true; } ; popd &gt;/dev/null || true; popd &gt;/dev/null || true;
  for d in ~/roundcube/public_html ~/public_html/awstats; do pushd “$d” &gt;/dev/null 2&gt;/dev/null || true; ls; { cat index.php 2&gt;/dev/null || cat index.html 2&gt;/dev/null || true; } ; popd &gt;/dev/null || true; done
‘</p>

<h1 id="16-opt-tools-ai-bolit-app-version-detector-cloudlinux-flagshooks">16) /opt tools: ai-bolit, app-version-detector, cloudlinux flags/hooks</h1>
<p>alias h16_opt_tooling=’
  pushd /opt &gt;/dev/null; ls -a;
    pushd ai-bolit &gt;/dev/null 2&gt;/dev/null || true; ls; cat ai-bolit.php || true; popd &gt;/dev/null || true;
    pushd app-version-detector &gt;/dev/null 2&gt;/dev/null || true; ls; bash app-version-detector.sh || true; cat app-version-detector-wrapper.sh || true; popd &gt;/dev/null || true;
    pushd cloudlinux &gt;/dev/null 2&gt;/dev/null || true; ls -a; { cat nginx_status 2&gt;/dev/null || true; cat litespeed_status 2&gt;/dev/null || true; cat cl_edition 2&gt;/dev/null || true; } ;
      pushd flags &gt;/dev/null 2&gt;/dev/null || true; ls -a; pushd available-flags.d &gt;/dev/null 2&gt;/dev/null || true; ls -a || true; popd &gt;/dev/null || true; pushd enabled-flags.d &gt;/dev/null 2&gt;/dev/null || true; ls -a || true; popd &gt;/dev/null || true; popd &gt;/dev/null || true;
      pushd rhn_hooks/post.d &gt;/dev/null 2&gt;/dev/null || true; ls; cat rhn-update-hook.sh || true; popd &gt;/dev/null || true;
    popd &gt;/dev/null || true;
  popd &gt;/dev/null
‘</p>

<h1 id="17-cloudlinux-venv--pythonpip-tooling">17) CloudLinux venv + Python/pip tooling</h1>
<p>alias h17_opt_python_venv=’
  pushd /opt/cloudlinux/venv &gt;/dev/null 2&gt;/dev/null || true; ls; cat pyvenv.cfg 2&gt;/dev/null || true; /opt/alt/python311/bin/python3 -m venv –upgrade-deps /opt/cloudlinux/venv || true; ls; pushd bin &gt;/dev/null 2&gt;/dev/null || true; ls; cat Activate.ps1 2&gt;/dev/null || true; cat activate 2&gt;/dev/null || true; popd &gt;/dev/null || true;
  pushd /opt/cloudlinux/venv/bin &gt;/dev/null 2&gt;/dev/null || true; python3 –version || true; pip3 –version || true; pip –version || true; popd &gt;/dev/null || true;
  python3 –version || true
‘</p>

<h1 id="18-cloudlinux-helper-scripts--packages">18) CloudLinux helper scripts &amp; packages</h1>
<p>alias h18_cl_scripts_pkgs=’
  pushd /opt/cloudlinux/usr/bin &gt;/dev/null 2&gt;/dev/null || true; ls; ./cpapirebuildcache 2&gt;/dev/null || true; popd &gt;/dev/null || true;
  pushd /opt/cloudlinux/share/python-cllib/scripts &gt;/dev/null 2&gt;/dev/null || true; ls; { cat cl-common 2&gt;/dev/null || true; ./cl-common 2&gt;/dev/null || true; } ; { cat cl_sysctl 2&gt;/dev/null || true; } ; { cat getpaneluserscount 2&gt;/dev/null || true; python3.11 getpaneluserscount 2&gt;/dev/null || true; } ; popd &gt;/dev/null || true
‘</p>

<h1 id="19-alt-php-and-php-fpm-binariesconfigs">19) alt-php and php-fpm binaries/configs</h1>
<p>alias h19_alt_php=’
  pushd /opt/alt-php84/root/etc &gt;/dev/null 2&gt;/dev/null || true; ls; { cat pear 2&gt;/dev/null || true; cat pear.conf 2&gt;/dev/null || true; cat php-fpm.conf 2&gt;/dev/null || true; } ; popd &gt;/dev/null || true;
  pushd /opt/alt-php84/usr/sbin &gt;/dev/null 2&gt;/dev/null || true; ls; ./php-fpm -t 2&gt;/dev/null || true; popd &gt;/dev/null || true;
  pushd /opt/alt-php-internal &gt;/dev/null 2&gt;/dev/null || true; ./enable 2&gt;/dev/null || true; popd &gt;/dev/null || true
‘</p>

<h1 id="20-cloudlinux-site-optimization--wpos">20) CloudLinux site optimization &amp; WPOS</h1>
<p>alias h20_clsop_wpos=’
  pushd /opt/cloudlinux-linksafe &gt;/dev/null 2&gt;/dev/null || true; ls; cat lib.sh 2&gt;/dev/null || true; popd &gt;/dev/null || true;
  pushd /opt/cloudlinux-site-optimization-module &gt;/dev/null 2&gt;/dev/null || true; ls; { cat requirements.json 2&gt;/dev/null || true; cat clsop.zip 2&gt;/dev/null || true; } ; popd &gt;/dev/null || true;
  pushd /opt/clwpos &gt;/dev/null 2&gt;/dev/null || true; ls; cat public_options.json 2&gt;/dev/null || true; popd &gt;/dev/null || true
‘</p>

<h1 id="21-cpaneleasyapache-libs--diagnostics">21) cPanel/EasyApache libs &amp; diagnostics</h1>
<p>alias h21_cpanel_ea_libs=’
  pushd /opt/cp/cpanel/ea-php84/usr/lib64/php/modules &gt;/dev/null 2&gt;/dev/null || true; ls; { cat clos_ssa.so 2&gt;/dev/null || true; cat xray.so 2&gt;/dev/null || true; } ; popd &gt;/dev/null || true;
  pushd /opt/netdata/var/cache/netdata &gt;/dev/null 2&gt;/dev/null || true; ls -a || true; popd &gt;/dev/null || true
‘</p>

<h1 id="22-passenger-bins-and-helper-scripts">22) Passenger bins and helper scripts</h1>
<p>alias h22_passenger_bins=’
  pushd /opt/passenger/bin &gt;/dev/null 2&gt;/dev/null || true; ls; ./passenger-status 2&gt;/dev/null || true; ./passenger 2&gt;/dev/null || true; popd &gt;/dev/null || true;
  pushd /opt/passenger/src/ruby_native_extension &gt;/dev/null 2&gt;/dev/null || true; ls -a || true; cat extconf.rb 2&gt;/dev/null || true; popd &gt;/dev/null || true;
  pushd /opt/passenger/helper-scripts &gt;/dev/null 2&gt;/dev/null || true; ls; cat README.md 2&gt;/dev/null || true; popd &gt;/dev/null || true;
  pushd /opt/passenger/download_binaries &gt;/dev/null 2&gt;/dev/null || true; ls; cat extconf.rb 2&gt;/dev/null || true; ruby *.rb 2&gt;/dev/null || true; popd &gt;/dev/null || true
‘</p>

<h1 id="23-system-package-managers--general-admin">23) System package managers &amp; general admin</h1>
<p>alias h23_pkgs_admin=’
  yum –help 2&gt;/dev/null || true;
  apk add ugrep ugrep-doc 2&gt;/dev/null || true;
  pkg install -y ugrep 2&gt;/dev/null || true
‘</p>

<h1 id="24-user-home-public_html-domains-passenger-demo--scl-npm">24) User home: public_html, domains, passenger demo &amp; SCL npm</h1>
<p>alias h24_user_web_node=’
  pushd ~ &gt;/dev/null; ls; pwd;
    pushd public_html &gt;/dev/null 2&gt;/dev/null || true; ls; popd &gt;/dev/null || true;
    pushd domains/cut.ia.br &gt;/dev/null 2&gt;/dev/null || true; ls -a; popd &gt;/dev/null || true;
    pushd domains/cut.ia.br &gt;/dev/null 2&gt;/dev/null || true;
      git clone https://github.com/phusion/passenger-nodejs-connect-demo.git 2&gt;/dev/null || true;
      pushd passenger-nodejs-connect-demo &gt;/dev/null 2&gt;/dev/null || true; npm install 2&gt;/dev/null || true; popd &gt;/dev/null || true;
      scl run alt-nodejs12 npm install 2&gt;/dev/null || true;
      scl enable alt-nodejs12 “npm -l” 2&gt;/dev/null || true;
      source /home/ibbsbbry/nodevenv/domains/cut.ia.br/passenger-nodejs-connect-demo/12/bin/activate 2&gt;/dev/null || true;
    popd &gt;/dev/null || true;
  popd &gt;/dev/null
‘</p>

<h1 id="25-optaltpostgresql11-exploration">25) /opt/alt/postgresql11 exploration</h1>
<p>alias h25_alt_postgresql=’
  pushd /opt/alt/postgresql11 &gt;/dev/null 2&gt;/dev/null || true; ls;
    pushd usr/bin &gt;/dev/null 2&gt;/dev/null || true; ls; popd &gt;/dev/null || true;
    pushd include/pgsql/internal/libpq &gt;/dev/null 2&gt;/dev/null || true; ls; popd &gt;/dev/null || true;
    pushd share/pgsql &gt;/dev/null 2&gt;/dev/null || true; ls; cat pg_service.conf.sample 2&gt;/dev/null || true; popd &gt;/dev/null || true;
    pushd doc/alt-postgresql11 &gt;/dev/null 2&gt;/dev/null || true; ls; cat README 2&gt;/dev/null || true; popd &gt;/dev/null || true;
    pushd lib64/pkgconfig &gt;/dev/null 2&gt;/dev/null || true; ls; popd &gt;/dev/null || true;
    pushd bin &gt;/dev/null 2&gt;/dev/null || true; ls; popd &gt;/dev/null || true;
  popd &gt;/dev/null || true
‘</p>

<h1 id="26-alt-nodejs12-internals-and-tools">26) alt-nodejs12 internals and tools</h1>
<p>alias h26_alt_nodejs_internals=’
  pushd /opt/alt/alt-nodejs12 &gt;/dev/null 2&gt;/dev/null || true; ls;
    pushd root/home &gt;/dev/null 2&gt;/dev/null || true; ls -a || true; popd &gt;/dev/null || true;
    pushd root/bin &gt;/dev/null 2&gt;/dev/null || true; ls; npx –help || true; npx –version || true; popd &gt;/dev/null || true;
  popd &gt;/dev/null || true;
  pushd /opt/sqlite/usr/bin &gt;/dev/null 2&gt;/dev/null || true; ls; popd &gt;/dev/null || true;
  pushd /opt/clos_ssa/run &gt;/dev/null 2&gt;/dev/null || true; ls; cat ssa.sock 2&gt;/dev/null || true; popd &gt;/dev/null || true;
  pushd /opt/alt-mod-passenger/etc &gt;/dev/null 2&gt;/dev/null || true; ls; cat mod_passenger.conf 2&gt;/dev/null || true; popd &gt;/dev/null || true
‘</p>

<h1 id="27-modulefiles-alternatives-and-ghostscript">27) Modulefiles, alternatives, and ghostscript</h1>
<p>alias h27_modules_misc=’
  pushd /etc/alternatives &gt;/dev/null 2&gt;/dev/null || true; ls; cat modules.sh 2&gt;/dev/null || true; popd &gt;/dev/null || true;
  pushd /usr/share/modulefiles &gt;/dev/null 2&gt;/dev/null || true; ls -a || true; popd &gt;/dev/null || true;
  pushd /usr/share/ghostscript &gt;/dev/null 2&gt;/dev/null || true; ls; popd &gt;/dev/null || true
‘</p>

<h1 id="28-node-virtualenvs-for-domains">28) Node virtualenvs for domains</h1>
<p>alias h28_nodevenv_bins=’
  pushd ~/nodevenv/domains/cut.ia.br/passenger-nodejs-connect-demo/12/bin &gt;/dev/null 2&gt;/dev/null || true; ls; popd &gt;/dev/null || true
‘</p>

<h1 id="29-ugrep-build-from-source-and-verification">29) Ugrep build from source (and verification)</h1>
<p>alias h29_ugrep_build=’
  pushd ~ &gt;/dev/null;
    git clone https://github.com/Genivia/ugrep 2&gt;/dev/null || true;
    pushd ugrep &gt;/dev/null; ls;
      ./build.sh || true; sudo make install || true; make install || true;
      pushd bin &gt;/dev/null 2&gt;/dev/null || true; ls; ./ugrep –version || true; popd &gt;/dev/null || true;
    popd &gt;/dev/null;
  popd &gt;/dev/null;
  ugrep –version || true
‘</p>

<h1 id="30-quick-misc-one-offs-captured">30) Quick misc one-offs captured</h1>
<p>alias h30_misc=’
  history | tail -n 50 || true;
  which npm || true; which npx || true;
  node -v 2&gt;/dev/null || true; install node 2&gt;/dev/null || true; script -V 2&gt;/dev/null || true;
  reset –help 2&gt;/dev/null || true; clear || true; printenv || true; whoami || true; pwdx 2&gt;/dev/null || true
‘</p>

<h1 id="31-domain-owners-quick-check">31) Domain owners quick check</h1>
<p>alias h31_mail_domainowners=’head /etc/virtual/domainowners || true’</p>

<h1 id="32-grep-directadmin-webserver-mode">32) Grep DirectAdmin webserver mode</h1>
<p>alias h32_da_web_mode=’grep -E “^(nginx|nginx_proxy|openlitespeed)=” /usr/local/directadmin/conf/directadmin.conf || true’</p>

<h1 id="33-passenger-status-shortcut">33) Passenger status shortcut</h1>
<p>alias h33_passenger_status=’/opt/passenger/bin/passenger-status 2&gt;/dev/null || passenger-status 2&gt;/dev/null || true’</p>

<h1 id="34-show-ssh-moduli-and-config-quickly">34) Show SSH moduli and config quickly</h1>
<p>alias h34_ssh_quick=’cat /etc/ssh/ssh_config 2&gt;/dev/null || true; cat /etc/ssh/moduli 2&gt;/dev/null || true’</p>

<h1 id="35-dns-resolvers-quick">35) DNS resolvers quick</h1>
<p>alias h35_resolvers_quick=’cat /etc/resolv.conf || true’</p>

<h1 id="36-hosts-quick">36) Hosts quick</h1>
<p>alias h36_hosts_quick=’cat /etc/hosts || true’</p>]]></content><author><name></name></author><category term="scratchpad" /></entry></feed>